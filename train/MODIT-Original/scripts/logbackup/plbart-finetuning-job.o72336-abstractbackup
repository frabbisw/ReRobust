######## start ##############
#############################################################################################
Experiment for PLBART
=============================================================================================
Small Dataset:
---------------------------------------------------------------------------------------------
Source: source Target: target
2022-10-30 23:27:58 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.1, batch_size=4, batch_size_valid=4, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, extra_lang_symbol='', fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/home/y_shi202/related-project/MODIT/models/pretrained/checkpoints/checkpoint_11_100000.pt', save_dir='/home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1234, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_in_same_language', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[4], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='/home/y_shi202/related-project/MODIT/src', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=500, weight_decay=0.0, zero_sharding='none')
2022-10-30 23:27:58 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2022-10-30 23:27:58 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2022-10-30 23:27:58 | INFO | fairseq.data.data_utils | loaded 5835 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/valid.source-target.source
2022-10-30 23:27:58 | INFO | fairseq.data.data_utils | loaded 5835 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/valid.source-target.target
2022-10-30 23:27:58 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin valid source-target 5835 examples
2022-10-30 23:28:02 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2022-10-30 23:28:02 | INFO | fairseq_cli.train | task: translation_in_same_language (TranslationCodeBARTTask)
2022-10-30 23:28:02 | INFO | fairseq_cli.train | model: mbart_base (BARTModel)
2022-10-30 23:28:02 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2022-10-30 23:28:02 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2022-10-30 23:28:06 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-30 23:28:06 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-30 23:28:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-10-30 23:28:06 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-PCIE-32GB                    
2022-10-30 23:28:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-10-30 23:28:06 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-10-30 23:28:06 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 4
2022-10-30 23:28:08 | INFO | fairseq.trainer | loaded checkpoint /home/y_shi202/related-project/MODIT/models/pretrained/checkpoints/checkpoint_11_100000.pt (epoch 11 @ 0 updates)
2022-10-30 23:28:08 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2022-10-30 23:28:08 | INFO | fairseq.trainer | loading train data for epoch 1
2022-10-30 23:28:08 | INFO | fairseq.data.data_utils | loaded 46680 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/train.source-target.source
2022-10-30 23:28:08 | INFO | fairseq.data.data_utils | loaded 46680 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/train.source-target.target
2022-10-30 23:28:08 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin train source-target 46680 examples
2022-10-30 23:28:08 | INFO | fairseq.trainer | begin training epoch 1
2022-10-30 23:28:51 | INFO | train_inner | {"epoch": 1, "update": 0.034, "loss": "4.654", "nll_loss": "2.217", "ppl": "4.65", "wps": "1444.9", "ups": "2.35", "wpb": "615.6", "bsz": "16", "num_updates": "100", "lr": "1e-05", "gnorm": "27.575", "train_wall": "42", "wall": "45"}
2022-10-30 23:29:36 | INFO | train_inner | {"epoch": 1, "update": 0.069, "loss": "2.644", "nll_loss": "0.641", "ppl": "1.56", "wps": "1401.5", "ups": "2.21", "wpb": "633.9", "bsz": "16", "num_updates": "200", "lr": "2e-05", "gnorm": "2.704", "train_wall": "45", "wall": "90"}
2022-10-30 23:30:19 | INFO | train_inner | {"epoch": 1, "update": 0.103, "loss": "2.455", "nll_loss": "0.517", "ppl": "1.43", "wps": "1485.6", "ups": "2.33", "wpb": "638.4", "bsz": "16", "num_updates": "300", "lr": "3e-05", "gnorm": "1.725", "train_wall": "42", "wall": "133"}
2022-10-30 23:30:58 | INFO | train_inner | {"epoch": 1, "update": 0.137, "loss": "2.391", "nll_loss": "0.478", "ppl": "1.39", "wps": "1621.3", "ups": "2.53", "wpb": "641.8", "bsz": "16", "num_updates": "400", "lr": "4e-05", "gnorm": "1.479", "train_wall": "39", "wall": "173"}
2022-10-30 23:31:24 | INFO | train_inner | {"epoch": 1, "update": 0.171, "loss": "2.365", "nll_loss": "0.464", "ppl": "1.38", "wps": "2514.4", "ups": "3.96", "wpb": "635.3", "bsz": "16", "num_updates": "500", "lr": "5e-05", "gnorm": "1.428", "train_wall": "25", "wall": "198"}
2022-10-30 23:32:07 | INFO | train_inner | {"epoch": 1, "update": 0.206, "loss": "2.366", "nll_loss": "0.474", "ppl": "1.39", "wps": "1431.1", "ups": "2.29", "wpb": "624.2", "bsz": "16", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "1.301", "train_wall": "43", "wall": "241"}
2022-10-30 23:32:52 | INFO | train_inner | {"epoch": 1, "update": 0.24, "loss": "2.335", "nll_loss": "0.444", "ppl": "1.36", "wps": "1399.2", "ups": "2.22", "wpb": "630.2", "bsz": "16", "num_updates": "700", "lr": "4.999e-05", "gnorm": "1.235", "train_wall": "44", "wall": "286"}
2022-10-30 23:33:36 | INFO | train_inner | {"epoch": 1, "update": 0.274, "loss": "2.328", "nll_loss": "0.441", "ppl": "1.36", "wps": "1460", "ups": "2.28", "wpb": "639.2", "bsz": "16", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "1.165", "train_wall": "43", "wall": "330"}
2022-10-30 23:34:22 | INFO | train_inner | {"epoch": 1, "update": 0.308, "loss": "2.323", "nll_loss": "0.439", "ppl": "1.36", "wps": "1385.3", "ups": "2.2", "wpb": "629.7", "bsz": "16", "num_updates": "900", "lr": "4.998e-05", "gnorm": "1.139", "train_wall": "45", "wall": "376"}
2022-10-30 23:35:05 | INFO | train_inner | {"epoch": 1, "update": 0.343, "loss": "2.315", "nll_loss": "0.432", "ppl": "1.35", "wps": "1453.4", "ups": "2.3", "wpb": "631.2", "bsz": "16", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "1.088", "train_wall": "43", "wall": "419"}
2022-10-30 23:35:52 | INFO | train_inner | {"epoch": 1, "update": 0.377, "loss": "2.316", "nll_loss": "0.434", "ppl": "1.35", "wps": "1302.4", "ups": "2.13", "wpb": "610.6", "bsz": "16", "num_updates": "1100", "lr": "4.997e-05", "gnorm": "1.096", "train_wall": "46", "wall": "466"}
2022-10-30 23:36:35 | INFO | train_inner | {"epoch": 1, "update": 0.411, "loss": "2.3", "nll_loss": "0.419", "ppl": "1.34", "wps": "1481.5", "ups": "2.32", "wpb": "637.8", "bsz": "16", "num_updates": "1200", "lr": "4.9965e-05", "gnorm": "1.139", "train_wall": "43", "wall": "509"}
2022-10-30 23:37:21 | INFO | train_inner | {"epoch": 1, "update": 0.446, "loss": "2.302", "nll_loss": "0.424", "ppl": "1.34", "wps": "1393.3", "ups": "2.17", "wpb": "641.3", "bsz": "16", "num_updates": "1300", "lr": "4.996e-05", "gnorm": "1.088", "train_wall": "45", "wall": "555"}
2022-10-30 23:37:57 | INFO | train_inner | {"epoch": 1, "update": 0.48, "loss": "2.306", "nll_loss": "0.428", "ppl": "1.34", "wps": "1807.9", "ups": "2.76", "wpb": "655.2", "bsz": "16", "num_updates": "1400", "lr": "4.9955e-05", "gnorm": "1.06", "train_wall": "36", "wall": "591"}
2022-10-30 23:38:38 | INFO | train_inner | {"epoch": 1, "update": 0.514, "loss": "2.303", "nll_loss": "0.427", "ppl": "1.34", "wps": "1522.4", "ups": "2.48", "wpb": "614.1", "bsz": "16", "num_updates": "1500", "lr": "4.995e-05", "gnorm": "1.038", "train_wall": "40", "wall": "632"}
2022-10-30 23:39:13 | INFO | train_inner | {"epoch": 1, "update": 0.548, "loss": "2.289", "nll_loss": "0.412", "ppl": "1.33", "wps": "1816.6", "ups": "2.83", "wpb": "641.9", "bsz": "16", "num_updates": "1600", "lr": "4.9945e-05", "gnorm": "0.972", "train_wall": "35", "wall": "667"}
2022-10-30 23:39:54 | INFO | train_inner | {"epoch": 1, "update": 0.583, "loss": "2.286", "nll_loss": "0.409", "ppl": "1.33", "wps": "1581.4", "ups": "2.43", "wpb": "651", "bsz": "16", "num_updates": "1700", "lr": "4.994e-05", "gnorm": "0.973", "train_wall": "41", "wall": "708"}
2022-10-30 23:40:33 | INFO | train_inner | {"epoch": 1, "update": 0.617, "loss": "2.283", "nll_loss": "0.407", "ppl": "1.33", "wps": "1682.4", "ups": "2.59", "wpb": "649.6", "bsz": "16", "num_updates": "1800", "lr": "4.9935e-05", "gnorm": "0.94", "train_wall": "38", "wall": "747"}
2022-10-30 23:41:14 | INFO | train_inner | {"epoch": 1, "update": 0.651, "loss": "2.277", "nll_loss": "0.402", "ppl": "1.32", "wps": "1555.9", "ups": "2.41", "wpb": "644.7", "bsz": "16", "num_updates": "1900", "lr": "4.993e-05", "gnorm": "0.928", "train_wall": "41", "wall": "788"}
2022-10-30 23:41:52 | INFO | train_inner | {"epoch": 1, "update": 0.685, "loss": "2.28", "nll_loss": "0.405", "ppl": "1.32", "wps": "1661.5", "ups": "2.64", "wpb": "630", "bsz": "16", "num_updates": "2000", "lr": "4.9925e-05", "gnorm": "0.989", "train_wall": "37", "wall": "826"}
2022-10-30 23:42:35 | INFO | train_inner | {"epoch": 1, "update": 0.72, "loss": "2.282", "nll_loss": "0.408", "ppl": "1.33", "wps": "1514.5", "ups": "2.35", "wpb": "645.6", "bsz": "16", "num_updates": "2100", "lr": "4.992e-05", "gnorm": "0.929", "train_wall": "42", "wall": "869"}
2022-10-30 23:43:10 | INFO | train_inner | {"epoch": 1, "update": 0.754, "loss": "2.28", "nll_loss": "0.406", "ppl": "1.33", "wps": "1762.4", "ups": "2.82", "wpb": "625.4", "bsz": "16", "num_updates": "2200", "lr": "4.9915e-05", "gnorm": "0.952", "train_wall": "35", "wall": "904"}
2022-10-30 23:43:52 | INFO | train_inner | {"epoch": 1, "update": 0.788, "loss": "2.272", "nll_loss": "0.397", "ppl": "1.32", "wps": "1544.4", "ups": "2.41", "wpb": "640.1", "bsz": "16", "num_updates": "2300", "lr": "4.991e-05", "gnorm": "0.85", "train_wall": "41", "wall": "946"}
2022-10-30 23:44:33 | INFO | train_inner | {"epoch": 1, "update": 0.822, "loss": "2.288", "nll_loss": "0.415", "ppl": "1.33", "wps": "1543.8", "ups": "2.44", "wpb": "631.6", "bsz": "16", "num_updates": "2400", "lr": "4.9905e-05", "gnorm": "0.908", "train_wall": "40", "wall": "987"}
2022-10-30 23:45:14 | INFO | train_inner | {"epoch": 1, "update": 0.857, "loss": "2.266", "nll_loss": "0.392", "ppl": "1.31", "wps": "1520.8", "ups": "2.41", "wpb": "631.7", "bsz": "16", "num_updates": "2500", "lr": "4.98999e-05", "gnorm": "0.883", "train_wall": "41", "wall": "1028"}
2022-10-30 23:45:52 | INFO | train_inner | {"epoch": 1, "update": 0.891, "loss": "2.277", "nll_loss": "0.404", "ppl": "1.32", "wps": "1663.4", "ups": "2.65", "wpb": "628.5", "bsz": "16", "num_updates": "2600", "lr": "4.98949e-05", "gnorm": "0.858", "train_wall": "37", "wall": "1066"}
2022-10-30 23:46:31 | INFO | train_inner | {"epoch": 1, "update": 0.925, "loss": "2.274", "nll_loss": "0.402", "ppl": "1.32", "wps": "1570.4", "ups": "2.56", "wpb": "612.8", "bsz": "16", "num_updates": "2700", "lr": "4.98899e-05", "gnorm": "0.855", "train_wall": "39", "wall": "1105"}
2022-10-30 23:47:12 | INFO | train_inner | {"epoch": 1, "update": 0.96, "loss": "2.269", "nll_loss": "0.396", "ppl": "1.32", "wps": "1515.1", "ups": "2.42", "wpb": "626.6", "bsz": "16", "num_updates": "2800", "lr": "4.98849e-05", "gnorm": "0.881", "train_wall": "41", "wall": "1146"}
2022-10-30 23:47:54 | INFO | train_inner | {"epoch": 1, "update": 0.994, "loss": "2.271", "nll_loss": "0.399", "ppl": "1.32", "wps": "1532.3", "ups": "2.38", "wpb": "643.6", "bsz": "16", "num_updates": "2900", "lr": "4.98799e-05", "gnorm": "0.846", "train_wall": "42", "wall": "1188"}
2022-10-30 23:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
/home/y_shi202/.local/lib/python3.6/site-packages/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  "amp_C fused kernels unavailable, disabling multi_tensor_l2norm; "
2022-10-31 00:02:32 | INFO | valid | {"epoch": 1, "valid_loss": "2.271", "valid_nll_loss": "0.315", "valid_ppl": "1.24", "valid_bleu": "73.16", "valid_wps": "267", "valid_wpb": "159", "valid_bsz": "4", "valid_num_updates": "2918"}
2022-10-31 00:02:32 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 00:02:45 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_best.pt (epoch 1 @ 2918 updates, score 73.16) (writing took 13.092996121849865 seconds)
2022-10-31 00:02:45 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-10-31 00:02:45 | INFO | train | {"epoch": 1, "train_loss": "2.397", "train_nll_loss": "0.492", "train_ppl": "1.41", "train_wps": "890.2", "train_ups": "1.41", "train_wpb": "633.6", "train_bsz": "16", "train_num_updates": "2918", "train_lr": "4.9879e-05", "train_gnorm": "2.028", "train_train_wall": "1180", "train_wall": "2079"}
2022-10-31 00:02:45 | INFO | fairseq.trainer | begin training epoch 2
2022-10-31 00:03:22 | INFO | train_inner | {"epoch": 2, "update": 1.028, "loss": "2.256", "nll_loss": "0.382", "ppl": "1.3", "wps": "67.2", "ups": "0.11", "wpb": "623.1", "bsz": "15.9", "num_updates": "3000", "lr": "4.98749e-05", "gnorm": "0.887", "train_wall": "45", "wall": "2116"}
2022-10-31 00:04:03 | INFO | train_inner | {"epoch": 2, "update": 1.062, "loss": "2.25", "nll_loss": "0.376", "ppl": "1.3", "wps": "1528.7", "ups": "2.41", "wpb": "634.2", "bsz": "16", "num_updates": "3100", "lr": "4.98699e-05", "gnorm": "0.826", "train_wall": "41", "wall": "2157"}
2022-10-31 00:04:46 | INFO | train_inner | {"epoch": 2, "update": 1.097, "loss": "2.249", "nll_loss": "0.375", "ppl": "1.3", "wps": "1530.1", "ups": "2.37", "wpb": "645.1", "bsz": "16", "num_updates": "3200", "lr": "4.98649e-05", "gnorm": "0.924", "train_wall": "42", "wall": "2200"}
2022-10-31 00:05:19 | INFO | train_inner | {"epoch": 2, "update": 1.131, "loss": "2.245", "nll_loss": "0.37", "ppl": "1.29", "wps": "1903.4", "ups": "2.99", "wpb": "635.6", "bsz": "16", "num_updates": "3300", "lr": "4.98599e-05", "gnorm": "0.824", "train_wall": "33", "wall": "2233"}
2022-10-31 00:05:59 | INFO | train_inner | {"epoch": 2, "update": 1.165, "loss": "2.25", "nll_loss": "0.376", "ppl": "1.3", "wps": "1579.9", "ups": "2.5", "wpb": "633", "bsz": "16", "num_updates": "3400", "lr": "4.98549e-05", "gnorm": "0.834", "train_wall": "40", "wall": "2273"}
2022-10-31 00:06:41 | INFO | train_inner | {"epoch": 2, "update": 1.199, "loss": "2.248", "nll_loss": "0.375", "ppl": "1.3", "wps": "1486.2", "ups": "2.4", "wpb": "619.1", "bsz": "16", "num_updates": "3500", "lr": "4.98499e-05", "gnorm": "0.809", "train_wall": "41", "wall": "2315"}
2022-10-31 00:07:20 | INFO | train_inner | {"epoch": 2, "update": 1.234, "loss": "2.255", "nll_loss": "0.383", "ppl": "1.3", "wps": "1617.8", "ups": "2.55", "wpb": "634.4", "bsz": "16", "num_updates": "3600", "lr": "4.98449e-05", "gnorm": "0.853", "train_wall": "39", "wall": "2354"}
2022-10-31 00:07:59 | INFO | train_inner | {"epoch": 2, "update": 1.268, "loss": "2.246", "nll_loss": "0.373", "ppl": "1.29", "wps": "1622.7", "ups": "2.55", "wpb": "635.5", "bsz": "16", "num_updates": "3700", "lr": "4.98399e-05", "gnorm": "0.821", "train_wall": "39", "wall": "2393"}
2022-10-31 00:08:40 | INFO | train_inner | {"epoch": 2, "update": 1.302, "loss": "2.249", "nll_loss": "0.377", "ppl": "1.3", "wps": "1539.6", "ups": "2.47", "wpb": "622.9", "bsz": "16", "num_updates": "3800", "lr": "4.98349e-05", "gnorm": "0.808", "train_wall": "40", "wall": "2434"}
2022-10-31 00:09:14 | INFO | train_inner | {"epoch": 2, "update": 1.337, "loss": "2.254", "nll_loss": "0.382", "ppl": "1.3", "wps": "1827.9", "ups": "2.92", "wpb": "625.3", "bsz": "16", "num_updates": "3900", "lr": "4.98299e-05", "gnorm": "0.873", "train_wall": "34", "wall": "2468"}
2022-10-31 00:09:51 | INFO | train_inner | {"epoch": 2, "update": 1.371, "loss": "2.248", "nll_loss": "0.376", "ppl": "1.3", "wps": "1682.9", "ups": "2.69", "wpb": "624.7", "bsz": "16", "num_updates": "4000", "lr": "4.98249e-05", "gnorm": "0.848", "train_wall": "37", "wall": "2505"}
2022-10-31 00:10:32 | INFO | train_inner | {"epoch": 2, "update": 1.405, "loss": "2.241", "nll_loss": "0.369", "ppl": "1.29", "wps": "1521.3", "ups": "2.41", "wpb": "631.4", "bsz": "16", "num_updates": "4100", "lr": "4.98199e-05", "gnorm": "0.777", "train_wall": "41", "wall": "2546"}
2022-10-31 00:11:16 | INFO | train_inner | {"epoch": 2, "update": 1.439, "loss": "2.247", "nll_loss": "0.374", "ppl": "1.3", "wps": "1463", "ups": "2.32", "wpb": "631.9", "bsz": "16", "num_updates": "4200", "lr": "4.98149e-05", "gnorm": "0.882", "train_wall": "43", "wall": "2590"}
2022-10-31 00:11:51 | INFO | train_inner | {"epoch": 2, "update": 1.474, "loss": "2.246", "nll_loss": "0.373", "ppl": "1.3", "wps": "1835.5", "ups": "2.86", "wpb": "641.7", "bsz": "16", "num_updates": "4300", "lr": "4.98099e-05", "gnorm": "0.931", "train_wall": "35", "wall": "2625"}
2022-10-31 00:12:33 | INFO | train_inner | {"epoch": 2, "update": 1.508, "loss": "2.246", "nll_loss": "0.375", "ppl": "1.3", "wps": "1514.3", "ups": "2.35", "wpb": "644.7", "bsz": "16", "num_updates": "4400", "lr": "4.98049e-05", "gnorm": "0.779", "train_wall": "42", "wall": "2667"}
2022-10-31 00:13:13 | INFO | train_inner | {"epoch": 2, "update": 1.542, "loss": "2.25", "nll_loss": "0.379", "ppl": "1.3", "wps": "1553.2", "ups": "2.5", "wpb": "621.8", "bsz": "16", "num_updates": "4500", "lr": "4.97999e-05", "gnorm": "0.838", "train_wall": "40", "wall": "2707"}
2022-10-31 00:13:53 | INFO | train_inner | {"epoch": 2, "update": 1.576, "loss": "2.239", "nll_loss": "0.366", "ppl": "1.29", "wps": "1643.3", "ups": "2.52", "wpb": "653.2", "bsz": "16", "num_updates": "4600", "lr": "4.97949e-05", "gnorm": "0.791", "train_wall": "39", "wall": "2747"}
2022-10-31 00:14:40 | INFO | train_inner | {"epoch": 2, "update": 1.611, "loss": "2.244", "nll_loss": "0.371", "ppl": "1.29", "wps": "1364.4", "ups": "2.14", "wpb": "638.4", "bsz": "16", "num_updates": "4700", "lr": "4.97899e-05", "gnorm": "0.835", "train_wall": "46", "wall": "2794"}
2022-10-31 00:15:21 | INFO | train_inner | {"epoch": 2, "update": 1.645, "loss": "2.247", "nll_loss": "0.376", "ppl": "1.3", "wps": "1522.5", "ups": "2.39", "wpb": "635.9", "bsz": "16", "num_updates": "4800", "lr": "4.97849e-05", "gnorm": "0.866", "train_wall": "41", "wall": "2836"}
2022-10-31 00:16:03 | INFO | train_inner | {"epoch": 2, "update": 1.679, "loss": "2.247", "nll_loss": "0.376", "ppl": "1.3", "wps": "1515.4", "ups": "2.4", "wpb": "630.1", "bsz": "16", "num_updates": "4900", "lr": "4.97799e-05", "gnorm": "0.775", "train_wall": "41", "wall": "2877"}
2022-10-31 00:16:45 | INFO | train_inner | {"epoch": 2, "update": 1.714, "loss": "2.241", "nll_loss": "0.37", "ppl": "1.29", "wps": "1540.9", "ups": "2.39", "wpb": "645.1", "bsz": "16", "num_updates": "5000", "lr": "4.97749e-05", "gnorm": "0.807", "train_wall": "41", "wall": "2919"}
2022-10-31 00:17:26 | INFO | train_inner | {"epoch": 2, "update": 1.748, "loss": "2.248", "nll_loss": "0.377", "ppl": "1.3", "wps": "1498", "ups": "2.42", "wpb": "618.8", "bsz": "16", "num_updates": "5100", "lr": "4.97699e-05", "gnorm": "0.79", "train_wall": "41", "wall": "2960"}
2022-10-31 00:17:49 | INFO | train_inner | {"epoch": 2, "update": 1.782, "loss": "2.247", "nll_loss": "0.377", "ppl": "1.3", "wps": "2796.9", "ups": "4.48", "wpb": "623.9", "bsz": "16", "num_updates": "5200", "lr": "4.97649e-05", "gnorm": "0.849", "train_wall": "22", "wall": "2983"}
2022-10-31 00:18:27 | INFO | train_inner | {"epoch": 2, "update": 1.816, "loss": "2.245", "nll_loss": "0.374", "ppl": "1.3", "wps": "1627.4", "ups": "2.58", "wpb": "629.6", "bsz": "16", "num_updates": "5300", "lr": "4.97599e-05", "gnorm": "0.771", "train_wall": "38", "wall": "3021"}
2022-10-31 00:19:03 | INFO | train_inner | {"epoch": 2, "update": 1.851, "loss": "2.25", "nll_loss": "0.381", "ppl": "1.3", "wps": "1787", "ups": "2.83", "wpb": "631.4", "bsz": "16", "num_updates": "5400", "lr": "4.97549e-05", "gnorm": "0.838", "train_wall": "35", "wall": "3057"}
2022-10-31 00:19:41 | INFO | train_inner | {"epoch": 2, "update": 1.885, "loss": "2.244", "nll_loss": "0.373", "ppl": "1.3", "wps": "1613.1", "ups": "2.6", "wpb": "620.5", "bsz": "16", "num_updates": "5500", "lr": "4.97499e-05", "gnorm": "0.794", "train_wall": "38", "wall": "3095"}
2022-10-31 00:20:15 | INFO | train_inner | {"epoch": 2, "update": 1.919, "loss": "2.241", "nll_loss": "0.37", "ppl": "1.29", "wps": "1941.2", "ups": "2.98", "wpb": "652.4", "bsz": "16", "num_updates": "5600", "lr": "4.97449e-05", "gnorm": "0.788", "train_wall": "33", "wall": "3129"}
2022-10-31 00:20:59 | INFO | train_inner | {"epoch": 2, "update": 1.953, "loss": "2.238", "nll_loss": "0.367", "ppl": "1.29", "wps": "1479.8", "ups": "2.28", "wpb": "650.4", "bsz": "16", "num_updates": "5700", "lr": "4.97399e-05", "gnorm": "0.813", "train_wall": "43", "wall": "3173"}
2022-10-31 00:21:40 | INFO | train_inner | {"epoch": 2, "update": 1.988, "loss": "2.252", "nll_loss": "0.383", "ppl": "1.3", "wps": "1538.3", "ups": "2.41", "wpb": "637.7", "bsz": "16", "num_updates": "5800", "lr": "4.97349e-05", "gnorm": "0.767", "train_wall": "41", "wall": "3214"}
2022-10-31 00:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 00:36:06 | INFO | valid | {"epoch": 2, "valid_loss": "2.256", "valid_nll_loss": "0.303", "valid_ppl": "1.23", "valid_bleu": "77.74", "valid_wps": "272.3", "valid_wpb": "159", "valid_bsz": "4", "valid_num_updates": "5836", "valid_best_bleu": "77.74"}
2022-10-31 00:36:06 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 00:36:21 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_best.pt (epoch 2 @ 5836 updates, score 77.74) (writing took 14.490354417357594 seconds)
2022-10-31 00:36:21 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-10-31 00:36:21 | INFO | train | {"epoch": 2, "train_loss": "2.247", "train_nll_loss": "0.375", "train_ppl": "1.3", "train_wps": "917.3", "train_ups": "1.45", "train_wpb": "633.6", "train_bsz": "16", "train_num_updates": "5836", "train_lr": "4.97331e-05", "train_gnorm": "0.826", "train_train_wall": "1134", "train_wall": "4095"}
2022-10-31 00:36:21 | INFO | fairseq.trainer | begin training epoch 3
2022-10-31 00:36:46 | INFO | train_inner | {"epoch": 3, "update": 2.022, "loss": "2.228", "nll_loss": "0.355", "ppl": "1.28", "wps": "70.1", "ups": "0.11", "wpb": "634.4", "bsz": "15.9", "num_updates": "5900", "lr": "4.97299e-05", "gnorm": "0.784", "train_wall": "38", "wall": "4120"}
2022-10-31 00:37:28 | INFO | train_inner | {"epoch": 3, "update": 2.056, "loss": "2.217", "nll_loss": "0.344", "ppl": "1.27", "wps": "1498.8", "ups": "2.34", "wpb": "641.6", "bsz": "16", "num_updates": "6000", "lr": "4.97249e-05", "gnorm": "0.773", "train_wall": "42", "wall": "4162"}
2022-10-31 00:38:07 | INFO | train_inner | {"epoch": 3, "update": 2.09, "loss": "2.212", "nll_loss": "0.338", "ppl": "1.26", "wps": "1671.1", "ups": "2.58", "wpb": "647.7", "bsz": "16", "num_updates": "6100", "lr": "4.97199e-05", "gnorm": "0.771", "train_wall": "38", "wall": "4201"}
2022-10-31 00:38:50 | INFO | train_inner | {"epoch": 3, "update": 2.125, "loss": "2.216", "nll_loss": "0.342", "ppl": "1.27", "wps": "1480.3", "ups": "2.33", "wpb": "636.5", "bsz": "16", "num_updates": "6200", "lr": "4.97149e-05", "gnorm": "0.797", "train_wall": "42", "wall": "4244"}
2022-10-31 00:39:32 | INFO | train_inner | {"epoch": 3, "update": 2.159, "loss": "2.225", "nll_loss": "0.353", "ppl": "1.28", "wps": "1481.5", "ups": "2.4", "wpb": "618.1", "bsz": "16", "num_updates": "6300", "lr": "4.97099e-05", "gnorm": "0.806", "train_wall": "41", "wall": "4286"}
2022-10-31 00:40:14 | INFO | train_inner | {"epoch": 3, "update": 2.193, "loss": "2.22", "nll_loss": "0.348", "ppl": "1.27", "wps": "1498.6", "ups": "2.38", "wpb": "630.1", "bsz": "16", "num_updates": "6400", "lr": "4.97049e-05", "gnorm": "0.746", "train_wall": "42", "wall": "4328"}
2022-10-31 00:40:55 | INFO | train_inner | {"epoch": 3, "update": 2.228, "loss": "2.222", "nll_loss": "0.35", "ppl": "1.27", "wps": "1601.8", "ups": "2.44", "wpb": "657.5", "bsz": "16", "num_updates": "6500", "lr": "4.96998e-05", "gnorm": "0.773", "train_wall": "41", "wall": "4369"}
2022-10-31 00:41:36 | INFO | train_inner | {"epoch": 3, "update": 2.262, "loss": "2.22", "nll_loss": "0.348", "ppl": "1.27", "wps": "1581.5", "ups": "2.44", "wpb": "648.4", "bsz": "16", "num_updates": "6600", "lr": "4.96948e-05", "gnorm": "0.824", "train_wall": "41", "wall": "4410"}
2022-10-31 00:42:18 | INFO | train_inner | {"epoch": 3, "update": 2.296, "loss": "2.22", "nll_loss": "0.347", "ppl": "1.27", "wps": "1508.1", "ups": "2.37", "wpb": "635.3", "bsz": "16", "num_updates": "6700", "lr": "4.96898e-05", "gnorm": "0.757", "train_wall": "42", "wall": "4452"}
2022-10-31 00:42:55 | INFO | train_inner | {"epoch": 3, "update": 2.33, "loss": "2.224", "nll_loss": "0.353", "ppl": "1.28", "wps": "1683.2", "ups": "2.7", "wpb": "622.4", "bsz": "16", "num_updates": "6800", "lr": "4.96848e-05", "gnorm": "0.801", "train_wall": "37", "wall": "4489"}
2022-10-31 00:43:34 | INFO | train_inner | {"epoch": 3, "update": 2.365, "loss": "2.223", "nll_loss": "0.351", "ppl": "1.28", "wps": "1585.4", "ups": "2.54", "wpb": "624.5", "bsz": "16", "num_updates": "6900", "lr": "4.96798e-05", "gnorm": "0.776", "train_wall": "39", "wall": "4529"}
2022-10-31 00:44:17 | INFO | train_inner | {"epoch": 3, "update": 2.399, "loss": "2.216", "nll_loss": "0.344", "ppl": "1.27", "wps": "1477", "ups": "2.35", "wpb": "629.8", "bsz": "16", "num_updates": "7000", "lr": "4.96748e-05", "gnorm": "0.754", "train_wall": "42", "wall": "4571"}
2022-10-31 00:44:59 | INFO | train_inner | {"epoch": 3, "update": 2.433, "loss": "2.225", "nll_loss": "0.353", "ppl": "1.28", "wps": "1513", "ups": "2.41", "wpb": "628.2", "bsz": "16", "num_updates": "7100", "lr": "4.96698e-05", "gnorm": "0.782", "train_wall": "41", "wall": "4613"}
2022-10-31 00:45:39 | INFO | train_inner | {"epoch": 3, "update": 2.467, "loss": "2.226", "nll_loss": "0.355", "ppl": "1.28", "wps": "1530.8", "ups": "2.48", "wpb": "617.9", "bsz": "16", "num_updates": "7200", "lr": "4.96648e-05", "gnorm": "0.792", "train_wall": "40", "wall": "4653"}
2022-10-31 00:46:20 | INFO | train_inner | {"epoch": 3, "update": 2.502, "loss": "2.221", "nll_loss": "0.35", "ppl": "1.27", "wps": "1538.2", "ups": "2.42", "wpb": "636.2", "bsz": "16", "num_updates": "7300", "lr": "4.96598e-05", "gnorm": "0.784", "train_wall": "41", "wall": "4694"}
2022-10-31 00:47:04 | INFO | train_inner | {"epoch": 3, "update": 2.536, "loss": "2.22", "nll_loss": "0.348", "ppl": "1.27", "wps": "1481.8", "ups": "2.29", "wpb": "646.4", "bsz": "16", "num_updates": "7400", "lr": "4.96548e-05", "gnorm": "0.746", "train_wall": "43", "wall": "4738"}
2022-10-31 00:47:42 | INFO | train_inner | {"epoch": 3, "update": 2.57, "loss": "2.223", "nll_loss": "0.352", "ppl": "1.28", "wps": "1602.3", "ups": "2.61", "wpb": "614.2", "bsz": "16", "num_updates": "7500", "lr": "4.96498e-05", "gnorm": "0.819", "train_wall": "38", "wall": "4776"}
2022-10-31 00:48:23 | INFO | train_inner | {"epoch": 3, "update": 2.605, "loss": "2.224", "nll_loss": "0.352", "ppl": "1.28", "wps": "1589.8", "ups": "2.44", "wpb": "651", "bsz": "16", "num_updates": "7600", "lr": "4.96448e-05", "gnorm": "0.812", "train_wall": "40", "wall": "4817"}
2022-10-31 00:49:03 | INFO | train_inner | {"epoch": 3, "update": 2.639, "loss": "2.224", "nll_loss": "0.354", "ppl": "1.28", "wps": "1604.4", "ups": "2.54", "wpb": "632", "bsz": "16", "num_updates": "7700", "lr": "4.96398e-05", "gnorm": "0.795", "train_wall": "39", "wall": "4857"}
2022-10-31 00:49:39 | INFO | train_inner | {"epoch": 3, "update": 2.673, "loss": "2.228", "nll_loss": "0.357", "ppl": "1.28", "wps": "1760.2", "ups": "2.74", "wpb": "643.3", "bsz": "16", "num_updates": "7800", "lr": "4.96348e-05", "gnorm": "0.819", "train_wall": "36", "wall": "4893"}
2022-10-31 00:50:15 | INFO | train_inner | {"epoch": 3, "update": 2.707, "loss": "2.229", "nll_loss": "0.359", "ppl": "1.28", "wps": "1698.7", "ups": "2.8", "wpb": "607", "bsz": "16", "num_updates": "7900", "lr": "4.96298e-05", "gnorm": "0.809", "train_wall": "35", "wall": "4929"}
2022-10-31 00:50:57 | INFO | train_inner | {"epoch": 3, "update": 2.742, "loss": "2.213", "nll_loss": "0.34", "ppl": "1.27", "wps": "1552.8", "ups": "2.4", "wpb": "646.2", "bsz": "16", "num_updates": "8000", "lr": "4.96248e-05", "gnorm": "0.768", "train_wall": "41", "wall": "4971"}
2022-10-31 00:51:36 | INFO | train_inner | {"epoch": 3, "update": 2.776, "loss": "2.225", "nll_loss": "0.355", "ppl": "1.28", "wps": "1608.7", "ups": "2.56", "wpb": "628.5", "bsz": "16", "num_updates": "8100", "lr": "4.96198e-05", "gnorm": "0.731", "train_wall": "39", "wall": "5010"}
2022-10-31 00:52:17 | INFO | train_inner | {"epoch": 3, "update": 2.81, "loss": "2.228", "nll_loss": "0.357", "ppl": "1.28", "wps": "1498.5", "ups": "2.4", "wpb": "624.2", "bsz": "16", "num_updates": "8200", "lr": "4.96148e-05", "gnorm": "0.752", "train_wall": "41", "wall": "5051"}
2022-10-31 00:52:58 | INFO | train_inner | {"epoch": 3, "update": 2.844, "loss": "2.221", "nll_loss": "0.35", "ppl": "1.27", "wps": "1544.1", "ups": "2.45", "wpb": "629.6", "bsz": "16", "num_updates": "8300", "lr": "4.96098e-05", "gnorm": "0.776", "train_wall": "40", "wall": "5092"}
2022-10-31 00:53:33 | INFO | train_inner | {"epoch": 3, "update": 2.879, "loss": "2.228", "nll_loss": "0.358", "ppl": "1.28", "wps": "1762.1", "ups": "2.85", "wpb": "618.8", "bsz": "16", "num_updates": "8400", "lr": "4.96048e-05", "gnorm": "0.741", "train_wall": "35", "wall": "5127"}
2022-10-31 00:54:19 | INFO | train_inner | {"epoch": 3, "update": 2.913, "loss": "2.223", "nll_loss": "0.353", "ppl": "1.28", "wps": "1415.4", "ups": "2.18", "wpb": "649.7", "bsz": "16", "num_updates": "8500", "lr": "4.95998e-05", "gnorm": "0.789", "train_wall": "45", "wall": "5173"}
2022-10-31 00:54:59 | INFO | train_inner | {"epoch": 3, "update": 2.947, "loss": "2.224", "nll_loss": "0.353", "ppl": "1.28", "wps": "1583.7", "ups": "2.48", "wpb": "639.5", "bsz": "16", "num_updates": "8600", "lr": "4.95948e-05", "gnorm": "0.855", "train_wall": "40", "wall": "5214"}
2022-10-31 00:55:38 | INFO | train_inner | {"epoch": 3, "update": 2.981, "loss": "2.215", "nll_loss": "0.344", "ppl": "1.27", "wps": "1686.8", "ups": "2.6", "wpb": "649", "bsz": "16", "num_updates": "8700", "lr": "4.95898e-05", "gnorm": "0.744", "train_wall": "38", "wall": "5252"}
2022-10-31 00:55:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 01:09:40 | INFO | valid | {"epoch": 3, "valid_loss": "2.248", "valid_nll_loss": "0.302", "valid_ppl": "1.23", "valid_bleu": "73.16", "valid_wps": "282.5", "valid_wpb": "159", "valid_bsz": "4", "valid_num_updates": "8754", "valid_best_bleu": "77.74"}
2022-10-31 01:09:40 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 01:09:48 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_last.pt (epoch 3 @ 8754 updates, score 73.16) (writing took 8.005695840809494 seconds)
2022-10-31 01:09:48 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-10-31 01:09:48 | INFO | train | {"epoch": 3, "train_loss": "2.222", "train_nll_loss": "0.35", "train_ppl": "1.27", "train_wps": "921.2", "train_ups": "1.45", "train_wpb": "633.6", "train_bsz": "16", "train_num_updates": "8754", "train_lr": "4.95871e-05", "train_gnorm": "0.782", "train_train_wall": "1163", "train_wall": "6102"}
2022-10-31 01:09:48 | INFO | fairseq.trainer | begin training epoch 4
2022-10-31 01:10:07 | INFO | train_inner | {"epoch": 4, "update": 3.016, "loss": "2.217", "nll_loss": "0.347", "ppl": "1.27", "wps": "71.7", "ups": "0.12", "wpb": "623.2", "bsz": "15.9", "num_updates": "8800", "lr": "4.95848e-05", "gnorm": "0.782", "train_wall": "39", "wall": "6121"}
2022-10-31 01:10:43 | INFO | train_inner | {"epoch": 4, "update": 3.05, "loss": "2.197", "nll_loss": "0.323", "ppl": "1.25", "wps": "1781.6", "ups": "2.78", "wpb": "639.9", "bsz": "16", "num_updates": "8900", "lr": "4.95798e-05", "gnorm": "0.736", "train_wall": "35", "wall": "6157"}
2022-10-31 01:11:18 | INFO | train_inner | {"epoch": 4, "update": 3.084, "loss": "2.2", "nll_loss": "0.326", "ppl": "1.25", "wps": "1760.9", "ups": "2.8", "wpb": "628.1", "bsz": "16", "num_updates": "9000", "lr": "4.95748e-05", "gnorm": "0.763", "train_wall": "35", "wall": "6192"}
2022-10-31 01:11:59 | INFO | train_inner | {"epoch": 4, "update": 3.119, "loss": "2.203", "nll_loss": "0.33", "ppl": "1.26", "wps": "1565.5", "ups": "2.46", "wpb": "635.3", "bsz": "16", "num_updates": "9100", "lr": "4.95698e-05", "gnorm": "0.758", "train_wall": "40", "wall": "6233"}
2022-10-31 01:12:43 | INFO | train_inner | {"epoch": 4, "update": 3.153, "loss": "2.201", "nll_loss": "0.327", "ppl": "1.25", "wps": "1423.9", "ups": "2.29", "wpb": "623", "bsz": "16", "num_updates": "9200", "lr": "4.95648e-05", "gnorm": "0.763", "train_wall": "43", "wall": "6277"}
2022-10-31 01:13:28 | INFO | train_inner | {"epoch": 4, "update": 3.187, "loss": "2.198", "nll_loss": "0.324", "ppl": "1.25", "wps": "1433.2", "ups": "2.21", "wpb": "649", "bsz": "16", "num_updates": "9300", "lr": "4.95598e-05", "gnorm": "0.717", "train_wall": "45", "wall": "6322"}
2022-10-31 01:14:14 | INFO | train_inner | {"epoch": 4, "update": 3.221, "loss": "2.199", "nll_loss": "0.325", "ppl": "1.25", "wps": "1372.8", "ups": "2.16", "wpb": "634.7", "bsz": "16", "num_updates": "9400", "lr": "4.95548e-05", "gnorm": "0.772", "train_wall": "46", "wall": "6368"}
2022-10-31 01:14:58 | INFO | train_inner | {"epoch": 4, "update": 3.256, "loss": "2.205", "nll_loss": "0.333", "ppl": "1.26", "wps": "1429", "ups": "2.26", "wpb": "631.7", "bsz": "16", "num_updates": "9500", "lr": "4.95498e-05", "gnorm": "0.776", "train_wall": "44", "wall": "6412"}
2022-10-31 01:15:44 | INFO | train_inner | {"epoch": 4, "update": 3.29, "loss": "2.199", "nll_loss": "0.327", "ppl": "1.25", "wps": "1400.8", "ups": "2.21", "wpb": "634.1", "bsz": "16", "num_updates": "9600", "lr": "4.95448e-05", "gnorm": "0.802", "train_wall": "45", "wall": "6458"}
2022-10-31 01:16:30 | INFO | train_inner | {"epoch": 4, "update": 3.324, "loss": "2.205", "nll_loss": "0.333", "ppl": "1.26", "wps": "1320", "ups": "2.15", "wpb": "613.6", "bsz": "16", "num_updates": "9700", "lr": "4.95398e-05", "gnorm": "0.75", "train_wall": "46", "wall": "6504"}
2022-10-31 01:17:02 | INFO | train_inner | {"epoch": 4, "update": 3.358, "loss": "2.204", "nll_loss": "0.331", "ppl": "1.26", "wps": "1929.8", "ups": "3.09", "wpb": "625", "bsz": "16", "num_updates": "9800", "lr": "4.95348e-05", "gnorm": "0.79", "train_wall": "32", "wall": "6536"}
2022-10-31 01:17:46 | INFO | train_inner | {"epoch": 4, "update": 3.393, "loss": "2.203", "nll_loss": "0.331", "ppl": "1.26", "wps": "1453.9", "ups": "2.29", "wpb": "635.6", "bsz": "16", "num_updates": "9900", "lr": "4.95298e-05", "gnorm": "0.78", "train_wall": "43", "wall": "6580"}
2022-10-31 01:18:25 | INFO | train_inner | {"epoch": 4, "update": 3.427, "loss": "2.205", "nll_loss": "0.333", "ppl": "1.26", "wps": "1635.6", "ups": "2.56", "wpb": "638.2", "bsz": "16", "num_updates": "10000", "lr": "4.95248e-05", "gnorm": "0.755", "train_wall": "39", "wall": "6619"}
2022-10-31 01:19:11 | INFO | train_inner | {"epoch": 4, "update": 3.461, "loss": "2.199", "nll_loss": "0.327", "ppl": "1.25", "wps": "1386.8", "ups": "2.17", "wpb": "639.3", "bsz": "16", "num_updates": "10100", "lr": "4.95198e-05", "gnorm": "0.747", "train_wall": "46", "wall": "6665"}
2022-10-31 01:19:51 | INFO | train_inner | {"epoch": 4, "update": 3.496, "loss": "2.201", "nll_loss": "0.329", "ppl": "1.26", "wps": "1534.7", "ups": "2.49", "wpb": "617.4", "bsz": "16", "num_updates": "10200", "lr": "4.95148e-05", "gnorm": "0.782", "train_wall": "40", "wall": "6705"}
2022-10-31 01:20:35 | INFO | train_inner | {"epoch": 4, "update": 3.53, "loss": "2.2", "nll_loss": "0.328", "ppl": "1.26", "wps": "1465.7", "ups": "2.28", "wpb": "643", "bsz": "16", "num_updates": "10300", "lr": "4.95098e-05", "gnorm": "0.763", "train_wall": "43", "wall": "6749"}
2022-10-31 01:21:20 | INFO | train_inner | {"epoch": 4, "update": 3.564, "loss": "2.204", "nll_loss": "0.332", "ppl": "1.26", "wps": "1475.9", "ups": "2.26", "wpb": "652.8", "bsz": "16", "num_updates": "10400", "lr": "4.95048e-05", "gnorm": "0.723", "train_wall": "44", "wall": "6794"}
2022-10-31 01:22:00 | INFO | train_inner | {"epoch": 4, "update": 3.598, "loss": "2.206", "nll_loss": "0.334", "ppl": "1.26", "wps": "1538.6", "ups": "2.46", "wpb": "625.1", "bsz": "16", "num_updates": "10500", "lr": "4.94997e-05", "gnorm": "0.802", "train_wall": "40", "wall": "6834"}
2022-10-31 01:22:39 | INFO | train_inner | {"epoch": 4, "update": 3.633, "loss": "2.208", "nll_loss": "0.337", "ppl": "1.26", "wps": "1590.1", "ups": "2.55", "wpb": "622.6", "bsz": "16", "num_updates": "10600", "lr": "4.94947e-05", "gnorm": "0.779", "train_wall": "39", "wall": "6873"}
2022-10-31 01:23:20 | INFO | train_inner | {"epoch": 4, "update": 3.667, "loss": "2.205", "nll_loss": "0.333", "ppl": "1.26", "wps": "1551", "ups": "2.44", "wpb": "636", "bsz": "16", "num_updates": "10700", "lr": "4.94897e-05", "gnorm": "0.77", "train_wall": "41", "wall": "6914"}
2022-10-31 01:24:04 | INFO | train_inner | {"epoch": 4, "update": 3.701, "loss": "2.203", "nll_loss": "0.332", "ppl": "1.26", "wps": "1462.8", "ups": "2.27", "wpb": "644.3", "bsz": "16", "num_updates": "10800", "lr": "4.94847e-05", "gnorm": "0.784", "train_wall": "43", "wall": "6958"}
2022-10-31 01:24:42 | INFO | train_inner | {"epoch": 4, "update": 3.735, "loss": "2.21", "nll_loss": "0.339", "ppl": "1.27", "wps": "1721.6", "ups": "2.63", "wpb": "653.6", "bsz": "16", "num_updates": "10900", "lr": "4.94797e-05", "gnorm": "0.741", "train_wall": "37", "wall": "6996"}
2022-10-31 01:25:19 | INFO | train_inner | {"epoch": 4, "update": 3.77, "loss": "2.199", "nll_loss": "0.327", "ppl": "1.25", "wps": "1665.8", "ups": "2.7", "wpb": "616.7", "bsz": "16", "num_updates": "11000", "lr": "4.94747e-05", "gnorm": "0.762", "train_wall": "37", "wall": "7033"}
2022-10-31 01:26:00 | INFO | train_inner | {"epoch": 4, "update": 3.804, "loss": "2.203", "nll_loss": "0.331", "ppl": "1.26", "wps": "1582.2", "ups": "2.47", "wpb": "641.3", "bsz": "16", "num_updates": "11100", "lr": "4.94697e-05", "gnorm": "0.759", "train_wall": "40", "wall": "7074"}
2022-10-31 01:26:43 | INFO | train_inner | {"epoch": 4, "update": 3.838, "loss": "2.214", "nll_loss": "0.343", "ppl": "1.27", "wps": "1444.5", "ups": "2.34", "wpb": "617.6", "bsz": "16", "num_updates": "11200", "lr": "4.94647e-05", "gnorm": "0.815", "train_wall": "42", "wall": "7117"}
2022-10-31 01:27:23 | INFO | train_inner | {"epoch": 4, "update": 3.873, "loss": "2.206", "nll_loss": "0.335", "ppl": "1.26", "wps": "1615.8", "ups": "2.49", "wpb": "648.4", "bsz": "16", "num_updates": "11300", "lr": "4.94597e-05", "gnorm": "0.747", "train_wall": "40", "wall": "7157"}
2022-10-31 01:28:02 | INFO | train_inner | {"epoch": 4, "update": 3.907, "loss": "2.203", "nll_loss": "0.332", "ppl": "1.26", "wps": "1627.3", "ups": "2.54", "wpb": "641.7", "bsz": "16", "num_updates": "11400", "lr": "4.94547e-05", "gnorm": "0.771", "train_wall": "39", "wall": "7196"}
2022-10-31 01:28:45 | INFO | train_inner | {"epoch": 4, "update": 3.941, "loss": "2.206", "nll_loss": "0.335", "ppl": "1.26", "wps": "1454.7", "ups": "2.32", "wpb": "627.9", "bsz": "16", "num_updates": "11500", "lr": "4.94497e-05", "gnorm": "0.749", "train_wall": "43", "wall": "7239"}
2022-10-31 01:29:27 | INFO | train_inner | {"epoch": 4, "update": 3.975, "loss": "2.208", "nll_loss": "0.337", "ppl": "1.26", "wps": "1493.6", "ups": "2.43", "wpb": "614.1", "bsz": "16", "num_updates": "11600", "lr": "4.94447e-05", "gnorm": "0.762", "train_wall": "41", "wall": "7281"}
2022-10-31 01:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 01:43:53 | INFO | valid | {"epoch": 4, "valid_loss": "2.249", "valid_nll_loss": "0.308", "valid_ppl": "1.24", "valid_bleu": "74.94", "valid_wps": "277.2", "valid_wpb": "159", "valid_bsz": "4", "valid_num_updates": "11672", "valid_best_bleu": "77.74"}
2022-10-31 01:43:53 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 01:44:02 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_last.pt (epoch 4 @ 11672 updates, score 74.94) (writing took 8.372103604022413 seconds)
2022-10-31 01:44:02 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-10-31 01:44:02 | INFO | train | {"epoch": 4, "train_loss": "2.204", "train_nll_loss": "0.331", "train_ppl": "1.26", "train_wps": "900.1", "train_ups": "1.42", "train_wpb": "633.6", "train_bsz": "16", "train_num_updates": "11672", "train_lr": "4.94411e-05", "train_gnorm": "0.765", "train_train_wall": "1194", "train_wall": "8156"}
2022-10-31 01:44:02 | INFO | fairseq.trainer | begin training epoch 5
2022-10-31 01:44:14 | INFO | train_inner | {"epoch": 5, "update": 4.01, "loss": "2.205", "nll_loss": "0.334", "ppl": "1.26", "wps": "71.3", "ups": "0.11", "wpb": "632.4", "bsz": "15.9", "num_updates": "11700", "lr": "4.94397e-05", "gnorm": "0.753", "train_wall": "41", "wall": "8168"}
2022-10-31 01:44:55 | INFO | train_inner | {"epoch": 5, "update": 4.044, "loss": "2.18", "nll_loss": "0.305", "ppl": "1.24", "wps": "1571.1", "ups": "2.46", "wpb": "639.8", "bsz": "16", "num_updates": "11800", "lr": "4.94347e-05", "gnorm": "0.719", "train_wall": "40", "wall": "8209"}
2022-10-31 01:45:38 | INFO | train_inner | {"epoch": 5, "update": 4.078, "loss": "2.179", "nll_loss": "0.304", "ppl": "1.23", "wps": "1491.9", "ups": "2.31", "wpb": "645.2", "bsz": "16", "num_updates": "11900", "lr": "4.94297e-05", "gnorm": "0.721", "train_wall": "43", "wall": "8252"}
2022-10-31 01:46:19 | INFO | train_inner | {"epoch": 5, "update": 4.112, "loss": "2.182", "nll_loss": "0.308", "ppl": "1.24", "wps": "1505.6", "ups": "2.41", "wpb": "625.1", "bsz": "16", "num_updates": "12000", "lr": "4.94247e-05", "gnorm": "0.727", "train_wall": "41", "wall": "8293"}
2022-10-31 01:47:02 | INFO | train_inner | {"epoch": 5, "update": 4.147, "loss": "2.183", "nll_loss": "0.309", "ppl": "1.24", "wps": "1522.1", "ups": "2.35", "wpb": "647.1", "bsz": "16", "num_updates": "12100", "lr": "4.94197e-05", "gnorm": "0.749", "train_wall": "42", "wall": "8336"}
2022-10-31 01:47:32 | INFO | train_inner | {"epoch": 5, "update": 4.181, "loss": "2.184", "nll_loss": "0.31", "ppl": "1.24", "wps": "2104.3", "ups": "3.32", "wpb": "632.9", "bsz": "16", "num_updates": "12200", "lr": "4.94147e-05", "gnorm": "0.795", "train_wall": "30", "wall": "8366"}
2022-10-31 01:48:13 | INFO | train_inner | {"epoch": 5, "update": 4.215, "loss": "2.187", "nll_loss": "0.313", "ppl": "1.24", "wps": "1525.8", "ups": "2.43", "wpb": "627.8", "bsz": "16", "num_updates": "12300", "lr": "4.94097e-05", "gnorm": "0.825", "train_wall": "41", "wall": "8407"}
2022-10-31 01:48:53 | INFO | train_inner | {"epoch": 5, "update": 4.249, "loss": "2.188", "nll_loss": "0.315", "ppl": "1.24", "wps": "1551.3", "ups": "2.48", "wpb": "624.8", "bsz": "16", "num_updates": "12400", "lr": "4.94047e-05", "gnorm": "0.797", "train_wall": "40", "wall": "8447"}
2022-10-31 01:49:34 | INFO | train_inner | {"epoch": 5, "update": 4.284, "loss": "2.184", "nll_loss": "0.31", "ppl": "1.24", "wps": "1555.4", "ups": "2.45", "wpb": "634.6", "bsz": "16", "num_updates": "12500", "lr": "4.93997e-05", "gnorm": "0.768", "train_wall": "40", "wall": "8488"}
2022-10-31 01:50:12 | INFO | train_inner | {"epoch": 5, "update": 4.318, "loss": "2.177", "nll_loss": "0.302", "ppl": "1.23", "wps": "1751.3", "ups": "2.67", "wpb": "656.5", "bsz": "16", "num_updates": "12600", "lr": "4.93947e-05", "gnorm": "0.709", "train_wall": "37", "wall": "8526"}
2022-10-31 01:50:54 | INFO | train_inner | {"epoch": 5, "update": 4.352, "loss": "2.19", "nll_loss": "0.317", "ppl": "1.25", "wps": "1482.3", "ups": "2.37", "wpb": "626.4", "bsz": "16", "num_updates": "12700", "lr": "4.93897e-05", "gnorm": "0.811", "train_wall": "42", "wall": "8568"}
2022-10-31 01:51:28 | INFO | train_inner | {"epoch": 5, "update": 4.387, "loss": "2.193", "nll_loss": "0.32", "ppl": "1.25", "wps": "1883.4", "ups": "2.98", "wpb": "632.6", "bsz": "16", "num_updates": "12800", "lr": "4.93847e-05", "gnorm": "0.868", "train_wall": "33", "wall": "8602"}
2022-10-31 01:52:10 | INFO | train_inner | {"epoch": 5, "update": 4.421, "loss": "2.196", "nll_loss": "0.324", "ppl": "1.25", "wps": "1477.3", "ups": "2.38", "wpb": "621.8", "bsz": "16", "num_updates": "12900", "lr": "4.93797e-05", "gnorm": "0.789", "train_wall": "42", "wall": "8644"}
2022-10-31 01:52:42 | INFO | train_inner | {"epoch": 5, "update": 4.455, "loss": "2.194", "nll_loss": "0.322", "ppl": "1.25", "wps": "1890.6", "ups": "3.11", "wpb": "607.5", "bsz": "16", "num_updates": "13000", "lr": "4.93747e-05", "gnorm": "0.811", "train_wall": "32", "wall": "8676"}
2022-10-31 01:53:23 | INFO | train_inner | {"epoch": 5, "update": 4.489, "loss": "2.186", "nll_loss": "0.312", "ppl": "1.24", "wps": "1587.9", "ups": "2.44", "wpb": "651.1", "bsz": "16", "num_updates": "13100", "lr": "4.93697e-05", "gnorm": "0.758", "train_wall": "40", "wall": "8717"}
2022-10-31 01:54:02 | INFO | train_inner | {"epoch": 5, "update": 4.524, "loss": "2.19", "nll_loss": "0.317", "ppl": "1.25", "wps": "1556.3", "ups": "2.53", "wpb": "615.2", "bsz": "16", "num_updates": "13200", "lr": "4.93647e-05", "gnorm": "0.751", "train_wall": "39", "wall": "8756"}
2022-10-31 01:54:44 | INFO | train_inner | {"epoch": 5, "update": 4.558, "loss": "2.193", "nll_loss": "0.32", "ppl": "1.25", "wps": "1522.9", "ups": "2.38", "wpb": "639.2", "bsz": "16", "num_updates": "13300", "lr": "4.93597e-05", "gnorm": "0.798", "train_wall": "41", "wall": "8798"}
2022-10-31 01:55:31 | INFO | train_inner | {"epoch": 5, "update": 4.592, "loss": "2.188", "nll_loss": "0.315", "ppl": "1.24", "wps": "1407.2", "ups": "2.16", "wpb": "652.2", "bsz": "16", "num_updates": "13400", "lr": "4.93547e-05", "gnorm": "0.736", "train_wall": "46", "wall": "8845"}
2022-10-31 01:56:13 | INFO | train_inner | {"epoch": 5, "update": 4.626, "loss": "2.189", "nll_loss": "0.316", "ppl": "1.24", "wps": "1486", "ups": "2.34", "wpb": "636", "bsz": "16", "num_updates": "13500", "lr": "4.93497e-05", "gnorm": "0.804", "train_wall": "42", "wall": "8887"}
2022-10-31 01:56:54 | INFO | train_inner | {"epoch": 5, "update": 4.661, "loss": "2.189", "nll_loss": "0.316", "ppl": "1.24", "wps": "1516.1", "ups": "2.44", "wpb": "621.4", "bsz": "16", "num_updates": "13600", "lr": "4.93447e-05", "gnorm": "0.842", "train_wall": "40", "wall": "8928"}
2022-10-31 01:57:36 | INFO | train_inner | {"epoch": 5, "update": 4.695, "loss": "2.184", "nll_loss": "0.311", "ppl": "1.24", "wps": "1528.2", "ups": "2.41", "wpb": "634.1", "bsz": "16", "num_updates": "13700", "lr": "4.93397e-05", "gnorm": "0.781", "train_wall": "41", "wall": "8970"}
2022-10-31 01:58:20 | INFO | train_inner | {"epoch": 5, "update": 4.729, "loss": "2.184", "nll_loss": "0.311", "ppl": "1.24", "wps": "1453.2", "ups": "2.29", "wpb": "635.7", "bsz": "16", "num_updates": "13800", "lr": "4.93347e-05", "gnorm": "0.779", "train_wall": "43", "wall": "9014"}
2022-10-31 01:59:04 | INFO | train_inner | {"epoch": 5, "update": 4.764, "loss": "2.193", "nll_loss": "0.321", "ppl": "1.25", "wps": "1396.6", "ups": "2.23", "wpb": "626.1", "bsz": "16", "num_updates": "13900", "lr": "4.93297e-05", "gnorm": "0.818", "train_wall": "44", "wall": "9059"}
2022-10-31 01:59:43 | INFO | train_inner | {"epoch": 5, "update": 4.798, "loss": "2.188", "nll_loss": "0.315", "ppl": "1.24", "wps": "1665.7", "ups": "2.62", "wpb": "635.2", "bsz": "16", "num_updates": "14000", "lr": "4.93247e-05", "gnorm": "0.78", "train_wall": "38", "wall": "9097"}
2022-10-31 02:00:27 | INFO | train_inner | {"epoch": 5, "update": 4.832, "loss": "2.19", "nll_loss": "0.318", "ppl": "1.25", "wps": "1375.3", "ups": "2.25", "wpb": "612", "bsz": "16", "num_updates": "14100", "lr": "4.93197e-05", "gnorm": "0.752", "train_wall": "44", "wall": "9141"}
2022-10-31 02:01:11 | INFO | train_inner | {"epoch": 5, "update": 4.866, "loss": "2.193", "nll_loss": "0.321", "ppl": "1.25", "wps": "1463.7", "ups": "2.28", "wpb": "641.7", "bsz": "16", "num_updates": "14200", "lr": "4.93147e-05", "gnorm": "0.776", "train_wall": "43", "wall": "9185"}
2022-10-31 02:01:50 | INFO | train_inner | {"epoch": 5, "update": 4.901, "loss": "2.188", "nll_loss": "0.316", "ppl": "1.24", "wps": "1676.2", "ups": "2.55", "wpb": "656.1", "bsz": "16", "num_updates": "14300", "lr": "4.93097e-05", "gnorm": "0.748", "train_wall": "39", "wall": "9224"}
2022-10-31 02:02:31 | INFO | train_inner | {"epoch": 5, "update": 4.935, "loss": "2.187", "nll_loss": "0.315", "ppl": "1.24", "wps": "1572.9", "ups": "2.42", "wpb": "650.7", "bsz": "16", "num_updates": "14400", "lr": "4.93047e-05", "gnorm": "0.761", "train_wall": "41", "wall": "9266"}
2022-10-31 02:03:08 | INFO | train_inner | {"epoch": 5, "update": 4.969, "loss": "2.191", "nll_loss": "0.319", "ppl": "1.25", "wps": "1745.3", "ups": "2.77", "wpb": "629.3", "bsz": "16", "num_updates": "14500", "lr": "4.92996e-05", "gnorm": "0.752", "train_wall": "36", "wall": "9302"}
2022-10-31 02:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 02:17:22 | INFO | valid | {"epoch": 5, "valid_loss": "2.251", "valid_nll_loss": "0.312", "valid_ppl": "1.24", "valid_bleu": "72.48", "valid_wps": "283.5", "valid_wpb": "159", "valid_bsz": "4", "valid_num_updates": "14590", "valid_best_bleu": "77.74"}
2022-10-31 02:17:22 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 02:17:30 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_last.pt (epoch 5 @ 14590 updates, score 72.48) (writing took 8.651310926768929 seconds)
2022-10-31 02:17:30 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-10-31 02:17:30 | INFO | train | {"epoch": 5, "train_loss": "2.188", "train_nll_loss": "0.315", "train_ppl": "1.24", "train_wps": "920.6", "train_ups": "1.45", "train_wpb": "633.6", "train_bsz": "16", "train_num_updates": "14590", "train_lr": "4.92951e-05", "train_gnorm": "0.777", "train_train_wall": "1167", "train_wall": "10164"}
2022-10-31 02:17:30 | INFO | fairseq.trainer | begin training epoch 6
2022-10-31 02:17:34 | INFO | train_inner | {"epoch": 6, "update": 5.003, "loss": "2.191", "nll_loss": "0.319", "ppl": "1.25", "wps": "72.7", "ups": "0.12", "wpb": "629.8", "bsz": "15.9", "num_updates": "14600", "lr": "4.92946e-05", "gnorm": "0.812", "train_wall": "39", "wall": "10168"}
2022-10-31 02:18:08 | INFO | train_inner | {"epoch": 6, "update": 5.038, "loss": "2.164", "nll_loss": "0.288", "ppl": "1.22", "wps": "1888.6", "ups": "2.94", "wpb": "641.9", "bsz": "16", "num_updates": "14700", "lr": "4.92896e-05", "gnorm": "0.679", "train_wall": "34", "wall": "10202"}
2022-10-31 02:18:49 | INFO | train_inner | {"epoch": 6, "update": 5.072, "loss": "2.17", "nll_loss": "0.294", "ppl": "1.23", "wps": "1543.6", "ups": "2.48", "wpb": "623.5", "bsz": "16", "num_updates": "14800", "lr": "4.92846e-05", "gnorm": "0.764", "train_wall": "40", "wall": "10243"}
2022-10-31 02:19:34 | INFO | train_inner | {"epoch": 6, "update": 5.106, "loss": "2.166", "nll_loss": "0.291", "ppl": "1.22", "wps": "1437.1", "ups": "2.23", "wpb": "644.5", "bsz": "16", "num_updates": "14900", "lr": "4.92796e-05", "gnorm": "0.774", "train_wall": "44", "wall": "10288"}
2022-10-31 02:20:19 | INFO | train_inner | {"epoch": 6, "update": 5.141, "loss": "2.167", "nll_loss": "0.291", "ppl": "1.22", "wps": "1393.2", "ups": "2.22", "wpb": "628.6", "bsz": "16", "num_updates": "15000", "lr": "4.92746e-05", "gnorm": "0.758", "train_wall": "45", "wall": "10333"}
2022-10-31 02:20:59 | INFO | train_inner | {"epoch": 6, "update": 5.175, "loss": "2.175", "nll_loss": "0.3", "ppl": "1.23", "wps": "1565.7", "ups": "2.47", "wpb": "633.3", "bsz": "16", "num_updates": "15100", "lr": "4.92696e-05", "gnorm": "0.751", "train_wall": "40", "wall": "10373"}
2022-10-31 02:21:42 | INFO | train_inner | {"epoch": 6, "update": 5.209, "loss": "2.17", "nll_loss": "0.295", "ppl": "1.23", "wps": "1454.9", "ups": "2.32", "wpb": "627.9", "bsz": "16", "num_updates": "15200", "lr": "4.92646e-05", "gnorm": "0.795", "train_wall": "43", "wall": "10416"}
2022-10-31 02:22:24 | INFO | train_inner | {"epoch": 6, "update": 5.243, "loss": "2.165", "nll_loss": "0.29", "ppl": "1.22", "wps": "1542.8", "ups": "2.39", "wpb": "646.5", "bsz": "16", "num_updates": "15300", "lr": "4.92596e-05", "gnorm": "0.789", "train_wall": "41", "wall": "10458"}
2022-10-31 02:23:02 | INFO | train_inner | {"epoch": 6, "update": 5.278, "loss": "2.174", "nll_loss": "0.3", "ppl": "1.23", "wps": "1708.6", "ups": "2.64", "wpb": "648.1", "bsz": "16", "num_updates": "15400", "lr": "4.92546e-05", "gnorm": "0.785", "train_wall": "37", "wall": "10496"}
2022-10-31 02:23:43 | INFO | train_inner | {"epoch": 6, "update": 5.312, "loss": "2.169", "nll_loss": "0.294", "ppl": "1.23", "wps": "1537", "ups": "2.44", "wpb": "630.3", "bsz": "16", "num_updates": "15500", "lr": "4.92496e-05", "gnorm": "0.799", "train_wall": "41", "wall": "10537"}
2022-10-31 02:24:21 | INFO | train_inner | {"epoch": 6, "update": 5.346, "loss": "2.177", "nll_loss": "0.303", "ppl": "1.23", "wps": "1655.8", "ups": "2.61", "wpb": "635.1", "bsz": "16", "num_updates": "15600", "lr": "4.92446e-05", "gnorm": "0.778", "train_wall": "38", "wall": "10575"}
2022-10-31 02:25:00 | INFO | train_inner | {"epoch": 6, "update": 5.38, "loss": "2.169", "nll_loss": "0.294", "ppl": "1.23", "wps": "1671.6", "ups": "2.63", "wpb": "636.8", "bsz": "16", "num_updates": "15700", "lr": "4.92396e-05", "gnorm": "0.792", "train_wall": "38", "wall": "10614"}
2022-10-31 02:25:40 | INFO | train_inner | {"epoch": 6, "update": 5.415, "loss": "2.176", "nll_loss": "0.302", "ppl": "1.23", "wps": "1596.2", "ups": "2.5", "wpb": "637.8", "bsz": "16", "num_updates": "15800", "lr": "4.92346e-05", "gnorm": "0.788", "train_wall": "39", "wall": "10654"}
2022-10-31 02:26:16 | INFO | train_inner | {"epoch": 6, "update": 5.449, "loss": "2.177", "nll_loss": "0.303", "ppl": "1.23", "wps": "1674.8", "ups": "2.76", "wpb": "606", "bsz": "16", "num_updates": "15900", "lr": "4.92296e-05", "gnorm": "0.815", "train_wall": "36", "wall": "10690"}
2022-10-31 02:26:54 | INFO | train_inner | {"epoch": 6, "update": 5.483, "loss": "2.17", "nll_loss": "0.296", "ppl": "1.23", "wps": "1718", "ups": "2.6", "wpb": "660.6", "bsz": "16", "num_updates": "16000", "lr": "4.92246e-05", "gnorm": "0.754", "train_wall": "38", "wall": "10728"}
2022-10-31 02:27:36 | INFO | train_inner | {"epoch": 6, "update": 5.517, "loss": "2.169", "nll_loss": "0.295", "ppl": "1.23", "wps": "1511.4", "ups": "2.4", "wpb": "628.7", "bsz": "16", "num_updates": "16100", "lr": "4.92196e-05", "gnorm": "0.757", "train_wall": "41", "wall": "10770"}
2022-10-31 02:28:16 | INFO | train_inner | {"epoch": 6, "update": 5.552, "loss": "2.169", "nll_loss": "0.295", "ppl": "1.23", "wps": "1572", "ups": "2.49", "wpb": "631.5", "bsz": "16", "num_updates": "16200", "lr": "4.92146e-05", "gnorm": "0.773", "train_wall": "40", "wall": "10810"}
2022-10-31 02:28:58 | INFO | train_inner | {"epoch": 6, "update": 5.586, "loss": "2.177", "nll_loss": "0.304", "ppl": "1.23", "wps": "1479", "ups": "2.35", "wpb": "628.8", "bsz": "16", "num_updates": "16300", "lr": "4.92096e-05", "gnorm": "0.778", "train_wall": "42", "wall": "10852"}
2022-10-31 02:29:40 | INFO | train_inner | {"epoch": 6, "update": 5.62, "loss": "2.181", "nll_loss": "0.308", "ppl": "1.24", "wps": "1525.3", "ups": "2.38", "wpb": "640", "bsz": "16", "num_updates": "16400", "lr": "4.92046e-05", "gnorm": "0.806", "train_wall": "41", "wall": "10894"}
2022-10-31 02:30:21 | INFO | train_inner | {"epoch": 6, "update": 5.655, "loss": "2.173", "nll_loss": "0.299", "ppl": "1.23", "wps": "1590.6", "ups": "2.48", "wpb": "642.2", "bsz": "16", "num_updates": "16500", "lr": "4.91996e-05", "gnorm": "0.751", "train_wall": "40", "wall": "10935"}
2022-10-31 02:31:03 | INFO | train_inner | {"epoch": 6, "update": 5.689, "loss": "2.181", "nll_loss": "0.308", "ppl": "1.24", "wps": "1511.6", "ups": "2.39", "wpb": "632.8", "bsz": "16", "num_updates": "16600", "lr": "4.91946e-05", "gnorm": "0.798", "train_wall": "41", "wall": "10977"}
2022-10-31 02:31:43 | INFO | train_inner | {"epoch": 6, "update": 5.723, "loss": "2.173", "nll_loss": "0.299", "ppl": "1.23", "wps": "1611", "ups": "2.49", "wpb": "645.8", "bsz": "16", "num_updates": "16700", "lr": "4.91896e-05", "gnorm": "0.841", "train_wall": "40", "wall": "11017"}
2022-10-31 02:32:26 | INFO | train_inner | {"epoch": 6, "update": 5.757, "loss": "2.173", "nll_loss": "0.3", "ppl": "1.23", "wps": "1491", "ups": "2.33", "wpb": "639.1", "bsz": "16", "num_updates": "16800", "lr": "4.91846e-05", "gnorm": "0.754", "train_wall": "42", "wall": "11060"}
2022-10-31 02:33:08 | INFO | train_inner | {"epoch": 6, "update": 5.792, "loss": "2.178", "nll_loss": "0.305", "ppl": "1.24", "wps": "1489.9", "ups": "2.37", "wpb": "628.4", "bsz": "16", "num_updates": "16900", "lr": "4.91796e-05", "gnorm": "0.799", "train_wall": "42", "wall": "11102"}
2022-10-31 02:33:47 | INFO | train_inner | {"epoch": 6, "update": 5.826, "loss": "2.176", "nll_loss": "0.302", "ppl": "1.23", "wps": "1582.2", "ups": "2.54", "wpb": "623.3", "bsz": "16", "num_updates": "17000", "lr": "4.91746e-05", "gnorm": "0.77", "train_wall": "39", "wall": "11141"}
2022-10-31 02:34:21 | INFO | train_inner | {"epoch": 6, "update": 5.86, "loss": "2.175", "nll_loss": "0.302", "ppl": "1.23", "wps": "1875.4", "ups": "2.94", "wpb": "638", "bsz": "16", "num_updates": "17100", "lr": "4.91696e-05", "gnorm": "0.77", "train_wall": "34", "wall": "11175"}
2022-10-31 02:34:59 | INFO | train_inner | {"epoch": 6, "update": 5.894, "loss": "2.179", "nll_loss": "0.306", "ppl": "1.24", "wps": "1725.6", "ups": "2.66", "wpb": "648.4", "bsz": "16", "num_updates": "17200", "lr": "4.91646e-05", "gnorm": "0.768", "train_wall": "37", "wall": "11213"}
2022-10-31 02:35:34 | INFO | train_inner | {"epoch": 6, "update": 5.929, "loss": "2.179", "nll_loss": "0.306", "ppl": "1.24", "wps": "1788", "ups": "2.84", "wpb": "630.5", "bsz": "16", "num_updates": "17300", "lr": "4.91596e-05", "gnorm": "0.836", "train_wall": "35", "wall": "11248"}
2022-10-31 02:36:17 | INFO | train_inner | {"epoch": 6, "update": 5.963, "loss": "2.182", "nll_loss": "0.309", "ppl": "1.24", "wps": "1385.7", "ups": "2.31", "wpb": "600.8", "bsz": "16", "num_updates": "17400", "lr": "4.91546e-05", "gnorm": "0.801", "train_wall": "43", "wall": "11291"}
2022-10-31 02:37:03 | INFO | train_inner | {"epoch": 6, "update": 5.997, "loss": "2.179", "nll_loss": "0.306", "ppl": "1.24", "wps": "1351.6", "ups": "2.19", "wpb": "618.2", "bsz": "16", "num_updates": "17500", "lr": "4.91496e-05", "gnorm": "0.801", "train_wall": "45", "wall": "11337"}
2022-10-31 02:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 02:51:14 | INFO | valid | {"epoch": 6, "valid_loss": "2.249", "valid_nll_loss": "0.313", "valid_ppl": "1.24", "valid_bleu": "73.1", "valid_wps": "273.7", "valid_wpb": "159", "valid_bsz": "4", "valid_num_updates": "17508", "valid_best_bleu": "77.74"}
2022-10-31 02:51:14 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 02:51:23 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_last.pt (epoch 6 @ 17508 updates, score 73.1) (writing took 8.858718148898333 seconds)
2022-10-31 02:51:23 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-10-31 02:51:23 | INFO | train | {"epoch": 6, "train_loss": "2.173", "train_nll_loss": "0.299", "train_ppl": "1.23", "train_wps": "909.5", "train_ups": "1.44", "train_wpb": "633.6", "train_bsz": "16", "train_num_updates": "17508", "train_lr": "4.91492e-05", "train_gnorm": "0.78", "train_train_wall": "1162", "train_wall": "12197"}
2022-10-31 02:51:23 | INFO | fairseq.trainer | begin training epoch 7
2022-10-31 02:51:58 | INFO | train_inner | {"epoch": 7, "update": 6.032, "loss": "2.15", "nll_loss": "0.273", "ppl": "1.21", "wps": "72.1", "ups": "0.11", "wpb": "645.7", "bsz": "15.9", "num_updates": "17600", "lr": "4.91446e-05", "gnorm": "0.713", "train_wall": "38", "wall": "12232"}
2022-10-31 02:52:39 | INFO | train_inner | {"epoch": 7, "update": 6.066, "loss": "2.152", "nll_loss": "0.275", "ppl": "1.21", "wps": "1577.3", "ups": "2.49", "wpb": "633.7", "bsz": "16", "num_updates": "17700", "lr": "4.91396e-05", "gnorm": "0.773", "train_wall": "40", "wall": "12273"}
2022-10-31 02:53:19 | INFO | train_inner | {"epoch": 7, "update": 6.1, "loss": "2.157", "nll_loss": "0.281", "ppl": "1.22", "wps": "1540.4", "ups": "2.47", "wpb": "623.6", "bsz": "16", "num_updates": "17800", "lr": "4.91346e-05", "gnorm": "0.785", "train_wall": "40", "wall": "12313"}
2022-10-31 02:54:01 | INFO | train_inner | {"epoch": 7, "update": 6.134, "loss": "2.152", "nll_loss": "0.276", "ppl": "1.21", "wps": "1525.4", "ups": "2.41", "wpb": "631.8", "bsz": "16", "num_updates": "17900", "lr": "4.91296e-05", "gnorm": "0.78", "train_wall": "41", "wall": "12355"}
2022-10-31 02:54:44 | INFO | train_inner | {"epoch": 7, "update": 6.169, "loss": "2.157", "nll_loss": "0.281", "ppl": "1.22", "wps": "1539.5", "ups": "2.32", "wpb": "664.6", "bsz": "16", "num_updates": "18000", "lr": "4.91246e-05", "gnorm": "0.778", "train_wall": "43", "wall": "12398"}
2022-10-31 02:55:29 | INFO | train_inner | {"epoch": 7, "update": 6.203, "loss": "2.154", "nll_loss": "0.278", "ppl": "1.21", "wps": "1424", "ups": "2.2", "wpb": "645.9", "bsz": "16", "num_updates": "18100", "lr": "4.91196e-05", "gnorm": "0.764", "train_wall": "45", "wall": "12443"}
2022-10-31 02:56:11 | INFO | train_inner | {"epoch": 7, "update": 6.237, "loss": "2.162", "nll_loss": "0.287", "ppl": "1.22", "wps": "1477.2", "ups": "2.39", "wpb": "616.8", "bsz": "16", "num_updates": "18200", "lr": "4.91146e-05", "gnorm": "0.83", "train_wall": "41", "wall": "12485"}
2022-10-31 02:56:53 | INFO | train_inner | {"epoch": 7, "update": 6.271, "loss": "2.158", "nll_loss": "0.282", "ppl": "1.22", "wps": "1518.8", "ups": "2.38", "wpb": "637.8", "bsz": "16", "num_updates": "18300", "lr": "4.91096e-05", "gnorm": "0.798", "train_wall": "41", "wall": "12527"}
2022-10-31 02:57:37 | INFO | train_inner | {"epoch": 7, "update": 6.306, "loss": "2.159", "nll_loss": "0.283", "ppl": "1.22", "wps": "1487.7", "ups": "2.25", "wpb": "660.5", "bsz": "16", "num_updates": "18400", "lr": "4.91046e-05", "gnorm": "0.794", "train_wall": "44", "wall": "12571"}
2022-10-31 02:58:22 | INFO | train_inner | {"epoch": 7, "update": 6.34, "loss": "2.156", "nll_loss": "0.28", "ppl": "1.21", "wps": "1446", "ups": "2.22", "wpb": "650.6", "bsz": "16", "num_updates": "18500", "lr": "4.90995e-05", "gnorm": "0.814", "train_wall": "44", "wall": "12616"}
2022-10-31 02:59:09 | INFO | train_inner | {"epoch": 7, "update": 6.374, "loss": "2.159", "nll_loss": "0.284", "ppl": "1.22", "wps": "1324.4", "ups": "2.14", "wpb": "618.4", "bsz": "16", "num_updates": "18600", "lr": "4.90945e-05", "gnorm": "0.805", "train_wall": "46", "wall": "12663"}
2022-10-31 02:59:55 | INFO | train_inner | {"epoch": 7, "update": 6.408, "loss": "2.171", "nll_loss": "0.296", "ppl": "1.23", "wps": "1371.4", "ups": "2.19", "wpb": "626.9", "bsz": "16", "num_updates": "18700", "lr": "4.90895e-05", "gnorm": "0.83", "train_wall": "45", "wall": "12709"}
2022-10-31 03:00:36 | INFO | train_inner | {"epoch": 7, "update": 6.443, "loss": "2.161", "nll_loss": "0.287", "ppl": "1.22", "wps": "1539.4", "ups": "2.42", "wpb": "637.1", "bsz": "16", "num_updates": "18800", "lr": "4.90845e-05", "gnorm": "0.784", "train_wall": "41", "wall": "12750"}
2022-10-31 03:01:22 | INFO | train_inner | {"epoch": 7, "update": 6.477, "loss": "2.16", "nll_loss": "0.285", "ppl": "1.22", "wps": "1384.3", "ups": "2.18", "wpb": "634.6", "bsz": "16", "num_updates": "18900", "lr": "4.90795e-05", "gnorm": "0.759", "train_wall": "45", "wall": "12796"}
2022-10-31 03:02:05 | INFO | train_inner | {"epoch": 7, "update": 6.511, "loss": "2.166", "nll_loss": "0.291", "ppl": "1.22", "wps": "1444.7", "ups": "2.31", "wpb": "624.6", "bsz": "16", "num_updates": "19000", "lr": "4.90745e-05", "gnorm": "0.802", "train_wall": "43", "wall": "12839"}
2022-10-31 03:02:50 | INFO | train_inner | {"epoch": 7, "update": 6.546, "loss": "2.16", "nll_loss": "0.285", "ppl": "1.22", "wps": "1420", "ups": "2.23", "wpb": "636.9", "bsz": "16", "num_updates": "19100", "lr": "4.90695e-05", "gnorm": "0.765", "train_wall": "44", "wall": "12884"}
2022-10-31 03:03:27 | INFO | train_inner | {"epoch": 7, "update": 6.58, "loss": "2.163", "nll_loss": "0.289", "ppl": "1.22", "wps": "1699.9", "ups": "2.67", "wpb": "637.1", "bsz": "16", "num_updates": "19200", "lr": "4.90645e-05", "gnorm": "0.825", "train_wall": "37", "wall": "12921"}
2022-10-31 03:04:05 | INFO | train_inner | {"epoch": 7, "update": 6.614, "loss": "2.161", "nll_loss": "0.287", "ppl": "1.22", "wps": "1680.5", "ups": "2.68", "wpb": "626.8", "bsz": "16", "num_updates": "19300", "lr": "4.90595e-05", "gnorm": "0.831", "train_wall": "37", "wall": "12959"}
2022-10-31 03:04:44 | INFO | train_inner | {"epoch": 7, "update": 6.648, "loss": "2.165", "nll_loss": "0.29", "ppl": "1.22", "wps": "1608.8", "ups": "2.52", "wpb": "639.6", "bsz": "16", "num_updates": "19400", "lr": "4.90545e-05", "gnorm": "0.877", "train_wall": "39", "wall": "12998"}
2022-10-31 03:05:24 | INFO | train_inner | {"epoch": 7, "update": 6.683, "loss": "2.167", "nll_loss": "0.293", "ppl": "1.22", "wps": "1577.8", "ups": "2.53", "wpb": "623", "bsz": "16", "num_updates": "19500", "lr": "4.90495e-05", "gnorm": "0.794", "train_wall": "39", "wall": "13038"}
2022-10-31 03:06:00 | INFO | train_inner | {"epoch": 7, "update": 6.717, "loss": "2.162", "nll_loss": "0.288", "ppl": "1.22", "wps": "1792", "ups": "2.77", "wpb": "648", "bsz": "16", "num_updates": "19600", "lr": "4.90445e-05", "gnorm": "0.786", "train_wall": "36", "wall": "13074"}
2022-10-31 03:06:39 | INFO | train_inner | {"epoch": 7, "update": 6.751, "loss": "2.171", "nll_loss": "0.297", "ppl": "1.23", "wps": "1584.9", "ups": "2.6", "wpb": "610.5", "bsz": "16", "num_updates": "19700", "lr": "4.90395e-05", "gnorm": "0.828", "train_wall": "38", "wall": "13113"}
2022-10-31 03:07:13 | INFO | train_inner | {"epoch": 7, "update": 6.785, "loss": "2.165", "nll_loss": "0.291", "ppl": "1.22", "wps": "1814.8", "ups": "2.87", "wpb": "632", "bsz": "16", "num_updates": "19800", "lr": "4.90345e-05", "gnorm": "0.795", "train_wall": "34", "wall": "13147"}
2022-10-31 03:07:52 | INFO | train_inner | {"epoch": 7, "update": 6.82, "loss": "2.161", "nll_loss": "0.286", "ppl": "1.22", "wps": "1593.1", "ups": "2.58", "wpb": "618.3", "bsz": "16", "num_updates": "19900", "lr": "4.90295e-05", "gnorm": "0.86", "train_wall": "38", "wall": "13186"}
2022-10-31 03:08:31 | INFO | train_inner | {"epoch": 7, "update": 6.854, "loss": "2.16", "nll_loss": "0.286", "ppl": "1.22", "wps": "1609.9", "ups": "2.55", "wpb": "630.6", "bsz": "16", "num_updates": "20000", "lr": "4.90245e-05", "gnorm": "0.828", "train_wall": "39", "wall": "13225"}
2022-10-31 03:09:10 | INFO | train_inner | {"epoch": 7, "update": 6.888, "loss": "2.163", "nll_loss": "0.288", "ppl": "1.22", "wps": "1618.9", "ups": "2.59", "wpb": "626.2", "bsz": "16", "num_updates": "20100", "lr": "4.90195e-05", "gnorm": "0.815", "train_wall": "38", "wall": "13264"}
2022-10-31 03:09:48 | INFO | train_inner | {"epoch": 7, "update": 6.923, "loss": "2.163", "nll_loss": "0.288", "ppl": "1.22", "wps": "1692.2", "ups": "2.62", "wpb": "645.1", "bsz": "16", "num_updates": "20200", "lr": "4.90145e-05", "gnorm": "0.824", "train_wall": "38", "wall": "13302"}
2022-10-31 03:10:29 | INFO | train_inner | {"epoch": 7, "update": 6.957, "loss": "2.163", "nll_loss": "0.289", "ppl": "1.22", "wps": "1533.5", "ups": "2.47", "wpb": "622.1", "bsz": "16", "num_updates": "20300", "lr": "4.90095e-05", "gnorm": "0.794", "train_wall": "40", "wall": "13343"}
2022-10-31 03:11:11 | INFO | train_inner | {"epoch": 7, "update": 6.991, "loss": "2.172", "nll_loss": "0.299", "ppl": "1.23", "wps": "1515", "ups": "2.38", "wpb": "635.8", "bsz": "16", "num_updates": "20400", "lr": "4.90045e-05", "gnorm": "0.819", "train_wall": "41", "wall": "13385"}
2022-10-31 03:11:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 03:25:08 | INFO | valid | {"epoch": 7, "valid_loss": "2.26", "valid_nll_loss": "0.327", "valid_ppl": "1.25", "valid_bleu": "73.17", "valid_wps": "281", "valid_wpb": "159", "valid_bsz": "4", "valid_num_updates": "20426", "valid_best_bleu": "77.74"}
2022-10-31 03:25:08 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 5 runs
2022-10-31 03:25:08 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 03:25:16 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_last.pt (epoch 7 @ 20426 updates, score 73.17) (writing took 8.526324352715164 seconds)
2022-10-31 03:25:16 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-10-31 03:25:16 | INFO | train | {"epoch": 7, "train_loss": "2.161", "train_nll_loss": "0.286", "train_ppl": "1.22", "train_wps": "909.5", "train_ups": "1.44", "train_wpb": "633.6", "train_bsz": "16", "train_num_updates": "20426", "train_lr": "4.90032e-05", "train_gnorm": "0.801", "train_train_wall": "1184", "train_wall": "14230"}
2022-10-31 03:25:16 | INFO | fairseq_cli.train | done training in 14228.3 seconds
BLEU: 77.49 ; Acc: 17.6
Medium Dataset:
---------------------------------------------------------------------------------------------
Source: source Target: target
2022-10-31 03:28:53 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.1, batch_size=4, batch_size_valid=4, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, extra_lang_symbol='', fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/home/y_shi202/related-project/MODIT/models/pretrained/checkpoints/checkpoint_11_100000.pt', save_dir='/home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1234, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_in_same_language', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[4], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='/home/y_shi202/related-project/MODIT/src', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=500, weight_decay=0.0, zero_sharding='none')
2022-10-31 03:28:53 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2022-10-31 03:28:53 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2022-10-31 03:28:53 | INFO | fairseq.data.data_utils | loaded 6546 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/valid.source-target.source
2022-10-31 03:28:53 | INFO | fairseq.data.data_utils | loaded 6546 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/valid.source-target.target
2022-10-31 03:28:53 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin valid source-target 6546 examples
2022-10-31 03:28:58 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2022-10-31 03:28:58 | INFO | fairseq_cli.train | task: translation_in_same_language (TranslationCodeBARTTask)
2022-10-31 03:28:58 | INFO | fairseq_cli.train | model: mbart_base (BARTModel)
2022-10-31 03:28:58 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2022-10-31 03:28:58 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2022-10-31 03:29:01 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-31 03:29:01 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-31 03:29:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-10-31 03:29:01 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-PCIE-32GB                    
2022-10-31 03:29:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-10-31 03:29:01 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-10-31 03:29:01 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 4
2022-10-31 03:29:03 | INFO | fairseq.trainer | loaded checkpoint /home/y_shi202/related-project/MODIT/models/pretrained/checkpoints/checkpoint_11_100000.pt (epoch 11 @ 0 updates)
2022-10-31 03:29:03 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2022-10-31 03:29:03 | INFO | fairseq.trainer | loading train data for epoch 1
2022-10-31 03:29:03 | INFO | fairseq.data.data_utils | loaded 52364 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/train.source-target.source
2022-10-31 03:29:03 | INFO | fairseq.data.data_utils | loaded 52364 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/train.source-target.target
2022-10-31 03:29:03 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin train source-target 52364 examples
2022-10-31 03:29:03 | INFO | fairseq.trainer | begin training epoch 1
2022-10-31 03:29:42 | INFO | train_inner | {"epoch": 1, "update": 0.031, "loss": "4.039", "nll_loss": "1.518", "ppl": "2.86", "wps": "4056.1", "ups": "2.58", "wpb": "1573.8", "bsz": "16", "num_updates": "100", "lr": "1e-05", "gnorm": "20.399", "train_wall": "38", "wall": "41"}
2022-10-31 03:30:22 | INFO | train_inner | {"epoch": 1, "update": 0.061, "loss": "2.454", "nll_loss": "0.453", "ppl": "1.37", "wps": "3906.2", "ups": "2.46", "wpb": "1587.2", "bsz": "16", "num_updates": "200", "lr": "2e-05", "gnorm": "1.5", "train_wall": "40", "wall": "82"}
2022-10-31 03:31:06 | INFO | train_inner | {"epoch": 1, "update": 0.092, "loss": "2.316", "nll_loss": "0.376", "ppl": "1.3", "wps": "3602.9", "ups": "2.29", "wpb": "1571", "bsz": "16", "num_updates": "300", "lr": "3e-05", "gnorm": "0.994", "train_wall": "43", "wall": "125"}
2022-10-31 03:31:43 | INFO | train_inner | {"epoch": 1, "update": 0.122, "loss": "2.268", "nll_loss": "0.35", "ppl": "1.27", "wps": "4324", "ups": "2.7", "wpb": "1604.2", "bsz": "16", "num_updates": "400", "lr": "4e-05", "gnorm": "0.866", "train_wall": "37", "wall": "162"}
2022-10-31 03:32:24 | INFO | train_inner | {"epoch": 1, "update": 0.153, "loss": "2.248", "nll_loss": "0.341", "ppl": "1.27", "wps": "3853.3", "ups": "2.45", "wpb": "1572.3", "bsz": "16", "num_updates": "500", "lr": "5e-05", "gnorm": "0.967", "train_wall": "40", "wall": "203"}
2022-10-31 03:33:06 | INFO | train_inner | {"epoch": 1, "update": 0.183, "loss": "2.237", "nll_loss": "0.337", "ppl": "1.26", "wps": "3694.1", "ups": "2.35", "wpb": "1569.9", "bsz": "16", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "0.81", "train_wall": "42", "wall": "246"}
2022-10-31 03:33:49 | INFO | train_inner | {"epoch": 1, "update": 0.214, "loss": "2.23", "nll_loss": "0.334", "ppl": "1.26", "wps": "3631.2", "ups": "2.34", "wpb": "1552.7", "bsz": "16", "num_updates": "700", "lr": "4.999e-05", "gnorm": "0.847", "train_wall": "42", "wall": "288"}
2022-10-31 03:34:31 | INFO | train_inner | {"epoch": 1, "update": 0.244, "loss": "2.223", "nll_loss": "0.33", "ppl": "1.26", "wps": "3753.7", "ups": "2.4", "wpb": "1566.6", "bsz": "16", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "0.775", "train_wall": "41", "wall": "330"}
2022-10-31 03:35:15 | INFO | train_inner | {"epoch": 1, "update": 0.275, "loss": "2.218", "nll_loss": "0.327", "ppl": "1.25", "wps": "3549.7", "ups": "2.25", "wpb": "1575.8", "bsz": "16", "num_updates": "900", "lr": "4.998e-05", "gnorm": "0.757", "train_wall": "44", "wall": "374"}
2022-10-31 03:36:01 | INFO | train_inner | {"epoch": 1, "update": 0.306, "loss": "2.215", "nll_loss": "0.326", "ppl": "1.25", "wps": "3527.3", "ups": "2.21", "wpb": "1597.6", "bsz": "16", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "0.781", "train_wall": "45", "wall": "420"}
2022-10-31 03:36:49 | INFO | train_inner | {"epoch": 1, "update": 0.336, "loss": "2.212", "nll_loss": "0.324", "ppl": "1.25", "wps": "3177.8", "ups": "2.06", "wpb": "1539.5", "bsz": "16", "num_updates": "1100", "lr": "4.997e-05", "gnorm": "0.745", "train_wall": "48", "wall": "468"}
2022-10-31 03:37:29 | INFO | train_inner | {"epoch": 1, "update": 0.367, "loss": "2.206", "nll_loss": "0.32", "ppl": "1.25", "wps": "4000", "ups": "2.54", "wpb": "1577.3", "bsz": "16", "num_updates": "1200", "lr": "4.9965e-05", "gnorm": "0.701", "train_wall": "39", "wall": "508"}
2022-10-31 03:38:13 | INFO | train_inner | {"epoch": 1, "update": 0.397, "loss": "2.203", "nll_loss": "0.318", "ppl": "1.25", "wps": "3482.6", "ups": "2.25", "wpb": "1547", "bsz": "16", "num_updates": "1300", "lr": "4.996e-05", "gnorm": "0.683", "train_wall": "44", "wall": "552"}
2022-10-31 03:39:01 | INFO | train_inner | {"epoch": 1, "update": 0.428, "loss": "2.204", "nll_loss": "0.32", "ppl": "1.25", "wps": "3252.5", "ups": "2.1", "wpb": "1547.5", "bsz": "16", "num_updates": "1400", "lr": "4.9955e-05", "gnorm": "0.66", "train_wall": "47", "wall": "600"}
2022-10-31 03:39:46 | INFO | train_inner | {"epoch": 1, "update": 0.458, "loss": "2.2", "nll_loss": "0.316", "ppl": "1.25", "wps": "3484.1", "ups": "2.19", "wpb": "1592.4", "bsz": "16", "num_updates": "1500", "lr": "4.995e-05", "gnorm": "0.632", "train_wall": "45", "wall": "645"}
2022-10-31 03:40:27 | INFO | train_inner | {"epoch": 1, "update": 0.489, "loss": "2.192", "nll_loss": "0.309", "ppl": "1.24", "wps": "3840", "ups": "2.43", "wpb": "1582", "bsz": "16", "num_updates": "1600", "lr": "4.9945e-05", "gnorm": "0.636", "train_wall": "41", "wall": "687"}
2022-10-31 03:41:13 | INFO | train_inner | {"epoch": 1, "update": 0.519, "loss": "2.195", "nll_loss": "0.312", "ppl": "1.24", "wps": "3451.4", "ups": "2.19", "wpb": "1578", "bsz": "16", "num_updates": "1700", "lr": "4.994e-05", "gnorm": "0.597", "train_wall": "45", "wall": "732"}
2022-10-31 03:41:53 | INFO | train_inner | {"epoch": 1, "update": 0.55, "loss": "2.194", "nll_loss": "0.312", "ppl": "1.24", "wps": "3950", "ups": "2.49", "wpb": "1584.8", "bsz": "16", "num_updates": "1800", "lr": "4.9935e-05", "gnorm": "0.605", "train_wall": "40", "wall": "772"}
2022-10-31 03:42:35 | INFO | train_inner | {"epoch": 1, "update": 0.581, "loss": "2.191", "nll_loss": "0.309", "ppl": "1.24", "wps": "3707.1", "ups": "2.38", "wpb": "1555.1", "bsz": "16", "num_updates": "1900", "lr": "4.993e-05", "gnorm": "0.669", "train_wall": "41", "wall": "814"}
2022-10-31 03:43:18 | INFO | train_inner | {"epoch": 1, "update": 0.611, "loss": "2.192", "nll_loss": "0.311", "ppl": "1.24", "wps": "3759.6", "ups": "2.35", "wpb": "1597", "bsz": "16", "num_updates": "2000", "lr": "4.9925e-05", "gnorm": "0.589", "train_wall": "42", "wall": "857"}
2022-10-31 03:44:00 | INFO | train_inner | {"epoch": 1, "update": 0.642, "loss": "2.199", "nll_loss": "0.319", "ppl": "1.25", "wps": "3663.4", "ups": "2.34", "wpb": "1566.3", "bsz": "16", "num_updates": "2100", "lr": "4.992e-05", "gnorm": "0.701", "train_wall": "42", "wall": "900"}
2022-10-31 03:44:35 | INFO | train_inner | {"epoch": 1, "update": 0.672, "loss": "2.185", "nll_loss": "0.304", "ppl": "1.23", "wps": "4615.5", "ups": "2.86", "wpb": "1614.9", "bsz": "16", "num_updates": "2200", "lr": "4.9915e-05", "gnorm": "0.541", "train_wall": "35", "wall": "935"}
2022-10-31 03:45:11 | INFO | train_inner | {"epoch": 1, "update": 0.703, "loss": "2.189", "nll_loss": "0.308", "ppl": "1.24", "wps": "4338.6", "ups": "2.78", "wpb": "1558.6", "bsz": "16", "num_updates": "2300", "lr": "4.991e-05", "gnorm": "0.54", "train_wall": "36", "wall": "970"}
2022-10-31 03:45:49 | INFO | train_inner | {"epoch": 1, "update": 0.733, "loss": "2.183", "nll_loss": "0.302", "ppl": "1.23", "wps": "4164", "ups": "2.65", "wpb": "1573.3", "bsz": "16", "num_updates": "2400", "lr": "4.9905e-05", "gnorm": "0.643", "train_wall": "37", "wall": "1008"}
2022-10-31 03:46:30 | INFO | train_inner | {"epoch": 1, "update": 0.764, "loss": "2.186", "nll_loss": "0.307", "ppl": "1.24", "wps": "3822.7", "ups": "2.43", "wpb": "1570.4", "bsz": "16", "num_updates": "2500", "lr": "4.98999e-05", "gnorm": "0.586", "train_wall": "41", "wall": "1049"}
2022-10-31 03:47:14 | INFO | train_inner | {"epoch": 1, "update": 0.794, "loss": "2.189", "nll_loss": "0.31", "ppl": "1.24", "wps": "3666.9", "ups": "2.31", "wpb": "1589.8", "bsz": "16", "num_updates": "2600", "lr": "4.98949e-05", "gnorm": "0.592", "train_wall": "43", "wall": "1093"}
2022-10-31 03:47:51 | INFO | train_inner | {"epoch": 1, "update": 0.825, "loss": "2.185", "nll_loss": "0.305", "ppl": "1.24", "wps": "4163.5", "ups": "2.67", "wpb": "1561.6", "bsz": "16", "num_updates": "2700", "lr": "4.98899e-05", "gnorm": "0.586", "train_wall": "37", "wall": "1130"}
2022-10-31 03:48:24 | INFO | train_inner | {"epoch": 1, "update": 0.855, "loss": "2.179", "nll_loss": "0.3", "ppl": "1.23", "wps": "4711.1", "ups": "3", "wpb": "1570.4", "bsz": "16", "num_updates": "2800", "lr": "4.98849e-05", "gnorm": "0.555", "train_wall": "33", "wall": "1164"}
2022-10-31 03:49:03 | INFO | train_inner | {"epoch": 1, "update": 0.886, "loss": "2.183", "nll_loss": "0.304", "ppl": "1.23", "wps": "4139.1", "ups": "2.62", "wpb": "1581.3", "bsz": "16", "num_updates": "2900", "lr": "4.98799e-05", "gnorm": "0.57", "train_wall": "38", "wall": "1202"}
2022-10-31 03:49:43 | INFO | train_inner | {"epoch": 1, "update": 0.917, "loss": "2.18", "nll_loss": "0.301", "ppl": "1.23", "wps": "3845.7", "ups": "2.48", "wpb": "1550.5", "bsz": "16", "num_updates": "3000", "lr": "4.98749e-05", "gnorm": "0.593", "train_wall": "40", "wall": "1242"}
2022-10-31 03:50:23 | INFO | train_inner | {"epoch": 1, "update": 0.947, "loss": "2.18", "nll_loss": "0.301", "ppl": "1.23", "wps": "3905.1", "ups": "2.47", "wpb": "1582.4", "bsz": "16", "num_updates": "3100", "lr": "4.98699e-05", "gnorm": "0.54", "train_wall": "40", "wall": "1283"}
2022-10-31 03:51:06 | INFO | train_inner | {"epoch": 1, "update": 0.978, "loss": "2.179", "nll_loss": "0.301", "ppl": "1.23", "wps": "3699.3", "ups": "2.38", "wpb": "1555.7", "bsz": "16", "num_updates": "3200", "lr": "4.98649e-05", "gnorm": "0.57", "train_wall": "42", "wall": "1325"}
2022-10-31 03:51:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
/home/y_shi202/.local/lib/python3.6/site-packages/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  "amp_C fused kernels unavailable, disabling multi_tensor_l2norm; "
2022-10-31 04:24:08 | INFO | valid | {"epoch": 1, "valid_loss": "2.182", "valid_nll_loss": "0.222", "valid_ppl": "1.17", "valid_bleu": "86.27", "valid_wps": "330.4", "valid_wpb": "394.3", "valid_bsz": "4", "valid_num_updates": "3273"}
2022-10-31 04:24:08 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 04:24:22 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_best.pt (epoch 1 @ 3273 updates, score 86.27) (writing took 13.583294655196369 seconds)
2022-10-31 04:24:22 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-10-31 04:24:22 | INFO | train | {"epoch": 1, "train_loss": "2.269", "train_nll_loss": "0.358", "train_ppl": "1.28", "train_wps": "1550.9", "train_ups": "0.99", "train_wpb": "1573", "train_bsz": "16", "train_num_updates": "3273", "train_lr": "4.98613e-05", "train_gnorm": "1.304", "train_train_wall": "1336", "train_wall": "3321"}
2022-10-31 04:24:22 | INFO | fairseq.trainer | begin training epoch 2
2022-10-31 04:24:33 | INFO | train_inner | {"epoch": 2, "update": 1.008, "loss": "2.178", "nll_loss": "0.299", "ppl": "1.23", "wps": "77.2", "ups": "0.05", "wpb": "1549.6", "bsz": "16", "num_updates": "3300", "lr": "4.98599e-05", "gnorm": "0.597", "train_wall": "39", "wall": "3333"}
2022-10-31 04:25:14 | INFO | train_inner | {"epoch": 2, "update": 1.039, "loss": "2.167", "nll_loss": "0.287", "ppl": "1.22", "wps": "3946.2", "ups": "2.47", "wpb": "1596.8", "bsz": "16", "num_updates": "3400", "lr": "4.98549e-05", "gnorm": "0.572", "train_wall": "40", "wall": "3373"}
2022-10-31 04:25:48 | INFO | train_inner | {"epoch": 2, "update": 1.069, "loss": "2.167", "nll_loss": "0.288", "ppl": "1.22", "wps": "4454.1", "ups": "2.9", "wpb": "1536.9", "bsz": "16", "num_updates": "3500", "lr": "4.98499e-05", "gnorm": "0.59", "train_wall": "34", "wall": "3407"}
2022-10-31 04:26:32 | INFO | train_inner | {"epoch": 2, "update": 1.1, "loss": "2.163", "nll_loss": "0.283", "ppl": "1.22", "wps": "3605", "ups": "2.29", "wpb": "1577.3", "bsz": "16", "num_updates": "3600", "lr": "4.98449e-05", "gnorm": "0.55", "train_wall": "43", "wall": "3451"}
2022-10-31 04:27:15 | INFO | train_inner | {"epoch": 2, "update": 1.13, "loss": "2.17", "nll_loss": "0.292", "ppl": "1.22", "wps": "3732.5", "ups": "2.35", "wpb": "1585.7", "bsz": "16", "num_updates": "3700", "lr": "4.98399e-05", "gnorm": "0.552", "train_wall": "42", "wall": "3494"}
2022-10-31 04:27:54 | INFO | train_inner | {"epoch": 2, "update": 1.161, "loss": "2.168", "nll_loss": "0.289", "ppl": "1.22", "wps": "3938.7", "ups": "2.51", "wpb": "1568.8", "bsz": "16", "num_updates": "3800", "lr": "4.98349e-05", "gnorm": "0.522", "train_wall": "39", "wall": "3534"}
2022-10-31 04:28:34 | INFO | train_inner | {"epoch": 2, "update": 1.192, "loss": "2.166", "nll_loss": "0.287", "ppl": "1.22", "wps": "3917", "ups": "2.52", "wpb": "1555.5", "bsz": "16", "num_updates": "3900", "lr": "4.98299e-05", "gnorm": "0.559", "train_wall": "39", "wall": "3573"}
2022-10-31 04:29:12 | INFO | train_inner | {"epoch": 2, "update": 1.222, "loss": "2.16", "nll_loss": "0.281", "ppl": "1.21", "wps": "4130.9", "ups": "2.61", "wpb": "1581.3", "bsz": "16", "num_updates": "4000", "lr": "4.98249e-05", "gnorm": "0.512", "train_wall": "38", "wall": "3612"}
2022-10-31 04:29:53 | INFO | train_inner | {"epoch": 2, "update": 1.253, "loss": "2.166", "nll_loss": "0.288", "ppl": "1.22", "wps": "3819.7", "ups": "2.45", "wpb": "1558.8", "bsz": "16", "num_updates": "4100", "lr": "4.98199e-05", "gnorm": "0.578", "train_wall": "40", "wall": "3652"}
2022-10-31 04:30:36 | INFO | train_inner | {"epoch": 2, "update": 1.283, "loss": "2.168", "nll_loss": "0.29", "ppl": "1.22", "wps": "3678", "ups": "2.33", "wpb": "1581.7", "bsz": "16", "num_updates": "4200", "lr": "4.98149e-05", "gnorm": "0.563", "train_wall": "42", "wall": "3695"}
2022-10-31 04:31:16 | INFO | train_inner | {"epoch": 2, "update": 1.314, "loss": "2.172", "nll_loss": "0.294", "ppl": "1.23", "wps": "3947", "ups": "2.52", "wpb": "1569.2", "bsz": "16", "num_updates": "4300", "lr": "4.98099e-05", "gnorm": "0.575", "train_wall": "39", "wall": "3735"}
2022-10-31 04:32:00 | INFO | train_inner | {"epoch": 2, "update": 1.344, "loss": "2.165", "nll_loss": "0.287", "ppl": "1.22", "wps": "3573.8", "ups": "2.29", "wpb": "1558", "bsz": "16", "num_updates": "4400", "lr": "4.98049e-05", "gnorm": "0.541", "train_wall": "43", "wall": "3779"}
2022-10-31 04:32:42 | INFO | train_inner | {"epoch": 2, "update": 1.375, "loss": "2.164", "nll_loss": "0.286", "ppl": "1.22", "wps": "3763.6", "ups": "2.37", "wpb": "1586.6", "bsz": "16", "num_updates": "4500", "lr": "4.97999e-05", "gnorm": "0.548", "train_wall": "42", "wall": "3821"}
2022-10-31 04:33:21 | INFO | train_inner | {"epoch": 2, "update": 1.405, "loss": "2.165", "nll_loss": "0.287", "ppl": "1.22", "wps": "4047.7", "ups": "2.55", "wpb": "1587.3", "bsz": "16", "num_updates": "4600", "lr": "4.97949e-05", "gnorm": "0.524", "train_wall": "39", "wall": "3860"}
2022-10-31 04:33:59 | INFO | train_inner | {"epoch": 2, "update": 1.436, "loss": "2.165", "nll_loss": "0.287", "ppl": "1.22", "wps": "4146.1", "ups": "2.64", "wpb": "1570.4", "bsz": "16", "num_updates": "4700", "lr": "4.97899e-05", "gnorm": "0.511", "train_wall": "37", "wall": "3898"}
2022-10-31 04:34:39 | INFO | train_inner | {"epoch": 2, "update": 1.467, "loss": "2.162", "nll_loss": "0.284", "ppl": "1.22", "wps": "3921.7", "ups": "2.49", "wpb": "1572", "bsz": "16", "num_updates": "4800", "lr": "4.97849e-05", "gnorm": "0.508", "train_wall": "40", "wall": "3938"}
2022-10-31 04:35:18 | INFO | train_inner | {"epoch": 2, "update": 1.497, "loss": "2.162", "nll_loss": "0.284", "ppl": "1.22", "wps": "4040.2", "ups": "2.53", "wpb": "1598.7", "bsz": "16", "num_updates": "4900", "lr": "4.97799e-05", "gnorm": "0.514", "train_wall": "39", "wall": "3978"}
2022-10-31 04:36:05 | INFO | train_inner | {"epoch": 2, "update": 1.528, "loss": "2.165", "nll_loss": "0.288", "ppl": "1.22", "wps": "3403.9", "ups": "2.17", "wpb": "1568", "bsz": "16", "num_updates": "5000", "lr": "4.97749e-05", "gnorm": "0.522", "train_wall": "46", "wall": "4024"}
2022-10-31 04:36:50 | INFO | train_inner | {"epoch": 2, "update": 1.558, "loss": "2.165", "nll_loss": "0.287", "ppl": "1.22", "wps": "3410.6", "ups": "2.2", "wpb": "1552.1", "bsz": "16", "num_updates": "5100", "lr": "4.97699e-05", "gnorm": "0.533", "train_wall": "45", "wall": "4069"}
2022-10-31 04:37:33 | INFO | train_inner | {"epoch": 2, "update": 1.589, "loss": "2.161", "nll_loss": "0.284", "ppl": "1.22", "wps": "3674.6", "ups": "2.35", "wpb": "1565.3", "bsz": "16", "num_updates": "5200", "lr": "4.97649e-05", "gnorm": "0.512", "train_wall": "42", "wall": "4112"}
2022-10-31 04:38:15 | INFO | train_inner | {"epoch": 2, "update": 1.619, "loss": "2.165", "nll_loss": "0.288", "ppl": "1.22", "wps": "3696.7", "ups": "2.34", "wpb": "1579.9", "bsz": "16", "num_updates": "5300", "lr": "4.97599e-05", "gnorm": "0.531", "train_wall": "42", "wall": "4155"}
2022-10-31 04:38:59 | INFO | train_inner | {"epoch": 2, "update": 1.65, "loss": "2.165", "nll_loss": "0.288", "ppl": "1.22", "wps": "3624.5", "ups": "2.27", "wpb": "1595", "bsz": "16", "num_updates": "5400", "lr": "4.97549e-05", "gnorm": "0.549", "train_wall": "43", "wall": "4199"}
2022-10-31 04:39:45 | INFO | train_inner | {"epoch": 2, "update": 1.68, "loss": "2.163", "nll_loss": "0.287", "ppl": "1.22", "wps": "3392.6", "ups": "2.17", "wpb": "1564", "bsz": "16", "num_updates": "5500", "lr": "4.97499e-05", "gnorm": "0.534", "train_wall": "46", "wall": "4245"}
2022-10-31 04:40:34 | INFO | train_inner | {"epoch": 2, "update": 1.711, "loss": "2.159", "nll_loss": "0.282", "ppl": "1.22", "wps": "3283.5", "ups": "2.05", "wpb": "1605.1", "bsz": "16", "num_updates": "5600", "lr": "4.97449e-05", "gnorm": "0.51", "train_wall": "48", "wall": "4294"}
2022-10-31 04:41:23 | INFO | train_inner | {"epoch": 2, "update": 1.742, "loss": "2.162", "nll_loss": "0.286", "ppl": "1.22", "wps": "3180.8", "ups": "2.05", "wpb": "1554.2", "bsz": "16", "num_updates": "5700", "lr": "4.97399e-05", "gnorm": "0.488", "train_wall": "48", "wall": "4342"}
2022-10-31 04:42:08 | INFO | train_inner | {"epoch": 2, "update": 1.772, "loss": "2.163", "nll_loss": "0.286", "ppl": "1.22", "wps": "3467.2", "ups": "2.21", "wpb": "1568.3", "bsz": "16", "num_updates": "5800", "lr": "4.97349e-05", "gnorm": "0.514", "train_wall": "45", "wall": "4388"}
2022-10-31 04:42:56 | INFO | train_inner | {"epoch": 2, "update": 1.803, "loss": "2.161", "nll_loss": "0.285", "ppl": "1.22", "wps": "3292", "ups": "2.09", "wpb": "1571.4", "bsz": "16", "num_updates": "5900", "lr": "4.97299e-05", "gnorm": "0.54", "train_wall": "47", "wall": "4435"}
2022-10-31 04:43:42 | INFO | train_inner | {"epoch": 2, "update": 1.833, "loss": "2.162", "nll_loss": "0.285", "ppl": "1.22", "wps": "3428.3", "ups": "2.16", "wpb": "1587.4", "bsz": "16", "num_updates": "6000", "lr": "4.97249e-05", "gnorm": "0.532", "train_wall": "46", "wall": "4482"}
2022-10-31 04:44:23 | INFO | train_inner | {"epoch": 2, "update": 1.864, "loss": "2.159", "nll_loss": "0.283", "ppl": "1.22", "wps": "3843.1", "ups": "2.46", "wpb": "1561.8", "bsz": "16", "num_updates": "6100", "lr": "4.97199e-05", "gnorm": "0.496", "train_wall": "40", "wall": "4522"}
2022-10-31 04:45:00 | INFO | train_inner | {"epoch": 2, "update": 1.894, "loss": "2.164", "nll_loss": "0.288", "ppl": "1.22", "wps": "4288.5", "ups": "2.74", "wpb": "1563.7", "bsz": "16", "num_updates": "6200", "lr": "4.97149e-05", "gnorm": "0.485", "train_wall": "36", "wall": "4559"}
2022-10-31 04:45:39 | INFO | train_inner | {"epoch": 2, "update": 1.925, "loss": "2.162", "nll_loss": "0.286", "ppl": "1.22", "wps": "4008.3", "ups": "2.52", "wpb": "1593.3", "bsz": "16", "num_updates": "6300", "lr": "4.97099e-05", "gnorm": "0.506", "train_wall": "39", "wall": "4598"}
2022-10-31 04:46:19 | INFO | train_inner | {"epoch": 2, "update": 1.955, "loss": "2.157", "nll_loss": "0.281", "ppl": "1.22", "wps": "4003.6", "ups": "2.55", "wpb": "1569.9", "bsz": "16", "num_updates": "6400", "lr": "4.97049e-05", "gnorm": "0.515", "train_wall": "39", "wall": "4638"}
2022-10-31 04:46:59 | INFO | train_inner | {"epoch": 2, "update": 1.986, "loss": "2.158", "nll_loss": "0.281", "ppl": "1.22", "wps": "3957", "ups": "2.5", "wpb": "1581.4", "bsz": "16", "num_updates": "6500", "lr": "4.96998e-05", "gnorm": "0.495", "train_wall": "39", "wall": "4678"}
2022-10-31 04:47:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 05:20:08 | INFO | valid | {"epoch": 2, "valid_loss": "2.167", "valid_nll_loss": "0.218", "valid_ppl": "1.16", "valid_bleu": "87.66", "valid_wps": "327.7", "valid_wpb": "394.3", "valid_bsz": "4", "valid_num_updates": "6546", "valid_best_bleu": "87.66"}
2022-10-31 05:20:08 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 05:20:22 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_best.pt (epoch 2 @ 6546 updates, score 87.66) (writing took 14.504252971149981 seconds)
2022-10-31 05:20:22 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-10-31 05:20:22 | INFO | train | {"epoch": 2, "train_loss": "2.164", "train_nll_loss": "0.286", "train_ppl": "1.22", "train_wps": "1532.2", "train_ups": "0.97", "train_wpb": "1573", "train_bsz": "16", "train_num_updates": "6546", "train_lr": "4.96975e-05", "train_gnorm": "0.531", "train_train_wall": "1360", "train_wall": "6681"}
2022-10-31 05:20:22 | INFO | fairseq.trainer | begin training epoch 3
2022-10-31 05:20:48 | INFO | train_inner | {"epoch": 3, "update": 2.016, "loss": "2.151", "nll_loss": "0.274", "ppl": "1.21", "wps": "77.7", "ups": "0.05", "wpb": "1576", "bsz": "16", "num_updates": "6600", "lr": "4.96948e-05", "gnorm": "0.548", "train_wall": "44", "wall": "6707"}
2022-10-31 05:21:34 | INFO | train_inner | {"epoch": 3, "update": 2.047, "loss": "2.148", "nll_loss": "0.271", "ppl": "1.21", "wps": "3497.7", "ups": "2.19", "wpb": "1600.5", "bsz": "16", "num_updates": "6700", "lr": "4.96898e-05", "gnorm": "0.52", "train_wall": "45", "wall": "6753"}
2022-10-31 05:22:21 | INFO | train_inner | {"epoch": 3, "update": 2.078, "loss": "2.144", "nll_loss": "0.266", "ppl": "1.2", "wps": "3380.5", "ups": "2.13", "wpb": "1585.6", "bsz": "16", "num_updates": "6800", "lr": "4.96848e-05", "gnorm": "0.496", "train_wall": "46", "wall": "6800"}
2022-10-31 05:23:09 | INFO | train_inner | {"epoch": 3, "update": 2.108, "loss": "2.146", "nll_loss": "0.269", "ppl": "1.2", "wps": "3270.1", "ups": "2.07", "wpb": "1576.5", "bsz": "16", "num_updates": "6900", "lr": "4.96798e-05", "gnorm": "0.489", "train_wall": "48", "wall": "6848"}
2022-10-31 05:23:55 | INFO | train_inner | {"epoch": 3, "update": 2.139, "loss": "2.145", "nll_loss": "0.268", "ppl": "1.2", "wps": "3369.4", "ups": "2.15", "wpb": "1564.7", "bsz": "16", "num_updates": "7000", "lr": "4.96748e-05", "gnorm": "0.473", "train_wall": "46", "wall": "6894"}
2022-10-31 05:24:38 | INFO | train_inner | {"epoch": 3, "update": 2.169, "loss": "2.147", "nll_loss": "0.27", "ppl": "1.21", "wps": "3766", "ups": "2.36", "wpb": "1595.5", "bsz": "16", "num_updates": "7100", "lr": "4.96698e-05", "gnorm": "0.512", "train_wall": "42", "wall": "6937"}
2022-10-31 05:25:18 | INFO | train_inner | {"epoch": 3, "update": 2.2, "loss": "2.148", "nll_loss": "0.271", "ppl": "1.21", "wps": "3967.6", "ups": "2.49", "wpb": "1593.6", "bsz": "16", "num_updates": "7200", "lr": "4.96648e-05", "gnorm": "0.483", "train_wall": "40", "wall": "6977"}
2022-10-31 05:25:59 | INFO | train_inner | {"epoch": 3, "update": 2.23, "loss": "2.151", "nll_loss": "0.274", "ppl": "1.21", "wps": "3796.1", "ups": "2.4", "wpb": "1579.1", "bsz": "16", "num_updates": "7300", "lr": "4.96598e-05", "gnorm": "0.514", "train_wall": "41", "wall": "7019"}
2022-10-31 05:26:44 | INFO | train_inner | {"epoch": 3, "update": 2.261, "loss": "2.146", "nll_loss": "0.269", "ppl": "1.2", "wps": "3449.3", "ups": "2.23", "wpb": "1548.3", "bsz": "16", "num_updates": "7400", "lr": "4.96548e-05", "gnorm": "0.487", "train_wall": "44", "wall": "7063"}
2022-10-31 05:27:31 | INFO | train_inner | {"epoch": 3, "update": 2.291, "loss": "2.148", "nll_loss": "0.271", "ppl": "1.21", "wps": "3350.1", "ups": "2.16", "wpb": "1549.1", "bsz": "16", "num_updates": "7500", "lr": "4.96498e-05", "gnorm": "0.472", "train_wall": "46", "wall": "7110"}
2022-10-31 05:28:05 | INFO | train_inner | {"epoch": 3, "update": 2.322, "loss": "2.149", "nll_loss": "0.273", "ppl": "1.21", "wps": "4534.9", "ups": "2.88", "wpb": "1573.7", "bsz": "16", "num_updates": "7600", "lr": "4.96448e-05", "gnorm": "0.483", "train_wall": "34", "wall": "7144"}
2022-10-31 05:28:43 | INFO | train_inner | {"epoch": 3, "update": 2.353, "loss": "2.148", "nll_loss": "0.271", "ppl": "1.21", "wps": "4162", "ups": "2.64", "wpb": "1578.5", "bsz": "16", "num_updates": "7700", "lr": "4.96398e-05", "gnorm": "0.585", "train_wall": "37", "wall": "7182"}
2022-10-31 05:29:29 | INFO | train_inner | {"epoch": 3, "update": 2.383, "loss": "2.147", "nll_loss": "0.271", "ppl": "1.21", "wps": "3414.9", "ups": "2.2", "wpb": "1550.3", "bsz": "16", "num_updates": "7800", "lr": "4.96348e-05", "gnorm": "0.526", "train_wall": "45", "wall": "7228"}
2022-10-31 05:30:15 | INFO | train_inner | {"epoch": 3, "update": 2.414, "loss": "2.149", "nll_loss": "0.273", "ppl": "1.21", "wps": "3314", "ups": "2.17", "wpb": "1529.3", "bsz": "16", "num_updates": "7900", "lr": "4.96298e-05", "gnorm": "0.511", "train_wall": "46", "wall": "7274"}
2022-10-31 05:30:58 | INFO | train_inner | {"epoch": 3, "update": 2.444, "loss": "2.149", "nll_loss": "0.273", "ppl": "1.21", "wps": "3603.3", "ups": "2.3", "wpb": "1564.1", "bsz": "16", "num_updates": "8000", "lr": "4.96248e-05", "gnorm": "0.492", "train_wall": "43", "wall": "7317"}
2022-10-31 05:31:42 | INFO | train_inner | {"epoch": 3, "update": 2.475, "loss": "2.147", "nll_loss": "0.27", "ppl": "1.21", "wps": "3623.7", "ups": "2.29", "wpb": "1583.5", "bsz": "16", "num_updates": "8100", "lr": "4.96198e-05", "gnorm": "0.55", "train_wall": "43", "wall": "7361"}
2022-10-31 05:32:28 | INFO | train_inner | {"epoch": 3, "update": 2.505, "loss": "2.15", "nll_loss": "0.274", "ppl": "1.21", "wps": "3376", "ups": "2.16", "wpb": "1561.7", "bsz": "16", "num_updates": "8200", "lr": "4.96148e-05", "gnorm": "0.498", "train_wall": "46", "wall": "7407"}
2022-10-31 05:33:06 | INFO | train_inner | {"epoch": 3, "update": 2.536, "loss": "2.148", "nll_loss": "0.272", "ppl": "1.21", "wps": "4097.6", "ups": "2.64", "wpb": "1552", "bsz": "16", "num_updates": "8300", "lr": "4.96098e-05", "gnorm": "0.524", "train_wall": "37", "wall": "7445"}
2022-10-31 05:33:44 | INFO | train_inner | {"epoch": 3, "update": 2.566, "loss": "2.148", "nll_loss": "0.272", "ppl": "1.21", "wps": "4269.6", "ups": "2.66", "wpb": "1605", "bsz": "16", "num_updates": "8400", "lr": "4.96048e-05", "gnorm": "0.525", "train_wall": "37", "wall": "7483"}
2022-10-31 05:34:28 | INFO | train_inner | {"epoch": 3, "update": 2.597, "loss": "2.147", "nll_loss": "0.27", "ppl": "1.21", "wps": "3578.9", "ups": "2.25", "wpb": "1588.9", "bsz": "16", "num_updates": "8500", "lr": "4.95998e-05", "gnorm": "0.474", "train_wall": "44", "wall": "7527"}
2022-10-31 05:35:13 | INFO | train_inner | {"epoch": 3, "update": 2.628, "loss": "2.146", "nll_loss": "0.27", "ppl": "1.21", "wps": "3524", "ups": "2.22", "wpb": "1588.9", "bsz": "16", "num_updates": "8600", "lr": "4.95948e-05", "gnorm": "0.532", "train_wall": "45", "wall": "7572"}
2022-10-31 05:35:56 | INFO | train_inner | {"epoch": 3, "update": 2.658, "loss": "2.147", "nll_loss": "0.27", "ppl": "1.21", "wps": "3586.6", "ups": "2.31", "wpb": "1552.1", "bsz": "16", "num_updates": "8700", "lr": "4.95898e-05", "gnorm": "0.44", "train_wall": "43", "wall": "7615"}
2022-10-31 05:36:37 | INFO | train_inner | {"epoch": 3, "update": 2.689, "loss": "2.152", "nll_loss": "0.277", "ppl": "1.21", "wps": "3862.9", "ups": "2.45", "wpb": "1578.1", "bsz": "16", "num_updates": "8800", "lr": "4.95848e-05", "gnorm": "0.465", "train_wall": "40", "wall": "7656"}
2022-10-31 05:37:20 | INFO | train_inner | {"epoch": 3, "update": 2.719, "loss": "2.147", "nll_loss": "0.271", "ppl": "1.21", "wps": "3602.2", "ups": "2.32", "wpb": "1554.5", "bsz": "16", "num_updates": "8900", "lr": "4.95798e-05", "gnorm": "0.483", "train_wall": "43", "wall": "7699"}
2022-10-31 05:38:04 | INFO | train_inner | {"epoch": 3, "update": 2.75, "loss": "2.146", "nll_loss": "0.269", "ppl": "1.21", "wps": "3622.7", "ups": "2.3", "wpb": "1573.7", "bsz": "16", "num_updates": "9000", "lr": "4.95748e-05", "gnorm": "0.475", "train_wall": "43", "wall": "7743"}
2022-10-31 05:38:43 | INFO | train_inner | {"epoch": 3, "update": 2.78, "loss": "2.145", "nll_loss": "0.27", "ppl": "1.21", "wps": "4007.3", "ups": "2.58", "wpb": "1552.8", "bsz": "16", "num_updates": "9100", "lr": "4.95698e-05", "gnorm": "0.46", "train_wall": "38", "wall": "7782"}
2022-10-31 05:39:28 | INFO | train_inner | {"epoch": 3, "update": 2.811, "loss": "2.147", "nll_loss": "0.271", "ppl": "1.21", "wps": "3440.2", "ups": "2.2", "wpb": "1561.2", "bsz": "16", "num_updates": "9200", "lr": "4.95648e-05", "gnorm": "0.488", "train_wall": "45", "wall": "7827"}
2022-10-31 05:40:11 | INFO | train_inner | {"epoch": 3, "update": 2.841, "loss": "2.14", "nll_loss": "0.263", "ppl": "1.2", "wps": "3670.1", "ups": "2.32", "wpb": "1582.9", "bsz": "16", "num_updates": "9300", "lr": "4.95598e-05", "gnorm": "0.49", "train_wall": "43", "wall": "7870"}
2022-10-31 05:40:52 | INFO | train_inner | {"epoch": 3, "update": 2.872, "loss": "2.146", "nll_loss": "0.27", "ppl": "1.21", "wps": "3750.7", "ups": "2.41", "wpb": "1554.5", "bsz": "16", "num_updates": "9400", "lr": "4.95548e-05", "gnorm": "0.441", "train_wall": "41", "wall": "7912"}
2022-10-31 05:41:39 | INFO | train_inner | {"epoch": 3, "update": 2.903, "loss": "2.148", "nll_loss": "0.273", "ppl": "1.21", "wps": "3421.7", "ups": "2.15", "wpb": "1590", "bsz": "16", "num_updates": "9500", "lr": "4.95498e-05", "gnorm": "0.497", "train_wall": "46", "wall": "7958"}
2022-10-31 05:42:12 | INFO | train_inner | {"epoch": 3, "update": 2.933, "loss": "2.149", "nll_loss": "0.274", "ppl": "1.21", "wps": "4737.5", "ups": "2.98", "wpb": "1588.6", "bsz": "16", "num_updates": "9600", "lr": "4.95448e-05", "gnorm": "0.516", "train_wall": "33", "wall": "7992"}
2022-10-31 05:42:58 | INFO | train_inner | {"epoch": 3, "update": 2.964, "loss": "2.151", "nll_loss": "0.276", "ppl": "1.21", "wps": "3533.9", "ups": "2.21", "wpb": "1600.8", "bsz": "16", "num_updates": "9700", "lr": "4.95398e-05", "gnorm": "0.448", "train_wall": "45", "wall": "8037"}
2022-10-31 05:43:42 | INFO | train_inner | {"epoch": 3, "update": 2.994, "loss": "2.149", "nll_loss": "0.273", "ppl": "1.21", "wps": "3587.4", "ups": "2.28", "wpb": "1572.5", "bsz": "16", "num_updates": "9800", "lr": "4.95348e-05", "gnorm": "0.483", "train_wall": "43", "wall": "8081"}
2022-10-31 05:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 06:16:33 | INFO | valid | {"epoch": 3, "valid_loss": "2.165", "valid_nll_loss": "0.22", "valid_ppl": "1.16", "valid_bleu": "85.78", "valid_wps": "328.9", "valid_wpb": "394.3", "valid_bsz": "4", "valid_num_updates": "9819", "valid_best_bleu": "87.66"}
2022-10-31 06:16:33 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 06:16:41 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_last.pt (epoch 3 @ 9819 updates, score 85.78) (writing took 8.231821086257696 seconds)
2022-10-31 06:16:41 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-10-31 06:16:41 | INFO | train | {"epoch": 3, "train_loss": "2.147", "train_nll_loss": "0.271", "train_ppl": "1.21", "train_wps": "1523.7", "train_ups": "0.97", "train_wpb": "1573", "train_bsz": "16", "train_num_updates": "9819", "train_lr": "4.95338e-05", "train_gnorm": "0.495", "train_train_wall": "1391", "train_wall": "10060"}
2022-10-31 06:16:41 | INFO | fairseq.trainer | begin training epoch 4
2022-10-31 06:17:19 | INFO | train_inner | {"epoch": 4, "update": 3.025, "loss": "2.141", "nll_loss": "0.264", "ppl": "1.2", "wps": "77.7", "ups": "0.05", "wpb": "1568.1", "bsz": "16", "num_updates": "9900", "lr": "4.95298e-05", "gnorm": "0.449", "train_wall": "45", "wall": "10098"}
2022-10-31 06:18:08 | INFO | train_inner | {"epoch": 4, "update": 3.055, "loss": "2.134", "nll_loss": "0.257", "ppl": "1.2", "wps": "3232.4", "ups": "2.04", "wpb": "1580.8", "bsz": "16", "num_updates": "10000", "lr": "4.95248e-05", "gnorm": "0.504", "train_wall": "48", "wall": "10147"}
2022-10-31 06:18:49 | INFO | train_inner | {"epoch": 4, "update": 3.086, "loss": "2.134", "nll_loss": "0.257", "ppl": "1.2", "wps": "3892.8", "ups": "2.44", "wpb": "1595.6", "bsz": "16", "num_updates": "10100", "lr": "4.95198e-05", "gnorm": "0.451", "train_wall": "41", "wall": "10188"}
2022-10-31 06:19:23 | INFO | train_inner | {"epoch": 4, "update": 3.116, "loss": "2.134", "nll_loss": "0.257", "ppl": "1.19", "wps": "4500.4", "ups": "2.9", "wpb": "1552", "bsz": "16", "num_updates": "10200", "lr": "4.95148e-05", "gnorm": "0.487", "train_wall": "34", "wall": "10222"}
2022-10-31 06:20:04 | INFO | train_inner | {"epoch": 4, "update": 3.147, "loss": "2.136", "nll_loss": "0.259", "ppl": "1.2", "wps": "3763.3", "ups": "2.43", "wpb": "1551.3", "bsz": "16", "num_updates": "10300", "lr": "4.95098e-05", "gnorm": "0.509", "train_wall": "41", "wall": "10263"}
2022-10-31 06:20:47 | INFO | train_inner | {"epoch": 4, "update": 3.178, "loss": "2.131", "nll_loss": "0.253", "ppl": "1.19", "wps": "3775.2", "ups": "2.36", "wpb": "1599.8", "bsz": "16", "num_updates": "10400", "lr": "4.95048e-05", "gnorm": "0.442", "train_wall": "42", "wall": "10306"}
2022-10-31 06:21:33 | INFO | train_inner | {"epoch": 4, "update": 3.208, "loss": "2.133", "nll_loss": "0.256", "ppl": "1.19", "wps": "3417.2", "ups": "2.15", "wpb": "1588.2", "bsz": "16", "num_updates": "10500", "lr": "4.94997e-05", "gnorm": "0.458", "train_wall": "46", "wall": "10352"}
2022-10-31 06:22:17 | INFO | train_inner | {"epoch": 4, "update": 3.239, "loss": "2.135", "nll_loss": "0.258", "ppl": "1.2", "wps": "3574.7", "ups": "2.26", "wpb": "1578.6", "bsz": "16", "num_updates": "10600", "lr": "4.94947e-05", "gnorm": "0.483", "train_wall": "44", "wall": "10396"}
2022-10-31 06:23:02 | INFO | train_inner | {"epoch": 4, "update": 3.269, "loss": "2.133", "nll_loss": "0.256", "ppl": "1.19", "wps": "3568.6", "ups": "2.26", "wpb": "1579.4", "bsz": "16", "num_updates": "10700", "lr": "4.94897e-05", "gnorm": "0.456", "train_wall": "44", "wall": "10441"}
2022-10-31 06:23:48 | INFO | train_inner | {"epoch": 4, "update": 3.3, "loss": "2.137", "nll_loss": "0.261", "ppl": "1.2", "wps": "3405.6", "ups": "2.16", "wpb": "1579.2", "bsz": "16", "num_updates": "10800", "lr": "4.94847e-05", "gnorm": "0.472", "train_wall": "46", "wall": "10487"}
2022-10-31 06:24:35 | INFO | train_inner | {"epoch": 4, "update": 3.33, "loss": "2.135", "nll_loss": "0.258", "ppl": "1.2", "wps": "3329.2", "ups": "2.11", "wpb": "1579.1", "bsz": "16", "num_updates": "10900", "lr": "4.94797e-05", "gnorm": "0.443", "train_wall": "47", "wall": "10534"}
2022-10-31 06:25:13 | INFO | train_inner | {"epoch": 4, "update": 3.361, "loss": "2.133", "nll_loss": "0.257", "ppl": "1.19", "wps": "4250.2", "ups": "2.66", "wpb": "1600.4", "bsz": "16", "num_updates": "11000", "lr": "4.94747e-05", "gnorm": "0.471", "train_wall": "37", "wall": "10572"}
2022-10-31 06:26:00 | INFO | train_inner | {"epoch": 4, "update": 3.391, "loss": "2.14", "nll_loss": "0.264", "ppl": "1.2", "wps": "3344", "ups": "2.15", "wpb": "1557.7", "bsz": "16", "num_updates": "11100", "lr": "4.94697e-05", "gnorm": "0.506", "train_wall": "46", "wall": "10619"}
2022-10-31 06:26:45 | INFO | train_inner | {"epoch": 4, "update": 3.422, "loss": "2.136", "nll_loss": "0.26", "ppl": "1.2", "wps": "3391", "ups": "2.19", "wpb": "1550.1", "bsz": "16", "num_updates": "11200", "lr": "4.94647e-05", "gnorm": "0.495", "train_wall": "45", "wall": "10664"}
2022-10-31 06:27:30 | INFO | train_inner | {"epoch": 4, "update": 3.452, "loss": "2.136", "nll_loss": "0.259", "ppl": "1.2", "wps": "3491.5", "ups": "2.23", "wpb": "1565.6", "bsz": "16", "num_updates": "11300", "lr": "4.94597e-05", "gnorm": "0.475", "train_wall": "44", "wall": "10709"}
2022-10-31 06:28:16 | INFO | train_inner | {"epoch": 4, "update": 3.483, "loss": "2.136", "nll_loss": "0.259", "ppl": "1.2", "wps": "3403", "ups": "2.17", "wpb": "1567", "bsz": "16", "num_updates": "11400", "lr": "4.94547e-05", "gnorm": "0.488", "train_wall": "45", "wall": "10755"}
2022-10-31 06:28:59 | INFO | train_inner | {"epoch": 4, "update": 3.514, "loss": "2.136", "nll_loss": "0.26", "ppl": "1.2", "wps": "3651.1", "ups": "2.31", "wpb": "1579", "bsz": "16", "num_updates": "11500", "lr": "4.94497e-05", "gnorm": "0.493", "train_wall": "43", "wall": "10799"}
2022-10-31 06:29:43 | INFO | train_inner | {"epoch": 4, "update": 3.544, "loss": "2.137", "nll_loss": "0.262", "ppl": "1.2", "wps": "3618.9", "ups": "2.31", "wpb": "1568", "bsz": "16", "num_updates": "11600", "lr": "4.94447e-05", "gnorm": "0.486", "train_wall": "43", "wall": "10842"}
2022-10-31 06:30:27 | INFO | train_inner | {"epoch": 4, "update": 3.575, "loss": "2.136", "nll_loss": "0.26", "ppl": "1.2", "wps": "3524.7", "ups": "2.24", "wpb": "1572.9", "bsz": "16", "num_updates": "11700", "lr": "4.94397e-05", "gnorm": "0.498", "train_wall": "44", "wall": "10886"}
2022-10-31 06:31:12 | INFO | train_inner | {"epoch": 4, "update": 3.605, "loss": "2.132", "nll_loss": "0.255", "ppl": "1.19", "wps": "3561.5", "ups": "2.24", "wpb": "1592.4", "bsz": "16", "num_updates": "11800", "lr": "4.94347e-05", "gnorm": "0.46", "train_wall": "44", "wall": "10931"}
2022-10-31 06:31:56 | INFO | train_inner | {"epoch": 4, "update": 3.636, "loss": "2.134", "nll_loss": "0.258", "ppl": "1.2", "wps": "3508", "ups": "2.26", "wpb": "1551.7", "bsz": "16", "num_updates": "11900", "lr": "4.94297e-05", "gnorm": "0.475", "train_wall": "44", "wall": "10975"}
2022-10-31 06:32:42 | INFO | train_inner | {"epoch": 4, "update": 3.666, "loss": "2.136", "nll_loss": "0.26", "ppl": "1.2", "wps": "3474.2", "ups": "2.19", "wpb": "1585.7", "bsz": "16", "num_updates": "12000", "lr": "4.94247e-05", "gnorm": "0.446", "train_wall": "45", "wall": "11021"}
2022-10-31 06:33:28 | INFO | train_inner | {"epoch": 4, "update": 3.697, "loss": "2.135", "nll_loss": "0.259", "ppl": "1.2", "wps": "3408.3", "ups": "2.17", "wpb": "1572.8", "bsz": "16", "num_updates": "12100", "lr": "4.94197e-05", "gnorm": "0.48", "train_wall": "46", "wall": "11067"}
2022-10-31 06:34:12 | INFO | train_inner | {"epoch": 4, "update": 3.727, "loss": "2.137", "nll_loss": "0.261", "ppl": "1.2", "wps": "3531.2", "ups": "2.26", "wpb": "1560.4", "bsz": "16", "num_updates": "12200", "lr": "4.94147e-05", "gnorm": "0.512", "train_wall": "44", "wall": "11111"}
2022-10-31 06:34:56 | INFO | train_inner | {"epoch": 4, "update": 3.758, "loss": "2.136", "nll_loss": "0.261", "ppl": "1.2", "wps": "3540.1", "ups": "2.27", "wpb": "1558.4", "bsz": "16", "num_updates": "12300", "lr": "4.94097e-05", "gnorm": "0.466", "train_wall": "44", "wall": "11155"}
2022-10-31 06:35:39 | INFO | train_inner | {"epoch": 4, "update": 3.789, "loss": "2.137", "nll_loss": "0.262", "ppl": "1.2", "wps": "3742.4", "ups": "2.35", "wpb": "1590.4", "bsz": "16", "num_updates": "12400", "lr": "4.94047e-05", "gnorm": "0.466", "train_wall": "42", "wall": "11198"}
2022-10-31 06:36:22 | INFO | train_inner | {"epoch": 4, "update": 3.819, "loss": "2.139", "nll_loss": "0.264", "ppl": "1.2", "wps": "3623.1", "ups": "2.32", "wpb": "1563.3", "bsz": "16", "num_updates": "12500", "lr": "4.93997e-05", "gnorm": "0.503", "train_wall": "43", "wall": "11241"}
2022-10-31 06:37:03 | INFO | train_inner | {"epoch": 4, "update": 3.85, "loss": "2.138", "nll_loss": "0.263", "ppl": "1.2", "wps": "3745", "ups": "2.41", "wpb": "1553", "bsz": "16", "num_updates": "12600", "lr": "4.93947e-05", "gnorm": "0.5", "train_wall": "41", "wall": "11283"}
2022-10-31 06:37:43 | INFO | train_inner | {"epoch": 4, "update": 3.88, "loss": "2.137", "nll_loss": "0.261", "ppl": "1.2", "wps": "4047.2", "ups": "2.56", "wpb": "1583.1", "bsz": "16", "num_updates": "12700", "lr": "4.93897e-05", "gnorm": "0.48", "train_wall": "39", "wall": "11322"}
2022-10-31 06:38:30 | INFO | train_inner | {"epoch": 4, "update": 3.911, "loss": "2.133", "nll_loss": "0.258", "ppl": "1.2", "wps": "3344", "ups": "2.1", "wpb": "1592.5", "bsz": "16", "num_updates": "12800", "lr": "4.93847e-05", "gnorm": "0.456", "train_wall": "47", "wall": "11369"}
2022-10-31 06:39:17 | INFO | train_inner | {"epoch": 4, "update": 3.941, "loss": "2.14", "nll_loss": "0.264", "ppl": "1.2", "wps": "3296", "ups": "2.13", "wpb": "1544.2", "bsz": "16", "num_updates": "12900", "lr": "4.93797e-05", "gnorm": "0.454", "train_wall": "46", "wall": "11416"}
2022-10-31 06:40:03 | INFO | train_inner | {"epoch": 4, "update": 3.972, "loss": "2.142", "nll_loss": "0.267", "ppl": "1.2", "wps": "3396.8", "ups": "2.2", "wpb": "1546.2", "bsz": "16", "num_updates": "13000", "lr": "4.93747e-05", "gnorm": "0.501", "train_wall": "45", "wall": "11462"}
2022-10-31 06:40:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 07:14:28 | INFO | valid | {"epoch": 4, "valid_loss": "2.161", "valid_nll_loss": "0.222", "valid_ppl": "1.17", "valid_bleu": "87.15", "valid_wps": "318.9", "valid_wpb": "394.3", "valid_bsz": "4", "valid_num_updates": "13092", "valid_best_bleu": "87.66"}
2022-10-31 07:14:28 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 07:14:36 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_last.pt (epoch 4 @ 13092 updates, score 87.15) (writing took 8.068489566911012 seconds)
2022-10-31 07:14:36 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-10-31 07:14:36 | INFO | train | {"epoch": 4, "train_loss": "2.136", "train_nll_loss": "0.26", "train_ppl": "1.2", "train_wps": "1481.7", "train_ups": "0.94", "train_wpb": "1573", "train_bsz": "16", "train_num_updates": "13092", "train_lr": "4.93701e-05", "train_gnorm": "0.477", "train_train_wall": "1425", "train_wall": "13535"}
2022-10-31 07:14:36 | INFO | fairseq.trainer | begin training epoch 5
2022-10-31 07:14:40 | INFO | train_inner | {"epoch": 5, "update": 4.002, "loss": "2.135", "nll_loss": "0.26", "ppl": "1.2", "wps": "76.6", "ups": "0.05", "wpb": "1591.7", "bsz": "16", "num_updates": "13100", "lr": "4.93697e-05", "gnorm": "0.469", "train_wall": "44", "wall": "13539"}
2022-10-31 07:15:19 | INFO | train_inner | {"epoch": 5, "update": 4.033, "loss": "2.122", "nll_loss": "0.244", "ppl": "1.18", "wps": "4033.9", "ups": "2.56", "wpb": "1577.5", "bsz": "16", "num_updates": "13200", "lr": "4.93647e-05", "gnorm": "0.438", "train_wall": "39", "wall": "13578"}
2022-10-31 07:16:03 | INFO | train_inner | {"epoch": 5, "update": 4.064, "loss": "2.12", "nll_loss": "0.242", "ppl": "1.18", "wps": "3675.3", "ups": "2.3", "wpb": "1596.8", "bsz": "16", "num_updates": "13300", "lr": "4.93597e-05", "gnorm": "0.476", "train_wall": "43", "wall": "13622"}
2022-10-31 07:16:44 | INFO | train_inner | {"epoch": 5, "update": 4.094, "loss": "2.125", "nll_loss": "0.248", "ppl": "1.19", "wps": "3767.7", "ups": "2.39", "wpb": "1576.8", "bsz": "16", "num_updates": "13400", "lr": "4.93547e-05", "gnorm": "0.478", "train_wall": "41", "wall": "13664"}
2022-10-31 07:17:27 | INFO | train_inner | {"epoch": 5, "update": 4.125, "loss": "2.121", "nll_loss": "0.244", "ppl": "1.18", "wps": "3675.3", "ups": "2.37", "wpb": "1551.1", "bsz": "16", "num_updates": "13500", "lr": "4.93497e-05", "gnorm": "0.45", "train_wall": "42", "wall": "13706"}
2022-10-31 07:18:07 | INFO | train_inner | {"epoch": 5, "update": 4.155, "loss": "2.127", "nll_loss": "0.251", "ppl": "1.19", "wps": "3768.2", "ups": "2.45", "wpb": "1538.1", "bsz": "16", "num_updates": "13600", "lr": "4.93447e-05", "gnorm": "0.517", "train_wall": "40", "wall": "13747"}
2022-10-31 07:18:46 | INFO | train_inner | {"epoch": 5, "update": 4.186, "loss": "2.123", "nll_loss": "0.246", "ppl": "1.19", "wps": "4179.3", "ups": "2.62", "wpb": "1596.7", "bsz": "16", "num_updates": "13700", "lr": "4.93397e-05", "gnorm": "0.479", "train_wall": "38", "wall": "13785"}
2022-10-31 07:19:27 | INFO | train_inner | {"epoch": 5, "update": 4.216, "loss": "2.126", "nll_loss": "0.249", "ppl": "1.19", "wps": "3774.8", "ups": "2.42", "wpb": "1561.9", "bsz": "16", "num_updates": "13800", "lr": "4.93347e-05", "gnorm": "0.491", "train_wall": "41", "wall": "13826"}
2022-10-31 07:20:09 | INFO | train_inner | {"epoch": 5, "update": 4.247, "loss": "2.124", "nll_loss": "0.247", "ppl": "1.19", "wps": "3844.7", "ups": "2.39", "wpb": "1605.5", "bsz": "16", "num_updates": "13900", "lr": "4.93297e-05", "gnorm": "0.508", "train_wall": "41", "wall": "13868"}
2022-10-31 07:20:48 | INFO | train_inner | {"epoch": 5, "update": 4.277, "loss": "2.128", "nll_loss": "0.252", "ppl": "1.19", "wps": "3983.3", "ups": "2.55", "wpb": "1562.7", "bsz": "16", "num_updates": "14000", "lr": "4.93247e-05", "gnorm": "0.522", "train_wall": "39", "wall": "13907"}
2022-10-31 07:21:29 | INFO | train_inner | {"epoch": 5, "update": 4.308, "loss": "2.127", "nll_loss": "0.25", "ppl": "1.19", "wps": "3838.8", "ups": "2.43", "wpb": "1579.1", "bsz": "16", "num_updates": "14100", "lr": "4.93197e-05", "gnorm": "0.439", "train_wall": "41", "wall": "13948"}
2022-10-31 07:22:10 | INFO | train_inner | {"epoch": 5, "update": 4.339, "loss": "2.128", "nll_loss": "0.252", "ppl": "1.19", "wps": "3809.8", "ups": "2.45", "wpb": "1553.6", "bsz": "16", "num_updates": "14200", "lr": "4.93147e-05", "gnorm": "0.463", "train_wall": "40", "wall": "13989"}
2022-10-31 07:22:49 | INFO | train_inner | {"epoch": 5, "update": 4.369, "loss": "2.126", "nll_loss": "0.25", "ppl": "1.19", "wps": "4069", "ups": "2.54", "wpb": "1604.8", "bsz": "16", "num_updates": "14300", "lr": "4.93097e-05", "gnorm": "0.467", "train_wall": "39", "wall": "14029"}
2022-10-31 07:23:33 | INFO | train_inner | {"epoch": 5, "update": 4.4, "loss": "2.127", "nll_loss": "0.251", "ppl": "1.19", "wps": "3622.2", "ups": "2.31", "wpb": "1567", "bsz": "16", "num_updates": "14400", "lr": "4.93047e-05", "gnorm": "0.47", "train_wall": "43", "wall": "14072"}
2022-10-31 07:24:16 | INFO | train_inner | {"epoch": 5, "update": 4.43, "loss": "2.125", "nll_loss": "0.248", "ppl": "1.19", "wps": "3656.4", "ups": "2.33", "wpb": "1567.6", "bsz": "16", "num_updates": "14500", "lr": "4.92996e-05", "gnorm": "0.478", "train_wall": "42", "wall": "14115"}
2022-10-31 07:24:58 | INFO | train_inner | {"epoch": 5, "update": 4.461, "loss": "2.127", "nll_loss": "0.251", "ppl": "1.19", "wps": "3654.3", "ups": "2.35", "wpb": "1552.8", "bsz": "16", "num_updates": "14600", "lr": "4.92946e-05", "gnorm": "0.474", "train_wall": "42", "wall": "14157"}
2022-10-31 07:25:43 | INFO | train_inner | {"epoch": 5, "update": 4.491, "loss": "2.128", "nll_loss": "0.252", "ppl": "1.19", "wps": "3471.1", "ups": "2.23", "wpb": "1559.5", "bsz": "16", "num_updates": "14700", "lr": "4.92896e-05", "gnorm": "0.513", "train_wall": "44", "wall": "14202"}
2022-10-31 07:26:29 | INFO | train_inner | {"epoch": 5, "update": 4.522, "loss": "2.124", "nll_loss": "0.247", "ppl": "1.19", "wps": "3391.3", "ups": "2.16", "wpb": "1572.9", "bsz": "16", "num_updates": "14800", "lr": "4.92846e-05", "gnorm": "0.484", "train_wall": "46", "wall": "14248"}
2022-10-31 07:27:12 | INFO | train_inner | {"epoch": 5, "update": 4.552, "loss": "2.125", "nll_loss": "0.248", "ppl": "1.19", "wps": "3677.5", "ups": "2.36", "wpb": "1559.4", "bsz": "16", "num_updates": "14900", "lr": "4.92796e-05", "gnorm": "0.442", "train_wall": "42", "wall": "14291"}
2022-10-31 07:27:49 | INFO | train_inner | {"epoch": 5, "update": 4.583, "loss": "2.129", "nll_loss": "0.254", "ppl": "1.19", "wps": "4138.5", "ups": "2.65", "wpb": "1562.5", "bsz": "16", "num_updates": "15000", "lr": "4.92746e-05", "gnorm": "0.486", "train_wall": "37", "wall": "14329"}
2022-10-31 07:28:29 | INFO | train_inner | {"epoch": 5, "update": 4.614, "loss": "2.129", "nll_loss": "0.253", "ppl": "1.19", "wps": "3887.6", "ups": "2.51", "wpb": "1546.4", "bsz": "16", "num_updates": "15100", "lr": "4.92696e-05", "gnorm": "0.497", "train_wall": "39", "wall": "14368"}
2022-10-31 07:29:09 | INFO | train_inner | {"epoch": 5, "update": 4.644, "loss": "2.126", "nll_loss": "0.25", "ppl": "1.19", "wps": "3957.9", "ups": "2.51", "wpb": "1579.5", "bsz": "16", "num_updates": "15200", "lr": "4.92646e-05", "gnorm": "0.479", "train_wall": "39", "wall": "14408"}
2022-10-31 07:29:49 | INFO | train_inner | {"epoch": 5, "update": 4.675, "loss": "2.126", "nll_loss": "0.25", "ppl": "1.19", "wps": "3951.3", "ups": "2.5", "wpb": "1582", "bsz": "16", "num_updates": "15300", "lr": "4.92596e-05", "gnorm": "0.524", "train_wall": "40", "wall": "14448"}
2022-10-31 07:30:32 | INFO | train_inner | {"epoch": 5, "update": 4.705, "loss": "2.125", "nll_loss": "0.249", "ppl": "1.19", "wps": "3649.4", "ups": "2.32", "wpb": "1572.8", "bsz": "16", "num_updates": "15400", "lr": "4.92546e-05", "gnorm": "0.496", "train_wall": "43", "wall": "14491"}
2022-10-31 07:31:17 | INFO | train_inner | {"epoch": 5, "update": 4.736, "loss": "2.125", "nll_loss": "0.249", "ppl": "1.19", "wps": "3527.5", "ups": "2.24", "wpb": "1572.2", "bsz": "16", "num_updates": "15500", "lr": "4.92496e-05", "gnorm": "0.461", "train_wall": "44", "wall": "14536"}
2022-10-31 07:32:01 | INFO | train_inner | {"epoch": 5, "update": 4.766, "loss": "2.132", "nll_loss": "0.256", "ppl": "1.19", "wps": "3522.4", "ups": "2.27", "wpb": "1554.3", "bsz": "16", "num_updates": "15600", "lr": "4.92446e-05", "gnorm": "0.505", "train_wall": "44", "wall": "14580"}
2022-10-31 07:32:48 | INFO | train_inner | {"epoch": 5, "update": 4.797, "loss": "2.13", "nll_loss": "0.254", "ppl": "1.19", "wps": "3348.7", "ups": "2.11", "wpb": "1584.5", "bsz": "16", "num_updates": "15700", "lr": "4.92396e-05", "gnorm": "0.46", "train_wall": "47", "wall": "14627"}
2022-10-31 07:33:31 | INFO | train_inner | {"epoch": 5, "update": 4.827, "loss": "2.13", "nll_loss": "0.255", "ppl": "1.19", "wps": "3658.4", "ups": "2.32", "wpb": "1577", "bsz": "16", "num_updates": "15800", "lr": "4.92346e-05", "gnorm": "0.47", "train_wall": "43", "wall": "14671"}
2022-10-31 07:34:15 | INFO | train_inner | {"epoch": 5, "update": 4.858, "loss": "2.128", "nll_loss": "0.252", "ppl": "1.19", "wps": "3531.1", "ups": "2.28", "wpb": "1548.1", "bsz": "16", "num_updates": "15900", "lr": "4.92296e-05", "gnorm": "0.522", "train_wall": "43", "wall": "14714"}
2022-10-31 07:34:59 | INFO | train_inner | {"epoch": 5, "update": 4.888, "loss": "2.128", "nll_loss": "0.253", "ppl": "1.19", "wps": "3615.5", "ups": "2.28", "wpb": "1583.6", "bsz": "16", "num_updates": "16000", "lr": "4.92246e-05", "gnorm": "0.459", "train_wall": "43", "wall": "14758"}
2022-10-31 07:35:47 | INFO | train_inner | {"epoch": 5, "update": 4.919, "loss": "2.126", "nll_loss": "0.251", "ppl": "1.19", "wps": "3287.7", "ups": "2.07", "wpb": "1584.9", "bsz": "16", "num_updates": "16100", "lr": "4.92196e-05", "gnorm": "0.477", "train_wall": "48", "wall": "14806"}
2022-10-31 07:36:35 | INFO | train_inner | {"epoch": 5, "update": 4.95, "loss": "2.123", "nll_loss": "0.247", "ppl": "1.19", "wps": "3392.1", "ups": "2.11", "wpb": "1609", "bsz": "16", "num_updates": "16200", "lr": "4.92146e-05", "gnorm": "0.479", "train_wall": "47", "wall": "14854"}
2022-10-31 07:37:21 | INFO | train_inner | {"epoch": 5, "update": 4.98, "loss": "2.131", "nll_loss": "0.256", "ppl": "1.19", "wps": "3447.5", "ups": "2.16", "wpb": "1598", "bsz": "16", "num_updates": "16300", "lr": "4.92096e-05", "gnorm": "0.471", "train_wall": "46", "wall": "14900"}
2022-10-31 07:37:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 08:11:05 | INFO | valid | {"epoch": 5, "valid_loss": "2.165", "valid_nll_loss": "0.225", "valid_ppl": "1.17", "valid_bleu": "86.61", "valid_wps": "323.4", "valid_wpb": "394.3", "valid_bsz": "4", "valid_num_updates": "16365", "valid_best_bleu": "87.66"}
2022-10-31 08:11:05 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 08:11:13 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_last.pt (epoch 5 @ 16365 updates, score 86.61) (writing took 7.831671365071088 seconds)
2022-10-31 08:11:13 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-10-31 08:11:13 | INFO | train | {"epoch": 5, "train_loss": "2.126", "train_nll_loss": "0.25", "train_ppl": "1.19", "train_wps": "1515.6", "train_ups": "0.96", "train_wpb": "1573", "train_bsz": "16", "train_num_updates": "16365", "train_lr": "4.92064e-05", "train_gnorm": "0.481", "train_train_wall": "1376", "train_wall": "16932"}
2022-10-31 08:11:13 | INFO | fairseq.trainer | begin training epoch 6
2022-10-31 08:11:29 | INFO | train_inner | {"epoch": 6, "update": 5.011, "loss": "2.122", "nll_loss": "0.246", "ppl": "1.19", "wps": "76.8", "ups": "0.05", "wpb": "1572.5", "bsz": "16", "num_updates": "16400", "lr": "4.92046e-05", "gnorm": "0.472", "train_wall": "43", "wall": "16948"}
2022-10-31 08:12:09 | INFO | train_inner | {"epoch": 6, "update": 5.041, "loss": "2.114", "nll_loss": "0.236", "ppl": "1.18", "wps": "3836.6", "ups": "2.47", "wpb": "1556.4", "bsz": "16", "num_updates": "16500", "lr": "4.91996e-05", "gnorm": "0.44", "train_wall": "40", "wall": "16988"}
2022-10-31 08:12:53 | INFO | train_inner | {"epoch": 6, "update": 5.072, "loss": "2.115", "nll_loss": "0.238", "ppl": "1.18", "wps": "3617.1", "ups": "2.28", "wpb": "1584.1", "bsz": "16", "num_updates": "16600", "lr": "4.91946e-05", "gnorm": "0.485", "train_wall": "43", "wall": "17032"}
2022-10-31 08:13:29 | INFO | train_inner | {"epoch": 6, "update": 5.102, "loss": "2.113", "nll_loss": "0.235", "ppl": "1.18", "wps": "4363.9", "ups": "2.73", "wpb": "1596.1", "bsz": "16", "num_updates": "16700", "lr": "4.91896e-05", "gnorm": "0.475", "train_wall": "36", "wall": "17069"}
2022-10-31 08:14:11 | INFO | train_inner | {"epoch": 6, "update": 5.133, "loss": "2.114", "nll_loss": "0.236", "ppl": "1.18", "wps": "3731.1", "ups": "2.42", "wpb": "1543.6", "bsz": "16", "num_updates": "16800", "lr": "4.91846e-05", "gnorm": "0.507", "train_wall": "41", "wall": "17110"}
2022-10-31 08:14:53 | INFO | train_inner | {"epoch": 6, "update": 5.163, "loss": "2.117", "nll_loss": "0.24", "ppl": "1.18", "wps": "3705.8", "ups": "2.38", "wpb": "1557.5", "bsz": "16", "num_updates": "16900", "lr": "4.91796e-05", "gnorm": "0.493", "train_wall": "42", "wall": "17152"}
2022-10-31 08:15:33 | INFO | train_inner | {"epoch": 6, "update": 5.194, "loss": "2.116", "nll_loss": "0.239", "ppl": "1.18", "wps": "3960.3", "ups": "2.49", "wpb": "1591.8", "bsz": "16", "num_updates": "17000", "lr": "4.91746e-05", "gnorm": "0.449", "train_wall": "40", "wall": "17192"}
2022-10-31 08:16:17 | INFO | train_inner | {"epoch": 6, "update": 5.225, "loss": "2.116", "nll_loss": "0.239", "ppl": "1.18", "wps": "3571.9", "ups": "2.27", "wpb": "1576.3", "bsz": "16", "num_updates": "17100", "lr": "4.91696e-05", "gnorm": "0.484", "train_wall": "44", "wall": "17236"}
2022-10-31 08:16:58 | INFO | train_inner | {"epoch": 6, "update": 5.255, "loss": "2.116", "nll_loss": "0.239", "ppl": "1.18", "wps": "3881.6", "ups": "2.44", "wpb": "1591.1", "bsz": "16", "num_updates": "17200", "lr": "4.91646e-05", "gnorm": "0.461", "train_wall": "41", "wall": "17277"}
2022-10-31 08:17:41 | INFO | train_inner | {"epoch": 6, "update": 5.286, "loss": "2.115", "nll_loss": "0.239", "ppl": "1.18", "wps": "3604.6", "ups": "2.33", "wpb": "1549.7", "bsz": "16", "num_updates": "17300", "lr": "4.91596e-05", "gnorm": "0.477", "train_wall": "42", "wall": "17320"}
2022-10-31 08:18:22 | INFO | train_inner | {"epoch": 6, "update": 5.316, "loss": "2.119", "nll_loss": "0.242", "ppl": "1.18", "wps": "3843.2", "ups": "2.46", "wpb": "1561.5", "bsz": "16", "num_updates": "17400", "lr": "4.91546e-05", "gnorm": "0.479", "train_wall": "40", "wall": "17361"}
2022-10-31 08:18:53 | INFO | train_inner | {"epoch": 6, "update": 5.347, "loss": "2.117", "nll_loss": "0.24", "ppl": "1.18", "wps": "5051.3", "ups": "3.23", "wpb": "1562.9", "bsz": "16", "num_updates": "17500", "lr": "4.91496e-05", "gnorm": "0.526", "train_wall": "31", "wall": "17392"}
2022-10-31 08:19:33 | INFO | train_inner | {"epoch": 6, "update": 5.377, "loss": "2.117", "nll_loss": "0.24", "ppl": "1.18", "wps": "3868.9", "ups": "2.47", "wpb": "1564.1", "bsz": "16", "num_updates": "17600", "lr": "4.91446e-05", "gnorm": "0.47", "train_wall": "40", "wall": "17432"}
2022-10-31 08:20:19 | INFO | train_inner | {"epoch": 6, "update": 5.408, "loss": "2.121", "nll_loss": "0.245", "ppl": "1.19", "wps": "3508.3", "ups": "2.2", "wpb": "1595.6", "bsz": "16", "num_updates": "17700", "lr": "4.91396e-05", "gnorm": "0.501", "train_wall": "45", "wall": "17478"}
2022-10-31 08:20:54 | INFO | train_inner | {"epoch": 6, "update": 5.438, "loss": "2.115", "nll_loss": "0.238", "ppl": "1.18", "wps": "4483.1", "ups": "2.85", "wpb": "1575.2", "bsz": "16", "num_updates": "17800", "lr": "4.91346e-05", "gnorm": "0.453", "train_wall": "35", "wall": "17513"}
2022-10-31 08:21:37 | INFO | train_inner | {"epoch": 6, "update": 5.469, "loss": "2.121", "nll_loss": "0.245", "ppl": "1.19", "wps": "3653.2", "ups": "2.32", "wpb": "1577.7", "bsz": "16", "num_updates": "17900", "lr": "4.91296e-05", "gnorm": "0.477", "train_wall": "43", "wall": "17556"}
2022-10-31 08:22:20 | INFO | train_inner | {"epoch": 6, "update": 5.5, "loss": "2.116", "nll_loss": "0.239", "ppl": "1.18", "wps": "3708.7", "ups": "2.32", "wpb": "1596.7", "bsz": "16", "num_updates": "18000", "lr": "4.91246e-05", "gnorm": "0.474", "train_wall": "43", "wall": "17599"}
2022-10-31 08:23:01 | INFO | train_inner | {"epoch": 6, "update": 5.53, "loss": "2.116", "nll_loss": "0.24", "ppl": "1.18", "wps": "3946.5", "ups": "2.46", "wpb": "1605.7", "bsz": "16", "num_updates": "18100", "lr": "4.91196e-05", "gnorm": "0.474", "train_wall": "40", "wall": "17640"}
2022-10-31 08:23:41 | INFO | train_inner | {"epoch": 6, "update": 5.561, "loss": "2.116", "nll_loss": "0.239", "ppl": "1.18", "wps": "3896.9", "ups": "2.46", "wpb": "1584.8", "bsz": "16", "num_updates": "18200", "lr": "4.91146e-05", "gnorm": "0.469", "train_wall": "40", "wall": "17681"}
2022-10-31 08:24:23 | INFO | train_inner | {"epoch": 6, "update": 5.591, "loss": "2.118", "nll_loss": "0.242", "ppl": "1.18", "wps": "3732", "ups": "2.38", "wpb": "1570.3", "bsz": "16", "num_updates": "18300", "lr": "4.91096e-05", "gnorm": "0.48", "train_wall": "42", "wall": "17723"}
2022-10-31 08:25:08 | INFO | train_inner | {"epoch": 6, "update": 5.622, "loss": "2.119", "nll_loss": "0.243", "ppl": "1.18", "wps": "3527.4", "ups": "2.23", "wpb": "1580.9", "bsz": "16", "num_updates": "18400", "lr": "4.91046e-05", "gnorm": "0.465", "train_wall": "44", "wall": "17767"}
2022-10-31 08:25:53 | INFO | train_inner | {"epoch": 6, "update": 5.652, "loss": "2.117", "nll_loss": "0.24", "ppl": "1.18", "wps": "3530.2", "ups": "2.25", "wpb": "1568.7", "bsz": "16", "num_updates": "18500", "lr": "4.90995e-05", "gnorm": "0.453", "train_wall": "44", "wall": "17812"}
2022-10-31 08:26:35 | INFO | train_inner | {"epoch": 6, "update": 5.683, "loss": "2.12", "nll_loss": "0.243", "ppl": "1.18", "wps": "3789.4", "ups": "2.37", "wpb": "1598.7", "bsz": "16", "num_updates": "18600", "lr": "4.90945e-05", "gnorm": "0.464", "train_wall": "42", "wall": "17854"}
2022-10-31 08:27:18 | INFO | train_inner | {"epoch": 6, "update": 5.713, "loss": "2.12", "nll_loss": "0.244", "ppl": "1.18", "wps": "3600.5", "ups": "2.34", "wpb": "1535.8", "bsz": "16", "num_updates": "18700", "lr": "4.90895e-05", "gnorm": "0.508", "train_wall": "42", "wall": "17897"}
2022-10-31 08:28:02 | INFO | train_inner | {"epoch": 6, "update": 5.744, "loss": "2.115", "nll_loss": "0.239", "ppl": "1.18", "wps": "3577.6", "ups": "2.27", "wpb": "1579.3", "bsz": "16", "num_updates": "18800", "lr": "4.90845e-05", "gnorm": "0.473", "train_wall": "44", "wall": "17941"}
2022-10-31 08:28:44 | INFO | train_inner | {"epoch": 6, "update": 5.775, "loss": "2.122", "nll_loss": "0.246", "ppl": "1.19", "wps": "3742.3", "ups": "2.36", "wpb": "1583.1", "bsz": "16", "num_updates": "18900", "lr": "4.90795e-05", "gnorm": "0.489", "train_wall": "42", "wall": "17983"}
2022-10-31 08:29:31 | INFO | train_inner | {"epoch": 6, "update": 5.805, "loss": "2.118", "nll_loss": "0.241", "ppl": "1.18", "wps": "3312.7", "ups": "2.12", "wpb": "1565.6", "bsz": "16", "num_updates": "19000", "lr": "4.90745e-05", "gnorm": "0.448", "train_wall": "47", "wall": "18030"}
2022-10-31 08:30:17 | INFO | train_inner | {"epoch": 6, "update": 5.836, "loss": "2.12", "nll_loss": "0.245", "ppl": "1.18", "wps": "3449", "ups": "2.18", "wpb": "1582", "bsz": "16", "num_updates": "19100", "lr": "4.90695e-05", "gnorm": "0.478", "train_wall": "45", "wall": "18076"}
2022-10-31 08:30:59 | INFO | train_inner | {"epoch": 6, "update": 5.866, "loss": "2.12", "nll_loss": "0.244", "ppl": "1.18", "wps": "3719.1", "ups": "2.38", "wpb": "1563.1", "bsz": "16", "num_updates": "19200", "lr": "4.90645e-05", "gnorm": "0.486", "train_wall": "42", "wall": "18118"}
2022-10-31 08:31:43 | INFO | train_inner | {"epoch": 6, "update": 5.897, "loss": "2.118", "nll_loss": "0.242", "ppl": "1.18", "wps": "3588.2", "ups": "2.3", "wpb": "1558.5", "bsz": "16", "num_updates": "19300", "lr": "4.90595e-05", "gnorm": "0.479", "train_wall": "43", "wall": "18162"}
2022-10-31 08:32:31 | INFO | train_inner | {"epoch": 6, "update": 5.927, "loss": "2.122", "nll_loss": "0.246", "ppl": "1.19", "wps": "3268.1", "ups": "2.08", "wpb": "1569.7", "bsz": "16", "num_updates": "19400", "lr": "4.90545e-05", "gnorm": "0.517", "train_wall": "47", "wall": "18210"}
2022-10-31 08:33:17 | INFO | train_inner | {"epoch": 6, "update": 5.958, "loss": "2.121", "nll_loss": "0.245", "ppl": "1.19", "wps": "3347.1", "ups": "2.15", "wpb": "1555.8", "bsz": "16", "num_updates": "19500", "lr": "4.90495e-05", "gnorm": "0.47", "train_wall": "46", "wall": "18256"}
2022-10-31 08:34:05 | INFO | train_inner | {"epoch": 6, "update": 5.988, "loss": "2.12", "nll_loss": "0.245", "ppl": "1.18", "wps": "3325", "ups": "2.11", "wpb": "1575.5", "bsz": "16", "num_updates": "19600", "lr": "4.90445e-05", "gnorm": "0.475", "train_wall": "47", "wall": "18304"}
2022-10-31 08:34:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 09:07:52 | INFO | valid | {"epoch": 6, "valid_loss": "2.161", "valid_nll_loss": "0.229", "valid_ppl": "1.17", "valid_bleu": "85.88", "valid_wps": "321.1", "valid_wpb": "394.3", "valid_bsz": "4", "valid_num_updates": "19638", "valid_best_bleu": "87.66"}
2022-10-31 09:07:52 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 09:08:00 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_last.pt (epoch 6 @ 19638 updates, score 85.88) (writing took 8.237488124053925 seconds)
2022-10-31 09:08:00 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-10-31 09:08:00 | INFO | train | {"epoch": 6, "train_loss": "2.117", "train_nll_loss": "0.241", "train_ppl": "1.18", "train_wps": "1511.2", "train_ups": "0.96", "train_wpb": "1573", "train_bsz": "16", "train_num_updates": "19638", "train_lr": "4.90426e-05", "train_gnorm": "0.477", "train_train_wall": "1372", "train_wall": "20339"}
2022-10-31 09:08:00 | INFO | fairseq.trainer | begin training epoch 7
2022-10-31 09:08:21 | INFO | train_inner | {"epoch": 7, "update": 6.019, "loss": "2.111", "nll_loss": "0.234", "ppl": "1.18", "wps": "75.8", "ups": "0.05", "wpb": "1557.9", "bsz": "16", "num_updates": "19700", "lr": "4.90395e-05", "gnorm": "0.452", "train_wall": "37", "wall": "20360"}
2022-10-31 09:09:03 | INFO | train_inner | {"epoch": 7, "update": 6.049, "loss": "2.107", "nll_loss": "0.229", "ppl": "1.17", "wps": "3711.7", "ups": "2.37", "wpb": "1564.1", "bsz": "16", "num_updates": "19800", "lr": "4.90345e-05", "gnorm": "0.481", "train_wall": "42", "wall": "20402"}
2022-10-31 09:09:47 | INFO | train_inner | {"epoch": 7, "update": 6.08, "loss": "2.104", "nll_loss": "0.226", "ppl": "1.17", "wps": "3539.7", "ups": "2.25", "wpb": "1576", "bsz": "16", "num_updates": "19900", "lr": "4.90295e-05", "gnorm": "0.477", "train_wall": "44", "wall": "20447"}
2022-10-31 09:10:32 | INFO | train_inner | {"epoch": 7, "update": 6.111, "loss": "2.107", "nll_loss": "0.23", "ppl": "1.17", "wps": "3521.1", "ups": "2.26", "wpb": "1555.4", "bsz": "16", "num_updates": "20000", "lr": "4.90245e-05", "gnorm": "0.452", "train_wall": "44", "wall": "20491"}
2022-10-31 09:11:15 | INFO | train_inner | {"epoch": 7, "update": 6.141, "loss": "2.106", "nll_loss": "0.228", "ppl": "1.17", "wps": "3574.6", "ups": "2.28", "wpb": "1565", "bsz": "16", "num_updates": "20100", "lr": "4.90195e-05", "gnorm": "0.477", "train_wall": "43", "wall": "20535"}
2022-10-31 09:11:56 | INFO | train_inner | {"epoch": 7, "update": 6.172, "loss": "2.107", "nll_loss": "0.23", "ppl": "1.17", "wps": "3792", "ups": "2.45", "wpb": "1550", "bsz": "16", "num_updates": "20200", "lr": "4.90145e-05", "gnorm": "0.479", "train_wall": "40", "wall": "20575"}
2022-10-31 09:12:41 | INFO | train_inner | {"epoch": 7, "update": 6.202, "loss": "2.106", "nll_loss": "0.229", "ppl": "1.17", "wps": "3578.8", "ups": "2.23", "wpb": "1605.7", "bsz": "16", "num_updates": "20300", "lr": "4.90095e-05", "gnorm": "0.508", "train_wall": "44", "wall": "20620"}
2022-10-31 09:13:24 | INFO | train_inner | {"epoch": 7, "update": 6.233, "loss": "2.108", "nll_loss": "0.231", "ppl": "1.17", "wps": "3741.1", "ups": "2.33", "wpb": "1608.7", "bsz": "16", "num_updates": "20400", "lr": "4.90045e-05", "gnorm": "0.474", "train_wall": "42", "wall": "20663"}
2022-10-31 09:14:06 | INFO | train_inner | {"epoch": 7, "update": 6.263, "loss": "2.108", "nll_loss": "0.231", "ppl": "1.17", "wps": "3854", "ups": "2.36", "wpb": "1631.8", "bsz": "16", "num_updates": "20500", "lr": "4.89995e-05", "gnorm": "0.464", "train_wall": "42", "wall": "20706"}
2022-10-31 09:14:48 | INFO | train_inner | {"epoch": 7, "update": 6.294, "loss": "2.105", "nll_loss": "0.228", "ppl": "1.17", "wps": "3799.5", "ups": "2.39", "wpb": "1591.3", "bsz": "16", "num_updates": "20600", "lr": "4.89945e-05", "gnorm": "0.46", "train_wall": "41", "wall": "20748"}
2022-10-31 09:15:35 | INFO | train_inner | {"epoch": 7, "update": 6.324, "loss": "2.108", "nll_loss": "0.231", "ppl": "1.17", "wps": "3380.1", "ups": "2.16", "wpb": "1561.5", "bsz": "16", "num_updates": "20700", "lr": "4.89895e-05", "gnorm": "0.467", "train_wall": "46", "wall": "20794"}
2022-10-31 09:16:18 | INFO | train_inner | {"epoch": 7, "update": 6.355, "loss": "2.109", "nll_loss": "0.232", "ppl": "1.17", "wps": "3674.4", "ups": "2.33", "wpb": "1579.8", "bsz": "16", "num_updates": "20800", "lr": "4.89845e-05", "gnorm": "0.481", "train_wall": "42", "wall": "20837"}
2022-10-31 09:16:59 | INFO | train_inner | {"epoch": 7, "update": 6.386, "loss": "2.11", "nll_loss": "0.233", "ppl": "1.18", "wps": "3820.8", "ups": "2.42", "wpb": "1575.8", "bsz": "16", "num_updates": "20900", "lr": "4.89795e-05", "gnorm": "0.505", "train_wall": "41", "wall": "20878"}
2022-10-31 09:17:43 | INFO | train_inner | {"epoch": 7, "update": 6.416, "loss": "2.111", "nll_loss": "0.234", "ppl": "1.18", "wps": "3472.9", "ups": "2.24", "wpb": "1547.9", "bsz": "16", "num_updates": "21000", "lr": "4.89745e-05", "gnorm": "0.482", "train_wall": "44", "wall": "20923"}
2022-10-31 09:18:22 | INFO | train_inner | {"epoch": 7, "update": 6.447, "loss": "2.109", "nll_loss": "0.232", "ppl": "1.17", "wps": "4019", "ups": "2.59", "wpb": "1550.7", "bsz": "16", "num_updates": "21100", "lr": "4.89695e-05", "gnorm": "0.498", "train_wall": "38", "wall": "20961"}
2022-10-31 09:19:04 | INFO | train_inner | {"epoch": 7, "update": 6.477, "loss": "2.11", "nll_loss": "0.234", "ppl": "1.18", "wps": "3795.7", "ups": "2.38", "wpb": "1595", "bsz": "16", "num_updates": "21200", "lr": "4.89645e-05", "gnorm": "0.451", "train_wall": "42", "wall": "21003"}
2022-10-31 09:19:44 | INFO | train_inner | {"epoch": 7, "update": 6.508, "loss": "2.113", "nll_loss": "0.236", "ppl": "1.18", "wps": "3823.4", "ups": "2.47", "wpb": "1547.7", "bsz": "16", "num_updates": "21300", "lr": "4.89595e-05", "gnorm": "0.479", "train_wall": "40", "wall": "21044"}
2022-10-31 09:20:30 | INFO | train_inner | {"epoch": 7, "update": 6.538, "loss": "2.108", "nll_loss": "0.231", "ppl": "1.17", "wps": "3373.1", "ups": "2.17", "wpb": "1551.8", "bsz": "16", "num_updates": "21400", "lr": "4.89545e-05", "gnorm": "0.479", "train_wall": "46", "wall": "21090"}
2022-10-31 09:21:14 | INFO | train_inner | {"epoch": 7, "update": 6.569, "loss": "2.109", "nll_loss": "0.232", "ppl": "1.17", "wps": "3640.8", "ups": "2.32", "wpb": "1569.5", "bsz": "16", "num_updates": "21500", "lr": "4.89495e-05", "gnorm": "0.463", "train_wall": "43", "wall": "21133"}
2022-10-31 09:21:56 | INFO | train_inner | {"epoch": 7, "update": 6.599, "loss": "2.113", "nll_loss": "0.236", "ppl": "1.18", "wps": "3685", "ups": "2.38", "wpb": "1548.2", "bsz": "16", "num_updates": "21600", "lr": "4.89445e-05", "gnorm": "0.523", "train_wall": "42", "wall": "21175"}
2022-10-31 09:22:40 | INFO | train_inner | {"epoch": 7, "update": 6.63, "loss": "2.11", "nll_loss": "0.233", "ppl": "1.18", "wps": "3551.6", "ups": "2.27", "wpb": "1565.5", "bsz": "16", "num_updates": "21700", "lr": "4.89395e-05", "gnorm": "0.481", "train_wall": "44", "wall": "21219"}
2022-10-31 09:23:22 | INFO | train_inner | {"epoch": 7, "update": 6.661, "loss": "2.11", "nll_loss": "0.233", "ppl": "1.18", "wps": "3766.3", "ups": "2.34", "wpb": "1607.6", "bsz": "16", "num_updates": "21800", "lr": "4.89345e-05", "gnorm": "0.462", "train_wall": "42", "wall": "21262"}
2022-10-31 09:24:05 | INFO | train_inner | {"epoch": 7, "update": 6.691, "loss": "2.112", "nll_loss": "0.235", "ppl": "1.18", "wps": "3706.4", "ups": "2.35", "wpb": "1574.3", "bsz": "16", "num_updates": "21900", "lr": "4.89295e-05", "gnorm": "0.487", "train_wall": "42", "wall": "21304"}
2022-10-31 09:24:44 | INFO | train_inner | {"epoch": 7, "update": 6.722, "loss": "2.112", "nll_loss": "0.236", "ppl": "1.18", "wps": "3986.7", "ups": "2.55", "wpb": "1562.7", "bsz": "16", "num_updates": "22000", "lr": "4.89245e-05", "gnorm": "0.533", "train_wall": "39", "wall": "21343"}
2022-10-31 09:25:21 | INFO | train_inner | {"epoch": 7, "update": 6.752, "loss": "2.112", "nll_loss": "0.235", "ppl": "1.18", "wps": "4192.5", "ups": "2.68", "wpb": "1564.2", "bsz": "16", "num_updates": "22100", "lr": "4.89195e-05", "gnorm": "0.492", "train_wall": "37", "wall": "21381"}
2022-10-31 09:26:06 | INFO | train_inner | {"epoch": 7, "update": 6.783, "loss": "2.111", "nll_loss": "0.235", "ppl": "1.18", "wps": "3505.8", "ups": "2.26", "wpb": "1553.3", "bsz": "16", "num_updates": "22200", "lr": "4.89145e-05", "gnorm": "0.518", "train_wall": "44", "wall": "21425"}
2022-10-31 09:26:42 | INFO | train_inner | {"epoch": 7, "update": 6.813, "loss": "2.113", "nll_loss": "0.237", "ppl": "1.18", "wps": "4358.6", "ups": "2.76", "wpb": "1580.8", "bsz": "16", "num_updates": "22300", "lr": "4.89095e-05", "gnorm": "0.477", "train_wall": "36", "wall": "21461"}
2022-10-31 09:27:23 | INFO | train_inner | {"epoch": 7, "update": 6.844, "loss": "2.117", "nll_loss": "0.242", "ppl": "1.18", "wps": "3851.7", "ups": "2.45", "wpb": "1573.9", "bsz": "16", "num_updates": "22400", "lr": "4.89045e-05", "gnorm": "0.516", "train_wall": "40", "wall": "21502"}
2022-10-31 09:28:04 | INFO | train_inner | {"epoch": 7, "update": 6.874, "loss": "2.112", "nll_loss": "0.236", "ppl": "1.18", "wps": "3850.8", "ups": "2.45", "wpb": "1573", "bsz": "16", "num_updates": "22500", "lr": "4.88994e-05", "gnorm": "0.475", "train_wall": "40", "wall": "21543"}
2022-10-31 09:28:49 | INFO | train_inner | {"epoch": 7, "update": 6.905, "loss": "2.111", "nll_loss": "0.235", "ppl": "1.18", "wps": "3489.4", "ups": "2.19", "wpb": "1589.9", "bsz": "16", "num_updates": "22600", "lr": "4.88944e-05", "gnorm": "0.447", "train_wall": "45", "wall": "21588"}
2022-10-31 09:29:35 | INFO | train_inner | {"epoch": 7, "update": 6.936, "loss": "2.109", "nll_loss": "0.233", "ppl": "1.17", "wps": "3435.3", "ups": "2.17", "wpb": "1580.9", "bsz": "16", "num_updates": "22700", "lr": "4.88894e-05", "gnorm": "0.463", "train_wall": "46", "wall": "21634"}
2022-10-31 09:30:21 | INFO | train_inner | {"epoch": 7, "update": 6.966, "loss": "2.114", "nll_loss": "0.238", "ppl": "1.18", "wps": "3404.4", "ups": "2.19", "wpb": "1555.7", "bsz": "16", "num_updates": "22800", "lr": "4.88844e-05", "gnorm": "0.509", "train_wall": "45", "wall": "21680"}
2022-10-31 09:31:09 | INFO | train_inner | {"epoch": 7, "update": 6.997, "loss": "2.113", "nll_loss": "0.237", "ppl": "1.18", "wps": "3264.1", "ups": "2.06", "wpb": "1581.5", "bsz": "16", "num_updates": "22900", "lr": "4.88794e-05", "gnorm": "0.475", "train_wall": "48", "wall": "21729"}
2022-10-31 09:31:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-31 10:05:08 | INFO | valid | {"epoch": 7, "valid_loss": "2.165", "valid_nll_loss": "0.235", "valid_ppl": "1.18", "valid_bleu": "86.85", "valid_wps": "317.5", "valid_wpb": "394.3", "valid_bsz": "4", "valid_num_updates": "22911", "valid_best_bleu": "87.66"}
2022-10-31 10:05:08 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 5 runs
2022-10-31 10:05:08 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-31 10:05:16 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_last.pt (epoch 7 @ 22911 updates, score 86.85) (writing took 8.040068980306387 seconds)
2022-10-31 10:05:16 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-10-31 10:05:16 | INFO | train | {"epoch": 7, "train_loss": "2.11", "train_nll_loss": "0.233", "train_ppl": "1.18", "train_wps": "1498.4", "train_ups": "0.95", "train_wpb": "1573", "train_bsz": "16", "train_num_updates": "22911", "train_lr": "4.88789e-05", "train_gnorm": "0.481", "train_train_wall": "1379", "train_wall": "23775"}
2022-10-31 10:05:16 | INFO | fairseq_cli.train | done training in 23773.4 seconds
BLEU: 87.61 ; Acc: 8.71
#############################################################################################
######## end ################
