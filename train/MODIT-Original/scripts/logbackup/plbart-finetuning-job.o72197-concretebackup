######## start ##############
#############################################################################################
Experiment for PLBART
=============================================================================================
Small Dataset:
---------------------------------------------------------------------------------------------
Source: source Target: target
2022-10-26 20:57:47 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.1, batch_size=4, batch_size_valid=4, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, extra_lang_symbol='', fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/home/y_shi202/related-project/MODIT/models/pretrained/checkpoints/checkpoint_11_100000.pt', save_dir='/home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1234, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_in_same_language', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[4], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='/home/y_shi202/related-project/MODIT/src', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=500, weight_decay=0.0, zero_sharding='none')
2022-10-26 20:57:48 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2022-10-26 20:57:48 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2022-10-26 20:57:48 | INFO | fairseq.data.data_utils | loaded 5828 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/valid.source-target.source
2022-10-26 20:57:48 | INFO | fairseq.data.data_utils | loaded 5828 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/valid.source-target.target
2022-10-26 20:57:48 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin valid source-target 5828 examples
2022-10-26 20:57:51 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2022-10-26 20:57:51 | INFO | fairseq_cli.train | task: translation_in_same_language (TranslationCodeBARTTask)
2022-10-26 20:57:51 | INFO | fairseq_cli.train | model: mbart_base (BARTModel)
2022-10-26 20:57:51 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2022-10-26 20:57:51 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2022-10-26 20:57:54 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-26 20:57:54 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-26 20:57:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-10-26 20:57:54 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-PCIE-32GB                    
2022-10-26 20:57:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-10-26 20:57:54 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-10-26 20:57:54 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 4
2022-10-26 20:57:56 | INFO | fairseq.trainer | loaded checkpoint /home/y_shi202/related-project/MODIT/models/pretrained/checkpoints/checkpoint_11_100000.pt (epoch 11 @ 0 updates)
2022-10-26 20:57:56 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2022-10-26 20:57:56 | INFO | fairseq.trainer | loading train data for epoch 1
2022-10-26 20:57:56 | INFO | fairseq.data.data_utils | loaded 46628 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/train.source-target.source
2022-10-26 20:57:56 | INFO | fairseq.data.data_utils | loaded 46628 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/train.source-target.target
2022-10-26 20:57:56 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin train source-target 46628 examples
2022-10-26 20:57:56 | INFO | fairseq.trainer | begin training epoch 1
2022-10-26 20:58:20 | INFO | train_inner | {"epoch": 1, "update": 0.034, "loss": "4.558", "nll_loss": "2.238", "ppl": "4.72", "wps": "3938.3", "ups": "4.25", "wpb": "925", "bsz": "16", "num_updates": "100", "lr": "1e-05", "gnorm": "24.458", "train_wall": "24", "wall": "26"}
2022-10-26 20:59:08 | INFO | train_inner | {"epoch": 1, "update": 0.069, "loss": "2.661", "nll_loss": "0.608", "ppl": "1.52", "wps": "1816.9", "ups": "2.07", "wpb": "877", "bsz": "16", "num_updates": "200", "lr": "2e-05", "gnorm": "2.569", "train_wall": "48", "wall": "74"}
2022-10-26 20:59:58 | INFO | train_inner | {"epoch": 1, "update": 0.103, "loss": "2.446", "nll_loss": "0.461", "ppl": "1.38", "wps": "1832.6", "ups": "2", "wpb": "914.3", "bsz": "16", "num_updates": "300", "lr": "3e-05", "gnorm": "1.465", "train_wall": "49", "wall": "124"}
2022-10-26 21:00:48 | INFO | train_inner | {"epoch": 1, "update": 0.137, "loss": "2.376", "nll_loss": "0.421", "ppl": "1.34", "wps": "1729.4", "ups": "2.01", "wpb": "860.8", "bsz": "16", "num_updates": "400", "lr": "4e-05", "gnorm": "1.212", "train_wall": "49", "wall": "174"}
2022-10-26 21:01:38 | INFO | train_inner | {"epoch": 1, "update": 0.172, "loss": "2.349", "nll_loss": "0.405", "ppl": "1.32", "wps": "1817.7", "ups": "2.02", "wpb": "900.4", "bsz": "16", "num_updates": "500", "lr": "5e-05", "gnorm": "1.205", "train_wall": "49", "wall": "223"}
2022-10-26 21:02:28 | INFO | train_inner | {"epoch": 1, "update": 0.206, "loss": "2.338", "nll_loss": "0.402", "ppl": "1.32", "wps": "1821.9", "ups": "2", "wpb": "909.9", "bsz": "16", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "1.14", "train_wall": "49", "wall": "273"}
2022-10-26 21:03:17 | INFO | train_inner | {"epoch": 1, "update": 0.24, "loss": "2.325", "nll_loss": "0.396", "ppl": "1.32", "wps": "1741", "ups": "2.01", "wpb": "867.6", "bsz": "16", "num_updates": "700", "lr": "4.999e-05", "gnorm": "1.148", "train_wall": "49", "wall": "323"}
2022-10-26 21:04:07 | INFO | train_inner | {"epoch": 1, "update": 0.274, "loss": "2.315", "nll_loss": "0.389", "ppl": "1.31", "wps": "1799.1", "ups": "2", "wpb": "898.6", "bsz": "16", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "1.138", "train_wall": "49", "wall": "373"}
2022-10-26 21:04:57 | INFO | train_inner | {"epoch": 1, "update": 0.309, "loss": "2.306", "nll_loss": "0.383", "ppl": "1.3", "wps": "1847.5", "ups": "2", "wpb": "923.5", "bsz": "16", "num_updates": "900", "lr": "4.998e-05", "gnorm": "1.073", "train_wall": "49", "wall": "423"}
2022-10-26 21:05:47 | INFO | train_inner | {"epoch": 1, "update": 0.343, "loss": "2.31", "nll_loss": "0.391", "ppl": "1.31", "wps": "1760.8", "ups": "2.01", "wpb": "876.9", "bsz": "16", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "1.079", "train_wall": "49", "wall": "473"}
2022-10-26 21:06:36 | INFO | train_inner | {"epoch": 1, "update": 0.377, "loss": "2.313", "nll_loss": "0.397", "ppl": "1.32", "wps": "1647.3", "ups": "2.03", "wpb": "809.6", "bsz": "16", "num_updates": "1100", "lr": "4.997e-05", "gnorm": "1.175", "train_wall": "49", "wall": "522"}
2022-10-26 21:07:24 | INFO | train_inner | {"epoch": 1, "update": 0.412, "loss": "2.291", "nll_loss": "0.373", "ppl": "1.3", "wps": "1959.6", "ups": "2.09", "wpb": "936.2", "bsz": "16", "num_updates": "1200", "lr": "4.9965e-05", "gnorm": "1.032", "train_wall": "47", "wall": "570"}
2022-10-26 21:08:14 | INFO | train_inner | {"epoch": 1, "update": 0.446, "loss": "2.27", "nll_loss": "0.353", "ppl": "1.28", "wps": "1818.7", "ups": "2", "wpb": "911.4", "bsz": "16", "num_updates": "1300", "lr": "4.996e-05", "gnorm": "1.022", "train_wall": "50", "wall": "620"}
2022-10-26 21:09:04 | INFO | train_inner | {"epoch": 1, "update": 0.48, "loss": "2.278", "nll_loss": "0.365", "ppl": "1.29", "wps": "1837.8", "ups": "2.02", "wpb": "912", "bsz": "16", "num_updates": "1400", "lr": "4.9955e-05", "gnorm": "1.093", "train_wall": "49", "wall": "669"}
2022-10-26 21:09:52 | INFO | train_inner | {"epoch": 1, "update": 0.515, "loss": "2.291", "nll_loss": "0.379", "ppl": "1.3", "wps": "1834.4", "ups": "2.06", "wpb": "890.2", "bsz": "16", "num_updates": "1500", "lr": "4.995e-05", "gnorm": "1.107", "train_wall": "48", "wall": "718"}
2022-10-26 21:10:18 | INFO | train_inner | {"epoch": 1, "update": 0.549, "loss": "2.276", "nll_loss": "0.364", "ppl": "1.29", "wps": "3488.3", "ups": "3.84", "wpb": "907.5", "bsz": "16", "num_updates": "1600", "lr": "4.9945e-05", "gnorm": "0.986", "train_wall": "26", "wall": "744"}
2022-10-26 21:11:08 | INFO | train_inner | {"epoch": 1, "update": 0.583, "loss": "2.271", "nll_loss": "0.361", "ppl": "1.28", "wps": "1888.7", "ups": "2.02", "wpb": "936", "bsz": "16", "num_updates": "1700", "lr": "4.994e-05", "gnorm": "1.071", "train_wall": "49", "wall": "793"}
2022-10-26 21:11:58 | INFO | train_inner | {"epoch": 1, "update": 0.617, "loss": "2.271", "nll_loss": "0.362", "ppl": "1.29", "wps": "1853.1", "ups": "2", "wpb": "925", "bsz": "16", "num_updates": "1800", "lr": "4.9935e-05", "gnorm": "1.045", "train_wall": "49", "wall": "843"}
2022-10-26 21:12:48 | INFO | train_inner | {"epoch": 1, "update": 0.652, "loss": "2.267", "nll_loss": "0.359", "ppl": "1.28", "wps": "1851.7", "ups": "2", "wpb": "925.1", "bsz": "16", "num_updates": "1900", "lr": "4.993e-05", "gnorm": "0.926", "train_wall": "49", "wall": "893"}
2022-10-26 21:13:38 | INFO | train_inner | {"epoch": 1, "update": 0.686, "loss": "2.268", "nll_loss": "0.361", "ppl": "1.28", "wps": "1794.8", "ups": "2", "wpb": "897.9", "bsz": "16", "num_updates": "2000", "lr": "4.9925e-05", "gnorm": "0.948", "train_wall": "49", "wall": "943"}
2022-10-26 21:14:27 | INFO | train_inner | {"epoch": 1, "update": 0.72, "loss": "2.262", "nll_loss": "0.355", "ppl": "1.28", "wps": "1746.7", "ups": "2.01", "wpb": "867.1", "bsz": "16", "num_updates": "2100", "lr": "4.992e-05", "gnorm": "0.939", "train_wall": "49", "wall": "993"}
2022-10-26 21:15:17 | INFO | train_inner | {"epoch": 1, "update": 0.755, "loss": "2.27", "nll_loss": "0.364", "ppl": "1.29", "wps": "1779.8", "ups": "2", "wpb": "891", "bsz": "16", "num_updates": "2200", "lr": "4.9915e-05", "gnorm": "1.044", "train_wall": "49", "wall": "1043"}
2022-10-26 21:16:07 | INFO | train_inner | {"epoch": 1, "update": 0.789, "loss": "2.262", "nll_loss": "0.357", "ppl": "1.28", "wps": "1793.3", "ups": "2.02", "wpb": "886.7", "bsz": "16", "num_updates": "2300", "lr": "4.991e-05", "gnorm": "0.969", "train_wall": "49", "wall": "1092"}
2022-10-26 21:16:56 | INFO | train_inner | {"epoch": 1, "update": 0.823, "loss": "2.262", "nll_loss": "0.358", "ppl": "1.28", "wps": "1768.3", "ups": "2.02", "wpb": "875.4", "bsz": "16", "num_updates": "2400", "lr": "4.9905e-05", "gnorm": "1.025", "train_wall": "49", "wall": "1142"}
2022-10-26 21:17:46 | INFO | train_inner | {"epoch": 1, "update": 0.858, "loss": "2.264", "nll_loss": "0.36", "ppl": "1.28", "wps": "1821.1", "ups": "2", "wpb": "908.3", "bsz": "16", "num_updates": "2500", "lr": "4.98999e-05", "gnorm": "0.997", "train_wall": "49", "wall": "1192"}
2022-10-26 21:18:36 | INFO | train_inner | {"epoch": 1, "update": 0.892, "loss": "2.257", "nll_loss": "0.353", "ppl": "1.28", "wps": "1839.6", "ups": "2.01", "wpb": "917.2", "bsz": "16", "num_updates": "2600", "lr": "4.98949e-05", "gnorm": "0.952", "train_wall": "49", "wall": "1242"}
2022-10-26 21:19:26 | INFO | train_inner | {"epoch": 1, "update": 0.926, "loss": "2.258", "nll_loss": "0.355", "ppl": "1.28", "wps": "1725.7", "ups": "2.01", "wpb": "858.8", "bsz": "16", "num_updates": "2700", "lr": "4.98899e-05", "gnorm": "1.117", "train_wall": "49", "wall": "1291"}
2022-10-26 21:20:16 | INFO | train_inner | {"epoch": 1, "update": 0.961, "loss": "2.253", "nll_loss": "0.35", "ppl": "1.27", "wps": "1793.7", "ups": "2.01", "wpb": "892.4", "bsz": "16", "num_updates": "2800", "lr": "4.98849e-05", "gnorm": "0.943", "train_wall": "49", "wall": "1341"}
2022-10-26 21:21:03 | INFO | train_inner | {"epoch": 1, "update": 0.995, "loss": "2.252", "nll_loss": "0.349", "ppl": "1.27", "wps": "1932.4", "ups": "2.12", "wpb": "910.9", "bsz": "16", "num_updates": "2900", "lr": "4.98799e-05", "gnorm": "1", "train_wall": "47", "wall": "1388"}
2022-10-26 21:21:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
/home/y_shi202/.local/lib/python3.6/site-packages/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  "amp_C fused kernels unavailable, disabling multi_tensor_l2norm; "
2022-10-26 21:38:11 | INFO | valid | {"epoch": 1, "valid_loss": "2.278", "valid_nll_loss": "0.253", "valid_ppl": "1.19", "valid_bleu": "73.72", "valid_wps": "317", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "2915"}
2022-10-26 21:38:11 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-26 21:38:24 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_best.pt (epoch 1 @ 2915 updates, score 73.72) (writing took 12.823544468032196 seconds)
2022-10-26 21:38:24 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-10-26 21:38:24 | INFO | train | {"epoch": 1, "train_loss": "2.385", "train_nll_loss": "0.448", "train_ppl": "1.36", "train_wps": "1076.4", "train_ups": "1.2", "train_wpb": "896.6", "train_bsz": "16", "train_num_updates": "2915", "train_lr": "4.98792e-05", "train_gnorm": "1.922", "train_train_wall": "1377", "train_wall": "2430"}
2022-10-26 21:38:24 | INFO | fairseq.trainer | begin training epoch 2
2022-10-26 21:39:04 | INFO | train_inner | {"epoch": 2, "update": 1.029, "loss": "2.231", "nll_loss": "0.326", "ppl": "1.25", "wps": "78.9", "ups": "0.09", "wpb": "852.5", "bsz": "15.9", "num_updates": "3000", "lr": "4.98749e-05", "gnorm": "0.887", "train_wall": "46", "wall": "2469"}
2022-10-26 21:39:53 | INFO | train_inner | {"epoch": 2, "update": 1.063, "loss": "2.223", "nll_loss": "0.316", "ppl": "1.25", "wps": "1905.8", "ups": "2.05", "wpb": "928.7", "bsz": "16", "num_updates": "3100", "lr": "4.98699e-05", "gnorm": "0.922", "train_wall": "48", "wall": "2518"}
2022-10-26 21:40:41 | INFO | train_inner | {"epoch": 2, "update": 1.098, "loss": "2.224", "nll_loss": "0.32", "ppl": "1.25", "wps": "1845.5", "ups": "2.05", "wpb": "899.4", "bsz": "16", "num_updates": "3200", "lr": "4.98649e-05", "gnorm": "0.907", "train_wall": "48", "wall": "2567"}
2022-10-26 21:41:31 | INFO | train_inner | {"epoch": 2, "update": 1.132, "loss": "2.224", "nll_loss": "0.32", "ppl": "1.25", "wps": "1795.5", "ups": "2.03", "wpb": "884.2", "bsz": "16", "num_updates": "3300", "lr": "4.98599e-05", "gnorm": "1.01", "train_wall": "49", "wall": "2616"}
2022-10-26 21:42:20 | INFO | train_inner | {"epoch": 2, "update": 1.166, "loss": "2.221", "nll_loss": "0.317", "ppl": "1.25", "wps": "1757.3", "ups": "2.02", "wpb": "870.9", "bsz": "16", "num_updates": "3400", "lr": "4.98549e-05", "gnorm": "1.078", "train_wall": "49", "wall": "2666"}
2022-10-26 21:43:09 | INFO | train_inner | {"epoch": 2, "update": 1.201, "loss": "2.222", "nll_loss": "0.319", "ppl": "1.25", "wps": "1836", "ups": "2.06", "wpb": "891.4", "bsz": "16", "num_updates": "3500", "lr": "4.98499e-05", "gnorm": "0.93", "train_wall": "48", "wall": "2714"}
2022-10-26 21:43:58 | INFO | train_inner | {"epoch": 2, "update": 1.235, "loss": "2.222", "nll_loss": "0.319", "ppl": "1.25", "wps": "1759.4", "ups": "2.02", "wpb": "870.9", "bsz": "16", "num_updates": "3600", "lr": "4.98449e-05", "gnorm": "0.956", "train_wall": "49", "wall": "2764"}
2022-10-26 21:44:48 | INFO | train_inner | {"epoch": 2, "update": 1.269, "loss": "2.221", "nll_loss": "0.319", "ppl": "1.25", "wps": "1827.4", "ups": "2.01", "wpb": "907.2", "bsz": "16", "num_updates": "3700", "lr": "4.98399e-05", "gnorm": "0.888", "train_wall": "49", "wall": "2813"}
2022-10-26 21:45:35 | INFO | train_inner | {"epoch": 2, "update": 1.304, "loss": "2.222", "nll_loss": "0.319", "ppl": "1.25", "wps": "1902.6", "ups": "2.12", "wpb": "898", "bsz": "16", "num_updates": "3800", "lr": "4.98349e-05", "gnorm": "0.964", "train_wall": "47", "wall": "2861"}
2022-10-26 21:46:24 | INFO | train_inner | {"epoch": 2, "update": 1.338, "loss": "2.223", "nll_loss": "0.322", "ppl": "1.25", "wps": "1788.4", "ups": "2.04", "wpb": "878.7", "bsz": "16", "num_updates": "3900", "lr": "4.98299e-05", "gnorm": "0.983", "train_wall": "49", "wall": "2910"}
2022-10-26 21:47:14 | INFO | train_inner | {"epoch": 2, "update": 1.372, "loss": "2.226", "nll_loss": "0.325", "ppl": "1.25", "wps": "1805.7", "ups": "2.01", "wpb": "896.5", "bsz": "16", "num_updates": "4000", "lr": "4.98249e-05", "gnorm": "0.952", "train_wall": "49", "wall": "2959"}
2022-10-26 21:48:03 | INFO | train_inner | {"epoch": 2, "update": 1.407, "loss": "2.216", "nll_loss": "0.314", "ppl": "1.24", "wps": "1881.7", "ups": "2.03", "wpb": "925.4", "bsz": "16", "num_updates": "4100", "lr": "4.98199e-05", "gnorm": "0.912", "train_wall": "49", "wall": "3008"}
2022-10-26 21:48:52 | INFO | train_inner | {"epoch": 2, "update": 1.441, "loss": "2.216", "nll_loss": "0.314", "ppl": "1.24", "wps": "1933.8", "ups": "2.05", "wpb": "941.9", "bsz": "16", "num_updates": "4200", "lr": "4.98149e-05", "gnorm": "0.907", "train_wall": "48", "wall": "3057"}
2022-10-26 21:49:39 | INFO | train_inner | {"epoch": 2, "update": 1.475, "loss": "2.222", "nll_loss": "0.322", "ppl": "1.25", "wps": "1889.8", "ups": "2.11", "wpb": "893.9", "bsz": "16", "num_updates": "4300", "lr": "4.98099e-05", "gnorm": "0.964", "train_wall": "47", "wall": "3104"}
2022-10-26 21:50:25 | INFO | train_inner | {"epoch": 2, "update": 1.509, "loss": "2.221", "nll_loss": "0.321", "ppl": "1.25", "wps": "1897.8", "ups": "2.16", "wpb": "877.1", "bsz": "16", "num_updates": "4400", "lr": "4.98049e-05", "gnorm": "0.898", "train_wall": "46", "wall": "3151"}
2022-10-26 21:51:14 | INFO | train_inner | {"epoch": 2, "update": 1.544, "loss": "2.226", "nll_loss": "0.327", "ppl": "1.25", "wps": "1768.8", "ups": "2.03", "wpb": "870.6", "bsz": "16", "num_updates": "4500", "lr": "4.97999e-05", "gnorm": "0.994", "train_wall": "49", "wall": "3200"}
2022-10-26 21:51:49 | INFO | train_inner | {"epoch": 2, "update": 1.578, "loss": "2.217", "nll_loss": "0.318", "ppl": "1.25", "wps": "2561", "ups": "2.86", "wpb": "896.6", "bsz": "16", "num_updates": "4600", "lr": "4.97949e-05", "gnorm": "0.906", "train_wall": "35", "wall": "3235"}
2022-10-26 21:52:10 | INFO | train_inner | {"epoch": 2, "update": 1.612, "loss": "2.218", "nll_loss": "0.318", "ppl": "1.25", "wps": "4369.1", "ups": "4.77", "wpb": "916.1", "bsz": "16", "num_updates": "4700", "lr": "4.97899e-05", "gnorm": "0.947", "train_wall": "21", "wall": "3256"}
2022-10-26 21:52:59 | INFO | train_inner | {"epoch": 2, "update": 1.647, "loss": "2.236", "nll_loss": "0.339", "ppl": "1.27", "wps": "1841.3", "ups": "2.05", "wpb": "898", "bsz": "16", "num_updates": "4800", "lr": "4.97849e-05", "gnorm": "0.974", "train_wall": "48", "wall": "3305"}
2022-10-26 21:53:49 | INFO | train_inner | {"epoch": 2, "update": 1.681, "loss": "2.221", "nll_loss": "0.323", "ppl": "1.25", "wps": "1760.6", "ups": "2.02", "wpb": "873.4", "bsz": "16", "num_updates": "4900", "lr": "4.97799e-05", "gnorm": "0.964", "train_wall": "49", "wall": "3354"}
2022-10-26 21:54:39 | INFO | train_inner | {"epoch": 2, "update": 1.715, "loss": "2.208", "nll_loss": "0.308", "ppl": "1.24", "wps": "1878.7", "ups": "2.01", "wpb": "935.3", "bsz": "16", "num_updates": "5000", "lr": "4.97749e-05", "gnorm": "0.969", "train_wall": "49", "wall": "3404"}
2022-10-26 21:55:28 | INFO | train_inner | {"epoch": 2, "update": 1.75, "loss": "2.232", "nll_loss": "0.335", "ppl": "1.26", "wps": "1813.7", "ups": "2.02", "wpb": "896", "bsz": "16", "num_updates": "5100", "lr": "4.97699e-05", "gnorm": "1.02", "train_wall": "49", "wall": "3453"}
2022-10-26 21:56:17 | INFO | train_inner | {"epoch": 2, "update": 1.784, "loss": "2.23", "nll_loss": "0.333", "ppl": "1.26", "wps": "1765.4", "ups": "2.05", "wpb": "862", "bsz": "16", "num_updates": "5200", "lr": "4.97649e-05", "gnorm": "1.173", "train_wall": "48", "wall": "3502"}
2022-10-26 21:57:06 | INFO | train_inner | {"epoch": 2, "update": 1.818, "loss": "2.214", "nll_loss": "0.316", "ppl": "1.25", "wps": "1835.9", "ups": "2.02", "wpb": "910.1", "bsz": "16", "num_updates": "5300", "lr": "4.97599e-05", "gnorm": "0.862", "train_wall": "49", "wall": "3552"}
2022-10-26 21:57:56 | INFO | train_inner | {"epoch": 2, "update": 1.852, "loss": "2.218", "nll_loss": "0.32", "ppl": "1.25", "wps": "1848.1", "ups": "2.02", "wpb": "917", "bsz": "16", "num_updates": "5400", "lr": "4.97549e-05", "gnorm": "0.921", "train_wall": "49", "wall": "3602"}
2022-10-26 21:58:45 | INFO | train_inner | {"epoch": 2, "update": 1.887, "loss": "2.219", "nll_loss": "0.321", "ppl": "1.25", "wps": "1807", "ups": "2.03", "wpb": "889.6", "bsz": "16", "num_updates": "5500", "lr": "4.97499e-05", "gnorm": "0.924", "train_wall": "49", "wall": "3651"}
2022-10-26 21:59:29 | INFO | train_inner | {"epoch": 2, "update": 1.921, "loss": "2.21", "nll_loss": "0.312", "ppl": "1.24", "wps": "2111", "ups": "2.3", "wpb": "918.5", "bsz": "16", "num_updates": "5600", "lr": "4.97449e-05", "gnorm": "0.898", "train_wall": "43", "wall": "3694"}
2022-10-26 22:00:18 | INFO | train_inner | {"epoch": 2, "update": 1.955, "loss": "2.215", "nll_loss": "0.318", "ppl": "1.25", "wps": "1803.5", "ups": "2.02", "wpb": "894.2", "bsz": "16", "num_updates": "5700", "lr": "4.97399e-05", "gnorm": "0.88", "train_wall": "49", "wall": "3744"}
2022-10-26 22:01:08 | INFO | train_inner | {"epoch": 2, "update": 1.99, "loss": "2.212", "nll_loss": "0.314", "ppl": "1.24", "wps": "1804.4", "ups": "2.02", "wpb": "893.4", "bsz": "16", "num_updates": "5800", "lr": "4.97349e-05", "gnorm": "0.981", "train_wall": "49", "wall": "3793"}
2022-10-26 22:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-26 22:18:35 | INFO | valid | {"epoch": 2, "valid_loss": "2.264", "valid_nll_loss": "0.248", "valid_ppl": "1.19", "valid_bleu": "71.5", "valid_wps": "313.5", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "5830", "valid_best_bleu": "73.72"}
2022-10-26 22:18:35 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-26 22:18:43 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_last.pt (epoch 2 @ 5830 updates, score 71.5) (writing took 7.906104027060792 seconds)
2022-10-26 22:18:43 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-10-26 22:18:43 | INFO | train | {"epoch": 2, "train_loss": "2.221", "train_nll_loss": "0.32", "train_ppl": "1.25", "train_wps": "1080.6", "train_ups": "1.21", "train_wpb": "896.6", "train_bsz": "16", "train_num_updates": "5830", "train_lr": "4.97334e-05", "train_gnorm": "0.951", "train_train_wall": "1362", "train_wall": "4848"}
2022-10-26 22:18:43 | INFO | fairseq.trainer | begin training epoch 3
2022-10-26 22:18:57 | INFO | train_inner | {"epoch": 3, "update": 2.024, "loss": "2.197", "nll_loss": "0.297", "ppl": "1.23", "wps": "82.7", "ups": "0.09", "wpb": "884.6", "bsz": "15.9", "num_updates": "5900", "lr": "4.97299e-05", "gnorm": "1.116", "train_wall": "29", "wall": "4863"}
2022-10-26 22:19:36 | INFO | train_inner | {"epoch": 3, "update": 2.058, "loss": "2.184", "nll_loss": "0.283", "ppl": "1.22", "wps": "2353.2", "ups": "2.58", "wpb": "912.5", "bsz": "16", "num_updates": "6000", "lr": "4.97249e-05", "gnorm": "0.919", "train_wall": "38", "wall": "4902"}
2022-10-26 22:20:26 | INFO | train_inner | {"epoch": 3, "update": 2.093, "loss": "2.187", "nll_loss": "0.287", "ppl": "1.22", "wps": "1776.1", "ups": "2.02", "wpb": "878.4", "bsz": "16", "num_updates": "6100", "lr": "4.97199e-05", "gnorm": "0.907", "train_wall": "49", "wall": "4951"}
2022-10-26 22:21:15 | INFO | train_inner | {"epoch": 3, "update": 2.127, "loss": "2.183", "nll_loss": "0.282", "ppl": "1.22", "wps": "1860.8", "ups": "2.03", "wpb": "916", "bsz": "16", "num_updates": "6200", "lr": "4.97149e-05", "gnorm": "0.984", "train_wall": "49", "wall": "5000"}
2022-10-26 22:22:03 | INFO | train_inner | {"epoch": 3, "update": 2.161, "loss": "2.188", "nll_loss": "0.289", "ppl": "1.22", "wps": "1804", "ups": "2.07", "wpb": "873.2", "bsz": "16", "num_updates": "6300", "lr": "4.97099e-05", "gnorm": "0.96", "train_wall": "48", "wall": "5049"}
2022-10-26 22:22:53 | INFO | train_inner | {"epoch": 3, "update": 2.196, "loss": "2.189", "nll_loss": "0.289", "ppl": "1.22", "wps": "1811.1", "ups": "2.02", "wpb": "895.6", "bsz": "16", "num_updates": "6400", "lr": "4.97049e-05", "gnorm": "1.042", "train_wall": "49", "wall": "5098"}
2022-10-26 22:23:42 | INFO | train_inner | {"epoch": 3, "update": 2.23, "loss": "2.186", "nll_loss": "0.286", "ppl": "1.22", "wps": "1827.8", "ups": "2.01", "wpb": "907.9", "bsz": "16", "num_updates": "6500", "lr": "4.96998e-05", "gnorm": "1.012", "train_wall": "49", "wall": "5148"}
2022-10-26 22:24:30 | INFO | train_inner | {"epoch": 3, "update": 2.264, "loss": "2.184", "nll_loss": "0.285", "ppl": "1.22", "wps": "1928.9", "ups": "2.1", "wpb": "917.7", "bsz": "16", "num_updates": "6600", "lr": "4.96948e-05", "gnorm": "0.903", "train_wall": "47", "wall": "5196"}
2022-10-26 22:25:17 | INFO | train_inner | {"epoch": 3, "update": 2.298, "loss": "2.194", "nll_loss": "0.295", "ppl": "1.23", "wps": "1864.3", "ups": "2.11", "wpb": "882.9", "bsz": "16", "num_updates": "6700", "lr": "4.96898e-05", "gnorm": "0.908", "train_wall": "47", "wall": "5243"}
2022-10-26 22:26:07 | INFO | train_inner | {"epoch": 3, "update": 2.333, "loss": "2.183", "nll_loss": "0.284", "ppl": "1.22", "wps": "1812.5", "ups": "2.02", "wpb": "898.4", "bsz": "16", "num_updates": "6800", "lr": "4.96848e-05", "gnorm": "0.866", "train_wall": "49", "wall": "5292"}
2022-10-26 22:26:56 | INFO | train_inner | {"epoch": 3, "update": 2.367, "loss": "2.19", "nll_loss": "0.291", "ppl": "1.22", "wps": "1734.6", "ups": "2.03", "wpb": "855.5", "bsz": "16", "num_updates": "6900", "lr": "4.96798e-05", "gnorm": "1.063", "train_wall": "49", "wall": "5342"}
2022-10-26 22:27:46 | INFO | train_inner | {"epoch": 3, "update": 2.401, "loss": "2.192", "nll_loss": "0.293", "ppl": "1.23", "wps": "1774.2", "ups": "2.01", "wpb": "881.6", "bsz": "16", "num_updates": "7000", "lr": "4.96748e-05", "gnorm": "1.114", "train_wall": "49", "wall": "5391"}
2022-10-26 22:28:33 | INFO | train_inner | {"epoch": 3, "update": 2.436, "loss": "2.185", "nll_loss": "0.286", "ppl": "1.22", "wps": "1988", "ups": "2.11", "wpb": "942.5", "bsz": "16", "num_updates": "7100", "lr": "4.96698e-05", "gnorm": "1.095", "train_wall": "47", "wall": "5439"}
2022-10-26 22:29:01 | INFO | train_inner | {"epoch": 3, "update": 2.47, "loss": "2.184", "nll_loss": "0.285", "ppl": "1.22", "wps": "3163.2", "ups": "3.57", "wpb": "885.9", "bsz": "16", "num_updates": "7200", "lr": "4.96648e-05", "gnorm": "0.879", "train_wall": "28", "wall": "5467"}
2022-10-26 22:29:36 | INFO | train_inner | {"epoch": 3, "update": 2.504, "loss": "2.185", "nll_loss": "0.287", "ppl": "1.22", "wps": "2678.1", "ups": "2.88", "wpb": "930", "bsz": "16", "num_updates": "7300", "lr": "4.96598e-05", "gnorm": "0.915", "train_wall": "34", "wall": "5502"}
2022-10-26 22:30:25 | INFO | train_inner | {"epoch": 3, "update": 2.539, "loss": "2.189", "nll_loss": "0.291", "ppl": "1.22", "wps": "1917", "ups": "2.02", "wpb": "947", "bsz": "16", "num_updates": "7400", "lr": "4.96548e-05", "gnorm": "0.924", "train_wall": "49", "wall": "5551"}
2022-10-26 22:31:14 | INFO | train_inner | {"epoch": 3, "update": 2.573, "loss": "2.187", "nll_loss": "0.289", "ppl": "1.22", "wps": "1815.3", "ups": "2.07", "wpb": "875.9", "bsz": "16", "num_updates": "7500", "lr": "4.96498e-05", "gnorm": "0.908", "train_wall": "48", "wall": "5599"}
2022-10-26 22:32:03 | INFO | train_inner | {"epoch": 3, "update": 2.607, "loss": "2.185", "nll_loss": "0.287", "ppl": "1.22", "wps": "1872.4", "ups": "2.05", "wpb": "915.4", "bsz": "16", "num_updates": "7600", "lr": "4.96448e-05", "gnorm": "0.951", "train_wall": "48", "wall": "5648"}
2022-10-26 22:32:52 | INFO | train_inner | {"epoch": 3, "update": 2.642, "loss": "2.193", "nll_loss": "0.296", "ppl": "1.23", "wps": "1722.5", "ups": "2.01", "wpb": "855.2", "bsz": "16", "num_updates": "7700", "lr": "4.96398e-05", "gnorm": "0.965", "train_wall": "49", "wall": "5698"}
2022-10-26 22:33:42 | INFO | train_inner | {"epoch": 3, "update": 2.676, "loss": "2.193", "nll_loss": "0.296", "ppl": "1.23", "wps": "1791.6", "ups": "2.01", "wpb": "893.2", "bsz": "16", "num_updates": "7800", "lr": "4.96348e-05", "gnorm": "1.17", "train_wall": "49", "wall": "5748"}
2022-10-26 22:34:31 | INFO | train_inner | {"epoch": 3, "update": 2.71, "loss": "2.192", "nll_loss": "0.295", "ppl": "1.23", "wps": "1786.9", "ups": "2.03", "wpb": "881.3", "bsz": "16", "num_updates": "7900", "lr": "4.96298e-05", "gnorm": "0.949", "train_wall": "49", "wall": "5797"}
2022-10-26 22:35:20 | INFO | train_inner | {"epoch": 3, "update": 2.744, "loss": "2.186", "nll_loss": "0.29", "ppl": "1.22", "wps": "1813.3", "ups": "2.04", "wpb": "889.6", "bsz": "16", "num_updates": "8000", "lr": "4.96248e-05", "gnorm": "0.857", "train_wall": "48", "wall": "5846"}
2022-10-26 22:35:45 | INFO | train_inner | {"epoch": 3, "update": 2.779, "loss": "2.193", "nll_loss": "0.297", "ppl": "1.23", "wps": "3519.9", "ups": "4.01", "wpb": "877.7", "bsz": "16", "num_updates": "8100", "lr": "4.96198e-05", "gnorm": "1.009", "train_wall": "25", "wall": "5871"}
2022-10-26 22:36:15 | INFO | train_inner | {"epoch": 3, "update": 2.813, "loss": "2.212", "nll_loss": "0.317", "ppl": "1.25", "wps": "3018.8", "ups": "3.36", "wpb": "899.4", "bsz": "16", "num_updates": "8200", "lr": "4.96148e-05", "gnorm": "0.995", "train_wall": "29", "wall": "5901"}
2022-10-26 22:37:05 | INFO | train_inner | {"epoch": 3, "update": 2.847, "loss": "2.188", "nll_loss": "0.29", "ppl": "1.22", "wps": "1842.2", "ups": "2.02", "wpb": "911.6", "bsz": "16", "num_updates": "8300", "lr": "4.96098e-05", "gnorm": "0.909", "train_wall": "49", "wall": "5950"}
2022-10-26 22:37:54 | INFO | train_inner | {"epoch": 3, "update": 2.882, "loss": "2.19", "nll_loss": "0.294", "ppl": "1.23", "wps": "1762.5", "ups": "2.01", "wpb": "874.8", "bsz": "16", "num_updates": "8400", "lr": "4.96048e-05", "gnorm": "0.967", "train_wall": "49", "wall": "6000"}
2022-10-26 22:38:44 | INFO | train_inner | {"epoch": 3, "update": 2.916, "loss": "2.182", "nll_loss": "0.285", "ppl": "1.22", "wps": "1872.7", "ups": "2.02", "wpb": "929.1", "bsz": "16", "num_updates": "8500", "lr": "4.95998e-05", "gnorm": "0.908", "train_wall": "49", "wall": "6049"}
2022-10-26 22:39:34 | INFO | train_inner | {"epoch": 3, "update": 2.95, "loss": "2.19", "nll_loss": "0.294", "ppl": "1.23", "wps": "1766.2", "ups": "2.01", "wpb": "878.3", "bsz": "16", "num_updates": "8600", "lr": "4.95948e-05", "gnorm": "0.933", "train_wall": "49", "wall": "6099"}
2022-10-26 22:40:24 | INFO | train_inner | {"epoch": 3, "update": 2.985, "loss": "2.191", "nll_loss": "0.295", "ppl": "1.23", "wps": "1838.2", "ups": "2", "wpb": "917.3", "bsz": "16", "num_updates": "8700", "lr": "4.95898e-05", "gnorm": "1.044", "train_wall": "49", "wall": "6149"}
2022-10-26 22:40:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-26 22:58:11 | INFO | valid | {"epoch": 3, "valid_loss": "2.263", "valid_nll_loss": "0.246", "valid_ppl": "1.19", "valid_bleu": "77.23", "valid_wps": "309.6", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "8745", "valid_best_bleu": "77.23"}
2022-10-26 22:58:11 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-26 22:58:24 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_best.pt (epoch 3 @ 8745 updates, score 77.23) (writing took 13.134982554940507 seconds)
2022-10-26 22:58:24 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-10-26 22:58:24 | INFO | train | {"epoch": 3, "train_loss": "2.189", "train_nll_loss": "0.291", "train_ppl": "1.22", "train_wps": "1097.4", "train_ups": "1.22", "train_wpb": "896.6", "train_bsz": "16", "train_num_updates": "8745", "train_lr": "4.95875e-05", "train_gnorm": "0.97", "train_train_wall": "1307", "train_wall": "7230"}
2022-10-26 22:58:24 | INFO | fairseq.trainer | begin training epoch 4
2022-10-26 22:58:52 | INFO | train_inner | {"epoch": 4, "update": 3.019, "loss": "2.173", "nll_loss": "0.274", "ppl": "1.21", "wps": "81.4", "ups": "0.09", "wpb": "902.8", "bsz": "15.9", "num_updates": "8800", "lr": "4.95848e-05", "gnorm": "0.933", "train_wall": "49", "wall": "7258"}
2022-10-26 22:59:41 | INFO | train_inner | {"epoch": 4, "update": 3.053, "loss": "2.162", "nll_loss": "0.262", "ppl": "1.2", "wps": "1811.2", "ups": "2.07", "wpb": "874.9", "bsz": "16", "num_updates": "8900", "lr": "4.95798e-05", "gnorm": "0.986", "train_wall": "48", "wall": "7306"}
2022-10-26 23:00:31 | INFO | train_inner | {"epoch": 4, "update": 3.087, "loss": "2.158", "nll_loss": "0.259", "ppl": "1.2", "wps": "1823.3", "ups": "2", "wpb": "910.8", "bsz": "16", "num_updates": "9000", "lr": "4.95748e-05", "gnorm": "0.834", "train_wall": "49", "wall": "7356"}
2022-10-26 23:01:21 | INFO | train_inner | {"epoch": 4, "update": 3.122, "loss": "2.156", "nll_loss": "0.257", "ppl": "1.19", "wps": "1797.3", "ups": "2", "wpb": "898.2", "bsz": "16", "num_updates": "9100", "lr": "4.95698e-05", "gnorm": "0.829", "train_wall": "49", "wall": "7406"}
2022-10-26 23:02:11 | INFO | train_inner | {"epoch": 4, "update": 3.156, "loss": "2.167", "nll_loss": "0.269", "ppl": "1.2", "wps": "1828.5", "ups": "2", "wpb": "914.5", "bsz": "16", "num_updates": "9200", "lr": "4.95648e-05", "gnorm": "0.903", "train_wall": "49", "wall": "7456"}
2022-10-26 23:03:00 | INFO | train_inner | {"epoch": 4, "update": 3.19, "loss": "2.166", "nll_loss": "0.267", "ppl": "1.2", "wps": "1886.2", "ups": "2.01", "wpb": "936.8", "bsz": "16", "num_updates": "9300", "lr": "4.95598e-05", "gnorm": "0.884", "train_wall": "49", "wall": "7506"}
2022-10-26 23:03:43 | INFO | train_inner | {"epoch": 4, "update": 3.225, "loss": "2.167", "nll_loss": "0.268", "ppl": "1.2", "wps": "2092.1", "ups": "2.36", "wpb": "887.9", "bsz": "16", "num_updates": "9400", "lr": "4.95548e-05", "gnorm": "0.897", "train_wall": "42", "wall": "7548"}
2022-10-26 23:04:33 | INFO | train_inner | {"epoch": 4, "update": 3.259, "loss": "2.167", "nll_loss": "0.268", "ppl": "1.2", "wps": "1743.9", "ups": "2", "wpb": "872.1", "bsz": "16", "num_updates": "9500", "lr": "4.95498e-05", "gnorm": "0.878", "train_wall": "49", "wall": "7598"}
2022-10-26 23:05:22 | INFO | train_inner | {"epoch": 4, "update": 3.293, "loss": "2.16", "nll_loss": "0.262", "ppl": "1.2", "wps": "1811.7", "ups": "2.04", "wpb": "886.8", "bsz": "16", "num_updates": "9600", "lr": "4.95448e-05", "gnorm": "0.803", "train_wall": "48", "wall": "7647"}
2022-10-26 23:06:03 | INFO | train_inner | {"epoch": 4, "update": 3.328, "loss": "2.169", "nll_loss": "0.272", "ppl": "1.21", "wps": "2011.5", "ups": "2.43", "wpb": "828.6", "bsz": "16", "num_updates": "9700", "lr": "4.95398e-05", "gnorm": "0.91", "train_wall": "41", "wall": "7688"}
2022-10-26 23:06:53 | INFO | train_inner | {"epoch": 4, "update": 3.362, "loss": "2.164", "nll_loss": "0.266", "ppl": "1.2", "wps": "1741.9", "ups": "2", "wpb": "871.1", "bsz": "16", "num_updates": "9800", "lr": "4.95348e-05", "gnorm": "0.865", "train_wall": "49", "wall": "7738"}
2022-10-26 23:07:43 | INFO | train_inner | {"epoch": 4, "update": 3.396, "loss": "2.166", "nll_loss": "0.269", "ppl": "1.2", "wps": "1750.5", "ups": "2", "wpb": "873.3", "bsz": "16", "num_updates": "9900", "lr": "4.95298e-05", "gnorm": "0.97", "train_wall": "49", "wall": "7788"}
2022-10-26 23:08:33 | INFO | train_inner | {"epoch": 4, "update": 3.431, "loss": "2.17", "nll_loss": "0.272", "ppl": "1.21", "wps": "1803.1", "ups": "2", "wpb": "903.2", "bsz": "16", "num_updates": "10000", "lr": "4.95248e-05", "gnorm": "0.958", "train_wall": "49", "wall": "7838"}
2022-10-26 23:09:23 | INFO | train_inner | {"epoch": 4, "update": 3.465, "loss": "2.169", "nll_loss": "0.271", "ppl": "1.21", "wps": "1826.6", "ups": "2", "wpb": "913.2", "bsz": "16", "num_updates": "10100", "lr": "4.95198e-05", "gnorm": "1.013", "train_wall": "49", "wall": "7888"}
2022-10-26 23:10:13 | INFO | train_inner | {"epoch": 4, "update": 3.499, "loss": "2.165", "nll_loss": "0.268", "ppl": "1.2", "wps": "1821.4", "ups": "2.01", "wpb": "904.7", "bsz": "16", "num_updates": "10200", "lr": "4.95148e-05", "gnorm": "0.975", "train_wall": "49", "wall": "7938"}
2022-10-26 23:11:03 | INFO | train_inner | {"epoch": 4, "update": 3.533, "loss": "2.163", "nll_loss": "0.265", "ppl": "1.2", "wps": "1838.7", "ups": "2", "wpb": "918.8", "bsz": "16", "num_updates": "10300", "lr": "4.95098e-05", "gnorm": "0.919", "train_wall": "49", "wall": "7988"}
2022-10-26 23:11:52 | INFO | train_inner | {"epoch": 4, "update": 3.568, "loss": "2.175", "nll_loss": "0.278", "ppl": "1.21", "wps": "1795.4", "ups": "2.02", "wpb": "890.2", "bsz": "16", "num_updates": "10400", "lr": "4.95048e-05", "gnorm": "0.964", "train_wall": "49", "wall": "8038"}
2022-10-26 23:12:41 | INFO | train_inner | {"epoch": 4, "update": 3.602, "loss": "2.162", "nll_loss": "0.264", "ppl": "1.2", "wps": "1919.8", "ups": "2.05", "wpb": "934.8", "bsz": "16", "num_updates": "10500", "lr": "4.94997e-05", "gnorm": "0.869", "train_wall": "48", "wall": "8086"}
2022-10-26 23:13:31 | INFO | train_inner | {"epoch": 4, "update": 3.636, "loss": "2.165", "nll_loss": "0.269", "ppl": "1.2", "wps": "1812.9", "ups": "2", "wpb": "905.3", "bsz": "16", "num_updates": "10600", "lr": "4.94947e-05", "gnorm": "0.844", "train_wall": "49", "wall": "8136"}
2022-10-26 23:14:21 | INFO | train_inner | {"epoch": 4, "update": 3.671, "loss": "2.166", "nll_loss": "0.269", "ppl": "1.2", "wps": "1832.4", "ups": "2.01", "wpb": "913", "bsz": "16", "num_updates": "10700", "lr": "4.94897e-05", "gnorm": "0.88", "train_wall": "49", "wall": "8186"}
2022-10-26 23:15:05 | INFO | train_inner | {"epoch": 4, "update": 3.705, "loss": "2.173", "nll_loss": "0.276", "ppl": "1.21", "wps": "2048.2", "ups": "2.23", "wpb": "918.7", "bsz": "16", "num_updates": "10800", "lr": "4.94847e-05", "gnorm": "1.124", "train_wall": "44", "wall": "8231"}
2022-10-26 23:15:27 | INFO | train_inner | {"epoch": 4, "update": 3.739, "loss": "2.168", "nll_loss": "0.271", "ppl": "1.21", "wps": "4256.9", "ups": "4.75", "wpb": "897", "bsz": "16", "num_updates": "10900", "lr": "4.94797e-05", "gnorm": "0.882", "train_wall": "21", "wall": "8252"}
2022-10-26 23:16:03 | INFO | train_inner | {"epoch": 4, "update": 3.774, "loss": "2.171", "nll_loss": "0.275", "ppl": "1.21", "wps": "2475.8", "ups": "2.77", "wpb": "892.6", "bsz": "16", "num_updates": "11000", "lr": "4.94747e-05", "gnorm": "1.099", "train_wall": "36", "wall": "8288"}
2022-10-26 23:16:53 | INFO | train_inner | {"epoch": 4, "update": 3.808, "loss": "2.168", "nll_loss": "0.271", "ppl": "1.21", "wps": "1826.3", "ups": "2", "wpb": "913.4", "bsz": "16", "num_updates": "11100", "lr": "4.94697e-05", "gnorm": "0.928", "train_wall": "49", "wall": "8338"}
2022-10-26 23:17:42 | INFO | train_inner | {"epoch": 4, "update": 3.842, "loss": "2.172", "nll_loss": "0.276", "ppl": "1.21", "wps": "1693.6", "ups": "2", "wpb": "844.8", "bsz": "16", "num_updates": "11200", "lr": "4.94647e-05", "gnorm": "0.92", "train_wall": "49", "wall": "8388"}
2022-10-26 23:18:32 | INFO | train_inner | {"epoch": 4, "update": 3.877, "loss": "2.168", "nll_loss": "0.272", "ppl": "1.21", "wps": "1886.4", "ups": "2", "wpb": "942.7", "bsz": "16", "num_updates": "11300", "lr": "4.94597e-05", "gnorm": "0.873", "train_wall": "49", "wall": "8438"}
2022-10-26 23:19:22 | INFO | train_inner | {"epoch": 4, "update": 3.911, "loss": "2.167", "nll_loss": "0.271", "ppl": "1.21", "wps": "1860.3", "ups": "2", "wpb": "928.1", "bsz": "16", "num_updates": "11400", "lr": "4.94547e-05", "gnorm": "0.939", "train_wall": "49", "wall": "8488"}
2022-10-26 23:20:12 | INFO | train_inner | {"epoch": 4, "update": 3.945, "loss": "2.174", "nll_loss": "0.278", "ppl": "1.21", "wps": "1702.8", "ups": "2.02", "wpb": "843.6", "bsz": "16", "num_updates": "11500", "lr": "4.94497e-05", "gnorm": "0.946", "train_wall": "49", "wall": "8537"}
2022-10-26 23:21:02 | INFO | train_inner | {"epoch": 4, "update": 3.979, "loss": "2.19", "nll_loss": "0.296", "ppl": "1.23", "wps": "1764.5", "ups": "2.01", "wpb": "878.1", "bsz": "16", "num_updates": "11600", "lr": "4.94447e-05", "gnorm": "1.238", "train_wall": "49", "wall": "8587"}
2022-10-26 23:21:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-26 23:38:45 | INFO | valid | {"epoch": 4, "valid_loss": "2.269", "valid_nll_loss": "0.251", "valid_ppl": "1.19", "valid_bleu": "75.79", "valid_wps": "313.2", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "11660", "valid_best_bleu": "77.23"}
2022-10-26 23:38:45 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-26 23:38:53 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_last.pt (epoch 4 @ 11660 updates, score 75.79) (writing took 7.953918660990894 seconds)
2022-10-26 23:38:53 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-10-26 23:38:53 | INFO | train | {"epoch": 4, "train_loss": "2.167", "train_nll_loss": "0.27", "train_ppl": "1.21", "train_wps": "1076.3", "train_ups": "1.2", "train_wpb": "896.6", "train_bsz": "16", "train_num_updates": "11660", "train_lr": "4.94417e-05", "train_gnorm": "0.932", "train_train_wall": "1370", "train_wall": "9658"}
2022-10-26 23:38:53 | INFO | fairseq.trainer | begin training epoch 5
2022-10-26 23:39:07 | INFO | train_inner | {"epoch": 5, "update": 4.014, "loss": "2.156", "nll_loss": "0.258", "ppl": "1.2", "wps": "80.6", "ups": "0.09", "wpb": "874.6", "bsz": "15.9", "num_updates": "11700", "lr": "4.94397e-05", "gnorm": "0.91", "train_wall": "43", "wall": "9672"}
2022-10-26 23:39:40 | INFO | train_inner | {"epoch": 5, "update": 4.048, "loss": "2.143", "nll_loss": "0.243", "ppl": "1.18", "wps": "2765", "ups": "3", "wpb": "922.7", "bsz": "16", "num_updates": "11800", "lr": "4.94347e-05", "gnorm": "1", "train_wall": "33", "wall": "9706"}
2022-10-26 23:40:14 | INFO | train_inner | {"epoch": 5, "update": 4.082, "loss": "2.147", "nll_loss": "0.248", "ppl": "1.19", "wps": "2722.8", "ups": "2.99", "wpb": "912", "bsz": "16", "num_updates": "11900", "lr": "4.94297e-05", "gnorm": "0.867", "train_wall": "33", "wall": "9739"}
2022-10-26 23:40:57 | INFO | train_inner | {"epoch": 5, "update": 4.117, "loss": "2.146", "nll_loss": "0.248", "ppl": "1.19", "wps": "2076.4", "ups": "2.28", "wpb": "912.5", "bsz": "16", "num_updates": "12000", "lr": "4.94247e-05", "gnorm": "0.879", "train_wall": "43", "wall": "9783"}
2022-10-26 23:41:26 | INFO | train_inner | {"epoch": 5, "update": 4.151, "loss": "2.149", "nll_loss": "0.25", "ppl": "1.19", "wps": "3187.3", "ups": "3.53", "wpb": "902.8", "bsz": "16", "num_updates": "12100", "lr": "4.94197e-05", "gnorm": "1.024", "train_wall": "28", "wall": "9811"}
2022-10-26 23:42:15 | INFO | train_inner | {"epoch": 5, "update": 4.185, "loss": "2.145", "nll_loss": "0.246", "ppl": "1.19", "wps": "1815.1", "ups": "2.01", "wpb": "900.9", "bsz": "16", "num_updates": "12200", "lr": "4.94147e-05", "gnorm": "0.951", "train_wall": "49", "wall": "9861"}
2022-10-26 23:43:05 | INFO | train_inner | {"epoch": 5, "update": 4.22, "loss": "2.147", "nll_loss": "0.248", "ppl": "1.19", "wps": "1823.2", "ups": "2.01", "wpb": "906.2", "bsz": "16", "num_updates": "12300", "lr": "4.94097e-05", "gnorm": "0.936", "train_wall": "49", "wall": "9911"}
2022-10-26 23:43:55 | INFO | train_inner | {"epoch": 5, "update": 4.254, "loss": "2.153", "nll_loss": "0.255", "ppl": "1.19", "wps": "1735.1", "ups": "2.02", "wpb": "859.9", "bsz": "16", "num_updates": "12400", "lr": "4.94047e-05", "gnorm": "1.034", "train_wall": "49", "wall": "9960"}
2022-10-26 23:44:43 | INFO | train_inner | {"epoch": 5, "update": 4.288, "loss": "2.15", "nll_loss": "0.252", "ppl": "1.19", "wps": "1931.5", "ups": "2.05", "wpb": "941.3", "bsz": "16", "num_updates": "12500", "lr": "4.93997e-05", "gnorm": "0.94", "train_wall": "48", "wall": "10009"}
2022-10-26 23:45:32 | INFO | train_inner | {"epoch": 5, "update": 4.322, "loss": "2.147", "nll_loss": "0.25", "ppl": "1.19", "wps": "1838.7", "ups": "2.06", "wpb": "894.2", "bsz": "16", "num_updates": "12600", "lr": "4.93947e-05", "gnorm": "0.869", "train_wall": "48", "wall": "10058"}
2022-10-26 23:46:22 | INFO | train_inner | {"epoch": 5, "update": 4.357, "loss": "2.149", "nll_loss": "0.25", "ppl": "1.19", "wps": "1786.3", "ups": "2.01", "wpb": "886.7", "bsz": "16", "num_updates": "12700", "lr": "4.93897e-05", "gnorm": "0.818", "train_wall": "49", "wall": "10107"}
2022-10-26 23:47:05 | INFO | train_inner | {"epoch": 5, "update": 4.391, "loss": "2.152", "nll_loss": "0.255", "ppl": "1.19", "wps": "1977.3", "ups": "2.32", "wpb": "852.2", "bsz": "16", "num_updates": "12800", "lr": "4.93847e-05", "gnorm": "0.94", "train_wall": "43", "wall": "10150"}
2022-10-26 23:47:51 | INFO | train_inner | {"epoch": 5, "update": 4.425, "loss": "2.15", "nll_loss": "0.253", "ppl": "1.19", "wps": "1874.6", "ups": "2.16", "wpb": "866.4", "bsz": "16", "num_updates": "12900", "lr": "4.93797e-05", "gnorm": "0.981", "train_wall": "46", "wall": "10197"}
2022-10-26 23:48:40 | INFO | train_inner | {"epoch": 5, "update": 4.46, "loss": "2.153", "nll_loss": "0.255", "ppl": "1.19", "wps": "1789.5", "ups": "2.03", "wpb": "882.8", "bsz": "16", "num_updates": "13000", "lr": "4.93747e-05", "gnorm": "0.934", "train_wall": "49", "wall": "10246"}
2022-10-26 23:49:13 | INFO | train_inner | {"epoch": 5, "update": 4.494, "loss": "2.149", "nll_loss": "0.251", "ppl": "1.19", "wps": "2889.6", "ups": "3.08", "wpb": "937", "bsz": "16", "num_updates": "13100", "lr": "4.93697e-05", "gnorm": "0.873", "train_wall": "32", "wall": "10278"}
2022-10-26 23:50:02 | INFO | train_inner | {"epoch": 5, "update": 4.528, "loss": "2.157", "nll_loss": "0.261", "ppl": "1.2", "wps": "1720.5", "ups": "2.01", "wpb": "855.2", "bsz": "16", "num_updates": "13200", "lr": "4.93647e-05", "gnorm": "0.96", "train_wall": "49", "wall": "10328"}
2022-10-26 23:50:52 | INFO | train_inner | {"epoch": 5, "update": 4.563, "loss": "2.149", "nll_loss": "0.251", "ppl": "1.19", "wps": "1778.4", "ups": "2.01", "wpb": "883.9", "bsz": "16", "num_updates": "13300", "lr": "4.93597e-05", "gnorm": "1.021", "train_wall": "49", "wall": "10378"}
2022-10-26 23:51:42 | INFO | train_inner | {"epoch": 5, "update": 4.597, "loss": "2.153", "nll_loss": "0.255", "ppl": "1.19", "wps": "1863.4", "ups": "2.02", "wpb": "921", "bsz": "16", "num_updates": "13400", "lr": "4.93547e-05", "gnorm": "0.884", "train_wall": "49", "wall": "10427"}
2022-10-26 23:52:30 | INFO | train_inner | {"epoch": 5, "update": 4.631, "loss": "2.153", "nll_loss": "0.256", "ppl": "1.19", "wps": "1800.3", "ups": "2.05", "wpb": "877.2", "bsz": "16", "num_updates": "13500", "lr": "4.93497e-05", "gnorm": "0.956", "train_wall": "48", "wall": "10476"}
2022-10-26 23:53:20 | INFO | train_inner | {"epoch": 5, "update": 4.666, "loss": "2.154", "nll_loss": "0.257", "ppl": "1.2", "wps": "1762.8", "ups": "2.02", "wpb": "871.3", "bsz": "16", "num_updates": "13600", "lr": "4.93447e-05", "gnorm": "0.87", "train_wall": "49", "wall": "10525"}
2022-10-26 23:54:04 | INFO | train_inner | {"epoch": 5, "update": 4.7, "loss": "2.152", "nll_loss": "0.255", "ppl": "1.19", "wps": "2023.6", "ups": "2.27", "wpb": "890.8", "bsz": "16", "num_updates": "13700", "lr": "4.93397e-05", "gnorm": "0.932", "train_wall": "44", "wall": "10569"}
2022-10-26 23:54:25 | INFO | train_inner | {"epoch": 5, "update": 4.734, "loss": "2.152", "nll_loss": "0.255", "ppl": "1.19", "wps": "4394", "ups": "4.8", "wpb": "916", "bsz": "16", "num_updates": "13800", "lr": "4.93347e-05", "gnorm": "0.877", "train_wall": "21", "wall": "10590"}
2022-10-26 23:55:06 | INFO | train_inner | {"epoch": 5, "update": 4.768, "loss": "2.154", "nll_loss": "0.257", "ppl": "1.2", "wps": "2103.6", "ups": "2.45", "wpb": "860", "bsz": "16", "num_updates": "13900", "lr": "4.93297e-05", "gnorm": "1.044", "train_wall": "40", "wall": "10631"}
2022-10-26 23:55:55 | INFO | train_inner | {"epoch": 5, "update": 4.803, "loss": "2.156", "nll_loss": "0.26", "ppl": "1.2", "wps": "1825.5", "ups": "2.04", "wpb": "895.7", "bsz": "16", "num_updates": "14000", "lr": "4.93247e-05", "gnorm": "1.083", "train_wall": "49", "wall": "10680"}
2022-10-26 23:56:44 | INFO | train_inner | {"epoch": 5, "update": 4.837, "loss": "2.158", "nll_loss": "0.262", "ppl": "1.2", "wps": "1755.8", "ups": "2.02", "wpb": "867.5", "bsz": "16", "num_updates": "14100", "lr": "4.93197e-05", "gnorm": "1.106", "train_wall": "49", "wall": "10730"}
2022-10-26 23:57:33 | INFO | train_inner | {"epoch": 5, "update": 4.871, "loss": "2.162", "nll_loss": "0.265", "ppl": "1.2", "wps": "1931.6", "ups": "2.04", "wpb": "944.9", "bsz": "16", "num_updates": "14200", "lr": "4.93147e-05", "gnorm": "0.977", "train_wall": "48", "wall": "10778"}
2022-10-26 23:58:22 | INFO | train_inner | {"epoch": 5, "update": 4.906, "loss": "2.15", "nll_loss": "0.253", "ppl": "1.19", "wps": "1873.1", "ups": "2.04", "wpb": "916.4", "bsz": "16", "num_updates": "14300", "lr": "4.93097e-05", "gnorm": "1.008", "train_wall": "48", "wall": "10827"}
2022-10-26 23:59:11 | INFO | train_inner | {"epoch": 5, "update": 4.94, "loss": "2.151", "nll_loss": "0.254", "ppl": "1.19", "wps": "1878.7", "ups": "2.04", "wpb": "922.4", "bsz": "16", "num_updates": "14400", "lr": "4.93047e-05", "gnorm": "0.921", "train_wall": "49", "wall": "10876"}
2022-10-27 00:00:00 | INFO | train_inner | {"epoch": 5, "update": 4.974, "loss": "2.152", "nll_loss": "0.256", "ppl": "1.19", "wps": "1830", "ups": "2.02", "wpb": "904.1", "bsz": "16", "num_updates": "14500", "lr": "4.92996e-05", "gnorm": "0.932", "train_wall": "49", "wall": "10926"}
2022-10-27 00:00:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-27 00:17:56 | INFO | valid | {"epoch": 5, "valid_loss": "2.283", "valid_nll_loss": "0.262", "valid_ppl": "1.2", "valid_bleu": "74.54", "valid_wps": "309.1", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "14575", "valid_best_bleu": "77.23"}
2022-10-27 00:17:56 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-27 00:18:05 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_last.pt (epoch 5 @ 14575 updates, score 74.54) (writing took 8.30081460182555 seconds)
2022-10-27 00:18:05 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-10-27 00:18:05 | INFO | train | {"epoch": 5, "train_loss": "2.151", "train_nll_loss": "0.253", "train_ppl": "1.19", "train_wps": "1111.3", "train_ups": "1.24", "train_wpb": "896.6", "train_bsz": "16", "train_num_updates": "14575", "train_lr": "4.92959e-05", "train_gnorm": "0.953", "train_train_wall": "1281", "train_wall": "12010"}
2022-10-27 00:18:05 | INFO | fairseq.trainer | begin training epoch 6
2022-10-27 00:18:17 | INFO | train_inner | {"epoch": 6, "update": 5.009, "loss": "2.151", "nll_loss": "0.254", "ppl": "1.19", "wps": "83", "ups": "0.09", "wpb": "910.1", "bsz": "15.9", "num_updates": "14600", "lr": "4.92946e-05", "gnorm": "1.096", "train_wall": "41", "wall": "12023"}
2022-10-27 00:19:06 | INFO | train_inner | {"epoch": 6, "update": 5.043, "loss": "2.131", "nll_loss": "0.232", "ppl": "1.17", "wps": "1827.7", "ups": "2.07", "wpb": "884.5", "bsz": "16", "num_updates": "14700", "lr": "4.92896e-05", "gnorm": "0.844", "train_wall": "48", "wall": "12071"}
2022-10-27 00:19:26 | INFO | train_inner | {"epoch": 6, "update": 5.077, "loss": "2.135", "nll_loss": "0.236", "ppl": "1.18", "wps": "4290.8", "ups": "4.82", "wpb": "890.4", "bsz": "16", "num_updates": "14800", "lr": "4.92846e-05", "gnorm": "0.938", "train_wall": "20", "wall": "12092"}
2022-10-27 00:20:12 | INFO | train_inner | {"epoch": 6, "update": 5.111, "loss": "2.129", "nll_loss": "0.23", "ppl": "1.17", "wps": "1946.9", "ups": "2.17", "wpb": "897.6", "bsz": "16", "num_updates": "14900", "lr": "4.92796e-05", "gnorm": "0.908", "train_wall": "46", "wall": "12138"}
2022-10-27 00:21:02 | INFO | train_inner | {"epoch": 6, "update": 5.146, "loss": "2.133", "nll_loss": "0.234", "ppl": "1.18", "wps": "1755.7", "ups": "2.02", "wpb": "871", "bsz": "16", "num_updates": "15000", "lr": "4.92746e-05", "gnorm": "0.963", "train_wall": "49", "wall": "12188"}
2022-10-27 00:21:51 | INFO | train_inner | {"epoch": 6, "update": 5.18, "loss": "2.131", "nll_loss": "0.233", "ppl": "1.18", "wps": "1892.1", "ups": "2.05", "wpb": "922.9", "bsz": "16", "num_updates": "15100", "lr": "4.92696e-05", "gnorm": "0.964", "train_wall": "48", "wall": "12236"}
2022-10-27 00:22:40 | INFO | train_inner | {"epoch": 6, "update": 5.214, "loss": "2.135", "nll_loss": "0.236", "ppl": "1.18", "wps": "1822.4", "ups": "2.03", "wpb": "899.6", "bsz": "16", "num_updates": "15200", "lr": "4.92646e-05", "gnorm": "0.866", "train_wall": "49", "wall": "12286"}
2022-10-27 00:23:30 | INFO | train_inner | {"epoch": 6, "update": 5.249, "loss": "2.137", "nll_loss": "0.238", "ppl": "1.18", "wps": "1837.8", "ups": "2.01", "wpb": "913.6", "bsz": "16", "num_updates": "15300", "lr": "4.92596e-05", "gnorm": "0.971", "train_wall": "49", "wall": "12335"}
2022-10-27 00:24:19 | INFO | train_inner | {"epoch": 6, "update": 5.283, "loss": "2.134", "nll_loss": "0.236", "ppl": "1.18", "wps": "1791", "ups": "2.02", "wpb": "885.3", "bsz": "16", "num_updates": "15400", "lr": "4.92546e-05", "gnorm": "0.978", "train_wall": "49", "wall": "12385"}
2022-10-27 00:25:09 | INFO | train_inner | {"epoch": 6, "update": 5.317, "loss": "2.138", "nll_loss": "0.24", "ppl": "1.18", "wps": "1803", "ups": "2.03", "wpb": "889.7", "bsz": "16", "num_updates": "15500", "lr": "4.92496e-05", "gnorm": "0.942", "train_wall": "49", "wall": "12434"}
2022-10-27 00:25:57 | INFO | train_inner | {"epoch": 6, "update": 5.352, "loss": "2.136", "nll_loss": "0.238", "ppl": "1.18", "wps": "1828.1", "ups": "2.08", "wpb": "880", "bsz": "16", "num_updates": "15600", "lr": "4.92446e-05", "gnorm": "0.945", "train_wall": "48", "wall": "12482"}
2022-10-27 00:26:44 | INFO | train_inner | {"epoch": 6, "update": 5.386, "loss": "2.135", "nll_loss": "0.237", "ppl": "1.18", "wps": "1967.4", "ups": "2.13", "wpb": "923.9", "bsz": "16", "num_updates": "15700", "lr": "4.92396e-05", "gnorm": "0.907", "train_wall": "46", "wall": "12529"}
2022-10-27 00:27:25 | INFO | train_inner | {"epoch": 6, "update": 5.42, "loss": "2.136", "nll_loss": "0.238", "ppl": "1.18", "wps": "2144.5", "ups": "2.43", "wpb": "881.4", "bsz": "16", "num_updates": "15800", "lr": "4.92346e-05", "gnorm": "1.028", "train_wall": "41", "wall": "12570"}
2022-10-27 00:28:14 | INFO | train_inner | {"epoch": 6, "update": 5.455, "loss": "2.139", "nll_loss": "0.242", "ppl": "1.18", "wps": "1871.4", "ups": "2.03", "wpb": "923.7", "bsz": "16", "num_updates": "15900", "lr": "4.92296e-05", "gnorm": "0.924", "train_wall": "49", "wall": "12620"}
2022-10-27 00:29:04 | INFO | train_inner | {"epoch": 6, "update": 5.489, "loss": "2.14", "nll_loss": "0.242", "ppl": "1.18", "wps": "1808.7", "ups": "2.02", "wpb": "897.2", "bsz": "16", "num_updates": "16000", "lr": "4.92246e-05", "gnorm": "0.936", "train_wall": "49", "wall": "12669"}
2022-10-27 00:29:53 | INFO | train_inner | {"epoch": 6, "update": 5.523, "loss": "2.152", "nll_loss": "0.255", "ppl": "1.19", "wps": "1781.2", "ups": "2.03", "wpb": "877.7", "bsz": "16", "num_updates": "16100", "lr": "4.92196e-05", "gnorm": "1", "train_wall": "49", "wall": "12719"}
2022-10-27 00:30:43 | INFO | train_inner | {"epoch": 6, "update": 5.557, "loss": "2.138", "nll_loss": "0.24", "ppl": "1.18", "wps": "1822.3", "ups": "2.01", "wpb": "905", "bsz": "16", "num_updates": "16200", "lr": "4.92146e-05", "gnorm": "0.888", "train_wall": "49", "wall": "12768"}
2022-10-27 00:31:31 | INFO | train_inner | {"epoch": 6, "update": 5.592, "loss": "2.143", "nll_loss": "0.245", "ppl": "1.19", "wps": "1824.5", "ups": "2.07", "wpb": "881.5", "bsz": "16", "num_updates": "16300", "lr": "4.92096e-05", "gnorm": "0.913", "train_wall": "48", "wall": "12817"}
2022-10-27 00:32:20 | INFO | train_inner | {"epoch": 6, "update": 5.626, "loss": "2.138", "nll_loss": "0.24", "ppl": "1.18", "wps": "1852.5", "ups": "2.05", "wpb": "905.2", "bsz": "16", "num_updates": "16400", "lr": "4.92046e-05", "gnorm": "0.909", "train_wall": "48", "wall": "12865"}
2022-10-27 00:33:09 | INFO | train_inner | {"epoch": 6, "update": 5.66, "loss": "2.134", "nll_loss": "0.236", "ppl": "1.18", "wps": "1845", "ups": "2.02", "wpb": "914.4", "bsz": "16", "num_updates": "16500", "lr": "4.91996e-05", "gnorm": "0.849", "train_wall": "49", "wall": "12915"}
2022-10-27 00:33:59 | INFO | train_inner | {"epoch": 6, "update": 5.695, "loss": "2.14", "nll_loss": "0.242", "ppl": "1.18", "wps": "1777.9", "ups": "2.02", "wpb": "880.1", "bsz": "16", "num_updates": "16600", "lr": "4.91946e-05", "gnorm": "0.996", "train_wall": "49", "wall": "12965"}
2022-10-27 00:34:49 | INFO | train_inner | {"epoch": 6, "update": 5.729, "loss": "2.136", "nll_loss": "0.239", "ppl": "1.18", "wps": "1863.8", "ups": "2.01", "wpb": "925.5", "bsz": "16", "num_updates": "16700", "lr": "4.91896e-05", "gnorm": "1.012", "train_wall": "49", "wall": "13014"}
2022-10-27 00:35:38 | INFO | train_inner | {"epoch": 6, "update": 5.763, "loss": "2.142", "nll_loss": "0.246", "ppl": "1.19", "wps": "1914.1", "ups": "2.01", "wpb": "953.4", "bsz": "16", "num_updates": "16800", "lr": "4.91846e-05", "gnorm": "0.922", "train_wall": "49", "wall": "13064"}
2022-10-27 00:36:28 | INFO | train_inner | {"epoch": 6, "update": 5.798, "loss": "2.143", "nll_loss": "0.247", "ppl": "1.19", "wps": "1761.4", "ups": "2.01", "wpb": "877.1", "bsz": "16", "num_updates": "16900", "lr": "4.91796e-05", "gnorm": "0.966", "train_wall": "49", "wall": "13114"}
2022-10-27 00:37:17 | INFO | train_inner | {"epoch": 6, "update": 5.832, "loss": "2.141", "nll_loss": "0.244", "ppl": "1.18", "wps": "1850.6", "ups": "2.07", "wpb": "894.6", "bsz": "16", "num_updates": "17000", "lr": "4.91746e-05", "gnorm": "1.068", "train_wall": "48", "wall": "13162"}
2022-10-27 00:38:06 | INFO | train_inner | {"epoch": 6, "update": 5.866, "loss": "2.143", "nll_loss": "0.246", "ppl": "1.19", "wps": "1757.3", "ups": "2.01", "wpb": "872.5", "bsz": "16", "num_updates": "17100", "lr": "4.91696e-05", "gnorm": "0.967", "train_wall": "49", "wall": "13212"}
2022-10-27 00:38:56 | INFO | train_inner | {"epoch": 6, "update": 5.901, "loss": "2.141", "nll_loss": "0.244", "ppl": "1.18", "wps": "1878.1", "ups": "2.01", "wpb": "933.7", "bsz": "16", "num_updates": "17200", "lr": "4.91646e-05", "gnorm": "0.946", "train_wall": "49", "wall": "13262"}
2022-10-27 00:39:46 | INFO | train_inner | {"epoch": 6, "update": 5.935, "loss": "2.144", "nll_loss": "0.248", "ppl": "1.19", "wps": "1728.1", "ups": "2.01", "wpb": "859.2", "bsz": "16", "num_updates": "17300", "lr": "4.91596e-05", "gnorm": "0.957", "train_wall": "49", "wall": "13311"}
2022-10-27 00:40:35 | INFO | train_inner | {"epoch": 6, "update": 5.969, "loss": "2.144", "nll_loss": "0.248", "ppl": "1.19", "wps": "1791.4", "ups": "2.03", "wpb": "881.4", "bsz": "16", "num_updates": "17400", "lr": "4.91546e-05", "gnorm": "0.993", "train_wall": "49", "wall": "13360"}
2022-10-27 00:41:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-27 00:59:00 | INFO | valid | {"epoch": 6, "valid_loss": "2.287", "valid_nll_loss": "0.272", "valid_ppl": "1.21", "valid_bleu": "75.55", "valid_wps": "305.3", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "17490", "valid_best_bleu": "77.23"}
2022-10-27 00:59:00 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-27 00:59:08 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_last.pt (epoch 6 @ 17490 updates, score 75.55) (writing took 8.109021524898708 seconds)
2022-10-27 00:59:08 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-10-27 00:59:08 | INFO | train | {"epoch": 6, "train_loss": "2.138", "train_nll_loss": "0.241", "train_ppl": "1.18", "train_wps": "1061.1", "train_ups": "1.18", "train_wpb": "896.6", "train_bsz": "16", "train_num_updates": "17490", "train_lr": "4.91501e-05", "train_gnorm": "0.955", "train_train_wall": "1378", "train_wall": "14473"}
2022-10-27 00:59:08 | INFO | fairseq.trainer | begin training epoch 7
2022-10-27 00:59:13 | INFO | train_inner | {"epoch": 7, "update": 6.003, "loss": "2.14", "nll_loss": "0.244", "ppl": "1.18", "wps": "79.1", "ups": "0.09", "wpb": "883.9", "bsz": "15.9", "num_updates": "17500", "lr": "4.91496e-05", "gnorm": "1.115", "train_wall": "49", "wall": "14478"}
2022-10-27 01:00:02 | INFO | train_inner | {"epoch": 7, "update": 6.038, "loss": "2.122", "nll_loss": "0.222", "ppl": "1.17", "wps": "1838.6", "ups": "2.03", "wpb": "907.7", "bsz": "16", "num_updates": "17600", "lr": "4.91446e-05", "gnorm": "0.944", "train_wall": "49", "wall": "14528"}
2022-10-27 01:00:51 | INFO | train_inner | {"epoch": 7, "update": 6.072, "loss": "2.123", "nll_loss": "0.224", "ppl": "1.17", "wps": "1775.8", "ups": "2.03", "wpb": "876.5", "bsz": "16", "num_updates": "17700", "lr": "4.91396e-05", "gnorm": "0.786", "train_wall": "49", "wall": "14577"}
2022-10-27 01:01:41 | INFO | train_inner | {"epoch": 7, "update": 6.106, "loss": "2.126", "nll_loss": "0.228", "ppl": "1.17", "wps": "1826.3", "ups": "2.04", "wpb": "895.5", "bsz": "16", "num_updates": "17800", "lr": "4.91346e-05", "gnorm": "0.875", "train_wall": "48", "wall": "14626"}
2022-10-27 01:02:30 | INFO | train_inner | {"epoch": 7, "update": 6.141, "loss": "2.119", "nll_loss": "0.22", "ppl": "1.16", "wps": "1875.9", "ups": "2.03", "wpb": "924", "bsz": "16", "num_updates": "17900", "lr": "4.91296e-05", "gnorm": "0.828", "train_wall": "49", "wall": "14675"}
2022-10-27 01:03:19 | INFO | train_inner | {"epoch": 7, "update": 6.175, "loss": "2.127", "nll_loss": "0.229", "ppl": "1.17", "wps": "1897", "ups": "2.01", "wpb": "942.6", "bsz": "16", "num_updates": "18000", "lr": "4.91246e-05", "gnorm": "0.958", "train_wall": "49", "wall": "14725"}
2022-10-27 01:04:09 | INFO | train_inner | {"epoch": 7, "update": 6.209, "loss": "2.122", "nll_loss": "0.223", "ppl": "1.17", "wps": "1868.6", "ups": "2.01", "wpb": "927.9", "bsz": "16", "num_updates": "18100", "lr": "4.91196e-05", "gnorm": "0.918", "train_wall": "49", "wall": "14775"}
2022-10-27 01:04:56 | INFO | train_inner | {"epoch": 7, "update": 6.244, "loss": "2.127", "nll_loss": "0.229", "ppl": "1.17", "wps": "1914.4", "ups": "2.14", "wpb": "893.3", "bsz": "16", "num_updates": "18200", "lr": "4.91146e-05", "gnorm": "0.951", "train_wall": "46", "wall": "14821"}
2022-10-27 01:05:43 | INFO | train_inner | {"epoch": 7, "update": 6.278, "loss": "2.13", "nll_loss": "0.233", "ppl": "1.17", "wps": "1853.4", "ups": "2.12", "wpb": "874.7", "bsz": "16", "num_updates": "18300", "lr": "4.91096e-05", "gnorm": "0.898", "train_wall": "47", "wall": "14869"}
2022-10-27 01:06:32 | INFO | train_inner | {"epoch": 7, "update": 6.312, "loss": "2.122", "nll_loss": "0.223", "ppl": "1.17", "wps": "1913.5", "ups": "2.03", "wpb": "944.2", "bsz": "16", "num_updates": "18400", "lr": "4.91046e-05", "gnorm": "0.858", "train_wall": "49", "wall": "14918"}
2022-10-27 01:07:17 | INFO | train_inner | {"epoch": 7, "update": 6.346, "loss": "2.126", "nll_loss": "0.228", "ppl": "1.17", "wps": "2003.8", "ups": "2.22", "wpb": "904.1", "bsz": "16", "num_updates": "18500", "lr": "4.90995e-05", "gnorm": "0.954", "train_wall": "45", "wall": "14963"}
2022-10-27 01:07:48 | INFO | train_inner | {"epoch": 7, "update": 6.381, "loss": "2.127", "nll_loss": "0.229", "ppl": "1.17", "wps": "2912.4", "ups": "3.32", "wpb": "877.8", "bsz": "16", "num_updates": "18600", "lr": "4.90945e-05", "gnorm": "0.891", "train_wall": "30", "wall": "14993"}
2022-10-27 01:08:37 | INFO | train_inner | {"epoch": 7, "update": 6.415, "loss": "2.126", "nll_loss": "0.228", "ppl": "1.17", "wps": "1855.8", "ups": "2.01", "wpb": "922.1", "bsz": "16", "num_updates": "18700", "lr": "4.90895e-05", "gnorm": "1.011", "train_wall": "49", "wall": "15043"}
2022-10-27 01:09:27 | INFO | train_inner | {"epoch": 7, "update": 6.449, "loss": "2.13", "nll_loss": "0.232", "ppl": "1.17", "wps": "1779.2", "ups": "2.03", "wpb": "878.3", "bsz": "16", "num_updates": "18800", "lr": "4.90845e-05", "gnorm": "0.941", "train_wall": "49", "wall": "15092"}
2022-10-27 01:10:16 | INFO | train_inner | {"epoch": 7, "update": 6.484, "loss": "2.124", "nll_loss": "0.226", "ppl": "1.17", "wps": "1757.4", "ups": "2.01", "wpb": "873", "bsz": "16", "num_updates": "18900", "lr": "4.90795e-05", "gnorm": "0.931", "train_wall": "49", "wall": "15142"}
2022-10-27 01:11:06 | INFO | train_inner | {"epoch": 7, "update": 6.518, "loss": "2.132", "nll_loss": "0.235", "ppl": "1.18", "wps": "1759.9", "ups": "2.02", "wpb": "870.1", "bsz": "16", "num_updates": "19000", "lr": "4.90745e-05", "gnorm": "0.993", "train_wall": "49", "wall": "15191"}
2022-10-27 01:11:52 | INFO | train_inner | {"epoch": 7, "update": 6.552, "loss": "2.131", "nll_loss": "0.234", "ppl": "1.18", "wps": "1936.9", "ups": "2.18", "wpb": "890", "bsz": "16", "num_updates": "19100", "lr": "4.90695e-05", "gnorm": "0.935", "train_wall": "45", "wall": "15237"}
2022-10-27 01:12:40 | INFO | train_inner | {"epoch": 7, "update": 6.587, "loss": "2.131", "nll_loss": "0.234", "ppl": "1.18", "wps": "1857.1", "ups": "2.06", "wpb": "903.1", "bsz": "16", "num_updates": "19200", "lr": "4.90645e-05", "gnorm": "0.952", "train_wall": "48", "wall": "15286"}
2022-10-27 01:13:30 | INFO | train_inner | {"epoch": 7, "update": 6.621, "loss": "2.127", "nll_loss": "0.23", "ppl": "1.17", "wps": "1857.6", "ups": "2.02", "wpb": "921", "bsz": "16", "num_updates": "19300", "lr": "4.90595e-05", "gnorm": "0.914", "train_wall": "49", "wall": "15335"}
2022-10-27 01:14:18 | INFO | train_inner | {"epoch": 7, "update": 6.655, "loss": "2.13", "nll_loss": "0.234", "ppl": "1.18", "wps": "1809", "ups": "2.08", "wpb": "871.8", "bsz": "16", "num_updates": "19400", "lr": "4.90545e-05", "gnorm": "1.044", "train_wall": "48", "wall": "15384"}
2022-10-27 01:15:00 | INFO | train_inner | {"epoch": 7, "update": 6.69, "loss": "2.132", "nll_loss": "0.235", "ppl": "1.18", "wps": "2146", "ups": "2.41", "wpb": "891.2", "bsz": "16", "num_updates": "19500", "lr": "4.90495e-05", "gnorm": "1.075", "train_wall": "41", "wall": "15425"}
2022-10-27 01:15:49 | INFO | train_inner | {"epoch": 7, "update": 6.724, "loss": "2.131", "nll_loss": "0.233", "ppl": "1.18", "wps": "1793.3", "ups": "2.02", "wpb": "888.6", "bsz": "16", "num_updates": "19600", "lr": "4.90445e-05", "gnorm": "0.988", "train_wall": "49", "wall": "15475"}
2022-10-27 01:16:39 | INFO | train_inner | {"epoch": 7, "update": 6.758, "loss": "2.126", "nll_loss": "0.229", "ppl": "1.17", "wps": "1805.6", "ups": "2.03", "wpb": "891.3", "bsz": "16", "num_updates": "19700", "lr": "4.90395e-05", "gnorm": "0.996", "train_wall": "49", "wall": "15524"}
2022-10-27 01:17:28 | INFO | train_inner | {"epoch": 7, "update": 6.792, "loss": "2.138", "nll_loss": "0.242", "ppl": "1.18", "wps": "1823.5", "ups": "2.03", "wpb": "900.2", "bsz": "16", "num_updates": "19800", "lr": "4.90345e-05", "gnorm": "1.091", "train_wall": "49", "wall": "15573"}
2022-10-27 01:18:17 | INFO | train_inner | {"epoch": 7, "update": 6.827, "loss": "2.139", "nll_loss": "0.243", "ppl": "1.18", "wps": "1860.2", "ups": "2.06", "wpb": "904", "bsz": "16", "num_updates": "19900", "lr": "4.90295e-05", "gnorm": "0.902", "train_wall": "48", "wall": "15622"}
2022-10-27 01:19:06 | INFO | train_inner | {"epoch": 7, "update": 6.861, "loss": "2.133", "nll_loss": "0.237", "ppl": "1.18", "wps": "1843.2", "ups": "2.03", "wpb": "910", "bsz": "16", "num_updates": "20000", "lr": "4.90245e-05", "gnorm": "0.971", "train_wall": "49", "wall": "15671"}
2022-10-27 01:19:55 | INFO | train_inner | {"epoch": 7, "update": 6.895, "loss": "2.132", "nll_loss": "0.236", "ppl": "1.18", "wps": "1792.4", "ups": "2.02", "wpb": "888", "bsz": "16", "num_updates": "20100", "lr": "4.90195e-05", "gnorm": "1.018", "train_wall": "49", "wall": "15721"}
2022-10-27 01:20:44 | INFO | train_inner | {"epoch": 7, "update": 6.93, "loss": "2.132", "nll_loss": "0.235", "ppl": "1.18", "wps": "1820.2", "ups": "2.06", "wpb": "884.4", "bsz": "16", "num_updates": "20200", "lr": "4.90145e-05", "gnorm": "1.089", "train_wall": "48", "wall": "15770"}
2022-10-27 01:21:34 | INFO | train_inner | {"epoch": 7, "update": 6.964, "loss": "2.134", "nll_loss": "0.237", "ppl": "1.18", "wps": "1753.4", "ups": "2.01", "wpb": "870.3", "bsz": "16", "num_updates": "20300", "lr": "4.90095e-05", "gnorm": "0.898", "train_wall": "49", "wall": "15819"}
2022-10-27 01:22:23 | INFO | train_inner | {"epoch": 7, "update": 6.998, "loss": "2.137", "nll_loss": "0.241", "ppl": "1.18", "wps": "1796.5", "ups": "2.02", "wpb": "887.9", "bsz": "16", "num_updates": "20400", "lr": "4.90045e-05", "gnorm": "1.042", "train_wall": "49", "wall": "15869"}
2022-10-27 01:22:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-27 01:40:07 | INFO | valid | {"epoch": 7, "valid_loss": "2.284", "valid_nll_loss": "0.281", "valid_ppl": "1.22", "valid_bleu": "76.74", "valid_wps": "304.9", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "20405", "valid_best_bleu": "77.23"}
2022-10-27 01:40:07 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-27 01:40:15 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_last.pt (epoch 7 @ 20405 updates, score 76.74) (writing took 8.047300739912316 seconds)
2022-10-27 01:40:15 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-10-27 01:40:15 | INFO | train | {"epoch": 7, "train_loss": "2.129", "train_nll_loss": "0.231", "train_ppl": "1.17", "train_wps": "1059.3", "train_ups": "1.18", "train_wpb": "896.6", "train_bsz": "16", "train_num_updates": "20405", "train_lr": "4.90043e-05", "train_gnorm": "0.954", "train_train_wall": "1381", "train_wall": "16941"}
2022-10-27 01:40:15 | INFO | fairseq.trainer | begin training epoch 8
2022-10-27 01:41:02 | INFO | train_inner | {"epoch": 8, "update": 7.033, "loss": "2.115", "nll_loss": "0.217", "ppl": "1.16", "wps": "78.3", "ups": "0.09", "wpb": "876.2", "bsz": "15.9", "num_updates": "20500", "lr": "4.89995e-05", "gnorm": "0.965", "train_wall": "48", "wall": "16988"}
2022-10-27 01:41:52 | INFO | train_inner | {"epoch": 8, "update": 7.067, "loss": "2.113", "nll_loss": "0.214", "ppl": "1.16", "wps": "1798.2", "ups": "2.02", "wpb": "890.6", "bsz": "16", "num_updates": "20600", "lr": "4.89945e-05", "gnorm": "1.044", "train_wall": "49", "wall": "17037"}
2022-10-27 01:42:41 | INFO | train_inner | {"epoch": 8, "update": 7.101, "loss": "2.122", "nll_loss": "0.225", "ppl": "1.17", "wps": "1873.7", "ups": "2.01", "wpb": "931.7", "bsz": "16", "num_updates": "20700", "lr": "4.89895e-05", "gnorm": "1.016", "train_wall": "49", "wall": "17087"}
2022-10-27 01:43:30 | INFO | train_inner | {"epoch": 8, "update": 7.136, "loss": "2.11", "nll_loss": "0.21", "ppl": "1.16", "wps": "1876.6", "ups": "2.03", "wpb": "924", "bsz": "16", "num_updates": "20800", "lr": "4.89845e-05", "gnorm": "0.855", "train_wall": "49", "wall": "17136"}
2022-10-27 01:44:20 | INFO | train_inner | {"epoch": 8, "update": 7.17, "loss": "2.116", "nll_loss": "0.219", "ppl": "1.16", "wps": "1800.1", "ups": "2.03", "wpb": "884.8", "bsz": "16", "num_updates": "20900", "lr": "4.89795e-05", "gnorm": "0.879", "train_wall": "49", "wall": "17185"}
2022-10-27 01:45:09 | INFO | train_inner | {"epoch": 8, "update": 7.204, "loss": "2.116", "nll_loss": "0.217", "ppl": "1.16", "wps": "1831.1", "ups": "2.02", "wpb": "904.7", "bsz": "16", "num_updates": "21000", "lr": "4.89745e-05", "gnorm": "0.901", "train_wall": "49", "wall": "17235"}
2022-10-27 01:45:58 | INFO | train_inner | {"epoch": 8, "update": 7.238, "loss": "2.119", "nll_loss": "0.222", "ppl": "1.17", "wps": "1748.3", "ups": "2.02", "wpb": "863.7", "bsz": "16", "num_updates": "21100", "lr": "4.89695e-05", "gnorm": "1.086", "train_wall": "49", "wall": "17284"}
2022-10-27 01:46:48 | INFO | train_inner | {"epoch": 8, "update": 7.273, "loss": "2.123", "nll_loss": "0.226", "ppl": "1.17", "wps": "1717.8", "ups": "2.01", "wpb": "852.6", "bsz": "16", "num_updates": "21200", "lr": "4.89645e-05", "gnorm": "1.01", "train_wall": "49", "wall": "17334"}
2022-10-27 01:47:37 | INFO | train_inner | {"epoch": 8, "update": 7.307, "loss": "2.122", "nll_loss": "0.224", "ppl": "1.17", "wps": "1876.9", "ups": "2.03", "wpb": "925.6", "bsz": "16", "num_updates": "21300", "lr": "4.89595e-05", "gnorm": "1.182", "train_wall": "49", "wall": "17383"}
2022-10-27 01:48:26 | INFO | train_inner | {"epoch": 8, "update": 7.341, "loss": "2.12", "nll_loss": "0.223", "ppl": "1.17", "wps": "1891.9", "ups": "2.05", "wpb": "921.3", "bsz": "16", "num_updates": "21400", "lr": "4.89545e-05", "gnorm": "0.951", "train_wall": "48", "wall": "17432"}
2022-10-27 01:49:16 | INFO | train_inner | {"epoch": 8, "update": 7.376, "loss": "2.123", "nll_loss": "0.226", "ppl": "1.17", "wps": "1810.2", "ups": "2.02", "wpb": "896.1", "bsz": "16", "num_updates": "21500", "lr": "4.89495e-05", "gnorm": "0.969", "train_wall": "49", "wall": "17481"}
2022-10-27 01:50:04 | INFO | train_inner | {"epoch": 8, "update": 7.41, "loss": "2.117", "nll_loss": "0.219", "ppl": "1.16", "wps": "1935.5", "ups": "2.07", "wpb": "934.2", "bsz": "16", "num_updates": "21600", "lr": "4.89445e-05", "gnorm": "0.908", "train_wall": "48", "wall": "17529"}
2022-10-27 01:50:53 | INFO | train_inner | {"epoch": 8, "update": 7.444, "loss": "2.121", "nll_loss": "0.224", "ppl": "1.17", "wps": "1791.4", "ups": "2.03", "wpb": "883.5", "bsz": "16", "num_updates": "21700", "lr": "4.89395e-05", "gnorm": "1.048", "train_wall": "49", "wall": "17579"}
2022-10-27 01:51:43 | INFO | train_inner | {"epoch": 8, "update": 7.479, "loss": "2.12", "nll_loss": "0.223", "ppl": "1.17", "wps": "1864.9", "ups": "2.02", "wpb": "922.7", "bsz": "16", "num_updates": "21800", "lr": "4.89345e-05", "gnorm": "1.056", "train_wall": "49", "wall": "17628"}
2022-10-27 01:52:32 | INFO | train_inner | {"epoch": 8, "update": 7.513, "loss": "2.133", "nll_loss": "0.237", "ppl": "1.18", "wps": "1869.1", "ups": "2.02", "wpb": "926.5", "bsz": "16", "num_updates": "21900", "lr": "4.89295e-05", "gnorm": "1.005", "train_wall": "49", "wall": "17678"}
2022-10-27 01:53:22 | INFO | train_inner | {"epoch": 8, "update": 7.547, "loss": "2.121", "nll_loss": "0.224", "ppl": "1.17", "wps": "1816.7", "ups": "2.01", "wpb": "902.7", "bsz": "16", "num_updates": "22000", "lr": "4.89245e-05", "gnorm": "0.939", "train_wall": "49", "wall": "17727"}
2022-10-27 01:54:11 | INFO | train_inner | {"epoch": 8, "update": 7.581, "loss": "2.12", "nll_loss": "0.223", "ppl": "1.17", "wps": "1860.7", "ups": "2.02", "wpb": "920.6", "bsz": "16", "num_updates": "22100", "lr": "4.89195e-05", "gnorm": "1.021", "train_wall": "49", "wall": "17777"}
2022-10-27 01:55:01 | INFO | train_inner | {"epoch": 8, "update": 7.616, "loss": "2.119", "nll_loss": "0.222", "ppl": "1.17", "wps": "1767.3", "ups": "2.01", "wpb": "877.7", "bsz": "16", "num_updates": "22200", "lr": "4.89145e-05", "gnorm": "0.897", "train_wall": "49", "wall": "17827"}
2022-10-27 01:55:51 | INFO | train_inner | {"epoch": 8, "update": 7.65, "loss": "2.123", "nll_loss": "0.227", "ppl": "1.17", "wps": "1814.1", "ups": "2.02", "wpb": "899.8", "bsz": "16", "num_updates": "22300", "lr": "4.89095e-05", "gnorm": "0.997", "train_wall": "49", "wall": "17876"}
2022-10-27 01:56:40 | INFO | train_inner | {"epoch": 8, "update": 7.684, "loss": "2.124", "nll_loss": "0.227", "ppl": "1.17", "wps": "1771.6", "ups": "2.03", "wpb": "873.2", "bsz": "16", "num_updates": "22400", "lr": "4.89045e-05", "gnorm": "0.927", "train_wall": "49", "wall": "17926"}
2022-10-27 01:57:30 | INFO | train_inner | {"epoch": 8, "update": 7.719, "loss": "2.123", "nll_loss": "0.226", "ppl": "1.17", "wps": "1726.2", "ups": "2.02", "wpb": "855.6", "bsz": "16", "num_updates": "22500", "lr": "4.88994e-05", "gnorm": "0.964", "train_wall": "49", "wall": "17975"}
2022-10-27 01:58:19 | INFO | train_inner | {"epoch": 8, "update": 7.753, "loss": "2.129", "nll_loss": "0.233", "ppl": "1.18", "wps": "1772", "ups": "2.02", "wpb": "878.3", "bsz": "16", "num_updates": "22600", "lr": "4.88944e-05", "gnorm": "1.036", "train_wall": "49", "wall": "18025"}
2022-10-27 01:59:08 | INFO | train_inner | {"epoch": 8, "update": 7.787, "loss": "2.127", "nll_loss": "0.231", "ppl": "1.17", "wps": "1784.2", "ups": "2.03", "wpb": "880.1", "bsz": "16", "num_updates": "22700", "lr": "4.88894e-05", "gnorm": "1.317", "train_wall": "49", "wall": "18074"}
2022-10-27 01:59:58 | INFO | train_inner | {"epoch": 8, "update": 7.822, "loss": "2.122", "nll_loss": "0.226", "ppl": "1.17", "wps": "1807.2", "ups": "2.02", "wpb": "893.9", "bsz": "16", "num_updates": "22800", "lr": "4.88844e-05", "gnorm": "1.028", "train_wall": "49", "wall": "18123"}
2022-10-27 02:00:47 | INFO | train_inner | {"epoch": 8, "update": 7.856, "loss": "2.125", "nll_loss": "0.229", "ppl": "1.17", "wps": "1769.5", "ups": "2.02", "wpb": "877.1", "bsz": "16", "num_updates": "22900", "lr": "4.88794e-05", "gnorm": "1.007", "train_wall": "49", "wall": "18173"}
2022-10-27 02:01:37 | INFO | train_inner | {"epoch": 8, "update": 7.89, "loss": "2.13", "nll_loss": "0.234", "ppl": "1.18", "wps": "1736.8", "ups": "2.01", "wpb": "862.6", "bsz": "16", "num_updates": "23000", "lr": "4.88744e-05", "gnorm": "1.042", "train_wall": "49", "wall": "18223"}
2022-10-27 02:02:27 | INFO | train_inner | {"epoch": 8, "update": 7.925, "loss": "2.126", "nll_loss": "0.23", "ppl": "1.17", "wps": "1771.2", "ups": "2.01", "wpb": "881.5", "bsz": "16", "num_updates": "23100", "lr": "4.88694e-05", "gnorm": "1.091", "train_wall": "49", "wall": "18272"}
2022-10-27 02:03:17 | INFO | train_inner | {"epoch": 8, "update": 7.959, "loss": "2.126", "nll_loss": "0.23", "ppl": "1.17", "wps": "1855.5", "ups": "2.01", "wpb": "921.2", "bsz": "16", "num_updates": "23200", "lr": "4.88644e-05", "gnorm": "1.014", "train_wall": "49", "wall": "18322"}
2022-10-27 02:04:06 | INFO | train_inner | {"epoch": 8, "update": 7.993, "loss": "2.126", "nll_loss": "0.23", "ppl": "1.17", "wps": "1877.6", "ups": "2.02", "wpb": "929.5", "bsz": "16", "num_updates": "23300", "lr": "4.88594e-05", "gnorm": "1.01", "train_wall": "49", "wall": "18372"}
2022-10-27 02:04:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-27 02:21:36 | INFO | valid | {"epoch": 8, "valid_loss": "2.301", "valid_nll_loss": "0.295", "valid_ppl": "1.23", "valid_bleu": "74.56", "valid_wps": "311.1", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "23320", "valid_best_bleu": "77.23"}
2022-10-27 02:21:36 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 5 runs
2022-10-27 02:21:36 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-27 02:21:44 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/small.parent_code.child_full_code/checkpoint_last.pt (epoch 8 @ 23320 updates, score 74.56) (writing took 8.055060459068045 seconds)
2022-10-27 02:21:44 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-10-27 02:21:44 | INFO | train | {"epoch": 8, "train_loss": "2.122", "train_nll_loss": "0.225", "train_ppl": "1.17", "train_wps": "1049.9", "train_ups": "1.17", "train_wpb": "896.6", "train_bsz": "16", "train_num_updates": "23320", "train_lr": "4.88584e-05", "train_gnorm": "1.005", "train_train_wall": "1424", "train_wall": "19430"}
2022-10-27 02:21:44 | INFO | fairseq_cli.train | done training in 19428.4 seconds
BLEU: 76.87 ; Acc: 18.4
Medium Dataset:
---------------------------------------------------------------------------------------------
Source: source Target: target
2022-10-27 02:26:21 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.1, batch_size=4, batch_size_valid=4, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, extra_lang_symbol='', fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/home/y_shi202/related-project/MODIT/models/pretrained/checkpoints/checkpoint_11_100000.pt', save_dir='/home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1234, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_in_same_language', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[4], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='/home/y_shi202/related-project/MODIT/src', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=500, weight_decay=0.0, zero_sharding='none')
2022-10-27 02:26:21 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2022-10-27 02:26:21 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2022-10-27 02:26:21 | INFO | fairseq.data.data_utils | loaded 6542 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/valid.source-target.source
2022-10-27 02:26:21 | INFO | fairseq.data.data_utils | loaded 6542 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/valid.source-target.target
2022-10-27 02:26:21 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin valid source-target 6542 examples
2022-10-27 02:26:25 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2022-10-27 02:26:25 | INFO | fairseq_cli.train | task: translation_in_same_language (TranslationCodeBARTTask)
2022-10-27 02:26:25 | INFO | fairseq_cli.train | model: mbart_base (BARTModel)
2022-10-27 02:26:25 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2022-10-27 02:26:25 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2022-10-27 02:26:28 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-27 02:26:28 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-27 02:26:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-10-27 02:26:28 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-PCIE-32GB                    
2022-10-27 02:26:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-10-27 02:26:28 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-10-27 02:26:28 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 4
2022-10-27 02:26:29 | INFO | fairseq.trainer | loaded checkpoint /home/y_shi202/related-project/MODIT/models/pretrained/checkpoints/checkpoint_11_100000.pt (epoch 11 @ 0 updates)
2022-10-27 02:26:29 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2022-10-27 02:26:29 | INFO | fairseq.trainer | loading train data for epoch 1
2022-10-27 02:26:29 | INFO | fairseq.data.data_utils | loaded 52324 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/train.source-target.source
2022-10-27 02:26:29 | INFO | fairseq.data.data_utils | loaded 52324 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/train.source-target.target
2022-10-27 02:26:29 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin train source-target 52324 examples
2022-10-27 02:26:29 | INFO | fairseq.trainer | begin training epoch 1
2022-10-27 02:27:13 | INFO | train_inner | {"epoch": 1, "update": 0.031, "loss": "4.081", "nll_loss": "1.703", "ppl": "3.26", "wps": "5088.3", "ups": "2.31", "wpb": "2206.2", "bsz": "16", "num_updates": "100", "lr": "1e-05", "gnorm": "17.149", "train_wall": "43", "wall": "45"}
2022-10-27 02:27:48 | INFO | train_inner | {"epoch": 1, "update": 0.061, "loss": "2.473", "nll_loss": "0.43", "ppl": "1.35", "wps": "6296", "ups": "2.86", "wpb": "2198.2", "bsz": "16", "num_updates": "200", "lr": "2e-05", "gnorm": "1.456", "train_wall": "35", "wall": "80"}
2022-10-27 02:28:40 | INFO | train_inner | {"epoch": 1, "update": 0.092, "loss": "2.332", "nll_loss": "0.353", "ppl": "1.28", "wps": "4182.2", "ups": "1.92", "wpb": "2178", "bsz": "16", "num_updates": "300", "lr": "3e-05", "gnorm": "0.826", "train_wall": "51", "wall": "132"}
2022-10-27 02:29:32 | INFO | train_inner | {"epoch": 1, "update": 0.122, "loss": "2.274", "nll_loss": "0.32", "ppl": "1.25", "wps": "4077.2", "ups": "1.93", "wpb": "2118", "bsz": "16", "num_updates": "400", "lr": "4e-05", "gnorm": "0.709", "train_wall": "51", "wall": "184"}
2022-10-27 02:30:24 | INFO | train_inner | {"epoch": 1, "update": 0.153, "loss": "2.258", "nll_loss": "0.317", "ppl": "1.25", "wps": "4208.1", "ups": "1.92", "wpb": "2187.3", "bsz": "16", "num_updates": "500", "lr": "5e-05", "gnorm": "0.737", "train_wall": "51", "wall": "236"}
2022-10-27 02:31:13 | INFO | train_inner | {"epoch": 1, "update": 0.183, "loss": "2.243", "nll_loss": "0.308", "ppl": "1.24", "wps": "4405.1", "ups": "2.04", "wpb": "2162", "bsz": "16", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "0.656", "train_wall": "49", "wall": "285"}
2022-10-27 02:32:03 | INFO | train_inner | {"epoch": 1, "update": 0.214, "loss": "2.236", "nll_loss": "0.305", "ppl": "1.24", "wps": "4410.1", "ups": "2", "wpb": "2209", "bsz": "16", "num_updates": "700", "lr": "4.999e-05", "gnorm": "0.681", "train_wall": "50", "wall": "336"}
2022-10-27 02:32:55 | INFO | train_inner | {"epoch": 1, "update": 0.245, "loss": "2.226", "nll_loss": "0.301", "ppl": "1.23", "wps": "4112.5", "ups": "1.91", "wpb": "2149.8", "bsz": "16", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "0.652", "train_wall": "52", "wall": "388"}
2022-10-27 02:33:48 | INFO | train_inner | {"epoch": 1, "update": 0.275, "loss": "2.218", "nll_loss": "0.295", "ppl": "1.23", "wps": "4225.2", "ups": "1.9", "wpb": "2223.9", "bsz": "16", "num_updates": "900", "lr": "4.998e-05", "gnorm": "0.631", "train_wall": "52", "wall": "440"}
2022-10-27 02:34:41 | INFO | train_inner | {"epoch": 1, "update": 0.306, "loss": "2.212", "nll_loss": "0.292", "ppl": "1.22", "wps": "4230.4", "ups": "1.9", "wpb": "2229.7", "bsz": "16", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "0.58", "train_wall": "52", "wall": "493"}
2022-10-27 02:35:32 | INFO | train_inner | {"epoch": 1, "update": 0.336, "loss": "2.218", "nll_loss": "0.301", "ppl": "1.23", "wps": "4079.9", "ups": "1.94", "wpb": "2107.3", "bsz": "16", "num_updates": "1100", "lr": "4.997e-05", "gnorm": "0.598", "train_wall": "51", "wall": "545"}
2022-10-27 02:36:25 | INFO | train_inner | {"epoch": 1, "update": 0.367, "loss": "2.206", "nll_loss": "0.29", "ppl": "1.22", "wps": "4183.5", "ups": "1.92", "wpb": "2179", "bsz": "16", "num_updates": "1200", "lr": "4.9965e-05", "gnorm": "0.636", "train_wall": "52", "wall": "597"}
2022-10-27 02:37:16 | INFO | train_inner | {"epoch": 1, "update": 0.397, "loss": "2.21", "nll_loss": "0.297", "ppl": "1.23", "wps": "3983.8", "ups": "1.95", "wpb": "2048", "bsz": "16", "num_updates": "1300", "lr": "4.996e-05", "gnorm": "0.637", "train_wall": "51", "wall": "648"}
2022-10-27 02:38:04 | INFO | train_inner | {"epoch": 1, "update": 0.428, "loss": "2.207", "nll_loss": "0.294", "ppl": "1.23", "wps": "4419.1", "ups": "2.07", "wpb": "2135", "bsz": "16", "num_updates": "1400", "lr": "4.9955e-05", "gnorm": "0.634", "train_wall": "48", "wall": "697"}
2022-10-27 02:38:57 | INFO | train_inner | {"epoch": 1, "update": 0.459, "loss": "2.21", "nll_loss": "0.296", "ppl": "1.23", "wps": "4249.1", "ups": "1.9", "wpb": "2240.1", "bsz": "16", "num_updates": "1500", "lr": "4.995e-05", "gnorm": "0.635", "train_wall": "52", "wall": "749"}
2022-10-27 02:39:49 | INFO | train_inner | {"epoch": 1, "update": 0.489, "loss": "2.192", "nll_loss": "0.281", "ppl": "1.22", "wps": "4176.4", "ups": "1.91", "wpb": "2187.1", "bsz": "16", "num_updates": "1600", "lr": "4.9945e-05", "gnorm": "0.615", "train_wall": "52", "wall": "802"}
2022-10-27 02:40:42 | INFO | train_inner | {"epoch": 1, "update": 0.52, "loss": "2.199", "nll_loss": "0.288", "ppl": "1.22", "wps": "4257.9", "ups": "1.91", "wpb": "2226.1", "bsz": "16", "num_updates": "1700", "lr": "4.994e-05", "gnorm": "0.621", "train_wall": "52", "wall": "854"}
2022-10-27 02:41:32 | INFO | train_inner | {"epoch": 1, "update": 0.55, "loss": "2.192", "nll_loss": "0.283", "ppl": "1.22", "wps": "4262.4", "ups": "1.98", "wpb": "2155.7", "bsz": "16", "num_updates": "1800", "lr": "4.9935e-05", "gnorm": "0.572", "train_wall": "50", "wall": "905"}
2022-10-27 02:42:23 | INFO | train_inner | {"epoch": 1, "update": 0.581, "loss": "2.193", "nll_loss": "0.284", "ppl": "1.22", "wps": "4251", "ups": "1.97", "wpb": "2152.9", "bsz": "16", "num_updates": "1900", "lr": "4.993e-05", "gnorm": "0.569", "train_wall": "50", "wall": "955"}
2022-10-27 02:43:14 | INFO | train_inner | {"epoch": 1, "update": 0.611, "loss": "2.185", "nll_loss": "0.276", "ppl": "1.21", "wps": "4300.2", "ups": "1.95", "wpb": "2210.2", "bsz": "16", "num_updates": "2000", "lr": "4.9925e-05", "gnorm": "0.589", "train_wall": "51", "wall": "1007"}
2022-10-27 02:44:06 | INFO | train_inner | {"epoch": 1, "update": 0.642, "loss": "2.193", "nll_loss": "0.286", "ppl": "1.22", "wps": "4016", "ups": "1.92", "wpb": "2095.1", "bsz": "16", "num_updates": "2100", "lr": "4.992e-05", "gnorm": "0.603", "train_wall": "52", "wall": "1059"}
2022-10-27 02:44:58 | INFO | train_inner | {"epoch": 1, "update": 0.673, "loss": "2.187", "nll_loss": "0.281", "ppl": "1.21", "wps": "4345.5", "ups": "1.92", "wpb": "2261.6", "bsz": "16", "num_updates": "2200", "lr": "4.9915e-05", "gnorm": "0.6", "train_wall": "52", "wall": "1111"}
2022-10-27 02:45:51 | INFO | train_inner | {"epoch": 1, "update": 0.703, "loss": "2.188", "nll_loss": "0.282", "ppl": "1.22", "wps": "4129.7", "ups": "1.9", "wpb": "2172.2", "bsz": "16", "num_updates": "2300", "lr": "4.991e-05", "gnorm": "0.538", "train_wall": "52", "wall": "1163"}
2022-10-27 02:46:43 | INFO | train_inner | {"epoch": 1, "update": 0.734, "loss": "2.189", "nll_loss": "0.284", "ppl": "1.22", "wps": "4205.4", "ups": "1.92", "wpb": "2188.8", "bsz": "16", "num_updates": "2400", "lr": "4.9905e-05", "gnorm": "0.605", "train_wall": "52", "wall": "1215"}
2022-10-27 02:47:33 | INFO | train_inner | {"epoch": 1, "update": 0.764, "loss": "2.183", "nll_loss": "0.278", "ppl": "1.21", "wps": "4220.1", "ups": "2", "wpb": "2107.7", "bsz": "16", "num_updates": "2500", "lr": "4.98999e-05", "gnorm": "0.59", "train_wall": "49", "wall": "1265"}
2022-10-27 02:48:23 | INFO | train_inner | {"epoch": 1, "update": 0.795, "loss": "2.183", "nll_loss": "0.279", "ppl": "1.21", "wps": "4278.5", "ups": "1.99", "wpb": "2149.6", "bsz": "16", "num_updates": "2600", "lr": "4.98949e-05", "gnorm": "0.557", "train_wall": "50", "wall": "1316"}
2022-10-27 02:49:13 | INFO | train_inner | {"epoch": 1, "update": 0.825, "loss": "2.182", "nll_loss": "0.278", "ppl": "1.21", "wps": "4275.6", "ups": "2.02", "wpb": "2121.5", "bsz": "16", "num_updates": "2700", "lr": "4.98899e-05", "gnorm": "0.61", "train_wall": "49", "wall": "1365"}
2022-10-27 02:49:50 | INFO | train_inner | {"epoch": 1, "update": 0.856, "loss": "2.178", "nll_loss": "0.275", "ppl": "1.21", "wps": "5926.2", "ups": "2.73", "wpb": "2174.2", "bsz": "16", "num_updates": "2800", "lr": "4.98849e-05", "gnorm": "0.505", "train_wall": "36", "wall": "1402"}
2022-10-27 02:50:42 | INFO | train_inner | {"epoch": 1, "update": 0.887, "loss": "2.177", "nll_loss": "0.274", "ppl": "1.21", "wps": "4164.7", "ups": "1.91", "wpb": "2184.9", "bsz": "16", "num_updates": "2900", "lr": "4.98799e-05", "gnorm": "0.556", "train_wall": "52", "wall": "1454"}
2022-10-27 02:51:34 | INFO | train_inner | {"epoch": 1, "update": 0.917, "loss": "2.185", "nll_loss": "0.284", "ppl": "1.22", "wps": "4013.5", "ups": "1.93", "wpb": "2081.6", "bsz": "16", "num_updates": "3000", "lr": "4.98749e-05", "gnorm": "0.611", "train_wall": "51", "wall": "1506"}
2022-10-27 02:52:26 | INFO | train_inner | {"epoch": 1, "update": 0.948, "loss": "2.177", "nll_loss": "0.274", "ppl": "1.21", "wps": "4218.7", "ups": "1.92", "wpb": "2198.2", "bsz": "16", "num_updates": "3100", "lr": "4.98699e-05", "gnorm": "0.56", "train_wall": "52", "wall": "1558"}
2022-10-27 02:53:18 | INFO | train_inner | {"epoch": 1, "update": 0.978, "loss": "2.18", "nll_loss": "0.278", "ppl": "1.21", "wps": "4195.1", "ups": "1.92", "wpb": "2182.5", "bsz": "16", "num_updates": "3200", "lr": "4.98649e-05", "gnorm": "0.561", "train_wall": "51", "wall": "1610"}
2022-10-27 02:53:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
/home/y_shi202/.local/lib/python3.6/site-packages/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  "amp_C fused kernels unavailable, disabling multi_tensor_l2norm; "
2022-10-27 03:35:04 | INFO | valid | {"epoch": 1, "valid_loss": "2.202", "valid_nll_loss": "0.177", "valid_ppl": "1.13", "valid_bleu": "86.89", "valid_wps": "361.1", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "3271"}
2022-10-27 03:35:04 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-27 03:35:17 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_best.pt (epoch 1 @ 3271 updates, score 86.89) (writing took 13.73142516403459 seconds)
2022-10-27 03:35:17 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-10-27 03:35:17 | INFO | train | {"epoch": 1, "train_loss": "2.273", "train_nll_loss": "0.339", "train_ppl": "1.26", "train_wps": "1717.8", "train_ups": "0.79", "train_wpb": "2168.3", "train_bsz": "16", "train_num_updates": "3271", "train_lr": "4.98614e-05", "train_gnorm": "1.146", "train_train_wall": "1628", "train_wall": "4130"}
2022-10-27 03:35:17 | INFO | fairseq.trainer | begin training epoch 2
2022-10-27 03:35:30 | INFO | train_inner | {"epoch": 2, "update": 1.009, "loss": "2.171", "nll_loss": "0.27", "ppl": "1.21", "wps": "84.2", "ups": "0.04", "wpb": "2131.2", "bsz": "15.9", "num_updates": "3300", "lr": "4.98599e-05", "gnorm": "0.534", "train_wall": "48", "wall": "4142"}
2022-10-27 03:36:19 | INFO | train_inner | {"epoch": 2, "update": 1.039, "loss": "2.16", "nll_loss": "0.256", "ppl": "1.19", "wps": "4417.1", "ups": "2.05", "wpb": "2151.8", "bsz": "16", "num_updates": "3400", "lr": "4.98549e-05", "gnorm": "0.593", "train_wall": "48", "wall": "4191"}
2022-10-27 03:37:09 | INFO | train_inner | {"epoch": 2, "update": 1.07, "loss": "2.159", "nll_loss": "0.256", "ppl": "1.19", "wps": "4240.7", "ups": "1.99", "wpb": "2130.8", "bsz": "16", "num_updates": "3500", "lr": "4.98499e-05", "gnorm": "0.541", "train_wall": "50", "wall": "4241"}
2022-10-27 03:37:54 | INFO | train_inner | {"epoch": 2, "update": 1.101, "loss": "2.16", "nll_loss": "0.258", "ppl": "1.2", "wps": "4708.4", "ups": "2.24", "wpb": "2104.6", "bsz": "16", "num_updates": "3600", "lr": "4.98449e-05", "gnorm": "0.585", "train_wall": "44", "wall": "4286"}
2022-10-27 03:38:46 | INFO | train_inner | {"epoch": 2, "update": 1.131, "loss": "2.16", "nll_loss": "0.258", "ppl": "1.2", "wps": "4187.7", "ups": "1.9", "wpb": "2203.2", "bsz": "16", "num_updates": "3700", "lr": "4.98399e-05", "gnorm": "0.553", "train_wall": "52", "wall": "4338"}
2022-10-27 03:39:39 | INFO | train_inner | {"epoch": 2, "update": 1.162, "loss": "2.161", "nll_loss": "0.26", "ppl": "1.2", "wps": "4103.3", "ups": "1.91", "wpb": "2150.5", "bsz": "16", "num_updates": "3800", "lr": "4.98349e-05", "gnorm": "0.62", "train_wall": "52", "wall": "4391"}
2022-10-27 03:40:31 | INFO | train_inner | {"epoch": 2, "update": 1.192, "loss": "2.164", "nll_loss": "0.262", "ppl": "1.2", "wps": "4073.8", "ups": "1.91", "wpb": "2132.9", "bsz": "16", "num_updates": "3900", "lr": "4.98299e-05", "gnorm": "0.548", "train_wall": "52", "wall": "4443"}
2022-10-27 03:41:23 | INFO | train_inner | {"epoch": 2, "update": 1.223, "loss": "2.158", "nll_loss": "0.256", "ppl": "1.19", "wps": "4197.5", "ups": "1.92", "wpb": "2184", "bsz": "16", "num_updates": "4000", "lr": "4.98249e-05", "gnorm": "0.573", "train_wall": "51", "wall": "4495"}
2022-10-27 03:42:15 | INFO | train_inner | {"epoch": 2, "update": 1.253, "loss": "2.158", "nll_loss": "0.257", "ppl": "1.2", "wps": "4127.9", "ups": "1.92", "wpb": "2145.2", "bsz": "16", "num_updates": "4100", "lr": "4.98199e-05", "gnorm": "0.521", "train_wall": "51", "wall": "4547"}
2022-10-27 03:43:07 | INFO | train_inner | {"epoch": 2, "update": 1.284, "loss": "2.156", "nll_loss": "0.255", "ppl": "1.19", "wps": "4158.8", "ups": "1.91", "wpb": "2180.8", "bsz": "16", "num_updates": "4200", "lr": "4.98149e-05", "gnorm": "0.541", "train_wall": "52", "wall": "4600"}
2022-10-27 03:43:52 | INFO | train_inner | {"epoch": 2, "update": 1.315, "loss": "2.158", "nll_loss": "0.258", "ppl": "1.2", "wps": "4913.6", "ups": "2.26", "wpb": "2172.6", "bsz": "16", "num_updates": "4300", "lr": "4.98099e-05", "gnorm": "0.558", "train_wall": "44", "wall": "4644"}
2022-10-27 03:44:47 | INFO | train_inner | {"epoch": 2, "update": 1.345, "loss": "2.156", "nll_loss": "0.256", "ppl": "1.19", "wps": "3961", "ups": "1.81", "wpb": "2191.9", "bsz": "16", "num_updates": "4400", "lr": "4.98049e-05", "gnorm": "0.608", "train_wall": "55", "wall": "4699"}
2022-10-27 03:45:39 | INFO | train_inner | {"epoch": 2, "update": 1.376, "loss": "2.164", "nll_loss": "0.264", "ppl": "1.2", "wps": "4187.9", "ups": "1.9", "wpb": "2199.9", "bsz": "16", "num_updates": "4500", "lr": "4.97999e-05", "gnorm": "0.583", "train_wall": "52", "wall": "4752"}
2022-10-27 03:46:32 | INFO | train_inner | {"epoch": 2, "update": 1.406, "loss": "2.156", "nll_loss": "0.256", "ppl": "1.19", "wps": "4228.2", "ups": "1.91", "wpb": "2216.4", "bsz": "16", "num_updates": "4600", "lr": "4.97949e-05", "gnorm": "0.565", "train_wall": "52", "wall": "4804"}
2022-10-27 03:47:24 | INFO | train_inner | {"epoch": 2, "update": 1.437, "loss": "2.16", "nll_loss": "0.26", "ppl": "1.2", "wps": "4210.2", "ups": "1.91", "wpb": "2209.3", "bsz": "16", "num_updates": "4700", "lr": "4.97899e-05", "gnorm": "0.574", "train_wall": "52", "wall": "4857"}
2022-10-27 03:48:16 | INFO | train_inner | {"epoch": 2, "update": 1.467, "loss": "2.16", "nll_loss": "0.261", "ppl": "1.2", "wps": "4189.8", "ups": "1.93", "wpb": "2172.1", "bsz": "16", "num_updates": "4800", "lr": "4.97849e-05", "gnorm": "0.522", "train_wall": "51", "wall": "4909"}
2022-10-27 03:49:09 | INFO | train_inner | {"epoch": 2, "update": 1.498, "loss": "2.157", "nll_loss": "0.258", "ppl": "1.2", "wps": "4112.4", "ups": "1.91", "wpb": "2155.6", "bsz": "16", "num_updates": "4900", "lr": "4.97799e-05", "gnorm": "0.576", "train_wall": "52", "wall": "4961"}
2022-10-27 03:50:01 | INFO | train_inner | {"epoch": 2, "update": 1.529, "loss": "2.157", "nll_loss": "0.258", "ppl": "1.2", "wps": "4199.3", "ups": "1.9", "wpb": "2205.4", "bsz": "16", "num_updates": "5000", "lr": "4.97749e-05", "gnorm": "0.591", "train_wall": "52", "wall": "5013"}
2022-10-27 03:50:53 | INFO | train_inner | {"epoch": 2, "update": 1.559, "loss": "2.159", "nll_loss": "0.261", "ppl": "1.2", "wps": "4066.5", "ups": "1.93", "wpb": "2107.2", "bsz": "16", "num_updates": "5100", "lr": "4.97699e-05", "gnorm": "0.549", "train_wall": "51", "wall": "5065"}
2022-10-27 03:51:45 | INFO | train_inner | {"epoch": 2, "update": 1.59, "loss": "2.156", "nll_loss": "0.258", "ppl": "1.2", "wps": "4154.4", "ups": "1.92", "wpb": "2167.9", "bsz": "16", "num_updates": "5200", "lr": "4.97649e-05", "gnorm": "0.603", "train_wall": "52", "wall": "5117"}
2022-10-27 03:52:37 | INFO | train_inner | {"epoch": 2, "update": 1.62, "loss": "2.155", "nll_loss": "0.256", "ppl": "1.19", "wps": "4063.2", "ups": "1.92", "wpb": "2121.5", "bsz": "16", "num_updates": "5300", "lr": "4.97599e-05", "gnorm": "0.568", "train_wall": "52", "wall": "5170"}
2022-10-27 03:53:29 | INFO | train_inner | {"epoch": 2, "update": 1.651, "loss": "2.152", "nll_loss": "0.253", "ppl": "1.19", "wps": "4271.1", "ups": "1.92", "wpb": "2228.5", "bsz": "16", "num_updates": "5400", "lr": "4.97549e-05", "gnorm": "0.534", "train_wall": "52", "wall": "5222"}
2022-10-27 03:54:21 | INFO | train_inner | {"epoch": 2, "update": 1.681, "loss": "2.157", "nll_loss": "0.26", "ppl": "1.2", "wps": "4090.7", "ups": "1.92", "wpb": "2126", "bsz": "16", "num_updates": "5500", "lr": "4.97499e-05", "gnorm": "0.535", "train_wall": "51", "wall": "5274"}
2022-10-27 03:55:14 | INFO | train_inner | {"epoch": 2, "update": 1.712, "loss": "2.151", "nll_loss": "0.253", "ppl": "1.19", "wps": "4245.5", "ups": "1.91", "wpb": "2219.8", "bsz": "16", "num_updates": "5600", "lr": "4.97449e-05", "gnorm": "0.536", "train_wall": "52", "wall": "5326"}
2022-10-27 03:56:06 | INFO | train_inner | {"epoch": 2, "update": 1.743, "loss": "2.156", "nll_loss": "0.258", "ppl": "1.2", "wps": "4101.2", "ups": "1.92", "wpb": "2136.4", "bsz": "16", "num_updates": "5700", "lr": "4.97399e-05", "gnorm": "0.552", "train_wall": "52", "wall": "5378"}
2022-10-27 03:56:58 | INFO | train_inner | {"epoch": 2, "update": 1.773, "loss": "2.157", "nll_loss": "0.26", "ppl": "1.2", "wps": "4112.1", "ups": "1.91", "wpb": "2150.8", "bsz": "16", "num_updates": "5800", "lr": "4.97349e-05", "gnorm": "0.572", "train_wall": "52", "wall": "5430"}
2022-10-27 03:57:50 | INFO | train_inner | {"epoch": 2, "update": 1.804, "loss": "2.159", "nll_loss": "0.262", "ppl": "1.2", "wps": "4192.3", "ups": "1.93", "wpb": "2170.8", "bsz": "16", "num_updates": "5900", "lr": "4.97299e-05", "gnorm": "0.589", "train_wall": "51", "wall": "5482"}
2022-10-27 03:58:42 | INFO | train_inner | {"epoch": 2, "update": 1.834, "loss": "2.158", "nll_loss": "0.261", "ppl": "1.2", "wps": "4202.3", "ups": "1.92", "wpb": "2186", "bsz": "16", "num_updates": "6000", "lr": "4.97249e-05", "gnorm": "0.527", "train_wall": "51", "wall": "5534"}
2022-10-27 03:59:34 | INFO | train_inner | {"epoch": 2, "update": 1.865, "loss": "2.153", "nll_loss": "0.256", "ppl": "1.19", "wps": "4125.4", "ups": "1.91", "wpb": "2161", "bsz": "16", "num_updates": "6100", "lr": "4.97199e-05", "gnorm": "0.614", "train_wall": "52", "wall": "5587"}
2022-10-27 04:00:26 | INFO | train_inner | {"epoch": 2, "update": 1.895, "loss": "2.157", "nll_loss": "0.261", "ppl": "1.2", "wps": "4098.1", "ups": "1.92", "wpb": "2136.9", "bsz": "16", "num_updates": "6200", "lr": "4.97149e-05", "gnorm": "0.601", "train_wall": "52", "wall": "5639"}
2022-10-27 04:01:16 | INFO | train_inner | {"epoch": 2, "update": 1.926, "loss": "2.146", "nll_loss": "0.249", "ppl": "1.19", "wps": "4486", "ups": "2.02", "wpb": "2225.3", "bsz": "16", "num_updates": "6300", "lr": "4.97099e-05", "gnorm": "0.532", "train_wall": "49", "wall": "5688"}
2022-10-27 04:02:08 | INFO | train_inner | {"epoch": 2, "update": 1.957, "loss": "2.163", "nll_loss": "0.267", "ppl": "1.2", "wps": "4160.7", "ups": "1.92", "wpb": "2163.2", "bsz": "16", "num_updates": "6400", "lr": "4.97049e-05", "gnorm": "0.618", "train_wall": "51", "wall": "5740"}
2022-10-27 04:03:00 | INFO | train_inner | {"epoch": 2, "update": 1.987, "loss": "2.156", "nll_loss": "0.26", "ppl": "1.2", "wps": "4172.4", "ups": "1.91", "wpb": "2186.4", "bsz": "16", "num_updates": "6500", "lr": "4.96998e-05", "gnorm": "0.529", "train_wall": "52", "wall": "5793"}
2022-10-27 04:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-27 04:45:11 | INFO | valid | {"epoch": 2, "valid_loss": "2.189", "valid_nll_loss": "0.174", "valid_ppl": "1.13", "valid_bleu": "86.65", "valid_wps": "355.1", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "6542", "valid_best_bleu": "86.89"}
2022-10-27 04:45:11 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-27 04:45:20 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_last.pt (epoch 2 @ 6542 updates, score 86.65) (writing took 8.566482138819993 seconds)
2022-10-27 04:45:20 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-10-27 04:45:20 | INFO | train | {"epoch": 2, "train_loss": "2.157", "train_nll_loss": "0.258", "train_ppl": "1.2", "train_wps": "1687.7", "train_ups": "0.78", "train_wpb": "2168.3", "train_bsz": "16", "train_num_updates": "6542", "train_lr": "4.96977e-05", "train_gnorm": "0.567", "train_train_wall": "1665", "train_wall": "8332"}
2022-10-27 04:45:20 | INFO | fairseq.trainer | begin training epoch 3
2022-10-27 04:45:49 | INFO | train_inner | {"epoch": 3, "update": 2.018, "loss": "2.149", "nll_loss": "0.252", "ppl": "1.19", "wps": "83.1", "ups": "0.04", "wpb": "2133.7", "bsz": "15.9", "num_updates": "6600", "lr": "4.96948e-05", "gnorm": "0.614", "train_wall": "49", "wall": "8362"}
2022-10-27 04:46:42 | INFO | train_inner | {"epoch": 3, "update": 2.048, "loss": "2.137", "nll_loss": "0.239", "ppl": "1.18", "wps": "4164.7", "ups": "1.91", "wpb": "2177.9", "bsz": "16", "num_updates": "6700", "lr": "4.96898e-05", "gnorm": "0.557", "train_wall": "52", "wall": "8414"}
2022-10-27 04:47:34 | INFO | train_inner | {"epoch": 3, "update": 2.079, "loss": "2.135", "nll_loss": "0.237", "ppl": "1.18", "wps": "4188.5", "ups": "1.92", "wpb": "2185.7", "bsz": "16", "num_updates": "6800", "lr": "4.96848e-05", "gnorm": "0.546", "train_wall": "52", "wall": "8466"}
2022-10-27 04:48:26 | INFO | train_inner | {"epoch": 3, "update": 2.109, "loss": "2.138", "nll_loss": "0.241", "ppl": "1.18", "wps": "4087.9", "ups": "1.91", "wpb": "2143.2", "bsz": "16", "num_updates": "6900", "lr": "4.96798e-05", "gnorm": "0.547", "train_wall": "52", "wall": "8519"}
2022-10-27 04:49:19 | INFO | train_inner | {"epoch": 3, "update": 2.14, "loss": "2.134", "nll_loss": "0.236", "ppl": "1.18", "wps": "4135.1", "ups": "1.9", "wpb": "2171.6", "bsz": "16", "num_updates": "7000", "lr": "4.96748e-05", "gnorm": "0.544", "train_wall": "52", "wall": "8571"}
2022-10-27 04:50:11 | INFO | train_inner | {"epoch": 3, "update": 2.171, "loss": "2.132", "nll_loss": "0.234", "ppl": "1.18", "wps": "4217.9", "ups": "1.92", "wpb": "2196.2", "bsz": "16", "num_updates": "7100", "lr": "4.96698e-05", "gnorm": "0.482", "train_wall": "52", "wall": "8623"}
2022-10-27 04:51:03 | INFO | train_inner | {"epoch": 3, "update": 2.201, "loss": "2.136", "nll_loss": "0.238", "ppl": "1.18", "wps": "4264.4", "ups": "1.93", "wpb": "2210.4", "bsz": "16", "num_updates": "7200", "lr": "4.96648e-05", "gnorm": "0.545", "train_wall": "51", "wall": "8675"}
2022-10-27 04:51:54 | INFO | train_inner | {"epoch": 3, "update": 2.232, "loss": "2.137", "nll_loss": "0.24", "ppl": "1.18", "wps": "4093.5", "ups": "1.94", "wpb": "2115.4", "bsz": "16", "num_updates": "7300", "lr": "4.96598e-05", "gnorm": "0.501", "train_wall": "51", "wall": "8727"}
2022-10-27 04:52:47 | INFO | train_inner | {"epoch": 3, "update": 2.262, "loss": "2.136", "nll_loss": "0.239", "ppl": "1.18", "wps": "4136.6", "ups": "1.91", "wpb": "2161.8", "bsz": "16", "num_updates": "7400", "lr": "4.96548e-05", "gnorm": "0.513", "train_wall": "52", "wall": "8779"}
2022-10-27 04:53:38 | INFO | train_inner | {"epoch": 3, "update": 2.293, "loss": "2.138", "nll_loss": "0.242", "ppl": "1.18", "wps": "4129.5", "ups": "1.94", "wpb": "2129.8", "bsz": "16", "num_updates": "7500", "lr": "4.96498e-05", "gnorm": "0.557", "train_wall": "51", "wall": "8831"}
2022-10-27 04:54:29 | INFO | train_inner | {"epoch": 3, "update": 2.323, "loss": "2.136", "nll_loss": "0.24", "ppl": "1.18", "wps": "4355.5", "ups": "1.96", "wpb": "2224.8", "bsz": "16", "num_updates": "7600", "lr": "4.96448e-05", "gnorm": "0.511", "train_wall": "51", "wall": "8882"}
2022-10-27 04:55:21 | INFO | train_inner | {"epoch": 3, "update": 2.354, "loss": "2.138", "nll_loss": "0.241", "ppl": "1.18", "wps": "4125.6", "ups": "1.93", "wpb": "2137.7", "bsz": "16", "num_updates": "7700", "lr": "4.96398e-05", "gnorm": "0.532", "train_wall": "51", "wall": "8933"}
2022-10-27 04:56:13 | INFO | train_inner | {"epoch": 3, "update": 2.385, "loss": "2.142", "nll_loss": "0.246", "ppl": "1.19", "wps": "4163.6", "ups": "1.93", "wpb": "2160.7", "bsz": "16", "num_updates": "7800", "lr": "4.96348e-05", "gnorm": "0.565", "train_wall": "51", "wall": "8985"}
2022-10-27 04:57:05 | INFO | train_inner | {"epoch": 3, "update": 2.415, "loss": "2.142", "nll_loss": "0.247", "ppl": "1.19", "wps": "4082.6", "ups": "1.94", "wpb": "2107.1", "bsz": "16", "num_updates": "7900", "lr": "4.96298e-05", "gnorm": "0.573", "train_wall": "51", "wall": "9037"}
2022-10-27 04:57:57 | INFO | train_inner | {"epoch": 3, "update": 2.446, "loss": "2.134", "nll_loss": "0.238", "ppl": "1.18", "wps": "4231.3", "ups": "1.92", "wpb": "2205.1", "bsz": "16", "num_updates": "8000", "lr": "4.96248e-05", "gnorm": "0.495", "train_wall": "52", "wall": "9089"}
2022-10-27 04:58:49 | INFO | train_inner | {"epoch": 3, "update": 2.476, "loss": "2.137", "nll_loss": "0.241", "ppl": "1.18", "wps": "4202.8", "ups": "1.91", "wpb": "2199.4", "bsz": "16", "num_updates": "8100", "lr": "4.96198e-05", "gnorm": "0.525", "train_wall": "52", "wall": "9141"}
2022-10-27 04:59:41 | INFO | train_inner | {"epoch": 3, "update": 2.507, "loss": "2.136", "nll_loss": "0.24", "ppl": "1.18", "wps": "4088.7", "ups": "1.91", "wpb": "2138.1", "bsz": "16", "num_updates": "8200", "lr": "4.96148e-05", "gnorm": "0.537", "train_wall": "52", "wall": "9194"}
2022-10-27 05:00:33 | INFO | train_inner | {"epoch": 3, "update": 2.537, "loss": "2.14", "nll_loss": "0.245", "ppl": "1.18", "wps": "4075.9", "ups": "1.92", "wpb": "2121.8", "bsz": "16", "num_updates": "8300", "lr": "4.96098e-05", "gnorm": "0.523", "train_wall": "52", "wall": "9246"}
2022-10-27 05:01:26 | INFO | train_inner | {"epoch": 3, "update": 2.568, "loss": "2.135", "nll_loss": "0.24", "ppl": "1.18", "wps": "4265.1", "ups": "1.9", "wpb": "2238.9", "bsz": "16", "num_updates": "8400", "lr": "4.96048e-05", "gnorm": "0.558", "train_wall": "52", "wall": "9298"}
2022-10-27 05:02:18 | INFO | train_inner | {"epoch": 3, "update": 2.599, "loss": "2.136", "nll_loss": "0.241", "ppl": "1.18", "wps": "4241", "ups": "1.93", "wpb": "2198.6", "bsz": "16", "num_updates": "8500", "lr": "4.95998e-05", "gnorm": "0.54", "train_wall": "51", "wall": "9350"}
2022-10-27 05:03:10 | INFO | train_inner | {"epoch": 3, "update": 2.629, "loss": "2.137", "nll_loss": "0.241", "ppl": "1.18", "wps": "4212.8", "ups": "1.92", "wpb": "2199.3", "bsz": "16", "num_updates": "8600", "lr": "4.95948e-05", "gnorm": "0.541", "train_wall": "52", "wall": "9402"}
2022-10-27 05:04:02 | INFO | train_inner | {"epoch": 3, "update": 2.66, "loss": "2.137", "nll_loss": "0.241", "ppl": "1.18", "wps": "4120.6", "ups": "1.92", "wpb": "2151.1", "bsz": "16", "num_updates": "8700", "lr": "4.95898e-05", "gnorm": "0.559", "train_wall": "52", "wall": "9454"}
2022-10-27 05:04:54 | INFO | train_inner | {"epoch": 3, "update": 2.69, "loss": "2.142", "nll_loss": "0.248", "ppl": "1.19", "wps": "4144.4", "ups": "1.94", "wpb": "2133.2", "bsz": "16", "num_updates": "8800", "lr": "4.95848e-05", "gnorm": "0.571", "train_wall": "51", "wall": "9506"}
2022-10-27 05:05:43 | INFO | train_inner | {"epoch": 3, "update": 2.721, "loss": "2.137", "nll_loss": "0.242", "ppl": "1.18", "wps": "4449.9", "ups": "2.03", "wpb": "2186.9", "bsz": "16", "num_updates": "8900", "lr": "4.95798e-05", "gnorm": "0.68", "train_wall": "49", "wall": "9555"}
2022-10-27 05:06:32 | INFO | train_inner | {"epoch": 3, "update": 2.751, "loss": "2.136", "nll_loss": "0.241", "ppl": "1.18", "wps": "4325.5", "ups": "2.03", "wpb": "2135.1", "bsz": "16", "num_updates": "9000", "lr": "4.95748e-05", "gnorm": "0.57", "train_wall": "49", "wall": "9604"}
2022-10-27 05:07:24 | INFO | train_inner | {"epoch": 3, "update": 2.782, "loss": "2.138", "nll_loss": "0.243", "ppl": "1.18", "wps": "4114.3", "ups": "1.93", "wpb": "2132", "bsz": "16", "num_updates": "9100", "lr": "4.95698e-05", "gnorm": "0.542", "train_wall": "51", "wall": "9656"}
2022-10-27 05:08:16 | INFO | train_inner | {"epoch": 3, "update": 2.813, "loss": "2.144", "nll_loss": "0.249", "ppl": "1.19", "wps": "4104.3", "ups": "1.93", "wpb": "2124.4", "bsz": "16", "num_updates": "9200", "lr": "4.95648e-05", "gnorm": "0.577", "train_wall": "51", "wall": "9708"}
2022-10-27 05:09:08 | INFO | train_inner | {"epoch": 3, "update": 2.843, "loss": "2.144", "nll_loss": "0.249", "ppl": "1.19", "wps": "4227", "ups": "1.9", "wpb": "2227.9", "bsz": "16", "num_updates": "9300", "lr": "4.95598e-05", "gnorm": "0.541", "train_wall": "52", "wall": "9761"}
2022-10-27 05:10:00 | INFO | train_inner | {"epoch": 3, "update": 2.874, "loss": "2.135", "nll_loss": "0.241", "ppl": "1.18", "wps": "4048.2", "ups": "1.92", "wpb": "2107.9", "bsz": "16", "num_updates": "9400", "lr": "4.95548e-05", "gnorm": "0.578", "train_wall": "52", "wall": "9813"}
2022-10-27 05:10:53 | INFO | train_inner | {"epoch": 3, "update": 2.904, "loss": "2.137", "nll_loss": "0.243", "ppl": "1.18", "wps": "4190.2", "ups": "1.9", "wpb": "2207.2", "bsz": "16", "num_updates": "9500", "lr": "4.95498e-05", "gnorm": "0.515", "train_wall": "52", "wall": "9866"}
2022-10-27 05:11:45 | INFO | train_inner | {"epoch": 3, "update": 2.935, "loss": "2.136", "nll_loss": "0.242", "ppl": "1.18", "wps": "4236.8", "ups": "1.92", "wpb": "2203.9", "bsz": "16", "num_updates": "9600", "lr": "4.95448e-05", "gnorm": "0.547", "train_wall": "51", "wall": "9918"}
2022-10-27 05:12:38 | INFO | train_inner | {"epoch": 3, "update": 2.965, "loss": "2.135", "nll_loss": "0.24", "ppl": "1.18", "wps": "4250.2", "ups": "1.91", "wpb": "2227.2", "bsz": "16", "num_updates": "9700", "lr": "4.95398e-05", "gnorm": "0.605", "train_wall": "52", "wall": "9970"}
2022-10-27 05:13:29 | INFO | train_inner | {"epoch": 3, "update": 2.996, "loss": "2.143", "nll_loss": "0.249", "ppl": "1.19", "wps": "4176.5", "ups": "1.93", "wpb": "2167.5", "bsz": "16", "num_updates": "9800", "lr": "4.95348e-05", "gnorm": "0.594", "train_wall": "51", "wall": "10022"}
2022-10-27 05:13:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-27 05:55:07 | INFO | valid | {"epoch": 3, "valid_loss": "2.185", "valid_nll_loss": "0.177", "valid_ppl": "1.13", "valid_bleu": "86.25", "valid_wps": "357.9", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "9813", "valid_best_bleu": "86.89"}
2022-10-27 05:55:07 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-27 05:55:15 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_last.pt (epoch 3 @ 9813 updates, score 86.25) (writing took 8.286018745042384 seconds)
2022-10-27 05:55:15 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-10-27 05:55:15 | INFO | train | {"epoch": 3, "train_loss": "2.138", "train_nll_loss": "0.242", "train_ppl": "1.18", "train_wps": "1690.7", "train_ups": "0.78", "train_wpb": "2168.3", "train_bsz": "16", "train_num_updates": "9813", "train_lr": "4.95341e-05", "train_gnorm": "0.549", "train_train_wall": "1678", "train_wall": "12527"}
2022-10-27 05:55:15 | INFO | fairseq.trainer | begin training epoch 4
2022-10-27 05:55:54 | INFO | train_inner | {"epoch": 4, "update": 3.027, "loss": "2.124", "nll_loss": "0.228", "ppl": "1.17", "wps": "83.1", "ups": "0.04", "wpb": "2113.4", "bsz": "15.9", "num_updates": "9900", "lr": "4.95298e-05", "gnorm": "0.486", "train_wall": "45", "wall": "12566"}
2022-10-27 05:56:41 | INFO | train_inner | {"epoch": 4, "update": 3.057, "loss": "2.126", "nll_loss": "0.23", "ppl": "1.17", "wps": "4739.8", "ups": "2.14", "wpb": "2214.8", "bsz": "16", "num_updates": "10000", "lr": "4.95248e-05", "gnorm": "0.553", "train_wall": "46", "wall": "12613"}
2022-10-27 05:57:33 | INFO | train_inner | {"epoch": 4, "update": 3.088, "loss": "2.122", "nll_loss": "0.226", "ppl": "1.17", "wps": "4155.1", "ups": "1.92", "wpb": "2166.1", "bsz": "16", "num_updates": "10100", "lr": "4.95198e-05", "gnorm": "0.571", "train_wall": "52", "wall": "12665"}
2022-10-27 05:58:25 | INFO | train_inner | {"epoch": 4, "update": 3.118, "loss": "2.128", "nll_loss": "0.232", "ppl": "1.17", "wps": "4161.6", "ups": "1.91", "wpb": "2174.4", "bsz": "16", "num_updates": "10200", "lr": "4.95148e-05", "gnorm": "0.634", "train_wall": "52", "wall": "12717"}
2022-10-27 05:59:17 | INFO | train_inner | {"epoch": 4, "update": 3.149, "loss": "2.124", "nll_loss": "0.229", "ppl": "1.17", "wps": "4179.3", "ups": "1.91", "wpb": "2185.4", "bsz": "16", "num_updates": "10300", "lr": "4.95098e-05", "gnorm": "0.535", "train_wall": "52", "wall": "12770"}
2022-10-27 06:00:10 | INFO | train_inner | {"epoch": 4, "update": 3.179, "loss": "2.121", "nll_loss": "0.226", "ppl": "1.17", "wps": "4170.1", "ups": "1.91", "wpb": "2182.1", "bsz": "16", "num_updates": "10400", "lr": "4.95048e-05", "gnorm": "0.517", "train_wall": "52", "wall": "12822"}
2022-10-27 06:01:01 | INFO | train_inner | {"epoch": 4, "update": 3.21, "loss": "2.123", "nll_loss": "0.227", "ppl": "1.17", "wps": "4216.2", "ups": "1.94", "wpb": "2173.6", "bsz": "16", "num_updates": "10500", "lr": "4.94997e-05", "gnorm": "0.555", "train_wall": "51", "wall": "12874"}
2022-10-27 06:01:54 | INFO | train_inner | {"epoch": 4, "update": 3.241, "loss": "2.122", "nll_loss": "0.227", "ppl": "1.17", "wps": "4208.4", "ups": "1.91", "wpb": "2202.6", "bsz": "16", "num_updates": "10600", "lr": "4.94947e-05", "gnorm": "0.515", "train_wall": "52", "wall": "12926"}
2022-10-27 06:02:46 | INFO | train_inner | {"epoch": 4, "update": 3.271, "loss": "2.12", "nll_loss": "0.225", "ppl": "1.17", "wps": "4163.2", "ups": "1.91", "wpb": "2179.6", "bsz": "16", "num_updates": "10700", "lr": "4.94897e-05", "gnorm": "0.52", "train_wall": "52", "wall": "12978"}
2022-10-27 06:03:38 | INFO | train_inner | {"epoch": 4, "update": 3.302, "loss": "2.123", "nll_loss": "0.227", "ppl": "1.17", "wps": "4168.3", "ups": "1.91", "wpb": "2184.1", "bsz": "16", "num_updates": "10800", "lr": "4.94847e-05", "gnorm": "0.529", "train_wall": "52", "wall": "13031"}
2022-10-27 06:04:30 | INFO | train_inner | {"epoch": 4, "update": 3.332, "loss": "2.123", "nll_loss": "0.228", "ppl": "1.17", "wps": "4124.9", "ups": "1.92", "wpb": "2148.1", "bsz": "16", "num_updates": "10900", "lr": "4.94797e-05", "gnorm": "0.568", "train_wall": "52", "wall": "13083"}
2022-10-27 06:05:20 | INFO | train_inner | {"epoch": 4, "update": 3.363, "loss": "2.125", "nll_loss": "0.23", "ppl": "1.17", "wps": "4317.2", "ups": "2.01", "wpb": "2148.8", "bsz": "16", "num_updates": "11000", "lr": "4.94747e-05", "gnorm": "0.54", "train_wall": "49", "wall": "13133"}
2022-10-27 06:06:12 | INFO | train_inner | {"epoch": 4, "update": 3.393, "loss": "2.125", "nll_loss": "0.23", "ppl": "1.17", "wps": "4185", "ups": "1.95", "wpb": "2145.9", "bsz": "16", "num_updates": "11100", "lr": "4.94697e-05", "gnorm": "0.565", "train_wall": "51", "wall": "13184"}
2022-10-27 06:07:04 | INFO | train_inner | {"epoch": 4, "update": 3.424, "loss": "2.125", "nll_loss": "0.23", "ppl": "1.17", "wps": "4080.1", "ups": "1.91", "wpb": "2134.3", "bsz": "16", "num_updates": "11200", "lr": "4.94647e-05", "gnorm": "0.58", "train_wall": "52", "wall": "13236"}
2022-10-27 06:07:56 | INFO | train_inner | {"epoch": 4, "update": 3.455, "loss": "2.125", "nll_loss": "0.231", "ppl": "1.17", "wps": "4071.8", "ups": "1.91", "wpb": "2128", "bsz": "16", "num_updates": "11300", "lr": "4.94597e-05", "gnorm": "0.513", "train_wall": "52", "wall": "13288"}
2022-10-27 06:08:48 | INFO | train_inner | {"epoch": 4, "update": 3.485, "loss": "2.13", "nll_loss": "0.235", "ppl": "1.18", "wps": "4183.7", "ups": "1.91", "wpb": "2186.1", "bsz": "16", "num_updates": "11400", "lr": "4.94547e-05", "gnorm": "0.562", "train_wall": "52", "wall": "13341"}
2022-10-27 06:09:40 | INFO | train_inner | {"epoch": 4, "update": 3.516, "loss": "2.124", "nll_loss": "0.229", "ppl": "1.17", "wps": "4204.6", "ups": "1.93", "wpb": "2183.3", "bsz": "16", "num_updates": "11500", "lr": "4.94497e-05", "gnorm": "0.499", "train_wall": "51", "wall": "13393"}
2022-10-27 06:10:32 | INFO | train_inner | {"epoch": 4, "update": 3.546, "loss": "2.122", "nll_loss": "0.227", "ppl": "1.17", "wps": "4202.4", "ups": "1.92", "wpb": "2183.6", "bsz": "16", "num_updates": "11600", "lr": "4.94447e-05", "gnorm": "0.592", "train_wall": "51", "wall": "13445"}
2022-10-27 06:11:24 | INFO | train_inner | {"epoch": 4, "update": 3.577, "loss": "2.122", "nll_loss": "0.227", "ppl": "1.17", "wps": "4150.2", "ups": "1.91", "wpb": "2167.6", "bsz": "16", "num_updates": "11700", "lr": "4.94397e-05", "gnorm": "0.506", "train_wall": "52", "wall": "13497"}
2022-10-27 06:12:16 | INFO | train_inner | {"epoch": 4, "update": 3.607, "loss": "2.121", "nll_loss": "0.226", "ppl": "1.17", "wps": "4202.2", "ups": "1.92", "wpb": "2183.4", "bsz": "16", "num_updates": "11800", "lr": "4.94347e-05", "gnorm": "0.596", "train_wall": "51", "wall": "13549"}
2022-10-27 06:13:06 | INFO | train_inner | {"epoch": 4, "update": 3.638, "loss": "2.128", "nll_loss": "0.234", "ppl": "1.18", "wps": "4368.5", "ups": "2.03", "wpb": "2152.7", "bsz": "16", "num_updates": "11900", "lr": "4.94297e-05", "gnorm": "0.55", "train_wall": "49", "wall": "13598"}
2022-10-27 06:13:58 | INFO | train_inner | {"epoch": 4, "update": 3.669, "loss": "2.123", "nll_loss": "0.228", "ppl": "1.17", "wps": "4282.8", "ups": "1.91", "wpb": "2240", "bsz": "16", "num_updates": "12000", "lr": "4.94247e-05", "gnorm": "0.543", "train_wall": "52", "wall": "13650"}
2022-10-27 06:14:49 | INFO | train_inner | {"epoch": 4, "update": 3.699, "loss": "2.122", "nll_loss": "0.228", "ppl": "1.17", "wps": "4284.4", "ups": "1.96", "wpb": "2184.7", "bsz": "16", "num_updates": "12100", "lr": "4.94197e-05", "gnorm": "0.495", "train_wall": "50", "wall": "13701"}
2022-10-27 06:15:41 | INFO | train_inner | {"epoch": 4, "update": 3.73, "loss": "2.122", "nll_loss": "0.228", "ppl": "1.17", "wps": "4168.6", "ups": "1.91", "wpb": "2184.6", "bsz": "16", "num_updates": "12200", "lr": "4.94147e-05", "gnorm": "0.519", "train_wall": "52", "wall": "13754"}
2022-10-27 06:16:32 | INFO | train_inner | {"epoch": 4, "update": 3.76, "loss": "2.126", "nll_loss": "0.233", "ppl": "1.18", "wps": "4234.5", "ups": "1.97", "wpb": "2152.1", "bsz": "16", "num_updates": "12300", "lr": "4.94097e-05", "gnorm": "0.548", "train_wall": "50", "wall": "13805"}
2022-10-27 06:17:24 | INFO | train_inner | {"epoch": 4, "update": 3.791, "loss": "2.124", "nll_loss": "0.231", "ppl": "1.17", "wps": "4130.9", "ups": "1.91", "wpb": "2159.1", "bsz": "16", "num_updates": "12400", "lr": "4.94047e-05", "gnorm": "0.538", "train_wall": "52", "wall": "13857"}
2022-10-27 06:18:17 | INFO | train_inner | {"epoch": 4, "update": 3.821, "loss": "2.124", "nll_loss": "0.23", "ppl": "1.17", "wps": "4103.4", "ups": "1.92", "wpb": "2139.6", "bsz": "16", "num_updates": "12500", "lr": "4.93997e-05", "gnorm": "0.57", "train_wall": "52", "wall": "13909"}
2022-10-27 06:19:09 | INFO | train_inner | {"epoch": 4, "update": 3.852, "loss": "2.125", "nll_loss": "0.231", "ppl": "1.17", "wps": "4075.8", "ups": "1.93", "wpb": "2115.4", "bsz": "16", "num_updates": "12600", "lr": "4.93947e-05", "gnorm": "0.545", "train_wall": "51", "wall": "13961"}
2022-10-27 06:20:01 | INFO | train_inner | {"epoch": 4, "update": 3.883, "loss": "2.124", "nll_loss": "0.23", "ppl": "1.17", "wps": "4157", "ups": "1.91", "wpb": "2174.2", "bsz": "16", "num_updates": "12700", "lr": "4.93897e-05", "gnorm": "0.502", "train_wall": "52", "wall": "14013"}
2022-10-27 06:20:53 | INFO | train_inner | {"epoch": 4, "update": 3.913, "loss": "2.123", "nll_loss": "0.229", "ppl": "1.17", "wps": "4362.5", "ups": "1.9", "wpb": "2294.1", "bsz": "16", "num_updates": "12800", "lr": "4.93847e-05", "gnorm": "0.612", "train_wall": "52", "wall": "14066"}
2022-10-27 06:21:45 | INFO | train_inner | {"epoch": 4, "update": 3.944, "loss": "2.131", "nll_loss": "0.238", "ppl": "1.18", "wps": "4057.7", "ups": "1.93", "wpb": "2098.7", "bsz": "16", "num_updates": "12900", "lr": "4.93797e-05", "gnorm": "0.549", "train_wall": "51", "wall": "14118"}
2022-10-27 06:22:37 | INFO | train_inner | {"epoch": 4, "update": 3.974, "loss": "2.127", "nll_loss": "0.233", "ppl": "1.18", "wps": "4041.6", "ups": "1.92", "wpb": "2101.7", "bsz": "16", "num_updates": "13000", "lr": "4.93747e-05", "gnorm": "0.554", "train_wall": "51", "wall": "14170"}
2022-10-27 06:23:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-27 07:04:29 | INFO | valid | {"epoch": 4, "valid_loss": "2.185", "valid_nll_loss": "0.185", "valid_ppl": "1.14", "valid_bleu": "85.76", "valid_wps": "361.2", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "13084", "valid_best_bleu": "86.89"}
2022-10-27 07:04:29 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-27 07:04:37 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_last.pt (epoch 4 @ 13084 updates, score 85.76) (writing took 8.402752982918173 seconds)
2022-10-27 07:04:37 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-10-27 07:04:37 | INFO | train | {"epoch": 4, "train_loss": "2.124", "train_nll_loss": "0.229", "train_ppl": "1.17", "train_wps": "1703.9", "train_ups": "0.79", "train_wpb": "2168.3", "train_bsz": "16", "train_num_updates": "13084", "train_lr": "4.93705e-05", "train_gnorm": "0.545", "train_train_wall": "1668", "train_wall": "16690"}
2022-10-27 07:04:37 | INFO | fairseq.trainer | begin training epoch 5
2022-10-27 07:04:45 | INFO | train_inner | {"epoch": 5, "update": 4.005, "loss": "2.121", "nll_loss": "0.227", "ppl": "1.17", "wps": "85.5", "ups": "0.04", "wpb": "2160.4", "bsz": "15.9", "num_updates": "13100", "lr": "4.93697e-05", "gnorm": "0.513", "train_wall": "51", "wall": "16698"}
2022-10-27 07:05:37 | INFO | train_inner | {"epoch": 5, "update": 4.035, "loss": "2.114", "nll_loss": "0.218", "ppl": "1.16", "wps": "4217.2", "ups": "1.92", "wpb": "2196.2", "bsz": "16", "num_updates": "13200", "lr": "4.93647e-05", "gnorm": "0.529", "train_wall": "51", "wall": "16750"}
2022-10-27 07:06:30 | INFO | train_inner | {"epoch": 5, "update": 4.066, "loss": "2.112", "nll_loss": "0.217", "ppl": "1.16", "wps": "4160.7", "ups": "1.9", "wpb": "2187.9", "bsz": "16", "num_updates": "13300", "lr": "4.93597e-05", "gnorm": "0.531", "train_wall": "52", "wall": "16802"}
2022-10-27 07:07:22 | INFO | train_inner | {"epoch": 5, "update": 4.097, "loss": "2.11", "nll_loss": "0.215", "ppl": "1.16", "wps": "4101.4", "ups": "1.93", "wpb": "2129.9", "bsz": "16", "num_updates": "13400", "lr": "4.93547e-05", "gnorm": "0.483", "train_wall": "51", "wall": "16854"}
2022-10-27 07:08:00 | INFO | train_inner | {"epoch": 5, "update": 4.127, "loss": "2.11", "nll_loss": "0.215", "ppl": "1.16", "wps": "5493", "ups": "2.6", "wpb": "2109.3", "bsz": "16", "num_updates": "13500", "lr": "4.93497e-05", "gnorm": "0.522", "train_wall": "38", "wall": "16893"}
2022-10-27 07:08:37 | INFO | train_inner | {"epoch": 5, "update": 4.158, "loss": "2.113", "nll_loss": "0.218", "ppl": "1.16", "wps": "5810.5", "ups": "2.7", "wpb": "2148.6", "bsz": "16", "num_updates": "13600", "lr": "4.93447e-05", "gnorm": "0.555", "train_wall": "37", "wall": "16930"}
2022-10-27 07:09:15 | INFO | train_inner | {"epoch": 5, "update": 4.188, "loss": "2.11", "nll_loss": "0.216", "ppl": "1.16", "wps": "5825.5", "ups": "2.67", "wpb": "2183.1", "bsz": "16", "num_updates": "13700", "lr": "4.93397e-05", "gnorm": "0.541", "train_wall": "37", "wall": "16967"}
2022-10-27 07:10:03 | INFO | train_inner | {"epoch": 5, "update": 4.219, "loss": "2.109", "nll_loss": "0.214", "ppl": "1.16", "wps": "4606.5", "ups": "2.07", "wpb": "2221.6", "bsz": "16", "num_updates": "13800", "lr": "4.93347e-05", "gnorm": "0.463", "train_wall": "48", "wall": "17015"}
2022-10-27 07:10:52 | INFO | train_inner | {"epoch": 5, "update": 4.249, "loss": "2.111", "nll_loss": "0.217", "ppl": "1.16", "wps": "4514.3", "ups": "2.02", "wpb": "2230.7", "bsz": "16", "num_updates": "13900", "lr": "4.93297e-05", "gnorm": "0.586", "train_wall": "49", "wall": "17065"}
2022-10-27 07:11:44 | INFO | train_inner | {"epoch": 5, "update": 4.28, "loss": "2.111", "nll_loss": "0.216", "ppl": "1.16", "wps": "4152.7", "ups": "1.95", "wpb": "2128.4", "bsz": "16", "num_updates": "14000", "lr": "4.93247e-05", "gnorm": "0.534", "train_wall": "51", "wall": "17116"}
2022-10-27 07:12:36 | INFO | train_inner | {"epoch": 5, "update": 4.311, "loss": "2.115", "nll_loss": "0.22", "ppl": "1.17", "wps": "4162.1", "ups": "1.92", "wpb": "2171", "bsz": "16", "num_updates": "14100", "lr": "4.93197e-05", "gnorm": "0.557", "train_wall": "52", "wall": "17168"}
2022-10-27 07:13:22 | INFO | train_inner | {"epoch": 5, "update": 4.341, "loss": "2.112", "nll_loss": "0.218", "ppl": "1.16", "wps": "4487", "ups": "2.14", "wpb": "2096.4", "bsz": "16", "num_updates": "14200", "lr": "4.93147e-05", "gnorm": "0.597", "train_wall": "46", "wall": "17215"}
2022-10-27 07:14:15 | INFO | train_inner | {"epoch": 5, "update": 4.372, "loss": "2.112", "nll_loss": "0.217", "ppl": "1.16", "wps": "4245.3", "ups": "1.9", "wpb": "2230.6", "bsz": "16", "num_updates": "14300", "lr": "4.93097e-05", "gnorm": "0.558", "train_wall": "52", "wall": "17267"}
2022-10-27 07:15:07 | INFO | train_inner | {"epoch": 5, "update": 4.402, "loss": "2.115", "nll_loss": "0.221", "ppl": "1.17", "wps": "4071.1", "ups": "1.92", "wpb": "2120", "bsz": "16", "num_updates": "14400", "lr": "4.93047e-05", "gnorm": "0.527", "train_wall": "52", "wall": "17319"}
2022-10-27 07:15:59 | INFO | train_inner | {"epoch": 5, "update": 4.433, "loss": "2.114", "nll_loss": "0.219", "ppl": "1.16", "wps": "4129.4", "ups": "1.92", "wpb": "2148.1", "bsz": "16", "num_updates": "14500", "lr": "4.92996e-05", "gnorm": "0.506", "train_wall": "51", "wall": "17371"}
2022-10-27 07:16:52 | INFO | train_inner | {"epoch": 5, "update": 4.463, "loss": "2.111", "nll_loss": "0.217", "ppl": "1.16", "wps": "4111", "ups": "1.9", "wpb": "2163.4", "bsz": "16", "num_updates": "14600", "lr": "4.92946e-05", "gnorm": "0.48", "train_wall": "52", "wall": "17424"}
2022-10-27 07:17:44 | INFO | train_inner | {"epoch": 5, "update": 4.494, "loss": "2.116", "nll_loss": "0.222", "ppl": "1.17", "wps": "4111.9", "ups": "1.91", "wpb": "2155.7", "bsz": "16", "num_updates": "14700", "lr": "4.92896e-05", "gnorm": "0.571", "train_wall": "52", "wall": "17476"}
2022-10-27 07:18:37 | INFO | train_inner | {"epoch": 5, "update": 4.525, "loss": "2.119", "nll_loss": "0.225", "ppl": "1.17", "wps": "4244.9", "ups": "1.91", "wpb": "2224.8", "bsz": "16", "num_updates": "14800", "lr": "4.92846e-05", "gnorm": "0.542", "train_wall": "52", "wall": "17529"}
2022-10-27 07:19:29 | INFO | train_inner | {"epoch": 5, "update": 4.555, "loss": "2.114", "nll_loss": "0.221", "ppl": "1.17", "wps": "4076.6", "ups": "1.91", "wpb": "2132.8", "bsz": "16", "num_updates": "14900", "lr": "4.92796e-05", "gnorm": "0.539", "train_wall": "52", "wall": "17581"}
2022-10-27 07:20:21 | INFO | train_inner | {"epoch": 5, "update": 4.586, "loss": "2.113", "nll_loss": "0.219", "ppl": "1.16", "wps": "4196.6", "ups": "1.92", "wpb": "2183.2", "bsz": "16", "num_updates": "15000", "lr": "4.92746e-05", "gnorm": "0.508", "train_wall": "51", "wall": "17633"}
2022-10-27 07:21:12 | INFO | train_inner | {"epoch": 5, "update": 4.616, "loss": "2.117", "nll_loss": "0.223", "ppl": "1.17", "wps": "4149.7", "ups": "1.96", "wpb": "2118.8", "bsz": "16", "num_updates": "15100", "lr": "4.92696e-05", "gnorm": "0.631", "train_wall": "51", "wall": "17684"}
2022-10-27 07:22:03 | INFO | train_inner | {"epoch": 5, "update": 4.647, "loss": "2.114", "nll_loss": "0.221", "ppl": "1.17", "wps": "4268.1", "ups": "1.95", "wpb": "2185.5", "bsz": "16", "num_updates": "15200", "lr": "4.92646e-05", "gnorm": "0.541", "train_wall": "51", "wall": "17735"}
2022-10-27 07:22:55 | INFO | train_inner | {"epoch": 5, "update": 4.677, "loss": "2.12", "nll_loss": "0.227", "ppl": "1.17", "wps": "4189.9", "ups": "1.93", "wpb": "2173.4", "bsz": "16", "num_updates": "15300", "lr": "4.92596e-05", "gnorm": "0.563", "train_wall": "51", "wall": "17787"}
2022-10-27 07:23:47 | INFO | train_inner | {"epoch": 5, "update": 4.708, "loss": "2.121", "nll_loss": "0.228", "ppl": "1.17", "wps": "4152.7", "ups": "1.91", "wpb": "2170.6", "bsz": "16", "num_updates": "15400", "lr": "4.92546e-05", "gnorm": "0.528", "train_wall": "52", "wall": "17840"}
2022-10-27 07:24:37 | INFO | train_inner | {"epoch": 5, "update": 4.739, "loss": "2.117", "nll_loss": "0.223", "ppl": "1.17", "wps": "4339.1", "ups": "2.02", "wpb": "2149.4", "bsz": "16", "num_updates": "15500", "lr": "4.92496e-05", "gnorm": "0.558", "train_wall": "49", "wall": "17889"}
2022-10-27 07:25:19 | INFO | train_inner | {"epoch": 5, "update": 4.769, "loss": "2.111", "nll_loss": "0.217", "ppl": "1.16", "wps": "5017.2", "ups": "2.39", "wpb": "2101.4", "bsz": "16", "num_updates": "15600", "lr": "4.92446e-05", "gnorm": "0.516", "train_wall": "41", "wall": "17931"}
2022-10-27 07:26:09 | INFO | train_inner | {"epoch": 5, "update": 4.8, "loss": "2.12", "nll_loss": "0.227", "ppl": "1.17", "wps": "4315.9", "ups": "1.98", "wpb": "2183.4", "bsz": "16", "num_updates": "15700", "lr": "4.92396e-05", "gnorm": "0.577", "train_wall": "50", "wall": "17982"}
2022-10-27 07:27:01 | INFO | train_inner | {"epoch": 5, "update": 4.83, "loss": "2.116", "nll_loss": "0.223", "ppl": "1.17", "wps": "4081.6", "ups": "1.92", "wpb": "2123.6", "bsz": "16", "num_updates": "15800", "lr": "4.92346e-05", "gnorm": "0.545", "train_wall": "51", "wall": "18034"}
2022-10-27 07:27:54 | INFO | train_inner | {"epoch": 5, "update": 4.861, "loss": "2.123", "nll_loss": "0.229", "ppl": "1.17", "wps": "4209.9", "ups": "1.9", "wpb": "2216", "bsz": "16", "num_updates": "15900", "lr": "4.92296e-05", "gnorm": "0.601", "train_wall": "52", "wall": "18086"}
2022-10-27 07:28:46 | INFO | train_inner | {"epoch": 5, "update": 4.891, "loss": "2.114", "nll_loss": "0.22", "ppl": "1.17", "wps": "4192", "ups": "1.91", "wpb": "2189.7", "bsz": "16", "num_updates": "16000", "lr": "4.92246e-05", "gnorm": "0.553", "train_wall": "52", "wall": "18139"}
2022-10-27 07:29:39 | INFO | train_inner | {"epoch": 5, "update": 4.922, "loss": "2.112", "nll_loss": "0.219", "ppl": "1.16", "wps": "4206.4", "ups": "1.9", "wpb": "2218.7", "bsz": "16", "num_updates": "16100", "lr": "4.92196e-05", "gnorm": "0.557", "train_wall": "52", "wall": "18191"}
2022-10-27 07:30:31 | INFO | train_inner | {"epoch": 5, "update": 4.953, "loss": "2.114", "nll_loss": "0.22", "ppl": "1.17", "wps": "4298.9", "ups": "1.92", "wpb": "2241.8", "bsz": "16", "num_updates": "16200", "lr": "4.92146e-05", "gnorm": "0.559", "train_wall": "52", "wall": "18243"}
2022-10-27 07:31:23 | INFO | train_inner | {"epoch": 5, "update": 4.983, "loss": "2.111", "nll_loss": "0.217", "ppl": "1.16", "wps": "4202.1", "ups": "1.93", "wpb": "2176.9", "bsz": "16", "num_updates": "16300", "lr": "4.92096e-05", "gnorm": "0.525", "train_wall": "51", "wall": "18295"}
2022-10-27 07:31:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-27 08:13:46 | INFO | valid | {"epoch": 5, "valid_loss": "2.183", "valid_nll_loss": "0.188", "valid_ppl": "1.14", "valid_bleu": "84.68", "valid_wps": "354.5", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "16355", "valid_best_bleu": "86.89"}
2022-10-27 08:13:46 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-27 08:13:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_last.pt (epoch 5 @ 16355 updates, score 84.68) (writing took 8.351478065131232 seconds)
2022-10-27 08:13:54 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-10-27 08:13:54 | INFO | train | {"epoch": 5, "train_loss": "2.114", "train_nll_loss": "0.22", "train_ppl": "1.16", "train_wps": "1706.2", "train_ups": "0.79", "train_wpb": "2168.3", "train_bsz": "16", "train_num_updates": "16355", "train_lr": "4.92069e-05", "train_gnorm": "0.543", "train_train_wall": "1616", "train_wall": "20847"}
2022-10-27 08:13:54 | INFO | fairseq.trainer | begin training epoch 6
2022-10-27 08:14:18 | INFO | train_inner | {"epoch": 6, "update": 5.014, "loss": "2.111", "nll_loss": "0.217", "ppl": "1.16", "wps": "84", "ups": "0.04", "wpb": "2162.7", "bsz": "15.9", "num_updates": "16400", "lr": "4.92046e-05", "gnorm": "0.549", "train_wall": "51", "wall": "20870"}
2022-10-27 08:15:10 | INFO | train_inner | {"epoch": 6, "update": 5.044, "loss": "2.102", "nll_loss": "0.208", "ppl": "1.15", "wps": "4158.4", "ups": "1.94", "wpb": "2148", "bsz": "16", "num_updates": "16500", "lr": "4.91996e-05", "gnorm": "0.538", "train_wall": "51", "wall": "20922"}
2022-10-27 08:16:02 | INFO | train_inner | {"epoch": 6, "update": 5.075, "loss": "2.102", "nll_loss": "0.207", "ppl": "1.15", "wps": "4230.8", "ups": "1.93", "wpb": "2197.2", "bsz": "16", "num_updates": "16600", "lr": "4.91946e-05", "gnorm": "0.495", "train_wall": "51", "wall": "20974"}
2022-10-27 08:16:53 | INFO | train_inner | {"epoch": 6, "update": 5.105, "loss": "2.105", "nll_loss": "0.21", "ppl": "1.16", "wps": "4214.3", "ups": "1.94", "wpb": "2167.4", "bsz": "16", "num_updates": "16700", "lr": "4.91896e-05", "gnorm": "0.537", "train_wall": "51", "wall": "21025"}
2022-10-27 08:17:45 | INFO | train_inner | {"epoch": 6, "update": 5.136, "loss": "2.102", "nll_loss": "0.208", "ppl": "1.15", "wps": "4206.4", "ups": "1.92", "wpb": "2189", "bsz": "16", "num_updates": "16800", "lr": "4.91846e-05", "gnorm": "0.484", "train_wall": "51", "wall": "21077"}
2022-10-27 08:18:37 | INFO | train_inner | {"epoch": 6, "update": 5.167, "loss": "2.105", "nll_loss": "0.21", "ppl": "1.16", "wps": "3997.4", "ups": "1.92", "wpb": "2080.3", "bsz": "16", "num_updates": "16900", "lr": "4.91796e-05", "gnorm": "0.576", "train_wall": "51", "wall": "21129"}
2022-10-27 08:19:29 | INFO | train_inner | {"epoch": 6, "update": 5.197, "loss": "2.104", "nll_loss": "0.21", "ppl": "1.16", "wps": "4152", "ups": "1.92", "wpb": "2166.7", "bsz": "16", "num_updates": "17000", "lr": "4.91746e-05", "gnorm": "0.528", "train_wall": "52", "wall": "21182"}
2022-10-27 08:20:21 | INFO | train_inner | {"epoch": 6, "update": 5.228, "loss": "2.105", "nll_loss": "0.21", "ppl": "1.16", "wps": "4203.3", "ups": "1.93", "wpb": "2178.9", "bsz": "16", "num_updates": "17100", "lr": "4.91696e-05", "gnorm": "0.587", "train_wall": "51", "wall": "21233"}
2022-10-27 08:21:13 | INFO | train_inner | {"epoch": 6, "update": 5.258, "loss": "2.105", "nll_loss": "0.21", "ppl": "1.16", "wps": "4302.6", "ups": "1.92", "wpb": "2241.4", "bsz": "16", "num_updates": "17200", "lr": "4.91646e-05", "gnorm": "0.625", "train_wall": "52", "wall": "21286"}
2022-10-27 08:22:05 | INFO | train_inner | {"epoch": 6, "update": 5.289, "loss": "2.104", "nll_loss": "0.21", "ppl": "1.16", "wps": "4099.6", "ups": "1.91", "wpb": "2143.6", "bsz": "16", "num_updates": "17300", "lr": "4.91596e-05", "gnorm": "0.589", "train_wall": "52", "wall": "21338"}
2022-10-27 08:22:58 | INFO | train_inner | {"epoch": 6, "update": 5.319, "loss": "2.105", "nll_loss": "0.211", "ppl": "1.16", "wps": "4130.8", "ups": "1.91", "wpb": "2160.3", "bsz": "16", "num_updates": "17400", "lr": "4.91546e-05", "gnorm": "0.549", "train_wall": "52", "wall": "21390"}
2022-10-27 08:23:50 | INFO | train_inner | {"epoch": 6, "update": 5.35, "loss": "2.106", "nll_loss": "0.212", "ppl": "1.16", "wps": "4101.9", "ups": "1.92", "wpb": "2131.3", "bsz": "16", "num_updates": "17500", "lr": "4.91496e-05", "gnorm": "0.591", "train_wall": "51", "wall": "21442"}
2022-10-27 08:24:42 | INFO | train_inner | {"epoch": 6, "update": 5.381, "loss": "2.107", "nll_loss": "0.213", "ppl": "1.16", "wps": "4116.7", "ups": "1.9", "wpb": "2172.2", "bsz": "16", "num_updates": "17600", "lr": "4.91446e-05", "gnorm": "0.573", "train_wall": "52", "wall": "21495"}
2022-10-27 08:25:35 | INFO | train_inner | {"epoch": 6, "update": 5.411, "loss": "2.109", "nll_loss": "0.215", "ppl": "1.16", "wps": "4203.6", "ups": "1.89", "wpb": "2223.1", "bsz": "16", "num_updates": "17700", "lr": "4.91396e-05", "gnorm": "0.584", "train_wall": "52", "wall": "21548"}
2022-10-27 08:26:27 | INFO | train_inner | {"epoch": 6, "update": 5.442, "loss": "2.106", "nll_loss": "0.212", "ppl": "1.16", "wps": "4154.7", "ups": "1.93", "wpb": "2153.1", "bsz": "16", "num_updates": "17800", "lr": "4.91346e-05", "gnorm": "0.521", "train_wall": "51", "wall": "21600"}
2022-10-27 08:27:19 | INFO | train_inner | {"epoch": 6, "update": 5.472, "loss": "2.105", "nll_loss": "0.212", "ppl": "1.16", "wps": "4148.9", "ups": "1.92", "wpb": "2161.5", "bsz": "16", "num_updates": "17900", "lr": "4.91296e-05", "gnorm": "0.534", "train_wall": "52", "wall": "21652"}
2022-10-27 08:28:12 | INFO | train_inner | {"epoch": 6, "update": 5.503, "loss": "2.106", "nll_loss": "0.212", "ppl": "1.16", "wps": "4266", "ups": "1.91", "wpb": "2228", "bsz": "16", "num_updates": "18000", "lr": "4.91246e-05", "gnorm": "0.539", "train_wall": "52", "wall": "21704"}
2022-10-27 08:29:02 | INFO | train_inner | {"epoch": 6, "update": 5.533, "loss": "2.104", "nll_loss": "0.21", "ppl": "1.16", "wps": "4446.6", "ups": "1.97", "wpb": "2254.7", "bsz": "16", "num_updates": "18100", "lr": "4.91196e-05", "gnorm": "0.549", "train_wall": "50", "wall": "21755"}
2022-10-27 08:29:54 | INFO | train_inner | {"epoch": 6, "update": 5.564, "loss": "2.106", "nll_loss": "0.212", "ppl": "1.16", "wps": "4228.5", "ups": "1.93", "wpb": "2188.3", "bsz": "16", "num_updates": "18200", "lr": "4.91146e-05", "gnorm": "0.513", "train_wall": "51", "wall": "21806"}
2022-10-27 08:30:46 | INFO | train_inner | {"epoch": 6, "update": 5.595, "loss": "2.107", "nll_loss": "0.214", "ppl": "1.16", "wps": "4089.1", "ups": "1.92", "wpb": "2124.6", "bsz": "16", "num_updates": "18300", "lr": "4.91096e-05", "gnorm": "0.546", "train_wall": "51", "wall": "21858"}
2022-10-27 08:31:38 | INFO | train_inner | {"epoch": 6, "update": 5.625, "loss": "2.11", "nll_loss": "0.218", "ppl": "1.16", "wps": "4130.4", "ups": "1.93", "wpb": "2140.5", "bsz": "16", "num_updates": "18400", "lr": "4.91046e-05", "gnorm": "0.591", "train_wall": "51", "wall": "21910"}
2022-10-27 08:32:29 | INFO | train_inner | {"epoch": 6, "update": 5.656, "loss": "2.106", "nll_loss": "0.213", "ppl": "1.16", "wps": "4181.4", "ups": "1.94", "wpb": "2155.9", "bsz": "16", "num_updates": "18500", "lr": "4.90995e-05", "gnorm": "0.536", "train_wall": "51", "wall": "21962"}
2022-10-27 08:33:22 | INFO | train_inner | {"epoch": 6, "update": 5.686, "loss": "2.104", "nll_loss": "0.211", "ppl": "1.16", "wps": "4229.3", "ups": "1.91", "wpb": "2216.2", "bsz": "16", "num_updates": "18600", "lr": "4.90945e-05", "gnorm": "0.528", "train_wall": "52", "wall": "22014"}
2022-10-27 08:34:14 | INFO | train_inner | {"epoch": 6, "update": 5.717, "loss": "2.109", "nll_loss": "0.216", "ppl": "1.16", "wps": "4148", "ups": "1.93", "wpb": "2152.1", "bsz": "16", "num_updates": "18700", "lr": "4.90895e-05", "gnorm": "0.603", "train_wall": "51", "wall": "22066"}
2022-10-27 08:35:05 | INFO | train_inner | {"epoch": 6, "update": 5.747, "loss": "2.107", "nll_loss": "0.214", "ppl": "1.16", "wps": "4276.9", "ups": "1.94", "wpb": "2201.2", "bsz": "16", "num_updates": "18800", "lr": "4.90845e-05", "gnorm": "0.574", "train_wall": "51", "wall": "22117"}
2022-10-27 08:35:57 | INFO | train_inner | {"epoch": 6, "update": 5.778, "loss": "2.111", "nll_loss": "0.218", "ppl": "1.16", "wps": "4197.5", "ups": "1.93", "wpb": "2180.1", "bsz": "16", "num_updates": "18900", "lr": "4.90795e-05", "gnorm": "0.593", "train_wall": "51", "wall": "22169"}
2022-10-27 08:36:49 | INFO | train_inner | {"epoch": 6, "update": 5.809, "loss": "2.107", "nll_loss": "0.214", "ppl": "1.16", "wps": "4151.9", "ups": "1.93", "wpb": "2150.8", "bsz": "16", "num_updates": "19000", "lr": "4.90745e-05", "gnorm": "0.51", "train_wall": "51", "wall": "22221"}
2022-10-27 08:37:41 | INFO | train_inner | {"epoch": 6, "update": 5.839, "loss": "2.109", "nll_loss": "0.216", "ppl": "1.16", "wps": "4182", "ups": "1.92", "wpb": "2176.4", "bsz": "16", "num_updates": "19100", "lr": "4.90695e-05", "gnorm": "0.582", "train_wall": "52", "wall": "22273"}
2022-10-27 08:38:31 | INFO | train_inner | {"epoch": 6, "update": 5.87, "loss": "2.11", "nll_loss": "0.218", "ppl": "1.16", "wps": "4251.8", "ups": "2", "wpb": "2128.4", "bsz": "16", "num_updates": "19200", "lr": "4.90645e-05", "gnorm": "0.543", "train_wall": "50", "wall": "22323"}
2022-10-27 08:39:14 | INFO | train_inner | {"epoch": 6, "update": 5.9, "loss": "2.11", "nll_loss": "0.217", "ppl": "1.16", "wps": "5079.8", "ups": "2.32", "wpb": "2186.9", "bsz": "16", "num_updates": "19300", "lr": "4.90595e-05", "gnorm": "0.627", "train_wall": "43", "wall": "22366"}
2022-10-27 08:40:06 | INFO | train_inner | {"epoch": 6, "update": 5.931, "loss": "2.111", "nll_loss": "0.218", "ppl": "1.16", "wps": "4129.3", "ups": "1.93", "wpb": "2140.8", "bsz": "16", "num_updates": "19400", "lr": "4.90545e-05", "gnorm": "0.624", "train_wall": "51", "wall": "22418"}
2022-10-27 08:40:57 | INFO | train_inner | {"epoch": 6, "update": 5.961, "loss": "2.108", "nll_loss": "0.215", "ppl": "1.16", "wps": "4098.4", "ups": "1.94", "wpb": "2110.9", "bsz": "16", "num_updates": "19500", "lr": "4.90495e-05", "gnorm": "0.581", "train_wall": "51", "wall": "22470"}
2022-10-27 08:41:49 | INFO | train_inner | {"epoch": 6, "update": 5.992, "loss": "2.109", "nll_loss": "0.216", "ppl": "1.16", "wps": "4106.5", "ups": "1.93", "wpb": "2132.5", "bsz": "16", "num_updates": "19600", "lr": "4.90445e-05", "gnorm": "0.558", "train_wall": "51", "wall": "22522"}
2022-10-27 08:42:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-10-27 09:23:58 | INFO | valid | {"epoch": 6, "valid_loss": "2.184", "valid_nll_loss": "0.194", "valid_ppl": "1.14", "valid_bleu": "86.15", "valid_wps": "354.3", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "19626", "valid_best_bleu": "86.89"}
2022-10-27 09:23:58 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 5 runs
2022-10-27 09:23:58 | INFO | fairseq_cli.train | begin save checkpoint
2022-10-27 09:24:06 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/PLBART/medium.parent_code.child_full_code/checkpoint_last.pt (epoch 6 @ 19626 updates, score 86.15) (writing took 8.365421805065125 seconds)
2022-10-27 09:24:06 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-10-27 09:24:06 | INFO | train | {"epoch": 6, "train_loss": "2.106", "train_nll_loss": "0.213", "train_ppl": "1.16", "train_wps": "1683.8", "train_ups": "0.78", "train_wpb": "2168.3", "train_bsz": "16", "train_num_updates": "19626", "train_lr": "4.90432e-05", "train_gnorm": "0.56", "train_train_wall": "1670", "train_wall": "25059"}
2022-10-27 09:24:06 | INFO | fairseq_cli.train | done training in 25057.2 seconds
BLEU: 89.14 ; Acc: 6.13
#############################################################################################
######## end ################
