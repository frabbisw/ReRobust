######## start ##############
#############################################################################################
Experiment for Transformer-S2S
=============================================================================================
Small Dataset:
---------------------------------------------------------------------------------------------
Source: source Target: target
2022-11-10 23:22:29 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, batch_size=4, batch_size_valid=4, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, extra_lang_symbol='', fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1234, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_in_same_language', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='/home/y_shi202/related-project/MODIT/src', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=500, weight_decay=0.0, zero_sharding='none')
2022-11-10 23:22:29 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2022-11-10 23:22:29 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2022-11-10 23:22:29 | INFO | fairseq.data.data_utils | loaded 5828 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/valid.source-target.source
2022-11-10 23:22:29 | INFO | fairseq.data.data_utils | loaded 5828 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/valid.source-target.target
2022-11-10 23:22:29 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin valid source-target 5828 examples
2022-11-10 23:22:39 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1024, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2022-11-10 23:22:39 | INFO | fairseq_cli.train | task: translation_in_same_language (TranslationCodeBARTTask)
2022-11-10 23:22:39 | INFO | fairseq_cli.train | model: mbart_large (BARTModel)
2022-11-10 23:22:39 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2022-11-10 23:22:39 | INFO | fairseq_cli.train | num. model params: 406025216 (num. trained: 406025216)
2022-11-10 23:22:44 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-11-10 23:22:44 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-11-10 23:22:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-11-10 23:22:44 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-PCIE-32GB                    
2022-11-10 23:22:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-11-10 23:22:44 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-11-10 23:22:44 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 4
2022-11-10 23:22:44 | INFO | fairseq.trainer | no existing checkpoint found /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt
2022-11-10 23:22:44 | INFO | fairseq.trainer | loading train data for epoch 1
2022-11-10 23:22:44 | INFO | fairseq.data.data_utils | loaded 46628 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/train.source-target.source
2022-11-10 23:22:44 | INFO | fairseq.data.data_utils | loaded 46628 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin/train.source-target.target
2022-11-10 23:22:44 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/small.parent_code.child_full_code/data-bin train source-target 46628 examples
2022-11-10 23:22:44 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2022-11-10 23:22:44 | INFO | fairseq.trainer | begin training epoch 1
2022-11-10 23:24:06 | INFO | train_inner | {"epoch": 1, "update": 0.069, "loss": "12.702", "nll_loss": "12.33", "ppl": "5147.21", "wps": "2235.5", "ups": "1.24", "wpb": "1802", "bsz": "32", "num_updates": "100", "lr": "1e-05", "gnorm": "5.574", "train_wall": "81", "wall": "82"}
2022-11-10 23:25:28 | INFO | train_inner | {"epoch": 1, "update": 0.137, "loss": "9.633", "nll_loss": "8.86", "ppl": "464.8", "wps": "2153", "ups": "1.21", "wpb": "1775.1", "bsz": "32", "num_updates": "200", "lr": "2e-05", "gnorm": "3.008", "train_wall": "82", "wall": "164"}
2022-11-10 23:26:49 | INFO | train_inner | {"epoch": 1, "update": 0.206, "loss": "8.421", "nll_loss": "7.452", "ppl": "175.04", "wps": "2228.2", "ups": "1.23", "wpb": "1810.3", "bsz": "32", "num_updates": "300", "lr": "3e-05", "gnorm": "2.341", "train_wall": "81", "wall": "245"}
2022-11-10 23:28:09 | INFO | train_inner | {"epoch": 1, "update": 0.274, "loss": "7.623", "nll_loss": "6.496", "ppl": "90.27", "wps": "2220.1", "ups": "1.26", "wpb": "1766.1", "bsz": "32", "num_updates": "400", "lr": "4e-05", "gnorm": "2.208", "train_wall": "79", "wall": "325"}
2022-11-10 23:29:30 | INFO | train_inner | {"epoch": 1, "update": 0.343, "loss": "7.311", "nll_loss": "6.116", "ppl": "69.35", "wps": "2218.2", "ups": "1.23", "wpb": "1800.4", "bsz": "32", "num_updates": "500", "lr": "5e-05", "gnorm": "2.19", "train_wall": "81", "wall": "406"}
2022-11-10 23:30:50 | INFO | train_inner | {"epoch": 1, "update": 0.412, "loss": "6.97", "nll_loss": "5.72", "ppl": "52.69", "wps": "2181.3", "ups": "1.25", "wpb": "1745.7", "bsz": "32", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "2.072", "train_wall": "80", "wall": "486"}
2022-11-10 23:32:12 | INFO | train_inner | {"epoch": 1, "update": 0.48, "loss": "6.698", "nll_loss": "5.41", "ppl": "42.52", "wps": "2227.7", "ups": "1.22", "wpb": "1823.4", "bsz": "32", "num_updates": "700", "lr": "4.999e-05", "gnorm": "2.026", "train_wall": "81", "wall": "568"}
2022-11-10 23:33:33 | INFO | train_inner | {"epoch": 1, "update": 0.549, "loss": "6.405", "nll_loss": "5.079", "ppl": "33.81", "wps": "2215.9", "ups": "1.23", "wpb": "1797.6", "bsz": "32", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "1.96", "train_wall": "81", "wall": "649"}
2022-11-10 23:34:56 | INFO | train_inner | {"epoch": 1, "update": 0.617, "loss": "6.228", "nll_loss": "4.877", "ppl": "29.39", "wps": "2259.2", "ups": "1.21", "wpb": "1861.1", "bsz": "32", "num_updates": "900", "lr": "4.998e-05", "gnorm": "1.992", "train_wall": "82", "wall": "731"}
2022-11-10 23:36:18 | INFO | train_inner | {"epoch": 1, "update": 0.686, "loss": "6.011", "nll_loss": "4.632", "ppl": "24.79", "wps": "2201.8", "ups": "1.21", "wpb": "1823", "bsz": "32", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "2.013", "train_wall": "82", "wall": "814"}
2022-11-10 23:37:40 | INFO | train_inner | {"epoch": 1, "update": 0.754, "loss": "5.85", "nll_loss": "4.451", "ppl": "21.87", "wps": "2161.8", "ups": "1.23", "wpb": "1758", "bsz": "32", "num_updates": "1100", "lr": "4.997e-05", "gnorm": "2.022", "train_wall": "81", "wall": "895"}
2022-11-10 23:39:01 | INFO | train_inner | {"epoch": 1, "update": 0.823, "loss": "5.63", "nll_loss": "4.203", "ppl": "18.41", "wps": "2178.4", "ups": "1.24", "wpb": "1762.1", "bsz": "32", "num_updates": "1200", "lr": "4.9965e-05", "gnorm": "2.051", "train_wall": "80", "wall": "976"}
2022-11-10 23:40:23 | INFO | train_inner | {"epoch": 1, "update": 0.892, "loss": "5.513", "nll_loss": "4.069", "ppl": "16.79", "wps": "2221.2", "ups": "1.22", "wpb": "1825.5", "bsz": "32", "num_updates": "1300", "lr": "4.996e-05", "gnorm": "2.04", "train_wall": "82", "wall": "1058"}
2022-11-10 23:41:44 | INFO | train_inner | {"epoch": 1, "update": 0.96, "loss": "5.444", "nll_loss": "3.992", "ppl": "15.91", "wps": "2145.4", "ups": "1.23", "wpb": "1751.2", "bsz": "32", "num_updates": "1400", "lr": "4.9955e-05", "gnorm": "2.093", "train_wall": "81", "wall": "1140"}
2022-11-10 23:42:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
/home/y_shi202/.local/lib/python3.6/site-packages/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  "amp_C fused kernels unavailable, disabling multi_tensor_l2norm; "
2022-11-11 00:17:40 | INFO | valid | {"epoch": 1, "valid_loss": "5.156", "valid_nll_loss": "3.653", "valid_ppl": "12.58", "valid_bleu": "20.05", "valid_wps": "153.5", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "1458"}
2022-11-11 00:17:40 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 00:18:16 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 1 @ 1458 updates, score 20.05) (writing took 36.04723256127909 seconds)
2022-11-11 00:18:16 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-11-11 00:18:16 | INFO | train | {"epoch": 1, "train_loss": "7.104", "train_nll_loss": "5.897", "train_ppl": "59.58", "train_wps": "784.4", "train_ups": "0.44", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "1458", "train_lr": "4.99521e-05", "train_gnorm": "2.389", "train_train_wall": "1180", "train_wall": "3332"}
2022-11-11 00:18:16 | INFO | fairseq.trainer | begin training epoch 2
2022-11-11 00:18:49 | INFO | train_inner | {"epoch": 2, "update": 1.029, "loss": "5.271", "nll_loss": "3.797", "ppl": "13.9", "wps": "78.9", "ups": "0.04", "wpb": "1755.8", "bsz": "31.7", "num_updates": "1500", "lr": "4.995e-05", "gnorm": "2.13", "train_wall": "79", "wall": "3365"}
2022-11-11 00:20:10 | INFO | train_inner | {"epoch": 2, "update": 1.097, "loss": "5.185", "nll_loss": "3.7", "ppl": "12.99", "wps": "2262.5", "ups": "1.24", "wpb": "1828.2", "bsz": "32", "num_updates": "1600", "lr": "4.9945e-05", "gnorm": "2.114", "train_wall": "80", "wall": "3445"}
2022-11-11 00:21:30 | INFO | train_inner | {"epoch": 2, "update": 1.166, "loss": "5.023", "nll_loss": "3.515", "ppl": "11.44", "wps": "2188.6", "ups": "1.25", "wpb": "1751.6", "bsz": "32", "num_updates": "1700", "lr": "4.994e-05", "gnorm": "2.137", "train_wall": "80", "wall": "3525"}
2022-11-11 00:22:50 | INFO | train_inner | {"epoch": 2, "update": 1.235, "loss": "4.944", "nll_loss": "3.425", "ppl": "10.74", "wps": "2192.4", "ups": "1.24", "wpb": "1765.5", "bsz": "32", "num_updates": "1800", "lr": "4.9935e-05", "gnorm": "2.132", "train_wall": "80", "wall": "3606"}
2022-11-11 00:24:12 | INFO | train_inner | {"epoch": 2, "update": 1.303, "loss": "4.953", "nll_loss": "3.435", "ppl": "10.82", "wps": "2194.9", "ups": "1.22", "wpb": "1805.1", "bsz": "32", "num_updates": "1900", "lr": "4.993e-05", "gnorm": "2.16", "train_wall": "82", "wall": "3688"}
2022-11-11 00:25:33 | INFO | train_inner | {"epoch": 2, "update": 1.372, "loss": "4.862", "nll_loss": "3.334", "ppl": "10.09", "wps": "2194.4", "ups": "1.24", "wpb": "1775.3", "bsz": "32", "num_updates": "2000", "lr": "4.9925e-05", "gnorm": "2.169", "train_wall": "80", "wall": "3769"}
2022-11-11 00:26:56 | INFO | train_inner | {"epoch": 2, "update": 1.44, "loss": "4.854", "nll_loss": "3.325", "ppl": "10.02", "wps": "2257.7", "ups": "1.21", "wpb": "1868.1", "bsz": "32", "num_updates": "2100", "lr": "4.992e-05", "gnorm": "2.139", "train_wall": "82", "wall": "3852"}
2022-11-11 00:28:17 | INFO | train_inner | {"epoch": 2, "update": 1.509, "loss": "4.74", "nll_loss": "3.195", "ppl": "9.16", "wps": "2175.5", "ups": "1.23", "wpb": "1761.6", "bsz": "32", "num_updates": "2200", "lr": "4.9915e-05", "gnorm": "2.185", "train_wall": "81", "wall": "3933"}
2022-11-11 00:29:38 | INFO | train_inner | {"epoch": 2, "update": 1.578, "loss": "4.682", "nll_loss": "3.129", "ppl": "8.75", "wps": "2200", "ups": "1.24", "wpb": "1774.3", "bsz": "32", "num_updates": "2300", "lr": "4.991e-05", "gnorm": "2.168", "train_wall": "80", "wall": "4013"}
2022-11-11 00:31:00 | INFO | train_inner | {"epoch": 2, "update": 1.646, "loss": "4.697", "nll_loss": "3.146", "ppl": "8.85", "wps": "2220.1", "ups": "1.22", "wpb": "1818", "bsz": "32", "num_updates": "2400", "lr": "4.9905e-05", "gnorm": "2.158", "train_wall": "81", "wall": "4095"}
2022-11-11 00:32:20 | INFO | train_inner | {"epoch": 2, "update": 1.715, "loss": "4.602", "nll_loss": "3.039", "ppl": "8.22", "wps": "2226.6", "ups": "1.24", "wpb": "1797.3", "bsz": "32", "num_updates": "2500", "lr": "4.98999e-05", "gnorm": "2.198", "train_wall": "80", "wall": "4176"}
2022-11-11 00:33:40 | INFO | train_inner | {"epoch": 2, "update": 1.783, "loss": "4.571", "nll_loss": "3.005", "ppl": "8.03", "wps": "2224.6", "ups": "1.26", "wpb": "1764.7", "bsz": "32", "num_updates": "2600", "lr": "4.98949e-05", "gnorm": "2.198", "train_wall": "79", "wall": "4255"}
2022-11-11 00:35:01 | INFO | train_inner | {"epoch": 2, "update": 1.852, "loss": "4.526", "nll_loss": "2.953", "ppl": "7.74", "wps": "2250", "ups": "1.23", "wpb": "1827.3", "bsz": "32", "num_updates": "2700", "lr": "4.98899e-05", "gnorm": "2.142", "train_wall": "81", "wall": "4337"}
2022-11-11 00:36:22 | INFO | train_inner | {"epoch": 2, "update": 1.92, "loss": "4.511", "nll_loss": "2.935", "ppl": "7.65", "wps": "2229.8", "ups": "1.23", "wpb": "1811.4", "bsz": "32", "num_updates": "2800", "lr": "4.98849e-05", "gnorm": "2.182", "train_wall": "81", "wall": "4418"}
2022-11-11 00:37:42 | INFO | train_inner | {"epoch": 2, "update": 1.989, "loss": "4.422", "nll_loss": "2.836", "ppl": "7.14", "wps": "2231.2", "ups": "1.25", "wpb": "1786.3", "bsz": "32", "num_updates": "2900", "lr": "4.98799e-05", "gnorm": "2.203", "train_wall": "80", "wall": "4498"}
2022-11-11 00:37:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 01:06:51 | INFO | valid | {"epoch": 2, "valid_loss": "4.305", "valid_nll_loss": "2.665", "valid_ppl": "6.34", "valid_bleu": "30.49", "valid_wps": "186.4", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "2916", "valid_best_bleu": "30.49"}
2022-11-11 01:06:51 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 01:07:32 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 2 @ 2916 updates, score 30.49) (writing took 40.54473712807521 seconds)
2022-11-11 01:07:32 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-11-11 01:07:32 | INFO | train | {"epoch": 2, "train_loss": "4.763", "train_nll_loss": "3.221", "train_ppl": "9.32", "train_wps": "884.3", "train_ups": "0.49", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "2916", "train_lr": "4.98791e-05", "train_gnorm": "2.164", "train_train_wall": "1172", "train_wall": "6287"}
2022-11-11 01:07:32 | INFO | fairseq.trainer | begin training epoch 3
2022-11-11 01:08:39 | INFO | train_inner | {"epoch": 3, "update": 2.058, "loss": "4.289", "nll_loss": "2.684", "ppl": "6.43", "wps": "96.4", "ups": "0.05", "wpb": "1790.7", "bsz": "31.7", "num_updates": "3000", "lr": "4.98749e-05", "gnorm": "2.143", "train_wall": "79", "wall": "6355"}
2022-11-11 01:10:00 | INFO | train_inner | {"epoch": 3, "update": 2.126, "loss": "4.168", "nll_loss": "2.547", "ppl": "5.84", "wps": "2204.1", "ups": "1.23", "wpb": "1792.4", "bsz": "32", "num_updates": "3100", "lr": "4.98699e-05", "gnorm": "2.159", "train_wall": "81", "wall": "6436"}
2022-11-11 01:11:21 | INFO | train_inner | {"epoch": 3, "update": 2.195, "loss": "4.176", "nll_loss": "2.557", "ppl": "5.88", "wps": "2205.5", "ups": "1.25", "wpb": "1768.8", "bsz": "32", "num_updates": "3200", "lr": "4.98649e-05", "gnorm": "2.159", "train_wall": "80", "wall": "6516"}
2022-11-11 01:12:41 | INFO | train_inner | {"epoch": 3, "update": 2.263, "loss": "4.149", "nll_loss": "2.524", "ppl": "5.75", "wps": "2263.5", "ups": "1.24", "wpb": "1824.2", "bsz": "32", "num_updates": "3300", "lr": "4.98599e-05", "gnorm": "2.155", "train_wall": "80", "wall": "6597"}
2022-11-11 01:14:02 | INFO | train_inner | {"epoch": 3, "update": 2.332, "loss": "4.089", "nll_loss": "2.457", "ppl": "5.49", "wps": "2182.9", "ups": "1.23", "wpb": "1774.2", "bsz": "32", "num_updates": "3400", "lr": "4.98549e-05", "gnorm": "2.151", "train_wall": "81", "wall": "6678"}
2022-11-11 01:15:24 | INFO | train_inner | {"epoch": 3, "update": 2.401, "loss": "4.129", "nll_loss": "2.502", "ppl": "5.67", "wps": "2147.5", "ups": "1.23", "wpb": "1745.3", "bsz": "32", "num_updates": "3500", "lr": "4.98499e-05", "gnorm": "2.205", "train_wall": "81", "wall": "6759"}
2022-11-11 01:16:46 | INFO | train_inner | {"epoch": 3, "update": 2.469, "loss": "4.099", "nll_loss": "2.468", "ppl": "5.53", "wps": "2231.1", "ups": "1.22", "wpb": "1831.3", "bsz": "32", "num_updates": "3600", "lr": "4.98449e-05", "gnorm": "2.149", "train_wall": "82", "wall": "6842"}
2022-11-11 01:18:08 | INFO | train_inner | {"epoch": 3, "update": 2.538, "loss": "4.095", "nll_loss": "2.464", "ppl": "5.52", "wps": "2273.7", "ups": "1.21", "wpb": "1873.2", "bsz": "32", "num_updates": "3700", "lr": "4.98399e-05", "gnorm": "2.156", "train_wall": "82", "wall": "6924"}
2022-11-11 01:19:29 | INFO | train_inner | {"epoch": 3, "update": 2.606, "loss": "4.046", "nll_loss": "2.408", "ppl": "5.31", "wps": "2212.4", "ups": "1.24", "wpb": "1787.9", "bsz": "32", "num_updates": "3800", "lr": "4.98349e-05", "gnorm": "2.175", "train_wall": "80", "wall": "7005"}
2022-11-11 01:20:50 | INFO | train_inner | {"epoch": 3, "update": 2.675, "loss": "4.049", "nll_loss": "2.411", "ppl": "5.32", "wps": "2160.7", "ups": "1.23", "wpb": "1752.7", "bsz": "32", "num_updates": "3900", "lr": "4.98299e-05", "gnorm": "2.226", "train_wall": "81", "wall": "7086"}
2022-11-11 01:22:10 | INFO | train_inner | {"epoch": 3, "update": 2.743, "loss": "3.993", "nll_loss": "2.347", "ppl": "5.09", "wps": "2213.8", "ups": "1.25", "wpb": "1770.7", "bsz": "32", "num_updates": "4000", "lr": "4.98249e-05", "gnorm": "2.181", "train_wall": "80", "wall": "7166"}
2022-11-11 01:23:30 | INFO | train_inner | {"epoch": 3, "update": 2.812, "loss": "4.035", "nll_loss": "2.395", "ppl": "5.26", "wps": "2222.8", "ups": "1.25", "wpb": "1781.3", "bsz": "32", "num_updates": "4100", "lr": "4.98199e-05", "gnorm": "2.19", "train_wall": "80", "wall": "7246"}
2022-11-11 01:24:49 | INFO | train_inner | {"epoch": 3, "update": 2.881, "loss": "4", "nll_loss": "2.355", "ppl": "5.12", "wps": "2252.4", "ups": "1.27", "wpb": "1778.9", "bsz": "32", "num_updates": "4200", "lr": "4.98149e-05", "gnorm": "2.187", "train_wall": "79", "wall": "7325"}
2022-11-11 01:26:09 | INFO | train_inner | {"epoch": 3, "update": 2.949, "loss": "3.959", "nll_loss": "2.308", "ppl": "4.95", "wps": "2270.8", "ups": "1.26", "wpb": "1804.7", "bsz": "32", "num_updates": "4300", "lr": "4.98099e-05", "gnorm": "2.137", "train_wall": "79", "wall": "7404"}
2022-11-11 01:27:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 01:56:16 | INFO | valid | {"epoch": 3, "valid_loss": "3.913", "valid_nll_loss": "2.225", "valid_ppl": "4.67", "valid_bleu": "35.54", "valid_wps": "185.1", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "4374", "valid_best_bleu": "35.54"}
2022-11-11 01:56:16 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 01:56:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 3 @ 4374 updates, score 35.54) (writing took 37.463631025049835 seconds)
2022-11-11 01:56:54 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-11-11 01:56:54 | INFO | train | {"epoch": 3, "train_loss": "4.081", "train_nll_loss": "2.448", "train_ppl": "5.46", "train_wps": "882.4", "train_ups": "0.49", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "4374", "train_lr": "4.98062e-05", "train_gnorm": "2.172", "train_train_wall": "1169", "train_wall": "9249"}
2022-11-11 01:56:54 | INFO | fairseq.trainer | begin training epoch 4
2022-11-11 01:57:14 | INFO | train_inner | {"epoch": 4, "update": 3.018, "loss": "3.951", "nll_loss": "2.299", "ppl": "4.92", "wps": "97.2", "ups": "0.05", "wpb": "1814.2", "bsz": "31.7", "num_updates": "4400", "lr": "4.98049e-05", "gnorm": "2.219", "train_wall": "79", "wall": "9270"}
2022-11-11 01:58:33 | INFO | train_inner | {"epoch": 4, "update": 3.086, "loss": "3.725", "nll_loss": "2.043", "ppl": "4.12", "wps": "2275.6", "ups": "1.27", "wpb": "1787.9", "bsz": "32", "num_updates": "4500", "lr": "4.97999e-05", "gnorm": "2.098", "train_wall": "78", "wall": "9349"}
2022-11-11 01:59:55 | INFO | train_inner | {"epoch": 4, "update": 3.155, "loss": "3.712", "nll_loss": "2.028", "ppl": "4.08", "wps": "2220.3", "ups": "1.22", "wpb": "1816.8", "bsz": "32", "num_updates": "4600", "lr": "4.97949e-05", "gnorm": "2.083", "train_wall": "81", "wall": "9430"}
2022-11-11 02:01:14 | INFO | train_inner | {"epoch": 4, "update": 3.224, "loss": "3.741", "nll_loss": "2.061", "ppl": "4.17", "wps": "2298.4", "ups": "1.26", "wpb": "1822.1", "bsz": "32", "num_updates": "4700", "lr": "4.97899e-05", "gnorm": "2.118", "train_wall": "79", "wall": "9510"}
2022-11-11 02:02:32 | INFO | train_inner | {"epoch": 4, "update": 3.292, "loss": "3.692", "nll_loss": "2.005", "ppl": "4.01", "wps": "2241.1", "ups": "1.28", "wpb": "1757.6", "bsz": "32", "num_updates": "4800", "lr": "4.97849e-05", "gnorm": "2.155", "train_wall": "78", "wall": "9588"}
2022-11-11 02:03:49 | INFO | train_inner | {"epoch": 4, "update": 3.361, "loss": "3.657", "nll_loss": "1.965", "ppl": "3.9", "wps": "2214", "ups": "1.3", "wpb": "1696.8", "bsz": "32", "num_updates": "4900", "lr": "4.97799e-05", "gnorm": "2.15", "train_wall": "76", "wall": "9665"}
2022-11-11 02:05:08 | INFO | train_inner | {"epoch": 4, "update": 3.429, "loss": "3.701", "nll_loss": "2.015", "ppl": "4.04", "wps": "2252.7", "ups": "1.27", "wpb": "1774.8", "bsz": "32", "num_updates": "5000", "lr": "4.97749e-05", "gnorm": "2.165", "train_wall": "78", "wall": "9744"}
2022-11-11 02:06:27 | INFO | train_inner | {"epoch": 4, "update": 3.498, "loss": "3.701", "nll_loss": "2.014", "ppl": "4.04", "wps": "2289.6", "ups": "1.26", "wpb": "1818.2", "bsz": "32", "num_updates": "5100", "lr": "4.97699e-05", "gnorm": "2.146", "train_wall": "79", "wall": "9823"}
2022-11-11 02:07:47 | INFO | train_inner | {"epoch": 4, "update": 3.567, "loss": "3.7", "nll_loss": "2.013", "ppl": "4.04", "wps": "2280.3", "ups": "1.26", "wpb": "1816", "bsz": "32", "num_updates": "5200", "lr": "4.97649e-05", "gnorm": "2.13", "train_wall": "79", "wall": "9903"}
2022-11-11 02:09:07 | INFO | train_inner | {"epoch": 4, "update": 3.635, "loss": "3.686", "nll_loss": "1.996", "ppl": "3.99", "wps": "2295", "ups": "1.25", "wpb": "1841.6", "bsz": "32", "num_updates": "5300", "lr": "4.97599e-05", "gnorm": "2.151", "train_wall": "80", "wall": "9983"}
2022-11-11 02:10:27 | INFO | train_inner | {"epoch": 4, "update": 3.704, "loss": "3.697", "nll_loss": "2.009", "ppl": "4.02", "wps": "2282.8", "ups": "1.25", "wpb": "1822.6", "bsz": "32", "num_updates": "5400", "lr": "4.97549e-05", "gnorm": "2.152", "train_wall": "79", "wall": "10063"}
2022-11-11 02:11:46 | INFO | train_inner | {"epoch": 4, "update": 3.772, "loss": "3.641", "nll_loss": "1.947", "ppl": "3.86", "wps": "2268.9", "ups": "1.27", "wpb": "1786.2", "bsz": "32", "num_updates": "5500", "lr": "4.97499e-05", "gnorm": "2.117", "train_wall": "78", "wall": "10141"}
2022-11-11 02:13:04 | INFO | train_inner | {"epoch": 4, "update": 3.841, "loss": "3.626", "nll_loss": "1.928", "ppl": "3.8", "wps": "2253.7", "ups": "1.27", "wpb": "1769.5", "bsz": "32", "num_updates": "5600", "lr": "4.97449e-05", "gnorm": "2.128", "train_wall": "78", "wall": "10220"}
2022-11-11 02:14:25 | INFO | train_inner | {"epoch": 4, "update": 3.909, "loss": "3.641", "nll_loss": "1.947", "ppl": "3.86", "wps": "2321.5", "ups": "1.24", "wpb": "1871.8", "bsz": "32", "num_updates": "5700", "lr": "4.97399e-05", "gnorm": "2.103", "train_wall": "80", "wall": "10301"}
2022-11-11 02:15:42 | INFO | train_inner | {"epoch": 4, "update": 3.978, "loss": "3.609", "nll_loss": "1.909", "ppl": "3.75", "wps": "2227.9", "ups": "1.29", "wpb": "1720.4", "bsz": "32", "num_updates": "5800", "lr": "4.97349e-05", "gnorm": "2.143", "train_wall": "77", "wall": "10378"}
2022-11-11 02:16:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 02:48:15 | INFO | valid | {"epoch": 4, "valid_loss": "3.648", "valid_nll_loss": "1.912", "valid_ppl": "3.76", "valid_bleu": "42.87", "valid_wps": "167.9", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "5832", "valid_best_bleu": "42.87"}
2022-11-11 02:48:15 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 02:48:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 4 @ 5832 updates, score 42.87) (writing took 39.33527411939576 seconds)
2022-11-11 02:48:54 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-11-11 02:48:54 | INFO | train | {"epoch": 4, "train_loss": "3.683", "train_nll_loss": "1.994", "train_ppl": "3.98", "train_wps": "837.5", "train_ups": "0.47", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "5832", "train_lr": "4.97333e-05", "train_gnorm": "2.132", "train_train_wall": "1147", "train_wall": "12370"}
2022-11-11 02:48:54 | INFO | fairseq.trainer | begin training epoch 5
2022-11-11 02:49:48 | INFO | train_inner | {"epoch": 5, "update": 4.047, "loss": "3.481", "nll_loss": "1.765", "ppl": "3.4", "wps": "87.3", "ups": "0.05", "wpb": "1786.9", "bsz": "31.7", "num_updates": "5900", "lr": "4.97299e-05", "gnorm": "2.062", "train_wall": "78", "wall": "12424"}
2022-11-11 02:51:08 | INFO | train_inner | {"epoch": 5, "update": 4.115, "loss": "3.45", "nll_loss": "1.728", "ppl": "3.31", "wps": "2288.5", "ups": "1.26", "wpb": "1821.4", "bsz": "32", "num_updates": "6000", "lr": "4.97249e-05", "gnorm": "2.121", "train_wall": "79", "wall": "12503"}
2022-11-11 02:52:27 | INFO | train_inner | {"epoch": 5, "update": 4.184, "loss": "3.425", "nll_loss": "1.7", "ppl": "3.25", "wps": "2275.9", "ups": "1.26", "wpb": "1805.2", "bsz": "32", "num_updates": "6100", "lr": "4.97199e-05", "gnorm": "2.092", "train_wall": "79", "wall": "12583"}
2022-11-11 02:53:45 | INFO | train_inner | {"epoch": 5, "update": 4.252, "loss": "3.435", "nll_loss": "1.711", "ppl": "3.27", "wps": "2250.3", "ups": "1.28", "wpb": "1764", "bsz": "32", "num_updates": "6200", "lr": "4.97149e-05", "gnorm": "2.106", "train_wall": "78", "wall": "12661"}
2022-11-11 02:55:05 | INFO | train_inner | {"epoch": 5, "update": 4.321, "loss": "3.423", "nll_loss": "1.696", "ppl": "3.24", "wps": "2304.2", "ups": "1.25", "wpb": "1839.7", "bsz": "32", "num_updates": "6300", "lr": "4.97099e-05", "gnorm": "2.062", "train_wall": "79", "wall": "12741"}
2022-11-11 02:56:23 | INFO | train_inner | {"epoch": 5, "update": 4.39, "loss": "3.404", "nll_loss": "1.676", "ppl": "3.2", "wps": "2221.8", "ups": "1.28", "wpb": "1737.1", "bsz": "32", "num_updates": "6400", "lr": "4.97049e-05", "gnorm": "2.093", "train_wall": "78", "wall": "12819"}
2022-11-11 02:57:41 | INFO | train_inner | {"epoch": 5, "update": 4.458, "loss": "3.401", "nll_loss": "1.672", "ppl": "3.19", "wps": "2246.5", "ups": "1.28", "wpb": "1750.5", "bsz": "32", "num_updates": "6500", "lr": "4.96998e-05", "gnorm": "2.089", "train_wall": "78", "wall": "12897"}
2022-11-11 02:59:00 | INFO | train_inner | {"epoch": 5, "update": 4.527, "loss": "3.398", "nll_loss": "1.667", "ppl": "3.17", "wps": "2268.4", "ups": "1.27", "wpb": "1788.7", "bsz": "32", "num_updates": "6600", "lr": "4.96948e-05", "gnorm": "2.101", "train_wall": "78", "wall": "12976"}
2022-11-11 03:00:19 | INFO | train_inner | {"epoch": 5, "update": 4.595, "loss": "3.403", "nll_loss": "1.674", "ppl": "3.19", "wps": "2280.1", "ups": "1.26", "wpb": "1805.4", "bsz": "32", "num_updates": "6700", "lr": "4.96898e-05", "gnorm": "2.063", "train_wall": "79", "wall": "13055"}
2022-11-11 03:01:38 | INFO | train_inner | {"epoch": 5, "update": 4.664, "loss": "3.384", "nll_loss": "1.652", "ppl": "3.14", "wps": "2241.1", "ups": "1.28", "wpb": "1753.4", "bsz": "32", "num_updates": "6800", "lr": "4.96848e-05", "gnorm": "2.074", "train_wall": "78", "wall": "13133"}
2022-11-11 03:02:57 | INFO | train_inner | {"epoch": 5, "update": 4.733, "loss": "3.391", "nll_loss": "1.661", "ppl": "3.16", "wps": "2280.8", "ups": "1.27", "wpb": "1801.3", "bsz": "32", "num_updates": "6900", "lr": "4.96798e-05", "gnorm": "2.084", "train_wall": "79", "wall": "13212"}
2022-11-11 03:04:15 | INFO | train_inner | {"epoch": 5, "update": 4.801, "loss": "3.343", "nll_loss": "1.605", "ppl": "3.04", "wps": "2236.9", "ups": "1.28", "wpb": "1750.7", "bsz": "32", "num_updates": "7000", "lr": "4.96748e-05", "gnorm": "2.085", "train_wall": "78", "wall": "13291"}
2022-11-11 03:05:35 | INFO | train_inner | {"epoch": 5, "update": 4.87, "loss": "3.448", "nll_loss": "1.724", "ppl": "3.3", "wps": "2266.5", "ups": "1.25", "wpb": "1812.6", "bsz": "32", "num_updates": "7100", "lr": "4.96698e-05", "gnorm": "2.107", "train_wall": "80", "wall": "13371"}
2022-11-11 03:06:55 | INFO | train_inner | {"epoch": 5, "update": 4.938, "loss": "3.393", "nll_loss": "1.661", "ppl": "3.16", "wps": "2299.6", "ups": "1.25", "wpb": "1845.7", "bsz": "32", "num_updates": "7200", "lr": "4.96648e-05", "gnorm": "2.043", "train_wall": "80", "wall": "13451"}
2022-11-11 03:08:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 03:39:29 | INFO | valid | {"epoch": 5, "valid_loss": "3.507", "valid_nll_loss": "1.747", "valid_ppl": "3.36", "valid_bleu": "45.63", "valid_wps": "171.9", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "7290", "valid_best_bleu": "45.63"}
2022-11-11 03:39:29 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 03:40:06 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 5 @ 7290 updates, score 45.63) (writing took 36.84161180770025 seconds)
2022-11-11 03:40:06 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-11-11 03:40:06 | INFO | train | {"epoch": 5, "train_loss": "3.406", "train_nll_loss": "1.677", "train_ppl": "3.2", "train_wps": "850.8", "train_ups": "0.47", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "7290", "train_lr": "4.96603e-05", "train_gnorm": "2.082", "train_train_wall": "1146", "train_wall": "15442"}
2022-11-11 03:40:06 | INFO | fairseq.trainer | begin training epoch 6
2022-11-11 03:40:14 | INFO | train_inner | {"epoch": 6, "update": 5.007, "loss": "3.365", "nll_loss": "1.629", "ppl": "3.09", "wps": "90.5", "ups": "0.05", "wpb": "1809.6", "bsz": "31.7", "num_updates": "7300", "lr": "4.96598e-05", "gnorm": "2.075", "train_wall": "79", "wall": "15450"}
2022-11-11 03:41:33 | INFO | train_inner | {"epoch": 6, "update": 5.075, "loss": "3.164", "nll_loss": "1.401", "ppl": "2.64", "wps": "2257.6", "ups": "1.28", "wpb": "1770.5", "bsz": "32", "num_updates": "7400", "lr": "4.96548e-05", "gnorm": "1.963", "train_wall": "78", "wall": "15528"}
2022-11-11 03:42:51 | INFO | train_inner | {"epoch": 6, "update": 5.144, "loss": "3.187", "nll_loss": "1.428", "ppl": "2.69", "wps": "2247.2", "ups": "1.27", "wpb": "1769.1", "bsz": "32", "num_updates": "7500", "lr": "4.96498e-05", "gnorm": "1.989", "train_wall": "78", "wall": "15607"}
2022-11-11 03:44:10 | INFO | train_inner | {"epoch": 6, "update": 5.213, "loss": "3.177", "nll_loss": "1.415", "ppl": "2.67", "wps": "2306.4", "ups": "1.27", "wpb": "1822.5", "bsz": "32", "num_updates": "7600", "lr": "4.96448e-05", "gnorm": "2.001", "train_wall": "79", "wall": "15686"}
2022-11-11 03:45:30 | INFO | train_inner | {"epoch": 6, "update": 5.281, "loss": "3.186", "nll_loss": "1.425", "ppl": "2.69", "wps": "2265.9", "ups": "1.25", "wpb": "1808", "bsz": "32", "num_updates": "7700", "lr": "4.96398e-05", "gnorm": "2.07", "train_wall": "79", "wall": "15766"}
2022-11-11 03:46:49 | INFO | train_inner | {"epoch": 6, "update": 5.35, "loss": "3.18", "nll_loss": "1.419", "ppl": "2.67", "wps": "2235.9", "ups": "1.27", "wpb": "1758.4", "bsz": "32", "num_updates": "7800", "lr": "4.96348e-05", "gnorm": "2.019", "train_wall": "78", "wall": "15845"}
2022-11-11 03:48:08 | INFO | train_inner | {"epoch": 6, "update": 5.418, "loss": "3.193", "nll_loss": "1.433", "ppl": "2.7", "wps": "2278.3", "ups": "1.26", "wpb": "1806.2", "bsz": "32", "num_updates": "7900", "lr": "4.96298e-05", "gnorm": "2.052", "train_wall": "79", "wall": "15924"}
2022-11-11 03:49:28 | INFO | train_inner | {"epoch": 6, "update": 5.487, "loss": "3.201", "nll_loss": "1.442", "ppl": "2.72", "wps": "2283.1", "ups": "1.25", "wpb": "1820.1", "bsz": "32", "num_updates": "8000", "lr": "4.96248e-05", "gnorm": "2.028", "train_wall": "79", "wall": "16004"}
2022-11-11 03:50:47 | INFO | train_inner | {"epoch": 6, "update": 5.556, "loss": "3.208", "nll_loss": "1.449", "ppl": "2.73", "wps": "2268.9", "ups": "1.27", "wpb": "1787", "bsz": "32", "num_updates": "8100", "lr": "4.96198e-05", "gnorm": "2.014", "train_wall": "78", "wall": "16082"}
2022-11-11 03:52:05 | INFO | train_inner | {"epoch": 6, "update": 5.624, "loss": "3.184", "nll_loss": "1.422", "ppl": "2.68", "wps": "2265.7", "ups": "1.27", "wpb": "1783.4", "bsz": "32", "num_updates": "8200", "lr": "4.96148e-05", "gnorm": "2.047", "train_wall": "78", "wall": "16161"}
2022-11-11 03:53:25 | INFO | train_inner | {"epoch": 6, "update": 5.693, "loss": "3.203", "nll_loss": "1.445", "ppl": "2.72", "wps": "2267.3", "ups": "1.26", "wpb": "1797.6", "bsz": "32", "num_updates": "8300", "lr": "4.96098e-05", "gnorm": "2.054", "train_wall": "79", "wall": "16240"}
2022-11-11 03:54:47 | INFO | train_inner | {"epoch": 6, "update": 5.761, "loss": "3.232", "nll_loss": "1.478", "ppl": "2.79", "wps": "2271.9", "ups": "1.21", "wpb": "1879.5", "bsz": "32", "num_updates": "8400", "lr": "4.96048e-05", "gnorm": "2.034", "train_wall": "82", "wall": "16323"}
2022-11-11 03:56:09 | INFO | train_inner | {"epoch": 6, "update": 5.83, "loss": "3.182", "nll_loss": "1.42", "ppl": "2.68", "wps": "2176.3", "ups": "1.23", "wpb": "1774.3", "bsz": "32", "num_updates": "8500", "lr": "4.95998e-05", "gnorm": "2.016", "train_wall": "81", "wall": "16405"}
2022-11-11 03:57:28 | INFO | train_inner | {"epoch": 6, "update": 5.898, "loss": "3.197", "nll_loss": "1.437", "ppl": "2.71", "wps": "2266.1", "ups": "1.26", "wpb": "1794.7", "bsz": "32", "num_updates": "8600", "lr": "4.95948e-05", "gnorm": "2.045", "train_wall": "79", "wall": "16484"}
2022-11-11 03:58:47 | INFO | train_inner | {"epoch": 6, "update": 5.967, "loss": "3.197", "nll_loss": "1.438", "ppl": "2.71", "wps": "2221.4", "ups": "1.27", "wpb": "1748.5", "bsz": "32", "num_updates": "8700", "lr": "4.95898e-05", "gnorm": "2.053", "train_wall": "78", "wall": "16563"}
2022-11-11 03:59:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 04:29:33 | INFO | valid | {"epoch": 6, "valid_loss": "3.398", "valid_nll_loss": "1.609", "valid_ppl": "3.05", "valid_bleu": "43.54", "valid_wps": "178.9", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "8748", "valid_best_bleu": "45.63"}
2022-11-11 04:29:33 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 04:29:53 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 6 @ 8748 updates, score 43.54) (writing took 19.972783977165818 seconds)
2022-11-11 04:29:53 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-11-11 04:29:53 | INFO | train | {"epoch": 6, "train_loss": "3.192", "train_nll_loss": "1.432", "train_ppl": "2.7", "train_wps": "875.1", "train_ups": "0.49", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "8748", "train_lr": "4.95874e-05", "train_gnorm": "2.029", "train_train_wall": "1151", "train_wall": "18429"}
2022-11-11 04:29:53 | INFO | fairseq.trainer | begin training epoch 7
2022-11-11 04:30:34 | INFO | train_inner | {"epoch": 7, "update": 6.036, "loss": "3.078", "nll_loss": "1.301", "ppl": "2.46", "wps": "93.4", "ups": "0.05", "wpb": "1780.8", "bsz": "31.7", "num_updates": "8800", "lr": "4.95848e-05", "gnorm": "1.979", "train_wall": "78", "wall": "18470"}
2022-11-11 04:31:53 | INFO | train_inner | {"epoch": 7, "update": 6.104, "loss": "3.016", "nll_loss": "1.231", "ppl": "2.35", "wps": "2254.9", "ups": "1.27", "wpb": "1771.1", "bsz": "32", "num_updates": "8900", "lr": "4.95798e-05", "gnorm": "1.968", "train_wall": "78", "wall": "18549"}
2022-11-11 04:33:14 | INFO | train_inner | {"epoch": 7, "update": 6.173, "loss": "3.026", "nll_loss": "1.242", "ppl": "2.37", "wps": "2300.1", "ups": "1.23", "wpb": "1869.2", "bsz": "32", "num_updates": "9000", "lr": "4.95748e-05", "gnorm": "1.897", "train_wall": "81", "wall": "18630"}
2022-11-11 04:34:36 | INFO | train_inner | {"epoch": 7, "update": 6.241, "loss": "3.022", "nll_loss": "1.237", "ppl": "2.36", "wps": "2218.4", "ups": "1.22", "wpb": "1822", "bsz": "32", "num_updates": "9100", "lr": "4.95698e-05", "gnorm": "1.967", "train_wall": "82", "wall": "18712"}
2022-11-11 04:35:55 | INFO | train_inner | {"epoch": 7, "update": 6.31, "loss": "3.021", "nll_loss": "1.236", "ppl": "2.36", "wps": "2299.5", "ups": "1.26", "wpb": "1818", "bsz": "32", "num_updates": "9200", "lr": "4.95648e-05", "gnorm": "1.939", "train_wall": "79", "wall": "18791"}
2022-11-11 04:37:14 | INFO | train_inner | {"epoch": 7, "update": 6.379, "loss": "3.029", "nll_loss": "1.246", "ppl": "2.37", "wps": "2267.4", "ups": "1.27", "wpb": "1782", "bsz": "32", "num_updates": "9300", "lr": "4.95598e-05", "gnorm": "1.976", "train_wall": "78", "wall": "18870"}
2022-11-11 04:38:33 | INFO | train_inner | {"epoch": 7, "update": 6.447, "loss": "3.019", "nll_loss": "1.233", "ppl": "2.35", "wps": "2284.7", "ups": "1.27", "wpb": "1797.7", "bsz": "32", "num_updates": "9400", "lr": "4.95548e-05", "gnorm": "1.975", "train_wall": "78", "wall": "18948"}
2022-11-11 04:39:51 | INFO | train_inner | {"epoch": 7, "update": 6.516, "loss": "3.016", "nll_loss": "1.23", "ppl": "2.35", "wps": "2243.7", "ups": "1.28", "wpb": "1755.7", "bsz": "32", "num_updates": "9500", "lr": "4.95498e-05", "gnorm": "1.96", "train_wall": "78", "wall": "19027"}
2022-11-11 04:41:10 | INFO | train_inner | {"epoch": 7, "update": 6.584, "loss": "3.014", "nll_loss": "1.228", "ppl": "2.34", "wps": "2254.8", "ups": "1.27", "wpb": "1779.5", "bsz": "32", "num_updates": "9600", "lr": "4.95448e-05", "gnorm": "2.005", "train_wall": "79", "wall": "19106"}
2022-11-11 04:42:29 | INFO | train_inner | {"epoch": 7, "update": 6.653, "loss": "3.006", "nll_loss": "1.218", "ppl": "2.33", "wps": "2261.6", "ups": "1.26", "wpb": "1796.8", "bsz": "32", "num_updates": "9700", "lr": "4.95398e-05", "gnorm": "1.985", "train_wall": "79", "wall": "19185"}
2022-11-11 04:43:48 | INFO | train_inner | {"epoch": 7, "update": 6.722, "loss": "3.034", "nll_loss": "1.251", "ppl": "2.38", "wps": "2252.3", "ups": "1.27", "wpb": "1774.5", "bsz": "32", "num_updates": "9800", "lr": "4.95348e-05", "gnorm": "1.993", "train_wall": "78", "wall": "19264"}
2022-11-11 04:45:10 | INFO | train_inner | {"epoch": 7, "update": 6.79, "loss": "3.017", "nll_loss": "1.232", "ppl": "2.35", "wps": "2200.9", "ups": "1.22", "wpb": "1801.5", "bsz": "32", "num_updates": "9900", "lr": "4.95298e-05", "gnorm": "1.958", "train_wall": "81", "wall": "19346"}
2022-11-11 04:46:35 | INFO | train_inner | {"epoch": 7, "update": 6.859, "loss": "3.071", "nll_loss": "1.292", "ppl": "2.45", "wps": "2111.8", "ups": "1.17", "wpb": "1801", "bsz": "32", "num_updates": "10000", "lr": "4.95248e-05", "gnorm": "2.025", "train_wall": "85", "wall": "19431"}
2022-11-11 04:47:54 | INFO | train_inner | {"epoch": 7, "update": 6.927, "loss": "3.003", "nll_loss": "1.215", "ppl": "2.32", "wps": "2255.1", "ups": "1.27", "wpb": "1771.3", "bsz": "32", "num_updates": "10100", "lr": "4.95198e-05", "gnorm": "1.992", "train_wall": "78", "wall": "19509"}
2022-11-11 04:49:12 | INFO | train_inner | {"epoch": 7, "update": 6.996, "loss": "3.03", "nll_loss": "1.247", "ppl": "2.37", "wps": "2259.8", "ups": "1.28", "wpb": "1769.9", "bsz": "32", "num_updates": "10200", "lr": "4.95148e-05", "gnorm": "2.018", "train_wall": "78", "wall": "19588"}
2022-11-11 04:49:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 05:19:04 | INFO | valid | {"epoch": 7, "valid_loss": "3.322", "valid_nll_loss": "1.525", "valid_ppl": "2.88", "valid_bleu": "45.54", "valid_wps": "181", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "10206", "valid_best_bleu": "45.63"}
2022-11-11 05:19:04 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 05:19:24 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 7 @ 10206 updates, score 45.54) (writing took 20.118565955664963 seconds)
2022-11-11 05:19:24 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-11-11 05:19:24 | INFO | train | {"epoch": 7, "train_loss": "3.022", "train_nll_loss": "1.237", "train_ppl": "2.36", "train_wps": "879.6", "train_ups": "0.49", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "10206", "train_lr": "4.95145e-05", "train_gnorm": "1.974", "train_train_wall": "1156", "train_wall": "21400"}
2022-11-11 05:19:24 | INFO | fairseq.trainer | begin training epoch 8
2022-11-11 05:20:38 | INFO | train_inner | {"epoch": 8, "update": 7.064, "loss": "2.862", "nll_loss": "1.053", "ppl": "2.08", "wps": "92.7", "ups": "0.05", "wpb": "1748.9", "bsz": "31.7", "num_updates": "10300", "lr": "4.95098e-05", "gnorm": "1.903", "train_wall": "77", "wall": "21474"}
2022-11-11 05:21:59 | INFO | train_inner | {"epoch": 8, "update": 7.133, "loss": "2.922", "nll_loss": "1.123", "ppl": "2.18", "wps": "2301.8", "ups": "1.24", "wpb": "1857.2", "bsz": "32", "num_updates": "10400", "lr": "4.95048e-05", "gnorm": "1.888", "train_wall": "80", "wall": "21554"}
2022-11-11 05:23:18 | INFO | train_inner | {"epoch": 8, "update": 7.202, "loss": "2.85", "nll_loss": "1.04", "ppl": "2.06", "wps": "2258.7", "ups": "1.27", "wpb": "1785.3", "bsz": "32", "num_updates": "10500", "lr": "4.94997e-05", "gnorm": "1.88", "train_wall": "79", "wall": "21633"}
2022-11-11 05:24:36 | INFO | train_inner | {"epoch": 8, "update": 7.27, "loss": "2.868", "nll_loss": "1.061", "ppl": "2.09", "wps": "2222.5", "ups": "1.28", "wpb": "1732.9", "bsz": "32", "num_updates": "10600", "lr": "4.94947e-05", "gnorm": "1.917", "train_wall": "78", "wall": "21711"}
2022-11-11 05:25:56 | INFO | train_inner | {"epoch": 8, "update": 7.339, "loss": "2.875", "nll_loss": "1.068", "ppl": "2.1", "wps": "2301.8", "ups": "1.25", "wpb": "1840.9", "bsz": "32", "num_updates": "10700", "lr": "4.94897e-05", "gnorm": "1.901", "train_wall": "80", "wall": "21791"}
2022-11-11 05:27:16 | INFO | train_inner | {"epoch": 8, "update": 7.407, "loss": "2.897", "nll_loss": "1.093", "ppl": "2.13", "wps": "2285", "ups": "1.25", "wpb": "1829.4", "bsz": "32", "num_updates": "10800", "lr": "4.94847e-05", "gnorm": "1.916", "train_wall": "80", "wall": "21871"}
2022-11-11 05:28:35 | INFO | train_inner | {"epoch": 8, "update": 7.476, "loss": "2.895", "nll_loss": "1.091", "ppl": "2.13", "wps": "2279.8", "ups": "1.27", "wpb": "1797.2", "bsz": "32", "num_updates": "10900", "lr": "4.94797e-05", "gnorm": "1.901", "train_wall": "78", "wall": "21950"}
2022-11-11 05:29:57 | INFO | train_inner | {"epoch": 8, "update": 7.545, "loss": "2.935", "nll_loss": "1.137", "ppl": "2.2", "wps": "2229.4", "ups": "1.21", "wpb": "1839.2", "bsz": "32", "num_updates": "11000", "lr": "4.94747e-05", "gnorm": "1.928", "train_wall": "82", "wall": "22033"}
2022-11-11 05:31:22 | INFO | train_inner | {"epoch": 8, "update": 7.613, "loss": "2.878", "nll_loss": "1.072", "ppl": "2.1", "wps": "2124.3", "ups": "1.18", "wpb": "1796.4", "bsz": "32", "num_updates": "11100", "lr": "4.94697e-05", "gnorm": "1.912", "train_wall": "84", "wall": "22117"}
2022-11-11 05:32:41 | INFO | train_inner | {"epoch": 8, "update": 7.682, "loss": "2.889", "nll_loss": "1.085", "ppl": "2.12", "wps": "2230.2", "ups": "1.26", "wpb": "1764.6", "bsz": "32", "num_updates": "11200", "lr": "4.94647e-05", "gnorm": "1.931", "train_wall": "79", "wall": "22196"}
2022-11-11 05:33:59 | INFO | train_inner | {"epoch": 8, "update": 7.75, "loss": "2.873", "nll_loss": "1.067", "ppl": "2.09", "wps": "2237.4", "ups": "1.28", "wpb": "1741.3", "bsz": "32", "num_updates": "11300", "lr": "4.94597e-05", "gnorm": "1.939", "train_wall": "77", "wall": "22274"}
2022-11-11 05:35:17 | INFO | train_inner | {"epoch": 8, "update": 7.819, "loss": "2.873", "nll_loss": "1.068", "ppl": "2.1", "wps": "2257", "ups": "1.28", "wpb": "1764.5", "bsz": "32", "num_updates": "11400", "lr": "4.94547e-05", "gnorm": "1.925", "train_wall": "78", "wall": "22352"}
2022-11-11 05:36:35 | INFO | train_inner | {"epoch": 8, "update": 7.888, "loss": "2.889", "nll_loss": "1.084", "ppl": "2.12", "wps": "2238.8", "ups": "1.28", "wpb": "1753", "bsz": "32", "num_updates": "11500", "lr": "4.94497e-05", "gnorm": "1.956", "train_wall": "78", "wall": "22431"}
2022-11-11 05:37:54 | INFO | train_inner | {"epoch": 8, "update": 7.956, "loss": "2.903", "nll_loss": "1.101", "ppl": "2.15", "wps": "2262.1", "ups": "1.27", "wpb": "1787.4", "bsz": "32", "num_updates": "11600", "lr": "4.94447e-05", "gnorm": "1.931", "train_wall": "79", "wall": "22510"}
2022-11-11 05:38:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 06:10:31 | INFO | valid | {"epoch": 8, "valid_loss": "3.27", "valid_nll_loss": "1.465", "valid_ppl": "2.76", "valid_bleu": "48.8", "valid_wps": "169.8", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "11664", "valid_best_bleu": "48.8"}
2022-11-11 06:10:31 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 06:11:08 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 8 @ 11664 updates, score 48.8) (writing took 36.768546876031905 seconds)
2022-11-11 06:11:08 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-11-11 06:11:08 | INFO | train | {"epoch": 8, "train_loss": "2.887", "train_nll_loss": "1.082", "train_ppl": "2.12", "train_wps": "842.1", "train_ups": "0.47", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "11664", "train_lr": "4.94415e-05", "train_gnorm": "1.916", "train_train_wall": "1154", "train_wall": "24504"}
2022-11-11 06:11:08 | INFO | fairseq.trainer | begin training epoch 9
2022-11-11 06:11:35 | INFO | train_inner | {"epoch": 9, "update": 8.025, "loss": "2.818", "nll_loss": "1.005", "ppl": "2.01", "wps": "89.4", "ups": "0.05", "wpb": "1806.8", "bsz": "31.7", "num_updates": "11700", "lr": "4.94397e-05", "gnorm": "1.877", "train_wall": "78", "wall": "24531"}
2022-11-11 06:12:55 | INFO | train_inner | {"epoch": 9, "update": 8.093, "loss": "2.755", "nll_loss": "0.932", "ppl": "1.91", "wps": "2241.9", "ups": "1.26", "wpb": "1778.8", "bsz": "32", "num_updates": "11800", "lr": "4.94347e-05", "gnorm": "1.819", "train_wall": "79", "wall": "24611"}
2022-11-11 06:14:19 | INFO | train_inner | {"epoch": 9, "update": 8.162, "loss": "2.752", "nll_loss": "0.928", "ppl": "1.9", "wps": "2093.3", "ups": "1.19", "wpb": "1755.7", "bsz": "32", "num_updates": "11900", "lr": "4.94297e-05", "gnorm": "1.86", "train_wall": "83", "wall": "24694"}
2022-11-11 06:15:37 | INFO | train_inner | {"epoch": 9, "update": 8.23, "loss": "2.764", "nll_loss": "0.942", "ppl": "1.92", "wps": "2271.2", "ups": "1.27", "wpb": "1787.4", "bsz": "32", "num_updates": "12000", "lr": "4.94247e-05", "gnorm": "1.852", "train_wall": "78", "wall": "24773"}
2022-11-11 06:16:57 | INFO | train_inner | {"epoch": 9, "update": 8.299, "loss": "2.762", "nll_loss": "0.94", "ppl": "1.92", "wps": "2262.9", "ups": "1.25", "wpb": "1807.3", "bsz": "32", "num_updates": "12100", "lr": "4.94197e-05", "gnorm": "1.833", "train_wall": "79", "wall": "24853"}
2022-11-11 06:18:18 | INFO | train_inner | {"epoch": 9, "update": 8.368, "loss": "2.774", "nll_loss": "0.953", "ppl": "1.94", "wps": "2255.6", "ups": "1.24", "wpb": "1825.3", "bsz": "32", "num_updates": "12200", "lr": "4.94147e-05", "gnorm": "1.849", "train_wall": "80", "wall": "24934"}
2022-11-11 06:19:39 | INFO | train_inner | {"epoch": 9, "update": 8.436, "loss": "2.794", "nll_loss": "0.976", "ppl": "1.97", "wps": "2282.8", "ups": "1.24", "wpb": "1836.2", "bsz": "32", "num_updates": "12300", "lr": "4.94097e-05", "gnorm": "1.85", "train_wall": "80", "wall": "25014"}
2022-11-11 06:20:56 | INFO | train_inner | {"epoch": 9, "update": 8.505, "loss": "2.766", "nll_loss": "0.944", "ppl": "1.92", "wps": "2247.6", "ups": "1.28", "wpb": "1749.2", "bsz": "32", "num_updates": "12400", "lr": "4.94047e-05", "gnorm": "1.884", "train_wall": "77", "wall": "25092"}
2022-11-11 06:22:17 | INFO | train_inner | {"epoch": 9, "update": 8.573, "loss": "2.79", "nll_loss": "0.972", "ppl": "1.96", "wps": "2261.1", "ups": "1.24", "wpb": "1830.3", "bsz": "32", "num_updates": "12500", "lr": "4.93997e-05", "gnorm": "1.879", "train_wall": "80", "wall": "25173"}
2022-11-11 06:23:38 | INFO | train_inner | {"epoch": 9, "update": 8.642, "loss": "2.779", "nll_loss": "0.958", "ppl": "1.94", "wps": "2247", "ups": "1.24", "wpb": "1810.4", "bsz": "32", "num_updates": "12600", "lr": "4.93947e-05", "gnorm": "1.899", "train_wall": "80", "wall": "25254"}
2022-11-11 06:24:57 | INFO | train_inner | {"epoch": 9, "update": 8.711, "loss": "2.774", "nll_loss": "0.954", "ppl": "1.94", "wps": "2287.2", "ups": "1.26", "wpb": "1810.3", "bsz": "32", "num_updates": "12700", "lr": "4.93897e-05", "gnorm": "1.852", "train_wall": "79", "wall": "25333"}
2022-11-11 06:26:16 | INFO | train_inner | {"epoch": 9, "update": 8.779, "loss": "2.784", "nll_loss": "0.965", "ppl": "1.95", "wps": "2270.4", "ups": "1.27", "wpb": "1785.8", "bsz": "32", "num_updates": "12800", "lr": "4.93847e-05", "gnorm": "1.87", "train_wall": "78", "wall": "25412"}
2022-11-11 06:27:36 | INFO | train_inner | {"epoch": 9, "update": 8.848, "loss": "2.801", "nll_loss": "0.983", "ppl": "1.98", "wps": "2275.2", "ups": "1.25", "wpb": "1820", "bsz": "32", "num_updates": "12900", "lr": "4.93797e-05", "gnorm": "1.897", "train_wall": "80", "wall": "25492"}
2022-11-11 06:28:54 | INFO | train_inner | {"epoch": 9, "update": 8.916, "loss": "2.767", "nll_loss": "0.946", "ppl": "1.93", "wps": "2217.5", "ups": "1.28", "wpb": "1737.2", "bsz": "32", "num_updates": "13000", "lr": "4.93747e-05", "gnorm": "1.899", "train_wall": "78", "wall": "25570"}
2022-11-11 06:30:14 | INFO | train_inner | {"epoch": 9, "update": 8.985, "loss": "2.802", "nll_loss": "0.985", "ppl": "1.98", "wps": "2262.4", "ups": "1.26", "wpb": "1799.4", "bsz": "32", "num_updates": "13100", "lr": "4.93697e-05", "gnorm": "1.924", "train_wall": "79", "wall": "25649"}
2022-11-11 06:30:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 06:59:44 | INFO | valid | {"epoch": 9, "valid_loss": "3.224", "valid_nll_loss": "1.413", "valid_ppl": "2.66", "valid_bleu": "47.68", "valid_wps": "184.6", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "13122", "valid_best_bleu": "48.8"}
2022-11-11 06:59:44 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 07:00:08 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 9 @ 13122 updates, score 47.68) (writing took 23.631669792812318 seconds)
2022-11-11 07:00:08 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-11-11 07:00:08 | INFO | train | {"epoch": 9, "train_loss": "2.775", "train_nll_loss": "0.954", "train_ppl": "1.94", "train_wps": "889", "train_ups": "0.5", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "13122", "train_lr": "4.93686e-05", "train_gnorm": "1.87", "train_train_wall": "1156", "train_wall": "27444"}
2022-11-11 07:00:08 | INFO | fairseq.trainer | begin training epoch 10
2022-11-11 07:01:11 | INFO | train_inner | {"epoch": 10, "update": 9.053, "loss": "2.7", "nll_loss": "0.866", "ppl": "1.82", "wps": "95.2", "ups": "0.05", "wpb": "1768.3", "bsz": "31.7", "num_updates": "13200", "lr": "4.93647e-05", "gnorm": "1.882", "train_wall": "79", "wall": "27507"}
2022-11-11 07:02:31 | INFO | train_inner | {"epoch": 10, "update": 9.122, "loss": "2.653", "nll_loss": "0.815", "ppl": "1.76", "wps": "2250.3", "ups": "1.24", "wpb": "1808.5", "bsz": "32", "num_updates": "13300", "lr": "4.93597e-05", "gnorm": "1.74", "train_wall": "80", "wall": "27587"}
2022-11-11 07:03:52 | INFO | train_inner | {"epoch": 10, "update": 9.191, "loss": "2.677", "nll_loss": "0.843", "ppl": "1.79", "wps": "2242.4", "ups": "1.24", "wpb": "1815.4", "bsz": "32", "num_updates": "13400", "lr": "4.93547e-05", "gnorm": "1.807", "train_wall": "81", "wall": "27668"}
2022-11-11 07:05:14 | INFO | train_inner | {"epoch": 10, "update": 9.259, "loss": "2.716", "nll_loss": "0.886", "ppl": "1.85", "wps": "2221.8", "ups": "1.22", "wpb": "1821.3", "bsz": "32", "num_updates": "13500", "lr": "4.93497e-05", "gnorm": "1.824", "train_wall": "82", "wall": "27750"}
2022-11-11 07:06:36 | INFO | train_inner | {"epoch": 10, "update": 9.328, "loss": "2.671", "nll_loss": "0.835", "ppl": "1.78", "wps": "2240.3", "ups": "1.23", "wpb": "1822.9", "bsz": "32", "num_updates": "13600", "lr": "4.93447e-05", "gnorm": "1.782", "train_wall": "81", "wall": "27831"}
2022-11-11 07:07:56 | INFO | train_inner | {"epoch": 10, "update": 9.396, "loss": "2.666", "nll_loss": "0.831", "ppl": "1.78", "wps": "2207.2", "ups": "1.24", "wpb": "1773.6", "bsz": "32", "num_updates": "13700", "lr": "4.93397e-05", "gnorm": "1.802", "train_wall": "80", "wall": "27912"}
2022-11-11 07:09:16 | INFO | train_inner | {"epoch": 10, "update": 9.465, "loss": "2.675", "nll_loss": "0.841", "ppl": "1.79", "wps": "2180.8", "ups": "1.24", "wpb": "1753.6", "bsz": "32", "num_updates": "13800", "lr": "4.93347e-05", "gnorm": "1.836", "train_wall": "80", "wall": "27992"}
2022-11-11 07:10:37 | INFO | train_inner | {"epoch": 10, "update": 9.534, "loss": "2.69", "nll_loss": "0.858", "ppl": "1.81", "wps": "2207.8", "ups": "1.24", "wpb": "1776.5", "bsz": "32", "num_updates": "13900", "lr": "4.93297e-05", "gnorm": "1.836", "train_wall": "80", "wall": "28073"}
2022-11-11 07:11:58 | INFO | train_inner | {"epoch": 10, "update": 9.602, "loss": "2.695", "nll_loss": "0.863", "ppl": "1.82", "wps": "2226.1", "ups": "1.24", "wpb": "1797.5", "bsz": "32", "num_updates": "14000", "lr": "4.93247e-05", "gnorm": "1.822", "train_wall": "80", "wall": "28153"}
2022-11-11 07:13:19 | INFO | train_inner | {"epoch": 10, "update": 9.671, "loss": "2.701", "nll_loss": "0.87", "ppl": "1.83", "wps": "2226.8", "ups": "1.22", "wpb": "1818.4", "bsz": "32", "num_updates": "14100", "lr": "4.93197e-05", "gnorm": "1.828", "train_wall": "81", "wall": "28235"}
2022-11-11 07:14:41 | INFO | train_inner | {"epoch": 10, "update": 9.739, "loss": "2.703", "nll_loss": "0.872", "ppl": "1.83", "wps": "2235", "ups": "1.22", "wpb": "1828.8", "bsz": "32", "num_updates": "14200", "lr": "4.93147e-05", "gnorm": "1.841", "train_wall": "81", "wall": "28317"}
2022-11-11 07:16:02 | INFO | train_inner | {"epoch": 10, "update": 9.808, "loss": "2.692", "nll_loss": "0.859", "ppl": "1.81", "wps": "2211.9", "ups": "1.23", "wpb": "1801.2", "bsz": "32", "num_updates": "14300", "lr": "4.93097e-05", "gnorm": "1.842", "train_wall": "81", "wall": "28398"}
2022-11-11 07:17:23 | INFO | train_inner | {"epoch": 10, "update": 9.877, "loss": "2.673", "nll_loss": "0.839", "ppl": "1.79", "wps": "2183.8", "ups": "1.25", "wpb": "1748.9", "bsz": "32", "num_updates": "14400", "lr": "4.93047e-05", "gnorm": "1.829", "train_wall": "80", "wall": "28478"}
2022-11-11 07:18:43 | INFO | train_inner | {"epoch": 10, "update": 9.945, "loss": "2.681", "nll_loss": "0.847", "ppl": "1.8", "wps": "2182.7", "ups": "1.25", "wpb": "1752.1", "bsz": "32", "num_updates": "14500", "lr": "4.92996e-05", "gnorm": "1.842", "train_wall": "80", "wall": "28559"}
2022-11-11 07:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 07:48:17 | INFO | valid | {"epoch": 10, "valid_loss": "3.222", "valid_nll_loss": "1.403", "valid_ppl": "2.65", "valid_bleu": "48.85", "valid_wps": "189.3", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "14580", "valid_best_bleu": "48.85"}
2022-11-11 07:48:17 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 07:48:55 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 10 @ 14580 updates, score 48.85) (writing took 37.69378918921575 seconds)
2022-11-11 07:48:55 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-11-11 07:48:55 | INFO | train | {"epoch": 10, "train_loss": "2.683", "train_nll_loss": "0.849", "train_ppl": "1.8", "train_wps": "892.9", "train_ups": "0.5", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "14580", "train_lr": "4.92956e-05", "train_gnorm": "1.818", "train_train_wall": "1172", "train_wall": "30371"}
2022-11-11 07:48:55 | INFO | fairseq.trainer | begin training epoch 11
2022-11-11 07:49:11 | INFO | train_inner | {"epoch": 11, "update": 10.014, "loss": "2.663", "nll_loss": "0.828", "ppl": "1.77", "wps": "97.3", "ups": "0.05", "wpb": "1779.4", "bsz": "31.7", "num_updates": "14600", "lr": "4.92946e-05", "gnorm": "1.818", "train_wall": "79", "wall": "30387"}
2022-11-11 07:50:32 | INFO | train_inner | {"epoch": 11, "update": 10.082, "loss": "2.6", "nll_loss": "0.754", "ppl": "1.69", "wps": "2215.8", "ups": "1.23", "wpb": "1799.2", "bsz": "32", "num_updates": "14700", "lr": "4.92896e-05", "gnorm": "1.726", "train_wall": "81", "wall": "30468"}
2022-11-11 07:51:53 | INFO | train_inner | {"epoch": 11, "update": 10.151, "loss": "2.609", "nll_loss": "0.764", "ppl": "1.7", "wps": "2220.2", "ups": "1.23", "wpb": "1805.2", "bsz": "32", "num_updates": "14800", "lr": "4.92846e-05", "gnorm": "1.779", "train_wall": "81", "wall": "30549"}
2022-11-11 07:53:15 | INFO | train_inner | {"epoch": 11, "update": 10.219, "loss": "2.604", "nll_loss": "0.759", "ppl": "1.69", "wps": "2246.9", "ups": "1.23", "wpb": "1832.7", "bsz": "32", "num_updates": "14900", "lr": "4.92796e-05", "gnorm": "1.745", "train_wall": "81", "wall": "30631"}
2022-11-11 07:54:35 | INFO | train_inner | {"epoch": 11, "update": 10.288, "loss": "2.584", "nll_loss": "0.737", "ppl": "1.67", "wps": "2227.4", "ups": "1.25", "wpb": "1786.6", "bsz": "32", "num_updates": "15000", "lr": "4.92746e-05", "gnorm": "1.788", "train_wall": "80", "wall": "30711"}
2022-11-11 07:55:57 | INFO | train_inner | {"epoch": 11, "update": 10.357, "loss": "2.611", "nll_loss": "0.767", "ppl": "1.7", "wps": "2246.3", "ups": "1.23", "wpb": "1828.3", "bsz": "32", "num_updates": "15100", "lr": "4.92696e-05", "gnorm": "1.798", "train_wall": "81", "wall": "30792"}
2022-11-11 07:57:16 | INFO | train_inner | {"epoch": 11, "update": 10.425, "loss": "2.581", "nll_loss": "0.735", "ppl": "1.66", "wps": "2184.2", "ups": "1.26", "wpb": "1736.5", "bsz": "32", "num_updates": "15200", "lr": "4.92646e-05", "gnorm": "1.774", "train_wall": "79", "wall": "30872"}
2022-11-11 07:58:37 | INFO | train_inner | {"epoch": 11, "update": 10.494, "loss": "2.597", "nll_loss": "0.751", "ppl": "1.68", "wps": "2253.8", "ups": "1.24", "wpb": "1814.6", "bsz": "32", "num_updates": "15300", "lr": "4.92596e-05", "gnorm": "1.761", "train_wall": "80", "wall": "30952"}
2022-11-11 07:59:59 | INFO | train_inner | {"epoch": 11, "update": 10.562, "loss": "2.599", "nll_loss": "0.754", "ppl": "1.69", "wps": "2286.7", "ups": "1.22", "wpb": "1880.7", "bsz": "32", "num_updates": "15400", "lr": "4.92546e-05", "gnorm": "1.755", "train_wall": "82", "wall": "31035"}
2022-11-11 08:01:18 | INFO | train_inner | {"epoch": 11, "update": 10.631, "loss": "2.596", "nll_loss": "0.751", "ppl": "1.68", "wps": "2241.8", "ups": "1.27", "wpb": "1764.7", "bsz": "32", "num_updates": "15500", "lr": "4.92496e-05", "gnorm": "1.772", "train_wall": "78", "wall": "31113"}
2022-11-11 08:02:36 | INFO | train_inner | {"epoch": 11, "update": 10.7, "loss": "2.594", "nll_loss": "0.748", "ppl": "1.68", "wps": "2237", "ups": "1.27", "wpb": "1757.1", "bsz": "32", "num_updates": "15600", "lr": "4.92446e-05", "gnorm": "1.807", "train_wall": "78", "wall": "31192"}
2022-11-11 08:03:56 | INFO | train_inner | {"epoch": 11, "update": 10.768, "loss": "2.618", "nll_loss": "0.776", "ppl": "1.71", "wps": "2258", "ups": "1.25", "wpb": "1809.2", "bsz": "32", "num_updates": "15700", "lr": "4.92396e-05", "gnorm": "1.799", "train_wall": "80", "wall": "31272"}
2022-11-11 08:05:17 | INFO | train_inner | {"epoch": 11, "update": 10.837, "loss": "2.617", "nll_loss": "0.776", "ppl": "1.71", "wps": "2211.7", "ups": "1.24", "wpb": "1779.7", "bsz": "32", "num_updates": "15800", "lr": "4.92346e-05", "gnorm": "1.818", "train_wall": "80", "wall": "31352"}
2022-11-11 08:06:35 | INFO | train_inner | {"epoch": 11, "update": 10.905, "loss": "2.638", "nll_loss": "0.799", "ppl": "1.74", "wps": "2253.5", "ups": "1.27", "wpb": "1773.8", "bsz": "32", "num_updates": "15900", "lr": "4.92296e-05", "gnorm": "1.827", "train_wall": "78", "wall": "31431"}
2022-11-11 08:07:54 | INFO | train_inner | {"epoch": 11, "update": 10.974, "loss": "2.63", "nll_loss": "0.791", "ppl": "1.73", "wps": "2229.9", "ups": "1.27", "wpb": "1755.7", "bsz": "32", "num_updates": "16000", "lr": "4.92246e-05", "gnorm": "1.832", "train_wall": "78", "wall": "31510"}
2022-11-11 08:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 08:37:29 | INFO | valid | {"epoch": 11, "valid_loss": "3.211", "valid_nll_loss": "1.39", "valid_ppl": "2.62", "valid_bleu": "50.42", "valid_wps": "185.4", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "16038", "valid_best_bleu": "50.42"}
2022-11-11 08:37:29 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 08:38:05 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 11 @ 16038 updates, score 50.42) (writing took 36.309797478839755 seconds)
2022-11-11 08:38:05 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-11-11 08:38:05 | INFO | train | {"epoch": 11, "train_loss": "2.605", "train_nll_loss": "0.761", "train_ppl": "1.69", "train_wps": "885.8", "train_ups": "0.49", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "16038", "train_lr": "4.92227e-05", "train_gnorm": "1.786", "train_train_wall": "1162", "train_wall": "33321"}
2022-11-11 08:38:05 | INFO | fairseq.trainer | begin training epoch 12
2022-11-11 08:38:53 | INFO | train_inner | {"epoch": 12, "update": 11.043, "loss": "2.553", "nll_loss": "0.701", "ppl": "1.63", "wps": "92", "ups": "0.05", "wpb": "1710.3", "bsz": "31.7", "num_updates": "16100", "lr": "4.92196e-05", "gnorm": "1.778", "train_wall": "77", "wall": "33369"}
2022-11-11 08:40:12 | INFO | train_inner | {"epoch": 12, "update": 11.111, "loss": "2.517", "nll_loss": "0.66", "ppl": "1.58", "wps": "2298.9", "ups": "1.26", "wpb": "1821.1", "bsz": "32", "num_updates": "16200", "lr": "4.92146e-05", "gnorm": "1.647", "train_wall": "79", "wall": "33448"}
2022-11-11 08:41:30 | INFO | train_inner | {"epoch": 12, "update": 11.18, "loss": "2.503", "nll_loss": "0.646", "ppl": "1.56", "wps": "2235.7", "ups": "1.29", "wpb": "1734.2", "bsz": "32", "num_updates": "16300", "lr": "4.92096e-05", "gnorm": "1.68", "train_wall": "77", "wall": "33526"}
2022-11-11 08:42:48 | INFO | train_inner | {"epoch": 12, "update": 11.248, "loss": "2.518", "nll_loss": "0.662", "ppl": "1.58", "wps": "2254.8", "ups": "1.28", "wpb": "1758.1", "bsz": "32", "num_updates": "16400", "lr": "4.92046e-05", "gnorm": "1.71", "train_wall": "78", "wall": "33604"}
2022-11-11 08:44:07 | INFO | train_inner | {"epoch": 12, "update": 11.317, "loss": "2.533", "nll_loss": "0.678", "ppl": "1.6", "wps": "2272.1", "ups": "1.27", "wpb": "1793.6", "bsz": "32", "num_updates": "16500", "lr": "4.91996e-05", "gnorm": "1.74", "train_wall": "79", "wall": "33683"}
2022-11-11 08:45:28 | INFO | train_inner | {"epoch": 12, "update": 11.385, "loss": "2.607", "nll_loss": "0.762", "ppl": "1.7", "wps": "2318.8", "ups": "1.23", "wpb": "1879.8", "bsz": "32", "num_updates": "16600", "lr": "4.91946e-05", "gnorm": "1.774", "train_wall": "81", "wall": "33764"}
2022-11-11 08:46:47 | INFO | train_inner | {"epoch": 12, "update": 11.454, "loss": "2.521", "nll_loss": "0.666", "ppl": "1.59", "wps": "2297.2", "ups": "1.26", "wpb": "1819.5", "bsz": "32", "num_updates": "16700", "lr": "4.91896e-05", "gnorm": "1.684", "train_wall": "79", "wall": "33843"}
2022-11-11 08:48:06 | INFO | train_inner | {"epoch": 12, "update": 11.523, "loss": "2.541", "nll_loss": "0.688", "ppl": "1.61", "wps": "2208.6", "ups": "1.27", "wpb": "1738.5", "bsz": "32", "num_updates": "16800", "lr": "4.91846e-05", "gnorm": "1.771", "train_wall": "78", "wall": "33922"}
2022-11-11 08:49:25 | INFO | train_inner | {"epoch": 12, "update": 11.591, "loss": "2.547", "nll_loss": "0.695", "ppl": "1.62", "wps": "2266.7", "ups": "1.26", "wpb": "1795.3", "bsz": "32", "num_updates": "16900", "lr": "4.91796e-05", "gnorm": "1.76", "train_wall": "79", "wall": "34001"}
2022-11-11 08:50:45 | INFO | train_inner | {"epoch": 12, "update": 11.66, "loss": "2.535", "nll_loss": "0.682", "ppl": "1.6", "wps": "2277.9", "ups": "1.25", "wpb": "1815.9", "bsz": "32", "num_updates": "17000", "lr": "4.91746e-05", "gnorm": "1.714", "train_wall": "79", "wall": "34080"}
2022-11-11 08:52:04 | INFO | train_inner | {"epoch": 12, "update": 11.728, "loss": "2.537", "nll_loss": "0.685", "ppl": "1.61", "wps": "2288", "ups": "1.26", "wpb": "1821.6", "bsz": "32", "num_updates": "17100", "lr": "4.91696e-05", "gnorm": "1.737", "train_wall": "79", "wall": "34160"}
2022-11-11 08:53:23 | INFO | train_inner | {"epoch": 12, "update": 11.797, "loss": "2.553", "nll_loss": "0.702", "ppl": "1.63", "wps": "2260.7", "ups": "1.27", "wpb": "1780.8", "bsz": "32", "num_updates": "17200", "lr": "4.91646e-05", "gnorm": "1.767", "train_wall": "78", "wall": "34239"}
2022-11-11 08:54:42 | INFO | train_inner | {"epoch": 12, "update": 11.866, "loss": "2.557", "nll_loss": "0.707", "ppl": "1.63", "wps": "2273.8", "ups": "1.26", "wpb": "1803.4", "bsz": "32", "num_updates": "17300", "lr": "4.91596e-05", "gnorm": "1.76", "train_wall": "79", "wall": "34318"}
2022-11-11 08:56:02 | INFO | train_inner | {"epoch": 12, "update": 11.934, "loss": "2.565", "nll_loss": "0.716", "ppl": "1.64", "wps": "2245.6", "ups": "1.26", "wpb": "1778.3", "bsz": "32", "num_updates": "17400", "lr": "4.91546e-05", "gnorm": "1.792", "train_wall": "79", "wall": "34397"}
2022-11-11 08:57:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 09:26:43 | INFO | valid | {"epoch": 12, "valid_loss": "3.192", "valid_nll_loss": "1.357", "valid_ppl": "2.56", "valid_bleu": "51.77", "valid_wps": "183.4", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "17496", "valid_best_bleu": "51.77"}
2022-11-11 09:26:43 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 09:27:20 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 12 @ 17496 updates, score 51.77) (writing took 37.0949957431294 seconds)
2022-11-11 09:27:20 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-11-11 09:27:20 | INFO | train | {"epoch": 12, "train_loss": "2.542", "train_nll_loss": "0.689", "train_ppl": "1.61", "train_wps": "884.7", "train_ups": "0.49", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "17496", "train_lr": "4.91498e-05", "train_gnorm": "1.736", "train_train_wall": "1146", "train_wall": "36276"}
2022-11-11 09:27:20 | INFO | fairseq.trainer | begin training epoch 13
2022-11-11 09:27:23 | INFO | train_inner | {"epoch": 13, "update": 12.003, "loss": "2.558", "nll_loss": "0.709", "ppl": "1.63", "wps": "96.3", "ups": "0.05", "wpb": "1811.6", "bsz": "31.7", "num_updates": "17500", "lr": "4.91496e-05", "gnorm": "1.777", "train_wall": "79", "wall": "36279"}
2022-11-11 09:28:43 | INFO | train_inner | {"epoch": 13, "update": 12.071, "loss": "2.457", "nll_loss": "0.593", "ppl": "1.51", "wps": "2179.3", "ups": "1.26", "wpb": "1736.4", "bsz": "32", "num_updates": "17600", "lr": "4.91446e-05", "gnorm": "1.632", "train_wall": "79", "wall": "36358"}
2022-11-11 09:30:02 | INFO | train_inner | {"epoch": 13, "update": 12.14, "loss": "2.467", "nll_loss": "0.604", "ppl": "1.52", "wps": "2225.5", "ups": "1.26", "wpb": "1772.2", "bsz": "32", "num_updates": "17700", "lr": "4.91396e-05", "gnorm": "1.652", "train_wall": "79", "wall": "36438"}
2022-11-11 09:31:21 | INFO | train_inner | {"epoch": 13, "update": 12.209, "loss": "2.47", "nll_loss": "0.608", "ppl": "1.52", "wps": "2214.5", "ups": "1.27", "wpb": "1747.1", "bsz": "32", "num_updates": "17800", "lr": "4.91346e-05", "gnorm": "1.67", "train_wall": "78", "wall": "36517"}
2022-11-11 09:32:42 | INFO | train_inner | {"epoch": 13, "update": 12.277, "loss": "2.474", "nll_loss": "0.612", "ppl": "1.53", "wps": "2237.3", "ups": "1.24", "wpb": "1806", "bsz": "32", "num_updates": "17900", "lr": "4.91296e-05", "gnorm": "1.688", "train_wall": "80", "wall": "36598"}
2022-11-11 09:34:02 | INFO | train_inner | {"epoch": 13, "update": 12.346, "loss": "2.471", "nll_loss": "0.609", "ppl": "1.53", "wps": "2221.6", "ups": "1.25", "wpb": "1771.5", "bsz": "32", "num_updates": "18000", "lr": "4.91246e-05", "gnorm": "1.667", "train_wall": "79", "wall": "36677"}
2022-11-11 09:35:22 | INFO | train_inner | {"epoch": 13, "update": 12.414, "loss": "2.46", "nll_loss": "0.596", "ppl": "1.51", "wps": "2218.3", "ups": "1.25", "wpb": "1773", "bsz": "32", "num_updates": "18100", "lr": "4.91196e-05", "gnorm": "1.645", "train_wall": "80", "wall": "36757"}
2022-11-11 09:36:42 | INFO | train_inner | {"epoch": 13, "update": 12.483, "loss": "2.483", "nll_loss": "0.622", "ppl": "1.54", "wps": "2269.3", "ups": "1.24", "wpb": "1826.7", "bsz": "32", "num_updates": "18200", "lr": "4.91146e-05", "gnorm": "1.716", "train_wall": "80", "wall": "36838"}
2022-11-11 09:38:01 | INFO | train_inner | {"epoch": 13, "update": 12.551, "loss": "2.47", "nll_loss": "0.608", "ppl": "1.52", "wps": "2256.8", "ups": "1.26", "wpb": "1793.9", "bsz": "32", "num_updates": "18300", "lr": "4.91096e-05", "gnorm": "1.684", "train_wall": "79", "wall": "36917"}
2022-11-11 09:39:20 | INFO | train_inner | {"epoch": 13, "update": 12.62, "loss": "2.481", "nll_loss": "0.621", "ppl": "1.54", "wps": "2262.3", "ups": "1.27", "wpb": "1787.3", "bsz": "32", "num_updates": "18400", "lr": "4.91046e-05", "gnorm": "1.684", "train_wall": "79", "wall": "36996"}
2022-11-11 09:40:40 | INFO | train_inner | {"epoch": 13, "update": 12.689, "loss": "2.483", "nll_loss": "0.624", "ppl": "1.54", "wps": "2274.4", "ups": "1.26", "wpb": "1808.1", "bsz": "32", "num_updates": "18500", "lr": "4.90995e-05", "gnorm": "1.69", "train_wall": "79", "wall": "37076"}
2022-11-11 09:42:01 | INFO | train_inner | {"epoch": 13, "update": 12.757, "loss": "2.544", "nll_loss": "0.693", "ppl": "1.62", "wps": "2284.6", "ups": "1.23", "wpb": "1850.8", "bsz": "32", "num_updates": "18600", "lr": "4.90945e-05", "gnorm": "1.751", "train_wall": "81", "wall": "37157"}
2022-11-11 09:43:20 | INFO | train_inner | {"epoch": 13, "update": 12.826, "loss": "2.492", "nll_loss": "0.634", "ppl": "1.55", "wps": "2230.1", "ups": "1.27", "wpb": "1758.2", "bsz": "32", "num_updates": "18700", "lr": "4.90895e-05", "gnorm": "1.745", "train_wall": "78", "wall": "37236"}
2022-11-11 09:44:41 | INFO | train_inner | {"epoch": 13, "update": 12.894, "loss": "2.519", "nll_loss": "0.664", "ppl": "1.58", "wps": "2301.5", "ups": "1.24", "wpb": "1862", "bsz": "32", "num_updates": "18800", "lr": "4.90845e-05", "gnorm": "1.722", "train_wall": "81", "wall": "37317"}
2022-11-11 09:46:01 | INFO | train_inner | {"epoch": 13, "update": 12.963, "loss": "2.517", "nll_loss": "0.662", "ppl": "1.58", "wps": "2268.3", "ups": "1.25", "wpb": "1812.8", "bsz": "32", "num_updates": "18900", "lr": "4.90795e-05", "gnorm": "1.739", "train_wall": "79", "wall": "37396"}
2022-11-11 09:46:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 10:15:08 | INFO | valid | {"epoch": 13, "valid_loss": "3.197", "valid_nll_loss": "1.375", "valid_ppl": "2.59", "valid_bleu": "50.42", "valid_wps": "189.9", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "18954", "valid_best_bleu": "51.77"}
2022-11-11 10:15:08 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 10:15:31 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 13 @ 18954 updates, score 50.42) (writing took 23.630184531211853 seconds)
2022-11-11 10:15:31 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-11-11 10:15:31 | INFO | train | {"epoch": 13, "train_loss": "2.487", "train_nll_loss": "0.628", "train_ppl": "1.55", "train_wps": "903.9", "train_ups": "0.5", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "18954", "train_lr": "4.90768e-05", "train_gnorm": "1.696", "train_train_wall": "1157", "train_wall": "39167"}
2022-11-11 10:15:31 | INFO | fairseq.trainer | begin training epoch 14
2022-11-11 10:16:10 | INFO | train_inner | {"epoch": 14, "update": 13.032, "loss": "2.493", "nll_loss": "0.634", "ppl": "1.55", "wps": "100.3", "ups": "0.06", "wpb": "1814.9", "bsz": "31.7", "num_updates": "19000", "lr": "4.90745e-05", "gnorm": "1.719", "train_wall": "81", "wall": "39206"}
2022-11-11 10:17:31 | INFO | train_inner | {"epoch": 14, "update": 13.1, "loss": "2.426", "nll_loss": "0.558", "ppl": "1.47", "wps": "2267.3", "ups": "1.23", "wpb": "1837.3", "bsz": "32", "num_updates": "19100", "lr": "4.90695e-05", "gnorm": "1.584", "train_wall": "81", "wall": "39287"}
2022-11-11 10:18:52 | INFO | train_inner | {"epoch": 14, "update": 13.169, "loss": "2.426", "nll_loss": "0.558", "ppl": "1.47", "wps": "2181.7", "ups": "1.23", "wpb": "1769.9", "bsz": "32", "num_updates": "19200", "lr": "4.90645e-05", "gnorm": "1.621", "train_wall": "81", "wall": "39368"}
2022-11-11 10:20:12 | INFO | train_inner | {"epoch": 14, "update": 13.237, "loss": "2.418", "nll_loss": "0.55", "ppl": "1.46", "wps": "2235.2", "ups": "1.25", "wpb": "1785.2", "bsz": "32", "num_updates": "19300", "lr": "4.90595e-05", "gnorm": "1.626", "train_wall": "79", "wall": "39448"}
2022-11-11 10:21:33 | INFO | train_inner | {"epoch": 14, "update": 13.306, "loss": "2.428", "nll_loss": "0.561", "ppl": "1.47", "wps": "2223.5", "ups": "1.25", "wpb": "1784.5", "bsz": "32", "num_updates": "19400", "lr": "4.90545e-05", "gnorm": "1.631", "train_wall": "80", "wall": "39528"}
2022-11-11 10:22:54 | INFO | train_inner | {"epoch": 14, "update": 13.374, "loss": "2.42", "nll_loss": "0.553", "ppl": "1.47", "wps": "2134.4", "ups": "1.22", "wpb": "1745.6", "bsz": "32", "num_updates": "19500", "lr": "4.90495e-05", "gnorm": "1.663", "train_wall": "81", "wall": "39610"}
2022-11-11 10:24:19 | INFO | train_inner | {"epoch": 14, "update": 13.443, "loss": "2.438", "nll_loss": "0.572", "ppl": "1.49", "wps": "2115.7", "ups": "1.19", "wpb": "1785.1", "bsz": "32", "num_updates": "19600", "lr": "4.90445e-05", "gnorm": "1.673", "train_wall": "84", "wall": "39695"}
2022-11-11 10:25:39 | INFO | train_inner | {"epoch": 14, "update": 13.512, "loss": "2.448", "nll_loss": "0.584", "ppl": "1.5", "wps": "2256.7", "ups": "1.24", "wpb": "1812.7", "bsz": "32", "num_updates": "19700", "lr": "4.90395e-05", "gnorm": "1.644", "train_wall": "80", "wall": "39775"}
2022-11-11 10:26:59 | INFO | train_inner | {"epoch": 14, "update": 13.58, "loss": "2.442", "nll_loss": "0.576", "ppl": "1.49", "wps": "2198.3", "ups": "1.25", "wpb": "1759.7", "bsz": "32", "num_updates": "19800", "lr": "4.90345e-05", "gnorm": "1.691", "train_wall": "80", "wall": "39855"}
2022-11-11 10:28:20 | INFO | train_inner | {"epoch": 14, "update": 13.649, "loss": "2.445", "nll_loss": "0.579", "ppl": "1.49", "wps": "2228.1", "ups": "1.24", "wpb": "1795.3", "bsz": "32", "num_updates": "19900", "lr": "4.90295e-05", "gnorm": "1.672", "train_wall": "80", "wall": "39935"}
2022-11-11 10:29:40 | INFO | train_inner | {"epoch": 14, "update": 13.717, "loss": "2.448", "nll_loss": "0.584", "ppl": "1.5", "wps": "2230", "ups": "1.24", "wpb": "1801.6", "bsz": "32", "num_updates": "20000", "lr": "4.90245e-05", "gnorm": "1.675", "train_wall": "80", "wall": "40016"}
2022-11-11 10:31:04 | INFO | train_inner | {"epoch": 14, "update": 13.786, "loss": "2.498", "nll_loss": "0.64", "ppl": "1.56", "wps": "2193.9", "ups": "1.19", "wpb": "1839.5", "bsz": "32", "num_updates": "20100", "lr": "4.90195e-05", "gnorm": "1.695", "train_wall": "83", "wall": "40100"}
2022-11-11 10:32:30 | INFO | train_inner | {"epoch": 14, "update": 13.855, "loss": "2.454", "nll_loss": "0.592", "ppl": "1.51", "wps": "2092.3", "ups": "1.17", "wpb": "1792.8", "bsz": "32", "num_updates": "20200", "lr": "4.90145e-05", "gnorm": "1.72", "train_wall": "85", "wall": "40186"}
2022-11-11 10:33:56 | INFO | train_inner | {"epoch": 14, "update": 13.923, "loss": "2.44", "nll_loss": "0.574", "ppl": "1.49", "wps": "2106.3", "ups": "1.17", "wpb": "1807.7", "bsz": "32", "num_updates": "20300", "lr": "4.90095e-05", "gnorm": "1.698", "train_wall": "85", "wall": "40272"}
2022-11-11 10:35:20 | INFO | train_inner | {"epoch": 14, "update": 13.992, "loss": "2.442", "nll_loss": "0.578", "ppl": "1.49", "wps": "2146.8", "ups": "1.19", "wpb": "1796.6", "bsz": "32", "num_updates": "20400", "lr": "4.90045e-05", "gnorm": "1.657", "train_wall": "83", "wall": "40355"}
2022-11-11 10:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 11:04:10 | INFO | valid | {"epoch": 14, "valid_loss": "3.213", "valid_nll_loss": "1.373", "valid_ppl": "2.59", "valid_bleu": "50.27", "valid_wps": "188", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "20412", "valid_best_bleu": "51.77"}
2022-11-11 11:04:10 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 11:04:31 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 14 @ 20412 updates, score 50.27) (writing took 20.80110387597233 seconds)
2022-11-11 11:04:31 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-11-11 11:04:31 | INFO | train | {"epoch": 14, "train_loss": "2.441", "train_nll_loss": "0.576", "train_ppl": "1.49", "train_wps": "889.1", "train_ups": "0.5", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "20412", "train_lr": "4.90039e-05", "train_gnorm": "1.662", "train_train_wall": "1190", "train_wall": "42107"}
2022-11-11 11:04:31 | INFO | fairseq.trainer | begin training epoch 15
2022-11-11 11:05:41 | INFO | train_inner | {"epoch": 15, "update": 14.06, "loss": "2.39", "nll_loss": "0.517", "ppl": "1.43", "wps": "96.3", "ups": "0.05", "wpb": "1754", "bsz": "31.7", "num_updates": "20500", "lr": "4.89995e-05", "gnorm": "1.611", "train_wall": "78", "wall": "42177"}
2022-11-11 11:07:01 | INFO | train_inner | {"epoch": 15, "update": 14.129, "loss": "2.395", "nll_loss": "0.524", "ppl": "1.44", "wps": "2267.6", "ups": "1.25", "wpb": "1817.9", "bsz": "32", "num_updates": "20600", "lr": "4.89945e-05", "gnorm": "1.561", "train_wall": "80", "wall": "42257"}
2022-11-11 11:08:19 | INFO | train_inner | {"epoch": 15, "update": 14.198, "loss": "2.384", "nll_loss": "0.512", "ppl": "1.43", "wps": "2210.3", "ups": "1.28", "wpb": "1727.5", "bsz": "32", "num_updates": "20700", "lr": "4.89895e-05", "gnorm": "1.604", "train_wall": "78", "wall": "42335"}
2022-11-11 11:09:40 | INFO | train_inner | {"epoch": 15, "update": 14.266, "loss": "2.391", "nll_loss": "0.519", "ppl": "1.43", "wps": "2254.2", "ups": "1.24", "wpb": "1813.8", "bsz": "32", "num_updates": "20800", "lr": "4.89845e-05", "gnorm": "1.618", "train_wall": "80", "wall": "42415"}
2022-11-11 11:11:00 | INFO | train_inner | {"epoch": 15, "update": 14.335, "loss": "2.388", "nll_loss": "0.516", "ppl": "1.43", "wps": "2271.6", "ups": "1.25", "wpb": "1815.2", "bsz": "32", "num_updates": "20900", "lr": "4.89795e-05", "gnorm": "1.595", "train_wall": "79", "wall": "42495"}
2022-11-11 11:12:18 | INFO | train_inner | {"epoch": 15, "update": 14.403, "loss": "2.387", "nll_loss": "0.515", "ppl": "1.43", "wps": "2213.8", "ups": "1.27", "wpb": "1747.1", "bsz": "32", "num_updates": "21000", "lr": "4.89745e-05", "gnorm": "1.619", "train_wall": "78", "wall": "42574"}
2022-11-11 11:13:40 | INFO | train_inner | {"epoch": 15, "update": 14.472, "loss": "2.402", "nll_loss": "0.532", "ppl": "1.45", "wps": "2219.2", "ups": "1.23", "wpb": "1804.4", "bsz": "32", "num_updates": "21100", "lr": "4.89695e-05", "gnorm": "1.627", "train_wall": "81", "wall": "42656"}
2022-11-11 11:15:01 | INFO | train_inner | {"epoch": 15, "update": 14.54, "loss": "2.411", "nll_loss": "0.542", "ppl": "1.46", "wps": "2175.1", "ups": "1.24", "wpb": "1757.1", "bsz": "32", "num_updates": "21200", "lr": "4.89645e-05", "gnorm": "1.676", "train_wall": "80", "wall": "42736"}
2022-11-11 11:16:21 | INFO | train_inner | {"epoch": 15, "update": 14.609, "loss": "2.4", "nll_loss": "0.531", "ppl": "1.44", "wps": "2196.4", "ups": "1.24", "wpb": "1766.7", "bsz": "32", "num_updates": "21300", "lr": "4.89595e-05", "gnorm": "1.63", "train_wall": "80", "wall": "42817"}
2022-11-11 11:17:43 | INFO | train_inner | {"epoch": 15, "update": 14.678, "loss": "2.414", "nll_loss": "0.545", "ppl": "1.46", "wps": "2252.3", "ups": "1.23", "wpb": "1835.8", "bsz": "32", "num_updates": "21400", "lr": "4.89545e-05", "gnorm": "1.634", "train_wall": "81", "wall": "42898"}
2022-11-11 11:19:04 | INFO | train_inner | {"epoch": 15, "update": 14.746, "loss": "2.426", "nll_loss": "0.559", "ppl": "1.47", "wps": "2260.3", "ups": "1.23", "wpb": "1844.2", "bsz": "32", "num_updates": "21500", "lr": "4.89495e-05", "gnorm": "1.684", "train_wall": "81", "wall": "42980"}
2022-11-11 11:20:23 | INFO | train_inner | {"epoch": 15, "update": 14.815, "loss": "2.408", "nll_loss": "0.54", "ppl": "1.45", "wps": "2279.8", "ups": "1.26", "wpb": "1805.8", "bsz": "32", "num_updates": "21600", "lr": "4.89445e-05", "gnorm": "1.617", "train_wall": "79", "wall": "43059"}
2022-11-11 11:21:43 | INFO | train_inner | {"epoch": 15, "update": 14.883, "loss": "2.397", "nll_loss": "0.527", "ppl": "1.44", "wps": "2261.5", "ups": "1.26", "wpb": "1801.1", "bsz": "32", "num_updates": "21700", "lr": "4.89395e-05", "gnorm": "1.633", "train_wall": "79", "wall": "43139"}
2022-11-11 11:23:03 | INFO | train_inner | {"epoch": 15, "update": 14.952, "loss": "2.44", "nll_loss": "0.575", "ppl": "1.49", "wps": "2265.6", "ups": "1.24", "wpb": "1820.3", "bsz": "32", "num_updates": "21800", "lr": "4.89345e-05", "gnorm": "1.662", "train_wall": "80", "wall": "43219"}
2022-11-11 11:23:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 11:53:15 | INFO | valid | {"epoch": 15, "valid_loss": "3.204", "valid_nll_loss": "1.378", "valid_ppl": "2.6", "valid_bleu": "52.78", "valid_wps": "184.2", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "21870", "valid_best_bleu": "52.78"}
2022-11-11 11:53:15 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 11:53:52 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 15 @ 21870 updates, score 52.78) (writing took 37.19818460289389 seconds)
2022-11-11 11:53:52 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-11-11 11:53:52 | INFO | train | {"epoch": 15, "train_loss": "2.403", "train_nll_loss": "0.533", "train_ppl": "1.45", "train_wps": "882.6", "train_ups": "0.49", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "21870", "train_lr": "4.8931e-05", "train_gnorm": "1.628", "train_train_wall": "1160", "train_wall": "45068"}
2022-11-11 11:53:52 | INFO | fairseq.trainer | begin training epoch 16
2022-11-11 11:54:16 | INFO | train_inner | {"epoch": 16, "update": 15.021, "loss": "2.4", "nll_loss": "0.53", "ppl": "1.44", "wps": "91.8", "ups": "0.05", "wpb": "1718.4", "bsz": "31.7", "num_updates": "21900", "lr": "4.89295e-05", "gnorm": "1.698", "train_wall": "78", "wall": "45092"}
2022-11-11 11:55:36 | INFO | train_inner | {"epoch": 16, "update": 15.089, "loss": "2.364", "nll_loss": "0.488", "ppl": "1.4", "wps": "2273.8", "ups": "1.25", "wpb": "1824.6", "bsz": "32", "num_updates": "22000", "lr": "4.89245e-05", "gnorm": "1.551", "train_wall": "80", "wall": "45172"}
2022-11-11 11:56:56 | INFO | train_inner | {"epoch": 16, "update": 15.158, "loss": "2.341", "nll_loss": "0.463", "ppl": "1.38", "wps": "2244.5", "ups": "1.26", "wpb": "1781.9", "bsz": "32", "num_updates": "22100", "lr": "4.89195e-05", "gnorm": "1.528", "train_wall": "79", "wall": "45252"}
2022-11-11 11:58:16 | INFO | train_inner | {"epoch": 16, "update": 15.226, "loss": "2.37", "nll_loss": "0.496", "ppl": "1.41", "wps": "2258.6", "ups": "1.25", "wpb": "1806.7", "bsz": "32", "num_updates": "22200", "lr": "4.89145e-05", "gnorm": "1.571", "train_wall": "80", "wall": "45332"}
2022-11-11 11:59:35 | INFO | train_inner | {"epoch": 16, "update": 15.295, "loss": "2.366", "nll_loss": "0.491", "ppl": "1.41", "wps": "2246.3", "ups": "1.26", "wpb": "1788.9", "bsz": "32", "num_updates": "22300", "lr": "4.89095e-05", "gnorm": "1.558", "train_wall": "79", "wall": "45411"}
2022-11-11 12:00:56 | INFO | train_inner | {"epoch": 16, "update": 15.364, "loss": "2.371", "nll_loss": "0.497", "ppl": "1.41", "wps": "2263.2", "ups": "1.24", "wpb": "1823", "bsz": "32", "num_updates": "22400", "lr": "4.89045e-05", "gnorm": "1.594", "train_wall": "80", "wall": "45492"}
2022-11-11 12:02:15 | INFO | train_inner | {"epoch": 16, "update": 15.432, "loss": "2.358", "nll_loss": "0.483", "ppl": "1.4", "wps": "2237.5", "ups": "1.26", "wpb": "1775.7", "bsz": "32", "num_updates": "22500", "lr": "4.88994e-05", "gnorm": "1.549", "train_wall": "79", "wall": "45571"}
2022-11-11 12:03:36 | INFO | train_inner | {"epoch": 16, "update": 15.501, "loss": "2.364", "nll_loss": "0.489", "ppl": "1.4", "wps": "2248.9", "ups": "1.25", "wpb": "1804.4", "bsz": "32", "num_updates": "22600", "lr": "4.88944e-05", "gnorm": "1.594", "train_wall": "80", "wall": "45651"}
2022-11-11 12:04:55 | INFO | train_inner | {"epoch": 16, "update": 15.569, "loss": "2.362", "nll_loss": "0.488", "ppl": "1.4", "wps": "2275.7", "ups": "1.25", "wpb": "1817.8", "bsz": "32", "num_updates": "22700", "lr": "4.88894e-05", "gnorm": "1.604", "train_wall": "79", "wall": "45731"}
2022-11-11 12:06:16 | INFO | train_inner | {"epoch": 16, "update": 15.638, "loss": "2.372", "nll_loss": "0.499", "ppl": "1.41", "wps": "2258.1", "ups": "1.24", "wpb": "1818.7", "bsz": "32", "num_updates": "22800", "lr": "4.88844e-05", "gnorm": "1.634", "train_wall": "80", "wall": "45812"}
2022-11-11 12:07:35 | INFO | train_inner | {"epoch": 16, "update": 15.706, "loss": "2.407", "nll_loss": "0.539", "ppl": "1.45", "wps": "2218.8", "ups": "1.27", "wpb": "1750.4", "bsz": "32", "num_updates": "22900", "lr": "4.88794e-05", "gnorm": "1.651", "train_wall": "78", "wall": "45891"}
2022-11-11 12:08:54 | INFO | train_inner | {"epoch": 16, "update": 15.775, "loss": "2.363", "nll_loss": "0.489", "ppl": "1.4", "wps": "2235", "ups": "1.27", "wpb": "1760.5", "bsz": "32", "num_updates": "23000", "lr": "4.88744e-05", "gnorm": "1.641", "train_wall": "78", "wall": "45969"}
2022-11-11 12:10:13 | INFO | train_inner | {"epoch": 16, "update": 15.844, "loss": "2.379", "nll_loss": "0.507", "ppl": "1.42", "wps": "2251", "ups": "1.27", "wpb": "1777.4", "bsz": "32", "num_updates": "23100", "lr": "4.88694e-05", "gnorm": "1.661", "train_wall": "79", "wall": "46048"}
2022-11-11 12:11:33 | INFO | train_inner | {"epoch": 16, "update": 15.912, "loss": "2.371", "nll_loss": "0.498", "ppl": "1.41", "wps": "2273.5", "ups": "1.25", "wpb": "1818.8", "bsz": "32", "num_updates": "23200", "lr": "4.88644e-05", "gnorm": "1.626", "train_wall": "80", "wall": "46128"}
2022-11-11 12:12:52 | INFO | train_inner | {"epoch": 16, "update": 15.981, "loss": "2.374", "nll_loss": "0.501", "ppl": "1.42", "wps": "2256.7", "ups": "1.26", "wpb": "1795.7", "bsz": "32", "num_updates": "23300", "lr": "4.88594e-05", "gnorm": "1.652", "train_wall": "79", "wall": "46208"}
2022-11-11 12:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 12:42:08 | INFO | valid | {"epoch": 16, "valid_loss": "3.198", "valid_nll_loss": "1.369", "valid_ppl": "2.58", "valid_bleu": "54.18", "valid_wps": "186.6", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "23328", "valid_best_bleu": "54.18"}
2022-11-11 12:42:08 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 12:42:49 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 16 @ 23328 updates, score 54.18) (writing took 40.824836830142885 seconds)
2022-11-11 12:42:49 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-11-11 12:42:49 | INFO | train | {"epoch": 16, "train_loss": "2.369", "train_nll_loss": "0.495", "train_ppl": "1.41", "train_wps": "889.9", "train_ups": "0.5", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "23328", "train_lr": "4.8858e-05", "train_gnorm": "1.605", "train_train_wall": "1155", "train_wall": "48005"}
2022-11-11 12:42:49 | INFO | fairseq.trainer | begin training epoch 17
2022-11-11 12:43:46 | INFO | train_inner | {"epoch": 17, "update": 16.049, "loss": "2.339", "nll_loss": "0.462", "ppl": "1.38", "wps": "94.9", "ups": "0.05", "wpb": "1759.8", "bsz": "31.7", "num_updates": "23400", "lr": "4.88544e-05", "gnorm": "1.573", "train_wall": "78", "wall": "48062"}
2022-11-11 12:45:06 | INFO | train_inner | {"epoch": 17, "update": 16.118, "loss": "2.322", "nll_loss": "0.442", "ppl": "1.36", "wps": "2292", "ups": "1.25", "wpb": "1835.1", "bsz": "32", "num_updates": "23500", "lr": "4.88494e-05", "gnorm": "1.516", "train_wall": "80", "wall": "48142"}
2022-11-11 12:46:26 | INFO | train_inner | {"epoch": 17, "update": 16.187, "loss": "2.359", "nll_loss": "0.485", "ppl": "1.4", "wps": "2225.6", "ups": "1.26", "wpb": "1761.2", "bsz": "32", "num_updates": "23600", "lr": "4.88444e-05", "gnorm": "1.572", "train_wall": "79", "wall": "48221"}
2022-11-11 12:47:45 | INFO | train_inner | {"epoch": 17, "update": 16.255, "loss": "2.327", "nll_loss": "0.449", "ppl": "1.36", "wps": "2236.8", "ups": "1.27", "wpb": "1767.8", "bsz": "32", "num_updates": "23700", "lr": "4.88394e-05", "gnorm": "1.562", "train_wall": "79", "wall": "48300"}
2022-11-11 12:49:05 | INFO | train_inner | {"epoch": 17, "update": 16.324, "loss": "2.337", "nll_loss": "0.461", "ppl": "1.38", "wps": "2258.4", "ups": "1.25", "wpb": "1806.8", "bsz": "32", "num_updates": "23800", "lr": "4.88344e-05", "gnorm": "1.544", "train_wall": "80", "wall": "48380"}
2022-11-11 12:50:23 | INFO | train_inner | {"epoch": 17, "update": 16.392, "loss": "2.331", "nll_loss": "0.454", "ppl": "1.37", "wps": "2235.6", "ups": "1.27", "wpb": "1758.4", "bsz": "32", "num_updates": "23900", "lr": "4.88294e-05", "gnorm": "1.562", "train_wall": "78", "wall": "48459"}
2022-11-11 12:51:43 | INFO | train_inner | {"epoch": 17, "update": 16.461, "loss": "2.337", "nll_loss": "0.46", "ppl": "1.38", "wps": "2254.5", "ups": "1.25", "wpb": "1808.6", "bsz": "32", "num_updates": "24000", "lr": "4.88244e-05", "gnorm": "1.577", "train_wall": "80", "wall": "48539"}
2022-11-11 12:53:04 | INFO | train_inner | {"epoch": 17, "update": 16.529, "loss": "2.334", "nll_loss": "0.456", "ppl": "1.37", "wps": "2279.8", "ups": "1.24", "wpb": "1834.4", "bsz": "32", "num_updates": "24100", "lr": "4.88194e-05", "gnorm": "1.556", "train_wall": "80", "wall": "48620"}
2022-11-11 12:54:25 | INFO | train_inner | {"epoch": 17, "update": 16.598, "loss": "2.346", "nll_loss": "0.471", "ppl": "1.39", "wps": "2317.1", "ups": "1.23", "wpb": "1887.5", "bsz": "32", "num_updates": "24200", "lr": "4.88144e-05", "gnorm": "1.542", "train_wall": "81", "wall": "48701"}
2022-11-11 12:55:44 | INFO | train_inner | {"epoch": 17, "update": 16.667, "loss": "2.328", "nll_loss": "0.45", "ppl": "1.37", "wps": "2262.2", "ups": "1.27", "wpb": "1781.9", "bsz": "32", "num_updates": "24300", "lr": "4.88094e-05", "gnorm": "1.547", "train_wall": "78", "wall": "48780"}
2022-11-11 12:57:04 | INFO | train_inner | {"epoch": 17, "update": 16.735, "loss": "2.355", "nll_loss": "0.48", "ppl": "1.4", "wps": "2251.2", "ups": "1.25", "wpb": "1806.4", "bsz": "32", "num_updates": "24400", "lr": "4.88044e-05", "gnorm": "1.585", "train_wall": "80", "wall": "48860"}
2022-11-11 12:58:23 | INFO | train_inner | {"epoch": 17, "update": 16.804, "loss": "2.359", "nll_loss": "0.486", "ppl": "1.4", "wps": "2205.8", "ups": "1.27", "wpb": "1737.7", "bsz": "32", "num_updates": "24500", "lr": "4.87994e-05", "gnorm": "1.614", "train_wall": "78", "wall": "48939"}
2022-11-11 12:59:43 | INFO | train_inner | {"epoch": 17, "update": 16.872, "loss": "2.355", "nll_loss": "0.48", "ppl": "1.4", "wps": "2235.2", "ups": "1.25", "wpb": "1783.1", "bsz": "32", "num_updates": "24600", "lr": "4.87944e-05", "gnorm": "1.635", "train_wall": "79", "wall": "49019"}
2022-11-11 13:01:02 | INFO | train_inner | {"epoch": 17, "update": 16.941, "loss": "2.341", "nll_loss": "0.465", "ppl": "1.38", "wps": "2226.4", "ups": "1.27", "wpb": "1758.3", "bsz": "32", "num_updates": "24700", "lr": "4.87894e-05", "gnorm": "1.635", "train_wall": "79", "wall": "49098"}
2022-11-11 13:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 13:31:23 | INFO | valid | {"epoch": 17, "valid_loss": "3.197", "valid_nll_loss": "1.357", "valid_ppl": "2.56", "valid_bleu": "50.15", "valid_wps": "184.7", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "24786", "valid_best_bleu": "54.18"}
2022-11-11 13:31:23 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 13:31:44 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 17 @ 24786 updates, score 50.15) (writing took 21.321871446911246 seconds)
2022-11-11 13:31:44 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-11-11 13:31:44 | INFO | train | {"epoch": 17, "train_loss": "2.341", "train_nll_loss": "0.464", "train_ppl": "1.38", "train_wps": "890.6", "train_ups": "0.5", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "24786", "train_lr": "4.87851e-05", "train_gnorm": "1.573", "train_train_wall": "1155", "train_wall": "50940"}
2022-11-11 13:31:44 | INFO | fairseq.trainer | begin training epoch 18
2022-11-11 13:31:55 | INFO | train_inner | {"epoch": 18, "update": 17.01, "loss": "2.34", "nll_loss": "0.463", "ppl": "1.38", "wps": "95.5", "ups": "0.05", "wpb": "1770.7", "bsz": "31.7", "num_updates": "24800", "lr": "4.87844e-05", "gnorm": "1.632", "train_wall": "79", "wall": "50951"}
2022-11-11 13:33:15 | INFO | train_inner | {"epoch": 18, "update": 17.078, "loss": "2.29", "nll_loss": "0.406", "ppl": "1.33", "wps": "2233.6", "ups": "1.26", "wpb": "1776.9", "bsz": "32", "num_updates": "24900", "lr": "4.87794e-05", "gnorm": "1.449", "train_wall": "79", "wall": "51031"}
2022-11-11 13:34:35 | INFO | train_inner | {"epoch": 18, "update": 17.147, "loss": "2.294", "nll_loss": "0.411", "ppl": "1.33", "wps": "2199", "ups": "1.24", "wpb": "1775.1", "bsz": "32", "num_updates": "25000", "lr": "4.87744e-05", "gnorm": "1.491", "train_wall": "80", "wall": "51111"}
2022-11-11 13:35:56 | INFO | train_inner | {"epoch": 18, "update": 17.215, "loss": "2.315", "nll_loss": "0.436", "ppl": "1.35", "wps": "2172.7", "ups": "1.24", "wpb": "1750.7", "bsz": "32", "num_updates": "25100", "lr": "4.87694e-05", "gnorm": "1.569", "train_wall": "80", "wall": "51192"}
2022-11-11 13:37:18 | INFO | train_inner | {"epoch": 18, "update": 17.284, "loss": "2.306", "nll_loss": "0.425", "ppl": "1.34", "wps": "2237.3", "ups": "1.21", "wpb": "1844.9", "bsz": "32", "num_updates": "25200", "lr": "4.87644e-05", "gnorm": "1.51", "train_wall": "82", "wall": "51274"}
2022-11-11 13:38:41 | INFO | train_inner | {"epoch": 18, "update": 17.353, "loss": "2.317", "nll_loss": "0.438", "ppl": "1.35", "wps": "2229.3", "ups": "1.21", "wpb": "1842", "bsz": "32", "num_updates": "25300", "lr": "4.87594e-05", "gnorm": "1.51", "train_wall": "82", "wall": "51357"}
2022-11-11 13:40:02 | INFO | train_inner | {"epoch": 18, "update": 17.421, "loss": "2.303", "nll_loss": "0.423", "ppl": "1.34", "wps": "2205.2", "ups": "1.23", "wpb": "1791.6", "bsz": "32", "num_updates": "25400", "lr": "4.87544e-05", "gnorm": "1.522", "train_wall": "81", "wall": "51438"}
2022-11-11 13:41:26 | INFO | train_inner | {"epoch": 18, "update": 17.49, "loss": "2.323", "nll_loss": "0.444", "ppl": "1.36", "wps": "2230.6", "ups": "1.2", "wpb": "1864.5", "bsz": "32", "num_updates": "25500", "lr": "4.87494e-05", "gnorm": "1.551", "train_wall": "83", "wall": "51522"}
2022-11-11 13:42:47 | INFO | train_inner | {"epoch": 18, "update": 17.558, "loss": "2.315", "nll_loss": "0.436", "ppl": "1.35", "wps": "2173", "ups": "1.23", "wpb": "1765.6", "bsz": "32", "num_updates": "25600", "lr": "4.87444e-05", "gnorm": "1.582", "train_wall": "81", "wall": "51603"}
2022-11-11 13:44:08 | INFO | train_inner | {"epoch": 18, "update": 17.627, "loss": "2.322", "nll_loss": "0.444", "ppl": "1.36", "wps": "2158.4", "ups": "1.24", "wpb": "1746.7", "bsz": "32", "num_updates": "25700", "lr": "4.87394e-05", "gnorm": "1.605", "train_wall": "80", "wall": "51684"}
2022-11-11 13:45:29 | INFO | train_inner | {"epoch": 18, "update": 17.695, "loss": "2.311", "nll_loss": "0.432", "ppl": "1.35", "wps": "2149.8", "ups": "1.24", "wpb": "1733.7", "bsz": "32", "num_updates": "25800", "lr": "4.87344e-05", "gnorm": "1.563", "train_wall": "80", "wall": "51765"}
2022-11-11 13:46:52 | INFO | train_inner | {"epoch": 18, "update": 17.764, "loss": "2.358", "nll_loss": "0.484", "ppl": "1.4", "wps": "2208.8", "ups": "1.2", "wpb": "1838.5", "bsz": "32", "num_updates": "25900", "lr": "4.87294e-05", "gnorm": "1.589", "train_wall": "83", "wall": "51848"}
2022-11-11 13:48:13 | INFO | train_inner | {"epoch": 18, "update": 17.833, "loss": "2.319", "nll_loss": "0.441", "ppl": "1.36", "wps": "2182.6", "ups": "1.23", "wpb": "1769.6", "bsz": "32", "num_updates": "26000", "lr": "4.87244e-05", "gnorm": "1.567", "train_wall": "81", "wall": "51929"}
2022-11-11 13:49:34 | INFO | train_inner | {"epoch": 18, "update": 17.901, "loss": "2.333", "nll_loss": "0.457", "ppl": "1.37", "wps": "2258.8", "ups": "1.24", "wpb": "1816.6", "bsz": "32", "num_updates": "26100", "lr": "4.87194e-05", "gnorm": "1.617", "train_wall": "80", "wall": "52009"}
2022-11-11 13:50:54 | INFO | train_inner | {"epoch": 18, "update": 17.97, "loss": "2.327", "nll_loss": "0.449", "ppl": "1.37", "wps": "2236", "ups": "1.24", "wpb": "1809.1", "bsz": "32", "num_updates": "26200", "lr": "4.87144e-05", "gnorm": "1.586", "train_wall": "80", "wall": "52090"}
2022-11-11 13:51:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 14:19:11 | INFO | valid | {"epoch": 18, "valid_loss": "3.238", "valid_nll_loss": "1.408", "valid_ppl": "2.65", "valid_bleu": "51.63", "valid_wps": "194.7", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "26244", "valid_best_bleu": "54.18"}
2022-11-11 14:19:11 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 14:19:32 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 18 @ 26244 updates, score 51.63) (writing took 21.198311910033226 seconds)
2022-11-11 14:19:32 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-11-11 14:19:32 | INFO | train | {"epoch": 18, "train_loss": "2.317", "train_nll_loss": "0.438", "train_ppl": "1.35", "train_wps": "911.1", "train_ups": "0.51", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "26244", "train_lr": "4.87122e-05", "train_gnorm": "1.553", "train_train_wall": "1178", "train_wall": "53808"}
2022-11-11 14:19:32 | INFO | fairseq.trainer | begin training epoch 19
2022-11-11 14:20:17 | INFO | train_inner | {"epoch": 19, "update": 18.038, "loss": "2.293", "nll_loss": "0.411", "ppl": "1.33", "wps": "101.5", "ups": "0.06", "wpb": "1789.7", "bsz": "31.7", "num_updates": "26300", "lr": "4.87094e-05", "gnorm": "1.529", "train_wall": "79", "wall": "53853"}
2022-11-11 14:21:37 | INFO | train_inner | {"epoch": 19, "update": 18.107, "loss": "2.28", "nll_loss": "0.396", "ppl": "1.32", "wps": "2264.4", "ups": "1.25", "wpb": "1807", "bsz": "32", "num_updates": "26400", "lr": "4.87044e-05", "gnorm": "1.48", "train_wall": "79", "wall": "53933"}
2022-11-11 14:22:57 | INFO | train_inner | {"epoch": 19, "update": 18.176, "loss": "2.293", "nll_loss": "0.411", "ppl": "1.33", "wps": "2280.8", "ups": "1.25", "wpb": "1820", "bsz": "32", "num_updates": "26500", "lr": "4.86993e-05", "gnorm": "1.465", "train_wall": "79", "wall": "54013"}
2022-11-11 14:24:16 | INFO | train_inner | {"epoch": 19, "update": 18.244, "loss": "2.278", "nll_loss": "0.395", "ppl": "1.32", "wps": "2229.5", "ups": "1.27", "wpb": "1762.1", "bsz": "32", "num_updates": "26600", "lr": "4.86943e-05", "gnorm": "1.495", "train_wall": "79", "wall": "54092"}
2022-11-11 14:25:36 | INFO | train_inner | {"epoch": 19, "update": 18.313, "loss": "2.285", "nll_loss": "0.402", "ppl": "1.32", "wps": "2243.1", "ups": "1.26", "wpb": "1787.2", "bsz": "32", "num_updates": "26700", "lr": "4.86893e-05", "gnorm": "1.465", "train_wall": "79", "wall": "54172"}
2022-11-11 14:26:56 | INFO | train_inner | {"epoch": 19, "update": 18.381, "loss": "2.29", "nll_loss": "0.408", "ppl": "1.33", "wps": "2208.9", "ups": "1.25", "wpb": "1769.5", "bsz": "32", "num_updates": "26800", "lr": "4.86843e-05", "gnorm": "1.535", "train_wall": "80", "wall": "54252"}
2022-11-11 14:28:16 | INFO | train_inner | {"epoch": 19, "update": 18.45, "loss": "2.292", "nll_loss": "0.41", "ppl": "1.33", "wps": "2249.5", "ups": "1.24", "wpb": "1810.4", "bsz": "32", "num_updates": "26900", "lr": "4.86793e-05", "gnorm": "1.529", "train_wall": "80", "wall": "54332"}
2022-11-11 14:29:37 | INFO | train_inner | {"epoch": 19, "update": 18.519, "loss": "2.299", "nll_loss": "0.419", "ppl": "1.34", "wps": "2266.4", "ups": "1.23", "wpb": "1835.3", "bsz": "32", "num_updates": "27000", "lr": "4.86743e-05", "gnorm": "1.52", "train_wall": "81", "wall": "54413"}
2022-11-11 14:30:58 | INFO | train_inner | {"epoch": 19, "update": 18.587, "loss": "2.296", "nll_loss": "0.415", "ppl": "1.33", "wps": "2252.2", "ups": "1.25", "wpb": "1807.4", "bsz": "32", "num_updates": "27100", "lr": "4.86693e-05", "gnorm": "1.506", "train_wall": "80", "wall": "54493"}
2022-11-11 14:32:18 | INFO | train_inner | {"epoch": 19, "update": 18.656, "loss": "2.298", "nll_loss": "0.417", "ppl": "1.34", "wps": "2201.6", "ups": "1.25", "wpb": "1768.1", "bsz": "32", "num_updates": "27200", "lr": "4.86643e-05", "gnorm": "1.519", "train_wall": "80", "wall": "54574"}
2022-11-11 14:33:40 | INFO | train_inner | {"epoch": 19, "update": 18.724, "loss": "2.302", "nll_loss": "0.422", "ppl": "1.34", "wps": "2199", "ups": "1.21", "wpb": "1812.1", "bsz": "32", "num_updates": "27300", "lr": "4.86593e-05", "gnorm": "1.534", "train_wall": "82", "wall": "54656"}
2022-11-11 14:35:02 | INFO | train_inner | {"epoch": 19, "update": 18.793, "loss": "2.312", "nll_loss": "0.433", "ppl": "1.35", "wps": "2154.3", "ups": "1.23", "wpb": "1758.2", "bsz": "32", "num_updates": "27400", "lr": "4.86543e-05", "gnorm": "1.559", "train_wall": "81", "wall": "54738"}
2022-11-11 14:36:23 | INFO | train_inner | {"epoch": 19, "update": 18.861, "loss": "2.299", "nll_loss": "0.418", "ppl": "1.34", "wps": "2219.9", "ups": "1.23", "wpb": "1798", "bsz": "32", "num_updates": "27500", "lr": "4.86493e-05", "gnorm": "1.565", "train_wall": "81", "wall": "54819"}
2022-11-11 14:37:43 | INFO | train_inner | {"epoch": 19, "update": 18.93, "loss": "2.322", "nll_loss": "0.445", "ppl": "1.36", "wps": "2253.9", "ups": "1.25", "wpb": "1801.4", "bsz": "32", "num_updates": "27600", "lr": "4.86443e-05", "gnorm": "1.543", "train_wall": "80", "wall": "54899"}
2022-11-11 14:39:02 | INFO | train_inner | {"epoch": 19, "update": 18.999, "loss": "2.297", "nll_loss": "0.417", "ppl": "1.33", "wps": "2214.8", "ups": "1.26", "wpb": "1759.6", "bsz": "32", "num_updates": "27700", "lr": "4.86393e-05", "gnorm": "1.557", "train_wall": "79", "wall": "54978"}
2022-11-11 14:39:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 15:08:10 | INFO | valid | {"epoch": 19, "valid_loss": "3.227", "valid_nll_loss": "1.407", "valid_ppl": "2.65", "valid_bleu": "54.7", "valid_wps": "185.2", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "27702", "valid_best_bleu": "54.7"}
2022-11-11 15:08:10 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 15:08:47 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 19 @ 27702 updates, score 54.7) (writing took 36.80155855603516 seconds)
2022-11-11 15:08:47 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-11-11 15:08:47 | INFO | train | {"epoch": 19, "train_loss": "2.295", "train_nll_loss": "0.414", "train_ppl": "1.33", "train_wps": "884.5", "train_ups": "0.49", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "27702", "train_lr": "4.86392e-05", "train_gnorm": "1.521", "train_train_wall": "1164", "train_wall": "56763"}
2022-11-11 15:08:47 | INFO | fairseq.trainer | begin training epoch 20
2022-11-11 15:10:05 | INFO | train_inner | {"epoch": 20, "update": 19.067, "loss": "2.268", "nll_loss": "0.384", "ppl": "1.3", "wps": "93.4", "ups": "0.05", "wpb": "1739.2", "bsz": "31.7", "num_updates": "27800", "lr": "4.86343e-05", "gnorm": "1.579", "train_wall": "78", "wall": "56841"}
2022-11-11 15:11:25 | INFO | train_inner | {"epoch": 20, "update": 19.136, "loss": "2.263", "nll_loss": "0.379", "ppl": "1.3", "wps": "2267.6", "ups": "1.25", "wpb": "1807.3", "bsz": "32", "num_updates": "27900", "lr": "4.86293e-05", "gnorm": "1.421", "train_wall": "79", "wall": "56921"}
2022-11-11 15:12:44 | INFO | train_inner | {"epoch": 20, "update": 19.204, "loss": "2.267", "nll_loss": "0.383", "ppl": "1.3", "wps": "2228", "ups": "1.26", "wpb": "1767", "bsz": "32", "num_updates": "28000", "lr": "4.86243e-05", "gnorm": "1.46", "train_wall": "79", "wall": "57000"}
2022-11-11 15:14:04 | INFO | train_inner | {"epoch": 20, "update": 19.273, "loss": "2.271", "nll_loss": "0.387", "ppl": "1.31", "wps": "2262.3", "ups": "1.25", "wpb": "1805.8", "bsz": "32", "num_updates": "28100", "lr": "4.86193e-05", "gnorm": "1.465", "train_wall": "79", "wall": "57080"}
2022-11-11 15:15:24 | INFO | train_inner | {"epoch": 20, "update": 19.342, "loss": "2.271", "nll_loss": "0.388", "ppl": "1.31", "wps": "2283.2", "ups": "1.25", "wpb": "1821.3", "bsz": "32", "num_updates": "28200", "lr": "4.86143e-05", "gnorm": "1.477", "train_wall": "79", "wall": "57160"}
2022-11-11 15:16:45 | INFO | train_inner | {"epoch": 20, "update": 19.41, "loss": "2.284", "nll_loss": "0.402", "ppl": "1.32", "wps": "2257.3", "ups": "1.23", "wpb": "1835.9", "bsz": "32", "num_updates": "28300", "lr": "4.86093e-05", "gnorm": "1.473", "train_wall": "81", "wall": "57241"}
2022-11-11 15:18:04 | INFO | train_inner | {"epoch": 20, "update": 19.479, "loss": "2.268", "nll_loss": "0.384", "ppl": "1.3", "wps": "2213.6", "ups": "1.27", "wpb": "1747.2", "bsz": "32", "num_updates": "28400", "lr": "4.86043e-05", "gnorm": "1.518", "train_wall": "79", "wall": "57320"}
2022-11-11 15:19:24 | INFO | train_inner | {"epoch": 20, "update": 19.547, "loss": "2.288", "nll_loss": "0.406", "ppl": "1.32", "wps": "2233.4", "ups": "1.24", "wpb": "1796.9", "bsz": "32", "num_updates": "28500", "lr": "4.85993e-05", "gnorm": "1.539", "train_wall": "80", "wall": "57400"}
2022-11-11 15:20:45 | INFO | train_inner | {"epoch": 20, "update": 19.616, "loss": "2.283", "nll_loss": "0.401", "ppl": "1.32", "wps": "2217.5", "ups": "1.25", "wpb": "1776.3", "bsz": "32", "num_updates": "28600", "lr": "4.85943e-05", "gnorm": "1.517", "train_wall": "80", "wall": "57480"}
2022-11-11 15:22:04 | INFO | train_inner | {"epoch": 20, "update": 19.684, "loss": "2.269", "nll_loss": "0.386", "ppl": "1.31", "wps": "2235.1", "ups": "1.25", "wpb": "1781.3", "bsz": "32", "num_updates": "28700", "lr": "4.85893e-05", "gnorm": "1.507", "train_wall": "79", "wall": "57560"}
2022-11-11 15:23:24 | INFO | train_inner | {"epoch": 20, "update": 19.753, "loss": "2.274", "nll_loss": "0.391", "ppl": "1.31", "wps": "2213.4", "ups": "1.25", "wpb": "1766.9", "bsz": "32", "num_updates": "28800", "lr": "4.85843e-05", "gnorm": "1.527", "train_wall": "79", "wall": "57640"}
2022-11-11 15:24:44 | INFO | train_inner | {"epoch": 20, "update": 19.822, "loss": "2.288", "nll_loss": "0.407", "ppl": "1.33", "wps": "2215.9", "ups": "1.25", "wpb": "1774", "bsz": "32", "num_updates": "28900", "lr": "4.85793e-05", "gnorm": "1.566", "train_wall": "80", "wall": "57720"}
2022-11-11 15:26:06 | INFO | train_inner | {"epoch": 20, "update": 19.89, "loss": "2.276", "nll_loss": "0.393", "ppl": "1.31", "wps": "2294.8", "ups": "1.23", "wpb": "1869.6", "bsz": "32", "num_updates": "29000", "lr": "4.85743e-05", "gnorm": "1.516", "train_wall": "81", "wall": "57801"}
2022-11-11 15:27:25 | INFO | train_inner | {"epoch": 20, "update": 19.959, "loss": "2.282", "nll_loss": "0.401", "ppl": "1.32", "wps": "2197.4", "ups": "1.26", "wpb": "1750.6", "bsz": "32", "num_updates": "29100", "lr": "4.85693e-05", "gnorm": "1.554", "train_wall": "79", "wall": "57881"}
2022-11-11 15:28:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 15:57:07 | INFO | valid | {"epoch": 20, "valid_loss": "3.223", "valid_nll_loss": "1.395", "valid_ppl": "2.63", "valid_bleu": "55.22", "valid_wps": "186.8", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "29160", "valid_best_bleu": "55.22"}
2022-11-11 15:57:07 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 15:57:43 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 20 @ 29160 updates, score 55.22) (writing took 36.73943514097482 seconds)
2022-11-11 15:57:43 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-11-11 15:57:43 | INFO | train | {"epoch": 20, "train_loss": "2.278", "train_nll_loss": "0.395", "train_ppl": "1.32", "train_wps": "890.2", "train_ups": "0.5", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "29160", "train_lr": "4.85663e-05", "train_gnorm": "1.508", "train_train_wall": "1160", "train_wall": "59699"}
2022-11-11 15:57:43 | INFO | fairseq.trainer | begin training epoch 21
2022-11-11 15:58:15 | INFO | train_inner | {"epoch": 21, "update": 20.027, "loss": "2.306", "nll_loss": "0.428", "ppl": "1.35", "wps": "98.6", "ups": "0.05", "wpb": "1823.3", "bsz": "31.7", "num_updates": "29200", "lr": "4.85643e-05", "gnorm": "1.54", "train_wall": "80", "wall": "59731"}
2022-11-11 15:59:34 | INFO | train_inner | {"epoch": 21, "update": 20.096, "loss": "2.254", "nll_loss": "0.369", "ppl": "1.29", "wps": "2270.5", "ups": "1.27", "wpb": "1794.2", "bsz": "32", "num_updates": "29300", "lr": "4.85593e-05", "gnorm": "1.433", "train_wall": "79", "wall": "59810"}
2022-11-11 16:00:54 | INFO | train_inner | {"epoch": 21, "update": 20.165, "loss": "2.246", "nll_loss": "0.36", "ppl": "1.28", "wps": "2252.7", "ups": "1.25", "wpb": "1804.4", "bsz": "32", "num_updates": "29400", "lr": "4.85543e-05", "gnorm": "1.42", "train_wall": "80", "wall": "59890"}
2022-11-11 16:02:14 | INFO | train_inner | {"epoch": 21, "update": 20.233, "loss": "2.294", "nll_loss": "0.413", "ppl": "1.33", "wps": "2255.5", "ups": "1.24", "wpb": "1817.6", "bsz": "32", "num_updates": "29500", "lr": "4.85493e-05", "gnorm": "1.483", "train_wall": "80", "wall": "59970"}
2022-11-11 16:03:34 | INFO | train_inner | {"epoch": 21, "update": 20.302, "loss": "2.256", "nll_loss": "0.372", "ppl": "1.29", "wps": "2244.3", "ups": "1.25", "wpb": "1788.8", "bsz": "32", "num_updates": "29600", "lr": "4.85443e-05", "gnorm": "1.429", "train_wall": "79", "wall": "60050"}
2022-11-11 16:04:54 | INFO | train_inner | {"epoch": 21, "update": 20.37, "loss": "2.256", "nll_loss": "0.372", "ppl": "1.29", "wps": "2239.5", "ups": "1.26", "wpb": "1784.2", "bsz": "32", "num_updates": "29700", "lr": "4.85393e-05", "gnorm": "1.475", "train_wall": "79", "wall": "60130"}
2022-11-11 16:06:14 | INFO | train_inner | {"epoch": 21, "update": 20.439, "loss": "2.26", "nll_loss": "0.376", "ppl": "1.3", "wps": "2227.8", "ups": "1.24", "wpb": "1790", "bsz": "32", "num_updates": "29800", "lr": "4.85343e-05", "gnorm": "1.492", "train_wall": "80", "wall": "60210"}
2022-11-11 16:07:34 | INFO | train_inner | {"epoch": 21, "update": 20.508, "loss": "2.26", "nll_loss": "0.376", "ppl": "1.3", "wps": "2249.3", "ups": "1.25", "wpb": "1800.1", "bsz": "32", "num_updates": "29900", "lr": "4.85293e-05", "gnorm": "1.479", "train_wall": "80", "wall": "60290"}
2022-11-11 16:08:55 | INFO | train_inner | {"epoch": 21, "update": 20.576, "loss": "2.276", "nll_loss": "0.394", "ppl": "1.31", "wps": "2263.5", "ups": "1.24", "wpb": "1831.3", "bsz": "32", "num_updates": "30000", "lr": "4.85243e-05", "gnorm": "1.481", "train_wall": "80", "wall": "60371"}
2022-11-11 16:10:15 | INFO | train_inner | {"epoch": 21, "update": 20.645, "loss": "2.26", "nll_loss": "0.376", "ppl": "1.3", "wps": "2243.5", "ups": "1.25", "wpb": "1794.8", "bsz": "32", "num_updates": "30100", "lr": "4.85193e-05", "gnorm": "1.497", "train_wall": "80", "wall": "60451"}
2022-11-11 16:11:35 | INFO | train_inner | {"epoch": 21, "update": 20.713, "loss": "2.264", "nll_loss": "0.381", "ppl": "1.3", "wps": "2239.7", "ups": "1.25", "wpb": "1790", "bsz": "32", "num_updates": "30200", "lr": "4.85143e-05", "gnorm": "1.486", "train_wall": "79", "wall": "60531"}
2022-11-11 16:12:56 | INFO | train_inner | {"epoch": 21, "update": 20.782, "loss": "2.266", "nll_loss": "0.382", "ppl": "1.3", "wps": "2260.6", "ups": "1.24", "wpb": "1829.3", "bsz": "32", "num_updates": "30300", "lr": "4.85093e-05", "gnorm": "1.504", "train_wall": "80", "wall": "60612"}
2022-11-11 16:14:15 | INFO | train_inner | {"epoch": 21, "update": 20.85, "loss": "2.261", "nll_loss": "0.377", "ppl": "1.3", "wps": "2200.8", "ups": "1.27", "wpb": "1729.6", "bsz": "32", "num_updates": "30400", "lr": "4.85043e-05", "gnorm": "1.541", "train_wall": "78", "wall": "60690"}
2022-11-11 16:15:35 | INFO | train_inner | {"epoch": 21, "update": 20.919, "loss": "2.268", "nll_loss": "0.385", "ppl": "1.31", "wps": "2179.1", "ups": "1.24", "wpb": "1756.7", "bsz": "32", "num_updates": "30500", "lr": "4.84992e-05", "gnorm": "1.545", "train_wall": "80", "wall": "60771"}
2022-11-11 16:16:55 | INFO | train_inner | {"epoch": 21, "update": 20.988, "loss": "2.263", "nll_loss": "0.379", "ppl": "1.3", "wps": "2261.1", "ups": "1.25", "wpb": "1809", "bsz": "32", "num_updates": "30600", "lr": "4.84942e-05", "gnorm": "1.522", "train_wall": "80", "wall": "60851"}
2022-11-11 16:17:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 16:46:13 | INFO | valid | {"epoch": 21, "valid_loss": "3.232", "valid_nll_loss": "1.411", "valid_ppl": "2.66", "valid_bleu": "54.06", "valid_wps": "185.6", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "30618", "valid_best_bleu": "55.22"}
2022-11-11 16:46:13 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 16:46:33 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 21 @ 30618 updates, score 54.06) (writing took 20.412713104858994 seconds)
2022-11-11 16:46:33 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-11-11 16:46:33 | INFO | train | {"epoch": 21, "train_loss": "2.263", "train_nll_loss": "0.379", "train_ppl": "1.3", "train_wps": "892", "train_ups": "0.5", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "30618", "train_lr": "4.84933e-05", "train_gnorm": "1.484", "train_train_wall": "1159", "train_wall": "62629"}
2022-11-11 16:46:33 | INFO | fairseq.trainer | begin training epoch 22
2022-11-11 16:47:39 | INFO | train_inner | {"epoch": 22, "update": 21.056, "loss": "2.24", "nll_loss": "0.353", "ppl": "1.28", "wps": "96", "ups": "0.05", "wpb": "1768.9", "bsz": "31.7", "num_updates": "30700", "lr": "4.84892e-05", "gnorm": "1.417", "train_wall": "79", "wall": "62695"}
2022-11-11 16:48:59 | INFO | train_inner | {"epoch": 22, "update": 21.125, "loss": "2.229", "nll_loss": "0.341", "ppl": "1.27", "wps": "2256.9", "ups": "1.25", "wpb": "1812.5", "bsz": "32", "num_updates": "30800", "lr": "4.84842e-05", "gnorm": "1.364", "train_wall": "80", "wall": "62775"}
2022-11-11 16:50:20 | INFO | train_inner | {"epoch": 22, "update": 21.193, "loss": "2.235", "nll_loss": "0.348", "ppl": "1.27", "wps": "2253.1", "ups": "1.23", "wpb": "1834.5", "bsz": "32", "num_updates": "30900", "lr": "4.84792e-05", "gnorm": "1.399", "train_wall": "81", "wall": "62856"}
2022-11-11 16:51:41 | INFO | train_inner | {"epoch": 22, "update": 21.262, "loss": "2.248", "nll_loss": "0.363", "ppl": "1.29", "wps": "2205.2", "ups": "1.24", "wpb": "1776.4", "bsz": "32", "num_updates": "31000", "lr": "4.84742e-05", "gnorm": "1.447", "train_wall": "80", "wall": "62937"}
2022-11-11 16:53:02 | INFO | train_inner | {"epoch": 22, "update": 21.331, "loss": "2.245", "nll_loss": "0.359", "ppl": "1.28", "wps": "2239.6", "ups": "1.24", "wpb": "1803.8", "bsz": "32", "num_updates": "31100", "lr": "4.84692e-05", "gnorm": "1.486", "train_wall": "80", "wall": "63017"}
2022-11-11 16:54:21 | INFO | train_inner | {"epoch": 22, "update": 21.399, "loss": "2.239", "nll_loss": "0.353", "ppl": "1.28", "wps": "2234.6", "ups": "1.26", "wpb": "1779.5", "bsz": "32", "num_updates": "31200", "lr": "4.84642e-05", "gnorm": "1.423", "train_wall": "79", "wall": "63097"}
2022-11-11 16:55:41 | INFO | train_inner | {"epoch": 22, "update": 21.468, "loss": "2.248", "nll_loss": "0.362", "ppl": "1.29", "wps": "2237.1", "ups": "1.26", "wpb": "1775.9", "bsz": "32", "num_updates": "31300", "lr": "4.84592e-05", "gnorm": "1.476", "train_wall": "79", "wall": "63176"}
2022-11-11 16:57:00 | INFO | train_inner | {"epoch": 22, "update": 21.536, "loss": "2.241", "nll_loss": "0.356", "ppl": "1.28", "wps": "2220.7", "ups": "1.26", "wpb": "1759", "bsz": "32", "num_updates": "31400", "lr": "4.84542e-05", "gnorm": "1.492", "train_wall": "79", "wall": "63256"}
2022-11-11 16:58:20 | INFO | train_inner | {"epoch": 22, "update": 21.605, "loss": "2.249", "nll_loss": "0.365", "ppl": "1.29", "wps": "2226.4", "ups": "1.24", "wpb": "1792.6", "bsz": "32", "num_updates": "31500", "lr": "4.84492e-05", "gnorm": "1.484", "train_wall": "80", "wall": "63336"}
2022-11-11 16:59:40 | INFO | train_inner | {"epoch": 22, "update": 21.674, "loss": "2.276", "nll_loss": "0.395", "ppl": "1.31", "wps": "2205.4", "ups": "1.26", "wpb": "1752.8", "bsz": "32", "num_updates": "31600", "lr": "4.84442e-05", "gnorm": "1.479", "train_wall": "79", "wall": "63416"}
2022-11-11 17:01:01 | INFO | train_inner | {"epoch": 22, "update": 21.742, "loss": "2.259", "nll_loss": "0.376", "ppl": "1.3", "wps": "2260.2", "ups": "1.24", "wpb": "1829", "bsz": "32", "num_updates": "31700", "lr": "4.84392e-05", "gnorm": "1.504", "train_wall": "81", "wall": "63497"}
2022-11-11 17:02:21 | INFO | train_inner | {"epoch": 22, "update": 21.811, "loss": "2.247", "nll_loss": "0.362", "ppl": "1.28", "wps": "2228", "ups": "1.25", "wpb": "1778.9", "bsz": "32", "num_updates": "31800", "lr": "4.84342e-05", "gnorm": "1.498", "train_wall": "79", "wall": "63576"}
2022-11-11 17:03:41 | INFO | train_inner | {"epoch": 22, "update": 21.879, "loss": "2.26", "nll_loss": "0.377", "ppl": "1.3", "wps": "2281.7", "ups": "1.24", "wpb": "1845.9", "bsz": "32", "num_updates": "31900", "lr": "4.84292e-05", "gnorm": "1.505", "train_wall": "80", "wall": "63657"}
2022-11-11 17:05:01 | INFO | train_inner | {"epoch": 22, "update": 21.948, "loss": "2.248", "nll_loss": "0.363", "ppl": "1.29", "wps": "2255.6", "ups": "1.26", "wpb": "1797.2", "bsz": "32", "num_updates": "32000", "lr": "4.84242e-05", "gnorm": "1.48", "train_wall": "79", "wall": "63737"}
2022-11-11 17:06:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 17:34:58 | INFO | valid | {"epoch": 22, "valid_loss": "3.218", "valid_nll_loss": "1.402", "valid_ppl": "2.64", "valid_bleu": "54.45", "valid_wps": "186.4", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "32076", "valid_best_bleu": "55.22"}
2022-11-11 17:34:58 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 17:35:18 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 22 @ 32076 updates, score 54.45) (writing took 20.45809637196362 seconds)
2022-11-11 17:35:18 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-11-11 17:35:18 | INFO | train | {"epoch": 22, "train_loss": "2.248", "train_nll_loss": "0.363", "train_ppl": "1.29", "train_wps": "893.5", "train_ups": "0.5", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "32076", "train_lr": "4.84204e-05", "train_gnorm": "1.463", "train_train_wall": "1162", "train_wall": "65554"}
2022-11-11 17:35:18 | INFO | fairseq.trainer | begin training epoch 23
2022-11-11 17:35:38 | INFO | train_inner | {"epoch": 23, "update": 22.016, "loss": "2.246", "nll_loss": "0.361", "ppl": "1.28", "wps": "96.6", "ups": "0.05", "wpb": "1774.3", "bsz": "31.7", "num_updates": "32100", "lr": "4.84192e-05", "gnorm": "1.475", "train_wall": "79", "wall": "65574"}
2022-11-11 17:36:58 | INFO | train_inner | {"epoch": 23, "update": 22.085, "loss": "2.223", "nll_loss": "0.335", "ppl": "1.26", "wps": "2255.4", "ups": "1.25", "wpb": "1797.9", "bsz": "32", "num_updates": "32200", "lr": "4.84142e-05", "gnorm": "1.385", "train_wall": "79", "wall": "65654"}
2022-11-11 17:38:17 | INFO | train_inner | {"epoch": 23, "update": 22.154, "loss": "2.219", "nll_loss": "0.331", "ppl": "1.26", "wps": "2263.5", "ups": "1.26", "wpb": "1795.5", "bsz": "32", "num_updates": "32300", "lr": "4.84092e-05", "gnorm": "1.365", "train_wall": "79", "wall": "65733"}
2022-11-11 17:39:36 | INFO | train_inner | {"epoch": 23, "update": 22.222, "loss": "2.225", "nll_loss": "0.338", "ppl": "1.26", "wps": "2208.2", "ups": "1.27", "wpb": "1734", "bsz": "32", "num_updates": "32400", "lr": "4.84042e-05", "gnorm": "1.451", "train_wall": "78", "wall": "65811"}
2022-11-11 17:40:55 | INFO | train_inner | {"epoch": 23, "update": 22.291, "loss": "2.229", "nll_loss": "0.343", "ppl": "1.27", "wps": "2229.2", "ups": "1.27", "wpb": "1760.6", "bsz": "32", "num_updates": "32500", "lr": "4.83992e-05", "gnorm": "1.448", "train_wall": "79", "wall": "65890"}
2022-11-11 17:42:15 | INFO | train_inner | {"epoch": 23, "update": 22.359, "loss": "2.232", "nll_loss": "0.346", "ppl": "1.27", "wps": "2246.5", "ups": "1.25", "wpb": "1799.7", "bsz": "32", "num_updates": "32600", "lr": "4.83942e-05", "gnorm": "1.394", "train_wall": "80", "wall": "65971"}
2022-11-11 17:43:34 | INFO | train_inner | {"epoch": 23, "update": 22.428, "loss": "2.235", "nll_loss": "0.349", "ppl": "1.27", "wps": "2207.5", "ups": "1.26", "wpb": "1751.6", "bsz": "32", "num_updates": "32700", "lr": "4.83892e-05", "gnorm": "1.469", "train_wall": "79", "wall": "66050"}
2022-11-11 17:44:54 | INFO | train_inner | {"epoch": 23, "update": 22.497, "loss": "2.23", "nll_loss": "0.343", "ppl": "1.27", "wps": "2257.4", "ups": "1.25", "wpb": "1801.8", "bsz": "32", "num_updates": "32800", "lr": "4.83842e-05", "gnorm": "1.452", "train_wall": "79", "wall": "66130"}
2022-11-11 17:46:15 | INFO | train_inner | {"epoch": 23, "update": 22.565, "loss": "2.236", "nll_loss": "0.351", "ppl": "1.28", "wps": "2266.4", "ups": "1.24", "wpb": "1832.3", "bsz": "32", "num_updates": "32900", "lr": "4.83792e-05", "gnorm": "1.44", "train_wall": "80", "wall": "66211"}
2022-11-11 17:47:36 | INFO | train_inner | {"epoch": 23, "update": 22.634, "loss": "2.231", "nll_loss": "0.345", "ppl": "1.27", "wps": "2177.1", "ups": "1.23", "wpb": "1775", "bsz": "32", "num_updates": "33000", "lr": "4.83742e-05", "gnorm": "1.437", "train_wall": "81", "wall": "66292"}
2022-11-11 17:48:57 | INFO | train_inner | {"epoch": 23, "update": 22.702, "loss": "2.237", "nll_loss": "0.352", "ppl": "1.28", "wps": "2194.1", "ups": "1.24", "wpb": "1765.7", "bsz": "32", "num_updates": "33100", "lr": "4.83692e-05", "gnorm": "1.474", "train_wall": "80", "wall": "66373"}
2022-11-11 17:50:19 | INFO | train_inner | {"epoch": 23, "update": 22.771, "loss": "2.245", "nll_loss": "0.36", "ppl": "1.28", "wps": "2249.9", "ups": "1.22", "wpb": "1851.5", "bsz": "32", "num_updates": "33200", "lr": "4.83642e-05", "gnorm": "1.465", "train_wall": "82", "wall": "66455"}
2022-11-11 17:51:41 | INFO | train_inner | {"epoch": 23, "update": 22.84, "loss": "2.28", "nll_loss": "0.401", "ppl": "1.32", "wps": "2212.2", "ups": "1.22", "wpb": "1812.5", "bsz": "32", "num_updates": "33300", "lr": "4.83592e-05", "gnorm": "1.509", "train_wall": "81", "wall": "66537"}
2022-11-11 17:53:02 | INFO | train_inner | {"epoch": 23, "update": 22.908, "loss": "2.247", "nll_loss": "0.364", "ppl": "1.29", "wps": "2163.9", "ups": "1.24", "wpb": "1750.2", "bsz": "32", "num_updates": "33400", "lr": "4.83542e-05", "gnorm": "1.538", "train_wall": "80", "wall": "66618"}
2022-11-11 17:54:25 | INFO | train_inner | {"epoch": 23, "update": 22.977, "loss": "2.243", "nll_loss": "0.358", "ppl": "1.28", "wps": "2245.8", "ups": "1.21", "wpb": "1862.2", "bsz": "32", "num_updates": "33500", "lr": "4.83492e-05", "gnorm": "1.522", "train_wall": "82", "wall": "66701"}
2022-11-11 17:54:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 18:25:00 | INFO | valid | {"epoch": 23, "valid_loss": "3.231", "valid_nll_loss": "1.412", "valid_ppl": "2.66", "valid_bleu": "56.77", "valid_wps": "178.9", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "33534", "valid_best_bleu": "56.77"}
2022-11-11 18:25:00 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 18:25:38 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 23 @ 33534 updates, score 56.77) (writing took 37.531653698999435 seconds)
2022-11-11 18:25:38 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-11-11 18:25:38 | INFO | train | {"epoch": 23, "train_loss": "2.237", "train_nll_loss": "0.351", "train_ppl": "1.28", "train_wps": "865.6", "train_ups": "0.48", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "33534", "train_lr": "4.83475e-05", "train_gnorm": "1.454", "train_train_wall": "1166", "train_wall": "68574"}
2022-11-11 18:25:38 | INFO | fairseq.trainer | begin training epoch 24
2022-11-11 18:26:31 | INFO | train_inner | {"epoch": 24, "update": 23.045, "loss": "2.226", "nll_loss": "0.34", "ppl": "1.27", "wps": "93.2", "ups": "0.05", "wpb": "1794.9", "bsz": "31.7", "num_updates": "33600", "lr": "4.83442e-05", "gnorm": "1.42", "train_wall": "79", "wall": "68627"}
2022-11-11 18:27:52 | INFO | train_inner | {"epoch": 24, "update": 23.114, "loss": "2.215", "nll_loss": "0.327", "ppl": "1.25", "wps": "2259.3", "ups": "1.24", "wpb": "1825.5", "bsz": "32", "num_updates": "33700", "lr": "4.83392e-05", "gnorm": "1.369", "train_wall": "80", "wall": "68707"}
2022-11-11 18:29:11 | INFO | train_inner | {"epoch": 24, "update": 23.182, "loss": "2.218", "nll_loss": "0.331", "ppl": "1.26", "wps": "2194.2", "ups": "1.25", "wpb": "1748.8", "bsz": "32", "num_updates": "33800", "lr": "4.83342e-05", "gnorm": "1.414", "train_wall": "79", "wall": "68787"}
2022-11-11 18:30:33 | INFO | train_inner | {"epoch": 24, "update": 23.251, "loss": "2.218", "nll_loss": "0.331", "ppl": "1.26", "wps": "2207.5", "ups": "1.22", "wpb": "1812.4", "bsz": "32", "num_updates": "33900", "lr": "4.83292e-05", "gnorm": "1.375", "train_wall": "82", "wall": "68869"}
2022-11-11 18:31:54 | INFO | train_inner | {"epoch": 24, "update": 23.32, "loss": "2.216", "nll_loss": "0.329", "ppl": "1.26", "wps": "2259.1", "ups": "1.24", "wpb": "1822.3", "bsz": "32", "num_updates": "34000", "lr": "4.83242e-05", "gnorm": "1.38", "train_wall": "80", "wall": "68950"}
2022-11-11 18:33:14 | INFO | train_inner | {"epoch": 24, "update": 23.388, "loss": "2.217", "nll_loss": "0.33", "ppl": "1.26", "wps": "2205.5", "ups": "1.25", "wpb": "1767", "bsz": "32", "num_updates": "34100", "lr": "4.83192e-05", "gnorm": "1.42", "train_wall": "80", "wall": "69030"}
2022-11-11 18:34:34 | INFO | train_inner | {"epoch": 24, "update": 23.457, "loss": "2.224", "nll_loss": "0.338", "ppl": "1.26", "wps": "2224.6", "ups": "1.26", "wpb": "1770.1", "bsz": "32", "num_updates": "34200", "lr": "4.83142e-05", "gnorm": "1.396", "train_wall": "79", "wall": "69110"}
2022-11-11 18:35:54 | INFO | train_inner | {"epoch": 24, "update": 23.525, "loss": "2.22", "nll_loss": "0.333", "ppl": "1.26", "wps": "2224.9", "ups": "1.25", "wpb": "1780.6", "bsz": "32", "num_updates": "34300", "lr": "4.83092e-05", "gnorm": "1.425", "train_wall": "80", "wall": "69190"}
2022-11-11 18:37:13 | INFO | train_inner | {"epoch": 24, "update": 23.594, "loss": "2.223", "nll_loss": "0.337", "ppl": "1.26", "wps": "2205.8", "ups": "1.27", "wpb": "1743.3", "bsz": "32", "num_updates": "34400", "lr": "4.83042e-05", "gnorm": "1.439", "train_wall": "79", "wall": "69269"}
2022-11-11 18:38:33 | INFO | train_inner | {"epoch": 24, "update": 23.663, "loss": "2.231", "nll_loss": "0.346", "ppl": "1.27", "wps": "2233.6", "ups": "1.24", "wpb": "1801.8", "bsz": "32", "num_updates": "34500", "lr": "4.82991e-05", "gnorm": "1.467", "train_wall": "80", "wall": "69349"}
2022-11-11 18:39:53 | INFO | train_inner | {"epoch": 24, "update": 23.731, "loss": "2.24", "nll_loss": "0.357", "ppl": "1.28", "wps": "2208.3", "ups": "1.26", "wpb": "1756.9", "bsz": "32", "num_updates": "34600", "lr": "4.82941e-05", "gnorm": "1.467", "train_wall": "79", "wall": "69429"}
2022-11-11 18:41:15 | INFO | train_inner | {"epoch": 24, "update": 23.8, "loss": "2.251", "nll_loss": "0.369", "ppl": "1.29", "wps": "2285.7", "ups": "1.22", "wpb": "1867.2", "bsz": "32", "num_updates": "34700", "lr": "4.82891e-05", "gnorm": "1.483", "train_wall": "81", "wall": "69510"}
2022-11-11 18:42:37 | INFO | train_inner | {"epoch": 24, "update": 23.868, "loss": "2.23", "nll_loss": "0.344", "ppl": "1.27", "wps": "2289.6", "ups": "1.22", "wpb": "1881.2", "bsz": "32", "num_updates": "34800", "lr": "4.82841e-05", "gnorm": "1.429", "train_wall": "82", "wall": "69593"}
2022-11-11 18:43:55 | INFO | train_inner | {"epoch": 24, "update": 23.937, "loss": "2.222", "nll_loss": "0.336", "ppl": "1.26", "wps": "2219.5", "ups": "1.27", "wpb": "1744.7", "bsz": "32", "num_updates": "34900", "lr": "4.82791e-05", "gnorm": "1.488", "train_wall": "78", "wall": "69671"}
2022-11-11 18:45:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 19:14:51 | INFO | valid | {"epoch": 24, "valid_loss": "3.239", "valid_nll_loss": "1.42", "valid_ppl": "2.68", "valid_bleu": "57.11", "valid_wps": "181.5", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "34992", "valid_best_bleu": "57.11"}
2022-11-11 19:14:51 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 19:15:29 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_best.pt (epoch 24 @ 34992 updates, score 57.11) (writing took 37.479675482958555 seconds)
2022-11-11 19:15:29 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-11-11 19:15:29 | INFO | train | {"epoch": 24, "train_loss": "2.224", "train_nll_loss": "0.338", "train_ppl": "1.26", "train_wps": "873.9", "train_ups": "0.49", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "34992", "train_lr": "4.82745e-05", "train_gnorm": "1.431", "train_train_wall": "1163", "train_wall": "71565"}
2022-11-11 19:15:29 | INFO | fairseq.trainer | begin training epoch 25
2022-11-11 19:15:35 | INFO | train_inner | {"epoch": 25, "update": 24.005, "loss": "2.22", "nll_loss": "0.334", "ppl": "1.26", "wps": "92.6", "ups": "0.05", "wpb": "1759.3", "bsz": "31.7", "num_updates": "35000", "lr": "4.82741e-05", "gnorm": "1.506", "train_wall": "78", "wall": "71571"}
2022-11-11 19:16:55 | INFO | train_inner | {"epoch": 25, "update": 24.074, "loss": "2.212", "nll_loss": "0.324", "ppl": "1.25", "wps": "2235.2", "ups": "1.25", "wpb": "1792.2", "bsz": "32", "num_updates": "35100", "lr": "4.82691e-05", "gnorm": "1.383", "train_wall": "80", "wall": "71651"}
2022-11-11 19:18:15 | INFO | train_inner | {"epoch": 25, "update": 24.143, "loss": "2.207", "nll_loss": "0.319", "ppl": "1.25", "wps": "2236.5", "ups": "1.26", "wpb": "1780.6", "bsz": "32", "num_updates": "35200", "lr": "4.82641e-05", "gnorm": "1.397", "train_wall": "79", "wall": "71731"}
2022-11-11 19:19:35 | INFO | train_inner | {"epoch": 25, "update": 24.211, "loss": "2.2", "nll_loss": "0.311", "ppl": "1.24", "wps": "2210.4", "ups": "1.25", "wpb": "1761.3", "bsz": "32", "num_updates": "35300", "lr": "4.82591e-05", "gnorm": "1.366", "train_wall": "79", "wall": "71811"}
2022-11-11 19:20:55 | INFO | train_inner | {"epoch": 25, "update": 24.28, "loss": "2.205", "nll_loss": "0.317", "ppl": "1.25", "wps": "2220.3", "ups": "1.25", "wpb": "1782.1", "bsz": "32", "num_updates": "35400", "lr": "4.82541e-05", "gnorm": "1.407", "train_wall": "80", "wall": "71891"}
2022-11-11 19:22:14 | INFO | train_inner | {"epoch": 25, "update": 24.348, "loss": "2.214", "nll_loss": "0.328", "ppl": "1.25", "wps": "2203.9", "ups": "1.27", "wpb": "1738.2", "bsz": "32", "num_updates": "35500", "lr": "4.82491e-05", "gnorm": "1.455", "train_wall": "78", "wall": "71970"}
2022-11-11 19:23:34 | INFO | train_inner | {"epoch": 25, "update": 24.417, "loss": "2.212", "nll_loss": "0.324", "ppl": "1.25", "wps": "2245.8", "ups": "1.24", "wpb": "1805", "bsz": "32", "num_updates": "35600", "lr": "4.82441e-05", "gnorm": "1.412", "train_wall": "80", "wall": "72050"}
2022-11-11 19:24:55 | INFO | train_inner | {"epoch": 25, "update": 24.486, "loss": "2.242", "nll_loss": "0.359", "ppl": "1.28", "wps": "2252.6", "ups": "1.25", "wpb": "1808.6", "bsz": "32", "num_updates": "35700", "lr": "4.82391e-05", "gnorm": "1.451", "train_wall": "80", "wall": "72130"}
2022-11-11 19:26:15 | INFO | train_inner | {"epoch": 25, "update": 24.554, "loss": "2.214", "nll_loss": "0.327", "ppl": "1.25", "wps": "2281.6", "ups": "1.24", "wpb": "1845", "bsz": "32", "num_updates": "35800", "lr": "4.82341e-05", "gnorm": "1.414", "train_wall": "80", "wall": "72211"}
2022-11-11 19:27:35 | INFO | train_inner | {"epoch": 25, "update": 24.623, "loss": "2.21", "nll_loss": "0.323", "ppl": "1.25", "wps": "2229.1", "ups": "1.25", "wpb": "1776.2", "bsz": "32", "num_updates": "35900", "lr": "4.82291e-05", "gnorm": "1.395", "train_wall": "79", "wall": "72291"}
2022-11-11 19:28:56 | INFO | train_inner | {"epoch": 25, "update": 24.691, "loss": "2.218", "nll_loss": "0.331", "ppl": "1.26", "wps": "2269.9", "ups": "1.23", "wpb": "1842.2", "bsz": "32", "num_updates": "36000", "lr": "4.82241e-05", "gnorm": "1.428", "train_wall": "81", "wall": "72372"}
2022-11-11 19:30:17 | INFO | train_inner | {"epoch": 25, "update": 24.76, "loss": "2.218", "nll_loss": "0.331", "ppl": "1.26", "wps": "2238.3", "ups": "1.24", "wpb": "1805.8", "bsz": "32", "num_updates": "36100", "lr": "4.82191e-05", "gnorm": "1.453", "train_wall": "80", "wall": "72453"}
2022-11-11 19:31:36 | INFO | train_inner | {"epoch": 25, "update": 24.829, "loss": "2.215", "nll_loss": "0.328", "ppl": "1.26", "wps": "2237.3", "ups": "1.26", "wpb": "1777.8", "bsz": "32", "num_updates": "36200", "lr": "4.82141e-05", "gnorm": "1.454", "train_wall": "79", "wall": "72532"}
2022-11-11 19:32:57 | INFO | train_inner | {"epoch": 25, "update": 24.897, "loss": "2.228", "nll_loss": "0.344", "ppl": "1.27", "wps": "2230.5", "ups": "1.24", "wpb": "1799", "bsz": "32", "num_updates": "36300", "lr": "4.82091e-05", "gnorm": "1.482", "train_wall": "80", "wall": "72613"}
2022-11-11 19:34:18 | INFO | train_inner | {"epoch": 25, "update": 24.966, "loss": "2.229", "nll_loss": "0.345", "ppl": "1.27", "wps": "2261.2", "ups": "1.24", "wpb": "1821.1", "bsz": "32", "num_updates": "36400", "lr": "4.82041e-05", "gnorm": "1.483", "train_wall": "80", "wall": "72693"}
2022-11-11 19:34:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 20:03:43 | INFO | valid | {"epoch": 25, "valid_loss": "3.248", "valid_nll_loss": "1.439", "valid_ppl": "2.71", "valid_bleu": "55.65", "valid_wps": "187.5", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "36450", "valid_best_bleu": "57.11"}
2022-11-11 20:03:43 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 20:04:04 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 25 @ 36450 updates, score 55.65) (writing took 20.887359131127596 seconds)
2022-11-11 20:04:04 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-11-11 20:04:04 | INFO | train | {"epoch": 25, "train_loss": "2.216", "train_nll_loss": "0.329", "train_ppl": "1.26", "train_wps": "896.5", "train_ups": "0.5", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "36450", "train_lr": "4.82016e-05", "train_gnorm": "1.427", "train_train_wall": "1161", "train_wall": "74480"}
2022-11-11 20:04:04 | INFO | fairseq.trainer | begin training epoch 26
2022-11-11 20:04:45 | INFO | train_inner | {"epoch": 26, "update": 25.034, "loss": "2.202", "nll_loss": "0.314", "ppl": "1.24", "wps": "95.7", "ups": "0.05", "wpb": "1748.9", "bsz": "31.7", "num_updates": "36500", "lr": "4.81991e-05", "gnorm": "1.397", "train_wall": "79", "wall": "74520"}
2022-11-11 20:06:04 | INFO | train_inner | {"epoch": 26, "update": 25.103, "loss": "2.2", "nll_loss": "0.312", "ppl": "1.24", "wps": "2249.2", "ups": "1.25", "wpb": "1793.3", "bsz": "32", "num_updates": "36600", "lr": "4.81941e-05", "gnorm": "1.359", "train_wall": "79", "wall": "74600"}
2022-11-11 20:07:24 | INFO | train_inner | {"epoch": 26, "update": 25.171, "loss": "2.193", "nll_loss": "0.304", "ppl": "1.23", "wps": "2248.1", "ups": "1.26", "wpb": "1789.6", "bsz": "32", "num_updates": "36700", "lr": "4.81891e-05", "gnorm": "1.361", "train_wall": "79", "wall": "74680"}
2022-11-11 20:08:45 | INFO | train_inner | {"epoch": 26, "update": 25.24, "loss": "2.198", "nll_loss": "0.309", "ppl": "1.24", "wps": "2251.3", "ups": "1.24", "wpb": "1818.7", "bsz": "32", "num_updates": "36800", "lr": "4.81841e-05", "gnorm": "1.395", "train_wall": "80", "wall": "74760"}
2022-11-11 20:10:05 | INFO | train_inner | {"epoch": 26, "update": 25.309, "loss": "2.201", "nll_loss": "0.314", "ppl": "1.24", "wps": "2245.3", "ups": "1.24", "wpb": "1808.8", "bsz": "32", "num_updates": "36900", "lr": "4.81791e-05", "gnorm": "1.364", "train_wall": "80", "wall": "74841"}
2022-11-11 20:11:25 | INFO | train_inner | {"epoch": 26, "update": 25.377, "loss": "2.204", "nll_loss": "0.316", "ppl": "1.25", "wps": "2229.5", "ups": "1.26", "wpb": "1775.1", "bsz": "32", "num_updates": "37000", "lr": "4.81741e-05", "gnorm": "1.384", "train_wall": "79", "wall": "74921"}
2022-11-11 20:12:46 | INFO | train_inner | {"epoch": 26, "update": 25.446, "loss": "2.2", "nll_loss": "0.313", "ppl": "1.24", "wps": "2267.8", "ups": "1.23", "wpb": "1848.8", "bsz": "32", "num_updates": "37100", "lr": "4.81691e-05", "gnorm": "1.329", "train_wall": "81", "wall": "75002"}
2022-11-11 20:14:07 | INFO | train_inner | {"epoch": 26, "update": 25.514, "loss": "2.232", "nll_loss": "0.348", "ppl": "1.27", "wps": "2237.2", "ups": "1.24", "wpb": "1799.9", "bsz": "32", "num_updates": "37200", "lr": "4.81641e-05", "gnorm": "1.452", "train_wall": "80", "wall": "75083"}
2022-11-11 20:15:26 | INFO | train_inner | {"epoch": 26, "update": 25.583, "loss": "2.205", "nll_loss": "0.318", "ppl": "1.25", "wps": "2164.6", "ups": "1.26", "wpb": "1712.2", "bsz": "32", "num_updates": "37300", "lr": "4.81591e-05", "gnorm": "1.441", "train_wall": "79", "wall": "75162"}
2022-11-11 20:16:45 | INFO | train_inner | {"epoch": 26, "update": 25.652, "loss": "2.202", "nll_loss": "0.315", "ppl": "1.24", "wps": "2212.2", "ups": "1.26", "wpb": "1759.5", "bsz": "32", "num_updates": "37400", "lr": "4.81541e-05", "gnorm": "1.439", "train_wall": "79", "wall": "75241"}
2022-11-11 20:18:06 | INFO | train_inner | {"epoch": 26, "update": 25.72, "loss": "2.209", "nll_loss": "0.323", "ppl": "1.25", "wps": "2213.3", "ups": "1.25", "wpb": "1777", "bsz": "32", "num_updates": "37500", "lr": "4.81491e-05", "gnorm": "1.422", "train_wall": "80", "wall": "75321"}
2022-11-11 20:19:26 | INFO | train_inner | {"epoch": 26, "update": 25.789, "loss": "2.216", "nll_loss": "0.331", "ppl": "1.26", "wps": "2265.6", "ups": "1.25", "wpb": "1815.8", "bsz": "32", "num_updates": "37600", "lr": "4.81441e-05", "gnorm": "1.471", "train_wall": "80", "wall": "75402"}
2022-11-11 20:20:47 | INFO | train_inner | {"epoch": 26, "update": 25.857, "loss": "2.212", "nll_loss": "0.326", "ppl": "1.25", "wps": "2257.3", "ups": "1.23", "wpb": "1839.9", "bsz": "32", "num_updates": "37700", "lr": "4.81391e-05", "gnorm": "1.423", "train_wall": "81", "wall": "75483"}
2022-11-11 20:22:09 | INFO | train_inner | {"epoch": 26, "update": 25.926, "loss": "2.219", "nll_loss": "0.334", "ppl": "1.26", "wps": "2249.8", "ups": "1.22", "wpb": "1845.5", "bsz": "32", "num_updates": "37800", "lr": "4.81341e-05", "gnorm": "1.41", "train_wall": "82", "wall": "75565"}
2022-11-11 20:23:28 | INFO | train_inner | {"epoch": 26, "update": 25.995, "loss": "2.209", "nll_loss": "0.323", "ppl": "1.25", "wps": "2201.7", "ups": "1.27", "wpb": "1738.8", "bsz": "32", "num_updates": "37900", "lr": "4.81291e-05", "gnorm": "1.457", "train_wall": "79", "wall": "75644"}
2022-11-11 20:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 20:53:08 | INFO | valid | {"epoch": 26, "valid_loss": "3.278", "valid_nll_loss": "1.463", "valid_ppl": "2.76", "valid_bleu": "56.31", "valid_wps": "182.4", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "37908", "valid_best_bleu": "57.11"}
2022-11-11 20:53:08 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 20:53:29 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 26 @ 37908 updates, score 56.31) (writing took 20.887773590162396 seconds)
2022-11-11 20:53:29 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-11-11 20:53:29 | INFO | train | {"epoch": 26, "train_loss": "2.207", "train_nll_loss": "0.32", "train_ppl": "1.25", "train_wps": "881.5", "train_ups": "0.49", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "37908", "train_lr": "4.81287e-05", "train_gnorm": "1.407", "train_train_wall": "1163", "train_wall": "77445"}
2022-11-11 20:53:29 | INFO | fairseq.trainer | begin training epoch 27
2022-11-11 20:54:42 | INFO | train_inner | {"epoch": 27, "update": 26.063, "loss": "2.214", "nll_loss": "0.328", "ppl": "1.26", "wps": "93.4", "ups": "0.05", "wpb": "1750.3", "bsz": "31.7", "num_updates": "38000", "lr": "4.81241e-05", "gnorm": "1.39", "train_wall": "78", "wall": "77518"}
2022-11-11 20:56:02 | INFO | train_inner | {"epoch": 27, "update": 26.132, "loss": "2.192", "nll_loss": "0.303", "ppl": "1.23", "wps": "2233.2", "ups": "1.25", "wpb": "1787.3", "bsz": "32", "num_updates": "38100", "lr": "4.81191e-05", "gnorm": "1.341", "train_wall": "80", "wall": "77598"}
2022-11-11 20:57:23 | INFO | train_inner | {"epoch": 27, "update": 26.2, "loss": "2.192", "nll_loss": "0.304", "ppl": "1.23", "wps": "2251.2", "ups": "1.24", "wpb": "1810.6", "bsz": "32", "num_updates": "38200", "lr": "4.81141e-05", "gnorm": "1.4", "train_wall": "80", "wall": "77678"}
2022-11-11 20:58:43 | INFO | train_inner | {"epoch": 27, "update": 26.269, "loss": "2.188", "nll_loss": "0.3", "ppl": "1.23", "wps": "2235.1", "ups": "1.25", "wpb": "1786.9", "bsz": "32", "num_updates": "38300", "lr": "4.81091e-05", "gnorm": "1.37", "train_wall": "80", "wall": "77758"}
2022-11-11 21:00:03 | INFO | train_inner | {"epoch": 27, "update": 26.337, "loss": "2.201", "nll_loss": "0.314", "ppl": "1.24", "wps": "2214.7", "ups": "1.24", "wpb": "1784.4", "bsz": "32", "num_updates": "38400", "lr": "4.81041e-05", "gnorm": "1.381", "train_wall": "80", "wall": "77839"}
2022-11-11 21:01:25 | INFO | train_inner | {"epoch": 27, "update": 26.406, "loss": "2.196", "nll_loss": "0.309", "ppl": "1.24", "wps": "2224.3", "ups": "1.23", "wpb": "1814.4", "bsz": "32", "num_updates": "38500", "lr": "4.8099e-05", "gnorm": "1.402", "train_wall": "81", "wall": "77921"}
2022-11-11 21:02:46 | INFO | train_inner | {"epoch": 27, "update": 26.475, "loss": "2.188", "nll_loss": "0.299", "ppl": "1.23", "wps": "2241.6", "ups": "1.22", "wpb": "1831.1", "bsz": "32", "num_updates": "38600", "lr": "4.8094e-05", "gnorm": "1.343", "train_wall": "81", "wall": "78002"}
2022-11-11 21:04:07 | INFO | train_inner | {"epoch": 27, "update": 26.543, "loss": "2.198", "nll_loss": "0.31", "ppl": "1.24", "wps": "2236", "ups": "1.24", "wpb": "1804.5", "bsz": "32", "num_updates": "38700", "lr": "4.8089e-05", "gnorm": "1.393", "train_wall": "80", "wall": "78083"}
2022-11-11 21:05:28 | INFO | train_inner | {"epoch": 27, "update": 26.612, "loss": "2.204", "nll_loss": "0.318", "ppl": "1.25", "wps": "2234.4", "ups": "1.24", "wpb": "1802.6", "bsz": "32", "num_updates": "38800", "lr": "4.8084e-05", "gnorm": "1.402", "train_wall": "80", "wall": "78164"}
2022-11-11 21:06:48 | INFO | train_inner | {"epoch": 27, "update": 26.68, "loss": "2.198", "nll_loss": "0.309", "ppl": "1.24", "wps": "2231.5", "ups": "1.24", "wpb": "1795.7", "bsz": "32", "num_updates": "38900", "lr": "4.8079e-05", "gnorm": "1.384", "train_wall": "80", "wall": "78244"}
2022-11-11 21:08:08 | INFO | train_inner | {"epoch": 27, "update": 26.749, "loss": "2.199", "nll_loss": "0.312", "ppl": "1.24", "wps": "2234.6", "ups": "1.25", "wpb": "1785.9", "bsz": "32", "num_updates": "39000", "lr": "4.8074e-05", "gnorm": "1.449", "train_wall": "79", "wall": "78324"}
2022-11-11 21:09:29 | INFO | train_inner | {"epoch": 27, "update": 26.818, "loss": "2.203", "nll_loss": "0.318", "ppl": "1.25", "wps": "2216.7", "ups": "1.24", "wpb": "1791.3", "bsz": "32", "num_updates": "39100", "lr": "4.8069e-05", "gnorm": "1.469", "train_wall": "80", "wall": "78405"}
2022-11-11 21:10:50 | INFO | train_inner | {"epoch": 27, "update": 26.886, "loss": "2.201", "nll_loss": "0.314", "ppl": "1.24", "wps": "2174.4", "ups": "1.24", "wpb": "1750.4", "bsz": "32", "num_updates": "39200", "lr": "4.8064e-05", "gnorm": "1.449", "train_wall": "80", "wall": "78485"}
2022-11-11 21:12:11 | INFO | train_inner | {"epoch": 27, "update": 26.955, "loss": "2.215", "nll_loss": "0.331", "ppl": "1.26", "wps": "2279.7", "ups": "1.23", "wpb": "1852", "bsz": "32", "num_updates": "39300", "lr": "4.8059e-05", "gnorm": "1.439", "train_wall": "81", "wall": "78567"}
2022-11-11 21:13:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 21:42:10 | INFO | valid | {"epoch": 27, "valid_loss": "3.265", "valid_nll_loss": "1.452", "valid_ppl": "2.74", "valid_bleu": "54.2", "valid_wps": "185.1", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "39366", "valid_best_bleu": "57.11"}
2022-11-11 21:42:10 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 21:42:37 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 27 @ 39366 updates, score 54.2) (writing took 26.378051398321986 seconds)
2022-11-11 21:42:37 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-11-11 21:42:37 | INFO | train | {"epoch": 27, "train_loss": "2.2", "train_nll_loss": "0.313", "train_ppl": "1.24", "train_wps": "886.8", "train_ups": "0.49", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "39366", "train_lr": "4.80557e-05", "train_gnorm": "1.403", "train_train_wall": "1166", "train_wall": "80392"}
2022-11-11 21:42:37 | INFO | fairseq.trainer | begin training epoch 28
2022-11-11 21:43:05 | INFO | train_inner | {"epoch": 28, "update": 27.023, "loss": "2.199", "nll_loss": "0.312", "ppl": "1.24", "wps": "92.9", "ups": "0.05", "wpb": "1722.6", "bsz": "31.7", "num_updates": "39400", "lr": "4.8054e-05", "gnorm": "1.417", "train_wall": "79", "wall": "80420"}
2022-11-11 21:44:28 | INFO | train_inner | {"epoch": 28, "update": 27.092, "loss": "2.189", "nll_loss": "0.3", "ppl": "1.23", "wps": "2227.1", "ups": "1.2", "wpb": "1855.3", "bsz": "32", "num_updates": "39500", "lr": "4.8049e-05", "gnorm": "1.326", "train_wall": "83", "wall": "80504"}
2022-11-11 21:45:50 | INFO | train_inner | {"epoch": 28, "update": 27.16, "loss": "2.177", "nll_loss": "0.287", "ppl": "1.22", "wps": "2254.3", "ups": "1.22", "wpb": "1842.6", "bsz": "32", "num_updates": "39600", "lr": "4.8044e-05", "gnorm": "1.301", "train_wall": "81", "wall": "80585"}
2022-11-11 21:47:10 | INFO | train_inner | {"epoch": 28, "update": 27.229, "loss": "2.181", "nll_loss": "0.292", "ppl": "1.22", "wps": "2248", "ups": "1.24", "wpb": "1809.4", "bsz": "32", "num_updates": "39700", "lr": "4.8039e-05", "gnorm": "1.363", "train_wall": "80", "wall": "80666"}
2022-11-11 21:48:29 | INFO | train_inner | {"epoch": 28, "update": 27.298, "loss": "2.185", "nll_loss": "0.297", "ppl": "1.23", "wps": "2204.5", "ups": "1.27", "wpb": "1739", "bsz": "32", "num_updates": "39800", "lr": "4.8034e-05", "gnorm": "1.335", "train_wall": "78", "wall": "80745"}
2022-11-11 21:49:50 | INFO | train_inner | {"epoch": 28, "update": 27.366, "loss": "2.192", "nll_loss": "0.304", "ppl": "1.23", "wps": "2244.4", "ups": "1.24", "wpb": "1816.3", "bsz": "32", "num_updates": "39900", "lr": "4.8029e-05", "gnorm": "1.356", "train_wall": "80", "wall": "80826"}
2022-11-11 21:51:10 | INFO | train_inner | {"epoch": 28, "update": 27.435, "loss": "2.192", "nll_loss": "0.305", "ppl": "1.24", "wps": "2228", "ups": "1.25", "wpb": "1779.7", "bsz": "32", "num_updates": "40000", "lr": "4.8024e-05", "gnorm": "1.407", "train_wall": "79", "wall": "80906"}
2022-11-11 21:52:31 | INFO | train_inner | {"epoch": 28, "update": 27.503, "loss": "2.196", "nll_loss": "0.309", "ppl": "1.24", "wps": "2212.5", "ups": "1.24", "wpb": "1784.1", "bsz": "32", "num_updates": "40100", "lr": "4.8019e-05", "gnorm": "1.39", "train_wall": "80", "wall": "80986"}
2022-11-11 21:53:50 | INFO | train_inner | {"epoch": 28, "update": 27.572, "loss": "2.19", "nll_loss": "0.302", "ppl": "1.23", "wps": "2223.5", "ups": "1.25", "wpb": "1773.5", "bsz": "32", "num_updates": "40200", "lr": "4.8014e-05", "gnorm": "1.385", "train_wall": "79", "wall": "81066"}
2022-11-11 21:55:10 | INFO | train_inner | {"epoch": 28, "update": 27.641, "loss": "2.19", "nll_loss": "0.302", "ppl": "1.23", "wps": "2270.6", "ups": "1.25", "wpb": "1812.8", "bsz": "32", "num_updates": "40300", "lr": "4.8009e-05", "gnorm": "1.386", "train_wall": "79", "wall": "81146"}
2022-11-11 21:56:31 | INFO | train_inner | {"epoch": 28, "update": 27.709, "loss": "2.196", "nll_loss": "0.309", "ppl": "1.24", "wps": "2213", "ups": "1.24", "wpb": "1779.5", "bsz": "32", "num_updates": "40400", "lr": "4.8004e-05", "gnorm": "1.443", "train_wall": "80", "wall": "81226"}
2022-11-11 21:57:51 | INFO | train_inner | {"epoch": 28, "update": 27.778, "loss": "2.212", "nll_loss": "0.327", "ppl": "1.25", "wps": "2266", "ups": "1.24", "wpb": "1824.3", "bsz": "32", "num_updates": "40500", "lr": "4.7999e-05", "gnorm": "1.4", "train_wall": "80", "wall": "81307"}
2022-11-11 21:59:11 | INFO | train_inner | {"epoch": 28, "update": 27.846, "loss": "2.199", "nll_loss": "0.313", "ppl": "1.24", "wps": "2203.3", "ups": "1.25", "wpb": "1757.6", "bsz": "32", "num_updates": "40600", "lr": "4.7994e-05", "gnorm": "1.451", "train_wall": "79", "wall": "81387"}
2022-11-11 22:00:31 | INFO | train_inner | {"epoch": 28, "update": 27.915, "loss": "2.205", "nll_loss": "0.319", "ppl": "1.25", "wps": "2202.8", "ups": "1.25", "wpb": "1768.1", "bsz": "32", "num_updates": "40700", "lr": "4.7989e-05", "gnorm": "1.467", "train_wall": "80", "wall": "81467"}
2022-11-11 22:01:51 | INFO | train_inner | {"epoch": 28, "update": 27.984, "loss": "2.2", "nll_loss": "0.314", "ppl": "1.24", "wps": "2198.6", "ups": "1.25", "wpb": "1761", "bsz": "32", "num_updates": "40800", "lr": "4.7984e-05", "gnorm": "1.479", "train_wall": "80", "wall": "81547"}
2022-11-11 22:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 22:32:27 | INFO | valid | {"epoch": 28, "valid_loss": "3.27", "valid_nll_loss": "1.462", "valid_ppl": "2.75", "valid_bleu": "55.6", "valid_wps": "178.1", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "40824", "valid_best_bleu": "57.11"}
2022-11-11 22:32:27 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 22:32:53 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 28 @ 40824 updates, score 55.6) (writing took 25.61436859983951 seconds)
2022-11-11 22:32:53 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-11-11 22:32:53 | INFO | train | {"epoch": 28, "train_loss": "2.193", "train_nll_loss": "0.305", "train_ppl": "1.24", "train_wps": "866.5", "train_ups": "0.48", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "40824", "train_lr": "4.79828e-05", "train_gnorm": "1.391", "train_train_wall": "1167", "train_wall": "83409"}
2022-11-11 22:32:53 | INFO | fairseq.trainer | begin training epoch 29
2022-11-11 22:33:54 | INFO | train_inner | {"epoch": 29, "update": 28.052, "loss": "2.178", "nll_loss": "0.289", "ppl": "1.22", "wps": "92.2", "ups": "0.05", "wpb": "1772.5", "bsz": "31.7", "num_updates": "40900", "lr": "4.7979e-05", "gnorm": "1.367", "train_wall": "80", "wall": "83470"}
2022-11-11 22:35:15 | INFO | train_inner | {"epoch": 29, "update": 28.121, "loss": "2.167", "nll_loss": "0.277", "ppl": "1.21", "wps": "2157.4", "ups": "1.25", "wpb": "1732.5", "bsz": "32", "num_updates": "41000", "lr": "4.7974e-05", "gnorm": "1.314", "train_wall": "80", "wall": "83551"}
2022-11-11 22:36:35 | INFO | train_inner | {"epoch": 29, "update": 28.189, "loss": "2.193", "nll_loss": "0.307", "ppl": "1.24", "wps": "2242.7", "ups": "1.24", "wpb": "1809.2", "bsz": "32", "num_updates": "41100", "lr": "4.7969e-05", "gnorm": "1.373", "train_wall": "80", "wall": "83631"}
2022-11-11 22:37:55 | INFO | train_inner | {"epoch": 29, "update": 28.258, "loss": "2.183", "nll_loss": "0.294", "ppl": "1.23", "wps": "2232.8", "ups": "1.25", "wpb": "1782.9", "bsz": "32", "num_updates": "41200", "lr": "4.7964e-05", "gnorm": "1.356", "train_wall": "79", "wall": "83711"}
2022-11-11 22:39:17 | INFO | train_inner | {"epoch": 29, "update": 28.326, "loss": "2.197", "nll_loss": "0.311", "ppl": "1.24", "wps": "2267.6", "ups": "1.23", "wpb": "1848.7", "bsz": "32", "num_updates": "41300", "lr": "4.7959e-05", "gnorm": "1.379", "train_wall": "81", "wall": "83793"}
2022-11-11 22:40:38 | INFO | train_inner | {"epoch": 29, "update": 28.395, "loss": "2.181", "nll_loss": "0.293", "ppl": "1.23", "wps": "2224.1", "ups": "1.24", "wpb": "1799.4", "bsz": "32", "num_updates": "41400", "lr": "4.7954e-05", "gnorm": "1.397", "train_wall": "80", "wall": "83874"}
2022-11-11 22:41:56 | INFO | train_inner | {"epoch": 29, "update": 28.464, "loss": "2.179", "nll_loss": "0.29", "ppl": "1.22", "wps": "2249.6", "ups": "1.27", "wpb": "1771.6", "bsz": "32", "num_updates": "41500", "lr": "4.7949e-05", "gnorm": "1.41", "train_wall": "78", "wall": "83952"}
2022-11-11 22:43:16 | INFO | train_inner | {"epoch": 29, "update": 28.532, "loss": "2.186", "nll_loss": "0.299", "ppl": "1.23", "wps": "2260", "ups": "1.25", "wpb": "1801.6", "bsz": "32", "num_updates": "41600", "lr": "4.7944e-05", "gnorm": "1.389", "train_wall": "79", "wall": "84032"}
2022-11-11 22:44:38 | INFO | train_inner | {"epoch": 29, "update": 28.601, "loss": "2.215", "nll_loss": "0.331", "ppl": "1.26", "wps": "2257.7", "ups": "1.22", "wpb": "1850.3", "bsz": "32", "num_updates": "41700", "lr": "4.7939e-05", "gnorm": "1.433", "train_wall": "82", "wall": "84114"}
2022-11-11 22:45:58 | INFO | train_inner | {"epoch": 29, "update": 28.669, "loss": "2.188", "nll_loss": "0.301", "ppl": "1.23", "wps": "2255", "ups": "1.25", "wpb": "1803.7", "bsz": "32", "num_updates": "41800", "lr": "4.7934e-05", "gnorm": "1.389", "train_wall": "80", "wall": "84194"}
2022-11-11 22:47:18 | INFO | train_inner | {"epoch": 29, "update": 28.738, "loss": "2.191", "nll_loss": "0.304", "ppl": "1.23", "wps": "2233.9", "ups": "1.25", "wpb": "1793.7", "bsz": "32", "num_updates": "41900", "lr": "4.7929e-05", "gnorm": "1.434", "train_wall": "80", "wall": "84274"}
2022-11-11 22:48:38 | INFO | train_inner | {"epoch": 29, "update": 28.807, "loss": "2.185", "nll_loss": "0.298", "ppl": "1.23", "wps": "2248.4", "ups": "1.26", "wpb": "1780.3", "bsz": "32", "num_updates": "42000", "lr": "4.7924e-05", "gnorm": "1.406", "train_wall": "79", "wall": "84353"}
2022-11-11 22:49:58 | INFO | train_inner | {"epoch": 29, "update": 28.875, "loss": "2.192", "nll_loss": "0.305", "ppl": "1.24", "wps": "2212.3", "ups": "1.24", "wpb": "1785.2", "bsz": "32", "num_updates": "42100", "lr": "4.7919e-05", "gnorm": "1.428", "train_wall": "80", "wall": "84434"}
2022-11-11 22:51:18 | INFO | train_inner | {"epoch": 29, "update": 28.944, "loss": "2.185", "nll_loss": "0.298", "ppl": "1.23", "wps": "2220.3", "ups": "1.26", "wpb": "1764.2", "bsz": "32", "num_updates": "42200", "lr": "4.7914e-05", "gnorm": "1.437", "train_wall": "79", "wall": "84514"}
2022-11-11 22:52:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-11 23:21:23 | INFO | valid | {"epoch": 29, "valid_loss": "3.293", "valid_nll_loss": "1.491", "valid_ppl": "2.81", "valid_bleu": "56.61", "valid_wps": "186.1", "valid_wpb": "222.1", "valid_bsz": "4", "valid_num_updates": "42282", "valid_best_bleu": "57.11"}
2022-11-11 23:21:23 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 5 runs
2022-11-11 23:21:23 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-11 23:21:43 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/small.parent_code.child_full_code-large/checkpoint_last.pt (epoch 29 @ 42282 updates, score 56.61) (writing took 20.327017473988235 seconds)
2022-11-11 23:21:43 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-11-11 23:21:43 | INFO | train | {"epoch": 29, "train_loss": "2.187", "train_nll_loss": "0.3", "train_ppl": "1.23", "train_wps": "891.9", "train_ups": "0.5", "train_wpb": "1792.6", "train_bsz": "32", "train_num_updates": "42282", "train_lr": "4.79099e-05", "train_gnorm": "1.395", "train_train_wall": "1164", "train_wall": "86339"}
2022-11-11 23:21:43 | INFO | fairseq_cli.train | done training in 86338.9 seconds
BLEU+case.mixed+numrefs.1+smooth.none+tok.none+version.1.5.1 = 57.3 79.6/65.8/54.3/45.3 (BP = 0.956 ratio = 0.957 hyp_len = 164208 ref_len = 171574)
BLEU: 57.28 ; Acc: 5.61
ngram match: 0.5728193283817219, weighted ngram match: 0.5801109479627051, syntax_match: 0.7084208229936462, dataflow_match: 0.6405578000781963
CodeBLEU score: 62.55
Medium Dataset:
---------------------------------------------------------------------------------------------
Source: source Target: target
2022-11-11 23:37:54 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_large', attention_dropout=0.1, batch_size=4, batch_size_valid=4, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, extra_lang_symbol='', fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1234, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_in_same_language', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='/home/y_shi202/related-project/MODIT/src', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=500, weight_decay=0.0, zero_sharding='none')
2022-11-11 23:37:54 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2022-11-11 23:37:54 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2022-11-11 23:37:54 | INFO | fairseq.data.data_utils | loaded 6542 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/valid.source-target.source
2022-11-11 23:37:54 | INFO | fairseq.data.data_utils | loaded 6542 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/valid.source-target.target
2022-11-11 23:37:54 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin valid source-target 6542 examples
2022-11-11 23:38:04 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1024, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2022-11-11 23:38:04 | INFO | fairseq_cli.train | task: translation_in_same_language (TranslationCodeBARTTask)
2022-11-11 23:38:04 | INFO | fairseq_cli.train | model: mbart_large (BARTModel)
2022-11-11 23:38:04 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2022-11-11 23:38:04 | INFO | fairseq_cli.train | num. model params: 406025216 (num. trained: 406025216)
2022-11-11 23:38:08 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-11-11 23:38:08 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-11-11 23:38:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-11-11 23:38:08 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-PCIE-32GB                    
2022-11-11 23:38:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-11-11 23:38:08 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-11-11 23:38:08 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 4
2022-11-11 23:38:08 | INFO | fairseq.trainer | no existing checkpoint found /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_last.pt
2022-11-11 23:38:08 | INFO | fairseq.trainer | loading train data for epoch 1
2022-11-11 23:38:08 | INFO | fairseq.data.data_utils | loaded 52324 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/train.source-target.source
2022-11-11 23:38:08 | INFO | fairseq.data.data_utils | loaded 52324 examples from: /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin/train.source-target.target
2022-11-11 23:38:08 | INFO | fairseq.tasks.translation | /home/y_shi202/related-project/MODIT/data/PLBART_DATA/medium.parent_code.child_full_code/data-bin train source-target 52324 examples
2022-11-11 23:38:08 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2022-11-11 23:38:08 | INFO | fairseq.trainer | begin training epoch 1
2022-11-11 23:40:28 | INFO | train_inner | {"epoch": 1, "update": 0.061, "loss": "12.781", "nll_loss": "12.416", "ppl": "5463.99", "wps": "3165.6", "ups": "0.72", "wpb": "4404.4", "bsz": "32", "num_updates": "100", "lr": "1e-05", "gnorm": "5.035", "train_wall": "139", "wall": "140"}
2022-11-11 23:42:45 | INFO | train_inner | {"epoch": 1, "update": 0.122, "loss": "9.967", "nll_loss": "9.239", "ppl": "604.31", "wps": "3132.2", "ups": "0.73", "wpb": "4296", "bsz": "32", "num_updates": "200", "lr": "2e-05", "gnorm": "2.51", "train_wall": "137", "wall": "277"}
2022-11-11 23:45:05 | INFO | train_inner | {"epoch": 1, "update": 0.183, "loss": "8.682", "nll_loss": "7.747", "ppl": "214.82", "wps": "3110", "ups": "0.72", "wpb": "4349.2", "bsz": "32", "num_updates": "300", "lr": "3e-05", "gnorm": "1.795", "train_wall": "139", "wall": "417"}
2022-11-11 23:47:25 | INFO | train_inner | {"epoch": 1, "update": 0.244, "loss": "8.058", "nll_loss": "6.988", "ppl": "126.98", "wps": "3104.3", "ups": "0.71", "wpb": "4358.8", "bsz": "32", "num_updates": "400", "lr": "4e-05", "gnorm": "1.997", "train_wall": "140", "wall": "557"}
2022-11-11 23:49:48 | INFO | train_inner | {"epoch": 1, "update": 0.306, "loss": "7.63", "nll_loss": "6.478", "ppl": "89.14", "wps": "3116.9", "ups": "0.7", "wpb": "4453.6", "bsz": "32", "num_updates": "500", "lr": "5e-05", "gnorm": "2.057", "train_wall": "142", "wall": "700"}
2022-11-11 23:52:08 | INFO | train_inner | {"epoch": 1, "update": 0.367, "loss": "7.25", "nll_loss": "6.039", "ppl": "65.75", "wps": "3069.4", "ups": "0.72", "wpb": "4286.2", "bsz": "32", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "1.867", "train_wall": "139", "wall": "840"}
2022-11-11 23:54:23 | INFO | train_inner | {"epoch": 1, "update": 0.428, "loss": "6.888", "nll_loss": "5.627", "ppl": "49.41", "wps": "3090.6", "ups": "0.74", "wpb": "4183", "bsz": "32", "num_updates": "700", "lr": "4.999e-05", "gnorm": "1.843", "train_wall": "135", "wall": "975"}
2022-11-11 23:56:46 | INFO | train_inner | {"epoch": 1, "update": 0.489, "loss": "6.728", "nll_loss": "5.444", "ppl": "43.52", "wps": "3103.7", "ups": "0.7", "wpb": "4427.2", "bsz": "32", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "1.784", "train_wall": "142", "wall": "1118"}
2022-11-11 23:59:07 | INFO | train_inner | {"epoch": 1, "update": 0.55, "loss": "6.465", "nll_loss": "5.146", "ppl": "35.41", "wps": "3104.8", "ups": "0.71", "wpb": "4381.8", "bsz": "32", "num_updates": "900", "lr": "4.998e-05", "gnorm": "1.757", "train_wall": "141", "wall": "1259"}
2022-11-12 00:01:27 | INFO | train_inner | {"epoch": 1, "update": 0.611, "loss": "6.28", "nll_loss": "4.937", "ppl": "30.64", "wps": "3105.5", "ups": "0.71", "wpb": "4363.1", "bsz": "32", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "1.745", "train_wall": "140", "wall": "1400"}
2022-11-12 00:03:49 | INFO | train_inner | {"epoch": 1, "update": 0.672, "loss": "6.092", "nll_loss": "4.724", "ppl": "26.43", "wps": "3069.7", "ups": "0.7", "wpb": "4356.7", "bsz": "32", "num_updates": "1100", "lr": "4.997e-05", "gnorm": "1.75", "train_wall": "141", "wall": "1542"}
2022-11-12 00:06:10 | INFO | train_inner | {"epoch": 1, "update": 0.733, "loss": "5.919", "nll_loss": "4.528", "ppl": "23.08", "wps": "3095.5", "ups": "0.71", "wpb": "4361.1", "bsz": "32", "num_updates": "1200", "lr": "4.9965e-05", "gnorm": "1.749", "train_wall": "140", "wall": "1682"}
2022-11-12 00:08:28 | INFO | train_inner | {"epoch": 1, "update": 0.795, "loss": "5.728", "nll_loss": "4.311", "ppl": "19.85", "wps": "3091.9", "ups": "0.73", "wpb": "4257.3", "bsz": "32", "num_updates": "1300", "lr": "4.996e-05", "gnorm": "1.751", "train_wall": "137", "wall": "1820"}
2022-11-12 00:10:47 | INFO | train_inner | {"epoch": 1, "update": 0.856, "loss": "5.652", "nll_loss": "4.226", "ppl": "18.71", "wps": "3077.1", "ups": "0.72", "wpb": "4295.8", "bsz": "32", "num_updates": "1400", "lr": "4.9955e-05", "gnorm": "1.727", "train_wall": "139", "wall": "1960"}
2022-11-12 00:13:05 | INFO | train_inner | {"epoch": 1, "update": 0.917, "loss": "5.5", "nll_loss": "4.053", "ppl": "16.6", "wps": "3092.7", "ups": "0.72", "wpb": "4266.5", "bsz": "32", "num_updates": "1500", "lr": "4.995e-05", "gnorm": "1.739", "train_wall": "137", "wall": "2098"}
2022-11-12 00:15:27 | INFO | train_inner | {"epoch": 1, "update": 0.978, "loss": "5.455", "nll_loss": "4.003", "ppl": "16.03", "wps": "3092.7", "ups": "0.71", "wpb": "4380.7", "bsz": "32", "num_updates": "1600", "lr": "4.9945e-05", "gnorm": "1.763", "train_wall": "141", "wall": "2239"}
2022-11-12 00:16:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
/home/y_shi202/.local/lib/python3.6/site-packages/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  "amp_C fused kernels unavailable, disabling multi_tensor_l2norm; "
2022-11-12 01:41:10 | INFO | valid | {"epoch": 1, "valid_loss": "5.252", "valid_nll_loss": "3.74", "valid_ppl": "13.36", "valid_bleu": "26.36", "valid_wps": "175", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "1636"}
2022-11-12 01:41:10 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 01:41:49 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 1 @ 1636 updates, score 26.36) (writing took 38.82646612590179 seconds)
2022-11-12 01:41:49 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-11-12 01:41:49 | INFO | train | {"epoch": 1, "train_loss": "7.159", "train_nll_loss": "5.956", "train_ppl": "62.09", "train_wps": "955.5", "train_ups": "0.22", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "1636", "train_lr": "4.99432e-05", "train_gnorm": "2.048", "train_train_wall": "2280", "train_wall": "7421"}
2022-11-12 01:41:49 | INFO | fairseq.trainer | begin training epoch 2
2022-11-12 01:43:16 | INFO | train_inner | {"epoch": 2, "update": 1.039, "loss": "5.26", "nll_loss": "3.781", "ppl": "13.75", "wps": "80.6", "ups": "0.02", "wpb": "4245.3", "bsz": "31.7", "num_updates": "1700", "lr": "4.994e-05", "gnorm": "1.755", "train_wall": "135", "wall": "7508"}
2022-11-12 01:45:32 | INFO | train_inner | {"epoch": 2, "update": 1.1, "loss": "5.169", "nll_loss": "3.679", "ppl": "12.8", "wps": "3122.5", "ups": "0.73", "wpb": "4252.2", "bsz": "32", "num_updates": "1800", "lr": "4.9935e-05", "gnorm": "1.769", "train_wall": "136", "wall": "7644"}
2022-11-12 01:47:52 | INFO | train_inner | {"epoch": 2, "update": 1.161, "loss": "5.085", "nll_loss": "3.583", "ppl": "11.98", "wps": "3112.4", "ups": "0.71", "wpb": "4356.4", "bsz": "32", "num_updates": "1900", "lr": "4.993e-05", "gnorm": "1.755", "train_wall": "140", "wall": "7784"}
2022-11-12 01:50:11 | INFO | train_inner | {"epoch": 2, "update": 1.222, "loss": "5.023", "nll_loss": "3.512", "ppl": "11.41", "wps": "3101.8", "ups": "0.72", "wpb": "4301.8", "bsz": "32", "num_updates": "2000", "lr": "4.9925e-05", "gnorm": "1.726", "train_wall": "138", "wall": "7923"}
2022-11-12 01:52:31 | INFO | train_inner | {"epoch": 2, "update": 1.284, "loss": "4.986", "nll_loss": "3.471", "ppl": "11.09", "wps": "3089.5", "ups": "0.71", "wpb": "4333", "bsz": "32", "num_updates": "2100", "lr": "4.992e-05", "gnorm": "1.77", "train_wall": "140", "wall": "8063"}
2022-11-12 01:54:51 | INFO | train_inner | {"epoch": 2, "update": 1.345, "loss": "4.914", "nll_loss": "3.389", "ppl": "10.48", "wps": "3121.5", "ups": "0.71", "wpb": "4370.7", "bsz": "32", "num_updates": "2200", "lr": "4.9915e-05", "gnorm": "1.748", "train_wall": "140", "wall": "8203"}
2022-11-12 01:57:13 | INFO | train_inner | {"epoch": 2, "update": 1.406, "loss": "4.904", "nll_loss": "3.377", "ppl": "10.39", "wps": "3103", "ups": "0.7", "wpb": "4417.6", "bsz": "32", "num_updates": "2300", "lr": "4.991e-05", "gnorm": "1.774", "train_wall": "142", "wall": "8346"}
2022-11-12 01:59:35 | INFO | train_inner | {"epoch": 2, "update": 1.467, "loss": "4.895", "nll_loss": "3.367", "ppl": "10.32", "wps": "3093.5", "ups": "0.71", "wpb": "4381.2", "bsz": "32", "num_updates": "2400", "lr": "4.9905e-05", "gnorm": "1.746", "train_wall": "141", "wall": "8487"}
2022-11-12 02:01:56 | INFO | train_inner | {"epoch": 2, "update": 1.528, "loss": "4.814", "nll_loss": "3.275", "ppl": "9.68", "wps": "3088.6", "ups": "0.71", "wpb": "4359.5", "bsz": "32", "num_updates": "2500", "lr": "4.98999e-05", "gnorm": "1.736", "train_wall": "141", "wall": "8628"}
2022-11-12 02:04:14 | INFO | train_inner | {"epoch": 2, "update": 1.589, "loss": "4.711", "nll_loss": "3.158", "ppl": "8.93", "wps": "3098.4", "ups": "0.73", "wpb": "4271.6", "bsz": "32", "num_updates": "2600", "lr": "4.98949e-05", "gnorm": "1.735", "train_wall": "137", "wall": "8766"}
2022-11-12 02:06:35 | INFO | train_inner | {"epoch": 2, "update": 1.65, "loss": "4.735", "nll_loss": "3.184", "ppl": "9.09", "wps": "3097.3", "ups": "0.71", "wpb": "4354.4", "bsz": "32", "num_updates": "2700", "lr": "4.98899e-05", "gnorm": "1.754", "train_wall": "140", "wall": "8907"}
2022-11-12 02:08:55 | INFO | train_inner | {"epoch": 2, "update": 1.711, "loss": "4.65", "nll_loss": "3.088", "ppl": "8.51", "wps": "3093.2", "ups": "0.71", "wpb": "4347.3", "bsz": "32", "num_updates": "2800", "lr": "4.98849e-05", "gnorm": "1.708", "train_wall": "140", "wall": "9047"}
2022-11-12 02:11:13 | INFO | train_inner | {"epoch": 2, "update": 1.773, "loss": "4.593", "nll_loss": "3.024", "ppl": "8.13", "wps": "3103.4", "ups": "0.72", "wpb": "4286.9", "bsz": "32", "num_updates": "2900", "lr": "4.98799e-05", "gnorm": "1.739", "train_wall": "138", "wall": "9185"}
2022-11-12 02:13:34 | INFO | train_inner | {"epoch": 2, "update": 1.834, "loss": "4.596", "nll_loss": "3.027", "ppl": "8.15", "wps": "3103.3", "ups": "0.71", "wpb": "4355.4", "bsz": "32", "num_updates": "3000", "lr": "4.98749e-05", "gnorm": "1.717", "train_wall": "140", "wall": "9326"}
2022-11-12 02:15:53 | INFO | train_inner | {"epoch": 2, "update": 1.895, "loss": "4.509", "nll_loss": "2.928", "ppl": "7.61", "wps": "3072.8", "ups": "0.72", "wpb": "4296.2", "bsz": "32", "num_updates": "3100", "lr": "4.98699e-05", "gnorm": "1.74", "train_wall": "139", "wall": "9466"}
2022-11-12 02:18:16 | INFO | train_inner | {"epoch": 2, "update": 1.956, "loss": "4.544", "nll_loss": "2.967", "ppl": "7.82", "wps": "3081.8", "ups": "0.7", "wpb": "4387.5", "bsz": "32", "num_updates": "3200", "lr": "4.98649e-05", "gnorm": "1.753", "train_wall": "142", "wall": "9608"}
2022-11-12 02:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-12 03:41:52 | INFO | valid | {"epoch": 2, "valid_loss": "4.354", "valid_nll_loss": "2.701", "valid_ppl": "6.5", "valid_bleu": "32.51", "valid_wps": "181.4", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "3272", "valid_best_bleu": "32.51"}
2022-11-12 03:41:52 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 03:42:29 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 2 @ 3272 updates, score 32.51) (writing took 37.3720808760263 seconds)
2022-11-12 03:42:29 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-11-12 03:42:29 | INFO | train | {"epoch": 2, "train_loss": "4.81", "train_nll_loss": "3.27", "train_ppl": "9.65", "train_wps": "979.6", "train_ups": "0.23", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "3272", "train_lr": "4.98613e-05", "train_gnorm": "1.746", "train_train_wall": "2280", "train_wall": "14661"}
2022-11-12 03:42:29 | INFO | fairseq.trainer | begin training epoch 3
2022-11-12 03:43:07 | INFO | train_inner | {"epoch": 3, "update": 2.017, "loss": "4.428", "nll_loss": "2.836", "ppl": "7.14", "wps": "84.5", "ups": "0.02", "wpb": "4303.1", "bsz": "31.7", "num_updates": "3300", "lr": "4.98599e-05", "gnorm": "1.743", "train_wall": "137", "wall": "14699"}
2022-11-12 03:45:25 | INFO | train_inner | {"epoch": 3, "update": 2.078, "loss": "4.313", "nll_loss": "2.706", "ppl": "6.53", "wps": "3146.2", "ups": "0.72", "wpb": "4351.5", "bsz": "32", "num_updates": "3400", "lr": "4.98549e-05", "gnorm": "1.69", "train_wall": "138", "wall": "14837"}
2022-11-12 03:47:44 | INFO | train_inner | {"epoch": 3, "update": 2.139, "loss": "4.253", "nll_loss": "2.637", "ppl": "6.22", "wps": "3114.4", "ups": "0.72", "wpb": "4325.4", "bsz": "32", "num_updates": "3500", "lr": "4.98499e-05", "gnorm": "1.724", "train_wall": "138", "wall": "14976"}
2022-11-12 03:50:06 | INFO | train_inner | {"epoch": 3, "update": 2.2, "loss": "4.24", "nll_loss": "2.622", "ppl": "6.16", "wps": "3110.8", "ups": "0.71", "wpb": "4408.9", "bsz": "32", "num_updates": "3600", "lr": "4.98449e-05", "gnorm": "1.689", "train_wall": "141", "wall": "15118"}
2022-11-12 03:52:24 | INFO | train_inner | {"epoch": 3, "update": 2.262, "loss": "4.203", "nll_loss": "2.58", "ppl": "5.98", "wps": "3099.4", "ups": "0.72", "wpb": "4277.3", "bsz": "32", "num_updates": "3700", "lr": "4.98399e-05", "gnorm": "1.705", "train_wall": "138", "wall": "15256"}
2022-11-12 03:54:44 | INFO | train_inner | {"epoch": 3, "update": 2.323, "loss": "4.173", "nll_loss": "2.545", "ppl": "5.84", "wps": "3104.6", "ups": "0.71", "wpb": "4344.3", "bsz": "32", "num_updates": "3800", "lr": "4.98349e-05", "gnorm": "1.699", "train_wall": "139", "wall": "15396"}
2022-11-12 03:57:03 | INFO | train_inner | {"epoch": 3, "update": 2.384, "loss": "4.131", "nll_loss": "2.498", "ppl": "5.65", "wps": "3093.7", "ups": "0.72", "wpb": "4307.2", "bsz": "32", "num_updates": "3900", "lr": "4.98299e-05", "gnorm": "1.722", "train_wall": "139", "wall": "15535"}
2022-11-12 03:59:22 | INFO | train_inner | {"epoch": 3, "update": 2.445, "loss": "4.084", "nll_loss": "2.443", "ppl": "5.44", "wps": "3103.2", "ups": "0.72", "wpb": "4305.3", "bsz": "32", "num_updates": "4000", "lr": "4.98249e-05", "gnorm": "1.718", "train_wall": "138", "wall": "15674"}
2022-11-12 04:01:42 | INFO | train_inner | {"epoch": 3, "update": 2.506, "loss": "4.093", "nll_loss": "2.453", "ppl": "5.47", "wps": "3093.5", "ups": "0.71", "wpb": "4341.7", "bsz": "32", "num_updates": "4100", "lr": "4.98199e-05", "gnorm": "1.727", "train_wall": "140", "wall": "15814"}
2022-11-12 04:04:03 | INFO | train_inner | {"epoch": 3, "update": 2.567, "loss": "4.067", "nll_loss": "2.423", "ppl": "5.36", "wps": "3104.6", "ups": "0.71", "wpb": "4362.9", "bsz": "32", "num_updates": "4200", "lr": "4.98149e-05", "gnorm": "1.738", "train_wall": "140", "wall": "15955"}
2022-11-12 04:06:25 | INFO | train_inner | {"epoch": 3, "update": 2.628, "loss": "4.021", "nll_loss": "2.371", "ppl": "5.17", "wps": "3089.2", "ups": "0.7", "wpb": "4393.1", "bsz": "32", "num_updates": "4300", "lr": "4.98099e-05", "gnorm": "1.725", "train_wall": "142", "wall": "16097"}
2022-11-12 04:08:44 | INFO | train_inner | {"epoch": 3, "update": 2.689, "loss": "3.967", "nll_loss": "2.308", "ppl": "4.95", "wps": "3083", "ups": "0.72", "wpb": "4290.3", "bsz": "32", "num_updates": "4400", "lr": "4.98049e-05", "gnorm": "1.741", "train_wall": "139", "wall": "16236"}
2022-11-12 04:11:03 | INFO | train_inner | {"epoch": 3, "update": 2.751, "loss": "3.95", "nll_loss": "2.289", "ppl": "4.89", "wps": "3105.2", "ups": "0.72", "wpb": "4326", "bsz": "32", "num_updates": "4500", "lr": "4.97999e-05", "gnorm": "1.72", "train_wall": "139", "wall": "16375"}
2022-11-12 04:13:21 | INFO | train_inner | {"epoch": 3, "update": 2.812, "loss": "3.959", "nll_loss": "2.299", "ppl": "4.92", "wps": "3078.8", "ups": "0.72", "wpb": "4253.1", "bsz": "32", "num_updates": "4600", "lr": "4.97949e-05", "gnorm": "1.78", "train_wall": "138", "wall": "16514"}
2022-11-12 04:15:41 | INFO | train_inner | {"epoch": 3, "update": 2.873, "loss": "3.891", "nll_loss": "2.222", "ppl": "4.67", "wps": "3095.6", "ups": "0.72", "wpb": "4321.5", "bsz": "32", "num_updates": "4700", "lr": "4.97899e-05", "gnorm": "1.76", "train_wall": "139", "wall": "16653"}
2022-11-12 04:18:03 | INFO | train_inner | {"epoch": 3, "update": 2.934, "loss": "3.865", "nll_loss": "2.192", "ppl": "4.57", "wps": "3100.7", "ups": "0.7", "wpb": "4416.3", "bsz": "32", "num_updates": "4800", "lr": "4.97849e-05", "gnorm": "1.724", "train_wall": "142", "wall": "16796"}
2022-11-12 04:20:25 | INFO | train_inner | {"epoch": 3, "update": 2.995, "loss": "3.876", "nll_loss": "2.204", "ppl": "4.61", "wps": "3091.7", "ups": "0.7", "wpb": "4391.4", "bsz": "32", "num_updates": "4900", "lr": "4.97799e-05", "gnorm": "1.771", "train_wall": "142", "wall": "16938"}
2022-11-12 04:20:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-12 05:33:28 | INFO | valid | {"epoch": 3, "valid_loss": "3.731", "valid_nll_loss": "1.997", "valid_ppl": "3.99", "valid_bleu": "38.65", "valid_wps": "204", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "4908", "valid_best_bleu": "38.65"}
2022-11-12 05:33:28 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 05:34:08 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 3 @ 4908 updates, score 38.65) (writing took 40.19291790295392 seconds)
2022-11-12 05:34:08 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-11-12 05:34:08 | INFO | train | {"epoch": 3, "train_loss": "4.07", "train_nll_loss": "2.427", "train_ppl": "5.38", "train_wps": "1058.8", "train_ups": "0.24", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "4908", "train_lr": "4.97795e-05", "train_gnorm": "1.728", "train_train_wall": "2279", "train_wall": "21360"}
2022-11-12 05:34:08 | INFO | fairseq.trainer | begin training epoch 4
2022-11-12 05:36:17 | INFO | train_inner | {"epoch": 4, "update": 3.056, "loss": "3.703", "nll_loss": "2.007", "ppl": "4.02", "wps": "95.1", "ups": "0.02", "wpb": "4327", "bsz": "31.7", "num_updates": "5000", "lr": "4.97749e-05", "gnorm": "1.689", "train_wall": "138", "wall": "21489"}
2022-11-12 05:38:35 | INFO | train_inner | {"epoch": 4, "update": 3.117, "loss": "3.684", "nll_loss": "1.985", "ppl": "3.96", "wps": "3130.3", "ups": "0.72", "wpb": "4321.8", "bsz": "32", "num_updates": "5100", "lr": "4.97699e-05", "gnorm": "1.661", "train_wall": "138", "wall": "21627"}
2022-11-12 05:40:55 | INFO | train_inner | {"epoch": 4, "update": 3.178, "loss": "3.653", "nll_loss": "1.95", "ppl": "3.86", "wps": "3116.5", "ups": "0.71", "wpb": "4380.6", "bsz": "32", "num_updates": "5200", "lr": "4.97649e-05", "gnorm": "1.645", "train_wall": "140", "wall": "21767"}
2022-11-12 05:43:16 | INFO | train_inner | {"epoch": 4, "update": 3.24, "loss": "3.656", "nll_loss": "1.952", "ppl": "3.87", "wps": "3099.8", "ups": "0.71", "wpb": "4373.5", "bsz": "32", "num_updates": "5300", "lr": "4.97599e-05", "gnorm": "1.68", "train_wall": "141", "wall": "21909"}
2022-11-12 05:45:36 | INFO | train_inner | {"epoch": 4, "update": 3.301, "loss": "3.611", "nll_loss": "1.902", "ppl": "3.74", "wps": "3107.1", "ups": "0.71", "wpb": "4355.8", "bsz": "32", "num_updates": "5400", "lr": "4.97549e-05", "gnorm": "1.647", "train_wall": "140", "wall": "22049"}
2022-11-12 05:47:55 | INFO | train_inner | {"epoch": 4, "update": 3.362, "loss": "3.576", "nll_loss": "1.861", "ppl": "3.63", "wps": "3106", "ups": "0.72", "wpb": "4296.5", "bsz": "32", "num_updates": "5500", "lr": "4.97499e-05", "gnorm": "1.655", "train_wall": "138", "wall": "22187"}
2022-11-12 05:50:13 | INFO | train_inner | {"epoch": 4, "update": 3.423, "loss": "3.593", "nll_loss": "1.881", "ppl": "3.68", "wps": "3080.9", "ups": "0.72", "wpb": "4267.3", "bsz": "32", "num_updates": "5600", "lr": "4.97449e-05", "gnorm": "1.674", "train_wall": "138", "wall": "22326"}
2022-11-12 05:52:35 | INFO | train_inner | {"epoch": 4, "update": 3.484, "loss": "3.587", "nll_loss": "1.874", "ppl": "3.66", "wps": "3057.3", "ups": "0.71", "wpb": "4317.4", "bsz": "32", "num_updates": "5700", "lr": "4.97399e-05", "gnorm": "1.669", "train_wall": "141", "wall": "22467"}
2022-11-12 05:54:57 | INFO | train_inner | {"epoch": 4, "update": 3.545, "loss": "3.554", "nll_loss": "1.836", "ppl": "3.57", "wps": "3064.2", "ups": "0.7", "wpb": "4375.7", "bsz": "32", "num_updates": "5800", "lr": "4.97349e-05", "gnorm": "1.65", "train_wall": "142", "wall": "22610"}
2022-11-12 05:57:21 | INFO | train_inner | {"epoch": 4, "update": 3.606, "loss": "3.524", "nll_loss": "1.802", "ppl": "3.49", "wps": "3043", "ups": "0.7", "wpb": "4360.9", "bsz": "32", "num_updates": "5900", "lr": "4.97299e-05", "gnorm": "1.635", "train_wall": "143", "wall": "22753"}
2022-11-12 05:59:42 | INFO | train_inner | {"epoch": 4, "update": 3.667, "loss": "3.533", "nll_loss": "1.813", "ppl": "3.51", "wps": "3094.2", "ups": "0.71", "wpb": "4385.4", "bsz": "32", "num_updates": "6000", "lr": "4.97249e-05", "gnorm": "1.659", "train_wall": "141", "wall": "22895"}
2022-11-12 06:02:03 | INFO | train_inner | {"epoch": 4, "update": 3.729, "loss": "3.496", "nll_loss": "1.77", "ppl": "3.41", "wps": "3103.8", "ups": "0.71", "wpb": "4377.7", "bsz": "32", "num_updates": "6100", "lr": "4.97199e-05", "gnorm": "1.628", "train_wall": "141", "wall": "23036"}
2022-11-12 06:04:24 | INFO | train_inner | {"epoch": 4, "update": 3.79, "loss": "3.476", "nll_loss": "1.747", "ppl": "3.36", "wps": "3057.4", "ups": "0.71", "wpb": "4312.9", "bsz": "32", "num_updates": "6200", "lr": "4.97149e-05", "gnorm": "1.653", "train_wall": "141", "wall": "23177"}
2022-11-12 06:06:42 | INFO | train_inner | {"epoch": 4, "update": 3.851, "loss": "3.46", "nll_loss": "1.73", "ppl": "3.32", "wps": "3085.4", "ups": "0.73", "wpb": "4253.6", "bsz": "32", "num_updates": "6300", "lr": "4.97099e-05", "gnorm": "1.614", "train_wall": "137", "wall": "23315"}
2022-11-12 06:09:06 | INFO | train_inner | {"epoch": 4, "update": 3.912, "loss": "3.476", "nll_loss": "1.746", "ppl": "3.36", "wps": "3108", "ups": "0.7", "wpb": "4467.9", "bsz": "32", "num_updates": "6400", "lr": "4.97049e-05", "gnorm": "1.624", "train_wall": "143", "wall": "23458"}
2022-11-12 06:11:23 | INFO | train_inner | {"epoch": 4, "update": 3.973, "loss": "3.428", "nll_loss": "1.692", "ppl": "3.23", "wps": "3065", "ups": "0.73", "wpb": "4193.6", "bsz": "32", "num_updates": "6500", "lr": "4.96998e-05", "gnorm": "1.64", "train_wall": "136", "wall": "23595"}
2022-11-12 06:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-12 07:21:07 | INFO | valid | {"epoch": 4, "valid_loss": "3.435", "valid_nll_loss": "1.664", "valid_ppl": "3.17", "valid_bleu": "40.1", "valid_wps": "216.2", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "6544", "valid_best_bleu": "40.1"}
2022-11-12 07:21:07 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 07:21:44 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 4 @ 6544 updates, score 40.1) (writing took 37.414746639318764 seconds)
2022-11-12 07:21:44 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-11-12 07:21:44 | INFO | train | {"epoch": 4, "train_loss": "3.559", "train_nll_loss": "1.842", "train_ppl": "3.58", "train_wps": "1098.5", "train_ups": "0.25", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "6544", "train_lr": "4.96976e-05", "train_gnorm": "1.652", "train_train_wall": "2289", "train_wall": "27817"}
2022-11-12 07:21:44 | INFO | fairseq.trainer | begin training epoch 5
2022-11-12 07:23:02 | INFO | train_inner | {"epoch": 5, "update": 4.034, "loss": "3.399", "nll_loss": "1.66", "ppl": "3.16", "wps": "101.1", "ups": "0.02", "wpb": "4345.4", "bsz": "31.7", "num_updates": "6600", "lr": "4.96948e-05", "gnorm": "1.673", "train_wall": "139", "wall": "27895"}
2022-11-12 07:25:19 | INFO | train_inner | {"epoch": 5, "update": 4.095, "loss": "3.286", "nll_loss": "1.532", "ppl": "2.89", "wps": "3145.6", "ups": "0.73", "wpb": "4305.2", "bsz": "32", "num_updates": "6700", "lr": "4.96898e-05", "gnorm": "1.533", "train_wall": "136", "wall": "28031"}
2022-11-12 07:27:36 | INFO | train_inner | {"epoch": 5, "update": 4.156, "loss": "3.287", "nll_loss": "1.532", "ppl": "2.89", "wps": "3107.2", "ups": "0.73", "wpb": "4256.1", "bsz": "32", "num_updates": "6800", "lr": "4.96848e-05", "gnorm": "1.566", "train_wall": "137", "wall": "28168"}
2022-11-12 07:29:57 | INFO | train_inner | {"epoch": 5, "update": 4.218, "loss": "3.288", "nll_loss": "1.533", "ppl": "2.89", "wps": "3110.4", "ups": "0.71", "wpb": "4392.2", "bsz": "32", "num_updates": "6900", "lr": "4.96798e-05", "gnorm": "1.55", "train_wall": "141", "wall": "28310"}
2022-11-12 07:32:18 | INFO | train_inner | {"epoch": 5, "update": 4.279, "loss": "3.277", "nll_loss": "1.52", "ppl": "2.87", "wps": "3101.5", "ups": "0.71", "wpb": "4373.7", "bsz": "32", "num_updates": "7000", "lr": "4.96748e-05", "gnorm": "1.548", "train_wall": "141", "wall": "28451"}
2022-11-12 07:34:37 | INFO | train_inner | {"epoch": 5, "update": 4.34, "loss": "3.272", "nll_loss": "1.516", "ppl": "2.86", "wps": "3088.7", "ups": "0.72", "wpb": "4275.1", "bsz": "32", "num_updates": "7100", "lr": "4.96698e-05", "gnorm": "1.58", "train_wall": "138", "wall": "28589"}
2022-11-12 07:36:57 | INFO | train_inner | {"epoch": 5, "update": 4.401, "loss": "3.27", "nll_loss": "1.513", "ppl": "2.85", "wps": "3087.1", "ups": "0.71", "wpb": "4337.5", "bsz": "32", "num_updates": "7200", "lr": "4.96648e-05", "gnorm": "1.553", "train_wall": "140", "wall": "28730"}
2022-11-12 07:39:16 | INFO | train_inner | {"epoch": 5, "update": 4.462, "loss": "3.251", "nll_loss": "1.491", "ppl": "2.81", "wps": "3110.8", "ups": "0.72", "wpb": "4319.1", "bsz": "32", "num_updates": "7300", "lr": "4.96598e-05", "gnorm": "1.544", "train_wall": "138", "wall": "28868"}
2022-11-12 07:41:37 | INFO | train_inner | {"epoch": 5, "update": 4.523, "loss": "3.282", "nll_loss": "1.526", "ppl": "2.88", "wps": "3107.3", "ups": "0.71", "wpb": "4381.3", "bsz": "32", "num_updates": "7400", "lr": "4.96548e-05", "gnorm": "1.573", "train_wall": "141", "wall": "29009"}
2022-11-12 07:43:56 | INFO | train_inner | {"epoch": 5, "update": 4.584, "loss": "3.246", "nll_loss": "1.486", "ppl": "2.8", "wps": "3106.2", "ups": "0.72", "wpb": "4325.6", "bsz": "32", "num_updates": "7500", "lr": "4.96498e-05", "gnorm": "1.563", "train_wall": "139", "wall": "29149"}
2022-11-12 07:46:15 | INFO | train_inner | {"epoch": 5, "update": 4.645, "loss": "3.238", "nll_loss": "1.477", "ppl": "2.78", "wps": "3086.6", "ups": "0.72", "wpb": "4292.6", "bsz": "32", "num_updates": "7600", "lr": "4.96448e-05", "gnorm": "1.58", "train_wall": "139", "wall": "29288"}
2022-11-12 07:48:36 | INFO | train_inner | {"epoch": 5, "update": 4.707, "loss": "3.263", "nll_loss": "1.505", "ppl": "2.84", "wps": "3091.6", "ups": "0.71", "wpb": "4344.9", "bsz": "32", "num_updates": "7700", "lr": "4.96398e-05", "gnorm": "1.547", "train_wall": "140", "wall": "29428"}
2022-11-12 07:50:54 | INFO | train_inner | {"epoch": 5, "update": 4.768, "loss": "3.205", "nll_loss": "1.439", "ppl": "2.71", "wps": "3088.8", "ups": "0.73", "wpb": "4249.9", "bsz": "32", "num_updates": "7800", "lr": "4.96348e-05", "gnorm": "1.563", "train_wall": "137", "wall": "29566"}
2022-11-12 07:53:13 | INFO | train_inner | {"epoch": 5, "update": 4.829, "loss": "3.219", "nll_loss": "1.456", "ppl": "2.74", "wps": "3101.3", "ups": "0.72", "wpb": "4322.2", "bsz": "32", "num_updates": "7900", "lr": "4.96298e-05", "gnorm": "1.539", "train_wall": "139", "wall": "29705"}
2022-11-12 07:55:34 | INFO | train_inner | {"epoch": 5, "update": 4.89, "loss": "3.25", "nll_loss": "1.49", "ppl": "2.81", "wps": "3109.1", "ups": "0.71", "wpb": "4390.6", "bsz": "32", "num_updates": "8000", "lr": "4.96248e-05", "gnorm": "1.568", "train_wall": "141", "wall": "29846"}
2022-11-12 07:57:58 | INFO | train_inner | {"epoch": 5, "update": 4.951, "loss": "3.204", "nll_loss": "1.439", "ppl": "2.71", "wps": "3103.4", "ups": "0.7", "wpb": "4458.9", "bsz": "32", "num_updates": "8100", "lr": "4.96198e-05", "gnorm": "1.509", "train_wall": "143", "wall": "29990"}
2022-11-12 07:59:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-12 09:13:16 | INFO | valid | {"epoch": 5, "valid_loss": "3.237", "valid_nll_loss": "1.429", "valid_ppl": "2.69", "valid_bleu": "44.29", "valid_wps": "202.3", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "8180", "valid_best_bleu": "44.29"}
2022-11-12 09:13:16 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 09:13:56 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 5 @ 8180 updates, score 44.29) (writing took 40.28783312207088 seconds)
2022-11-12 09:13:56 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-11-12 09:13:56 | INFO | train | {"epoch": 5, "train_loss": "3.257", "train_nll_loss": "1.498", "train_ppl": "2.82", "train_wps": "1053.6", "train_ups": "0.24", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "8180", "train_lr": "4.96158e-05", "train_gnorm": "1.558", "train_train_wall": "2277", "train_wall": "34548"}
2022-11-12 09:13:56 | INFO | fairseq.trainer | begin training epoch 6
2022-11-12 09:14:24 | INFO | train_inner | {"epoch": 6, "update": 5.012, "loss": "3.169", "nll_loss": "1.398", "ppl": "2.63", "wps": "94.3", "ups": "0.02", "wpb": "4324.6", "bsz": "31.7", "num_updates": "8200", "lr": "4.96148e-05", "gnorm": "1.583", "train_wall": "139", "wall": "34577"}
2022-11-12 09:16:42 | INFO | train_inner | {"epoch": 6, "update": 5.073, "loss": "3.064", "nll_loss": "1.279", "ppl": "2.43", "wps": "3156.6", "ups": "0.73", "wpb": "4335.9", "bsz": "32", "num_updates": "8300", "lr": "4.96098e-05", "gnorm": "1.44", "train_wall": "137", "wall": "34714"}
2022-11-12 09:19:01 | INFO | train_inner | {"epoch": 6, "update": 5.134, "loss": "3.081", "nll_loss": "1.298", "ppl": "2.46", "wps": "3129.1", "ups": "0.72", "wpb": "4342.1", "bsz": "32", "num_updates": "8400", "lr": "4.96048e-05", "gnorm": "1.499", "train_wall": "138", "wall": "34853"}
2022-11-12 09:21:19 | INFO | train_inner | {"epoch": 6, "update": 5.196, "loss": "3.072", "nll_loss": "1.288", "ppl": "2.44", "wps": "3091.3", "ups": "0.72", "wpb": "4273.9", "bsz": "32", "num_updates": "8500", "lr": "4.95998e-05", "gnorm": "1.499", "train_wall": "138", "wall": "34991"}
2022-11-12 09:23:40 | INFO | train_inner | {"epoch": 6, "update": 5.257, "loss": "3.082", "nll_loss": "1.299", "ppl": "2.46", "wps": "3108.6", "ups": "0.71", "wpb": "4400.9", "bsz": "32", "num_updates": "8600", "lr": "4.95948e-05", "gnorm": "1.505", "train_wall": "141", "wall": "35133"}
2022-11-12 09:26:01 | INFO | train_inner | {"epoch": 6, "update": 5.318, "loss": "3.059", "nll_loss": "1.275", "ppl": "2.42", "wps": "3080.2", "ups": "0.71", "wpb": "4323.4", "bsz": "32", "num_updates": "8700", "lr": "4.95898e-05", "gnorm": "1.483", "train_wall": "140", "wall": "35273"}
2022-11-12 09:28:19 | INFO | train_inner | {"epoch": 6, "update": 5.379, "loss": "3.073", "nll_loss": "1.29", "ppl": "2.45", "wps": "3092.9", "ups": "0.72", "wpb": "4287.7", "bsz": "32", "num_updates": "8800", "lr": "4.95848e-05", "gnorm": "1.533", "train_wall": "138", "wall": "35412"}
2022-11-12 09:30:40 | INFO | train_inner | {"epoch": 6, "update": 5.44, "loss": "3.08", "nll_loss": "1.298", "ppl": "2.46", "wps": "3122", "ups": "0.71", "wpb": "4384", "bsz": "32", "num_updates": "8900", "lr": "4.95798e-05", "gnorm": "1.519", "train_wall": "140", "wall": "35552"}
2022-11-12 09:33:01 | INFO | train_inner | {"epoch": 6, "update": 5.501, "loss": "3.074", "nll_loss": "1.291", "ppl": "2.45", "wps": "3111.6", "ups": "0.71", "wpb": "4399.7", "bsz": "32", "num_updates": "9000", "lr": "4.95748e-05", "gnorm": "1.49", "train_wall": "141", "wall": "35693"}
2022-11-12 09:35:24 | INFO | train_inner | {"epoch": 6, "update": 5.562, "loss": "3.048", "nll_loss": "1.262", "ppl": "2.4", "wps": "3099.8", "ups": "0.7", "wpb": "4427.6", "bsz": "32", "num_updates": "9100", "lr": "4.95698e-05", "gnorm": "1.451", "train_wall": "142", "wall": "35836"}
2022-11-12 09:37:42 | INFO | train_inner | {"epoch": 6, "update": 5.623, "loss": "3.036", "nll_loss": "1.248", "ppl": "2.38", "wps": "3089.9", "ups": "0.72", "wpb": "4266", "bsz": "32", "num_updates": "9200", "lr": "4.95648e-05", "gnorm": "1.495", "train_wall": "138", "wall": "35974"}
2022-11-12 09:40:05 | INFO | train_inner | {"epoch": 6, "update": 5.685, "loss": "3.066", "nll_loss": "1.283", "ppl": "2.43", "wps": "3054.7", "ups": "0.7", "wpb": "4362.6", "bsz": "32", "num_updates": "9300", "lr": "4.95598e-05", "gnorm": "1.532", "train_wall": "142", "wall": "36117"}
2022-11-12 09:42:27 | INFO | train_inner | {"epoch": 6, "update": 5.746, "loss": "3.061", "nll_loss": "1.277", "ppl": "2.42", "wps": "3079.6", "ups": "0.7", "wpb": "4370.2", "bsz": "32", "num_updates": "9400", "lr": "4.95548e-05", "gnorm": "1.465", "train_wall": "141", "wall": "36259"}
2022-11-12 09:44:47 | INFO | train_inner | {"epoch": 6, "update": 5.807, "loss": "3.048", "nll_loss": "1.262", "ppl": "2.4", "wps": "3084.6", "ups": "0.71", "wpb": "4321.1", "bsz": "32", "num_updates": "9500", "lr": "4.95498e-05", "gnorm": "1.483", "train_wall": "140", "wall": "36399"}
2022-11-12 09:47:09 | INFO | train_inner | {"epoch": 6, "update": 5.868, "loss": "3.044", "nll_loss": "1.257", "ppl": "2.39", "wps": "3048.5", "ups": "0.71", "wpb": "4322.9", "bsz": "32", "num_updates": "9600", "lr": "4.95448e-05", "gnorm": "1.479", "train_wall": "141", "wall": "36541"}
2022-11-12 09:49:30 | INFO | train_inner | {"epoch": 6, "update": 5.929, "loss": "3.055", "nll_loss": "1.27", "ppl": "2.41", "wps": "3062.4", "ups": "0.71", "wpb": "4334.9", "bsz": "32", "num_updates": "9700", "lr": "4.95398e-05", "gnorm": "1.506", "train_wall": "141", "wall": "36682"}
2022-11-12 09:51:47 | INFO | train_inner | {"epoch": 6, "update": 5.99, "loss": "3.023", "nll_loss": "1.234", "ppl": "2.35", "wps": "3086.3", "ups": "0.73", "wpb": "4232.2", "bsz": "32", "num_updates": "9800", "lr": "4.95348e-05", "gnorm": "1.494", "train_wall": "137", "wall": "36820"}
2022-11-12 09:52:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-12 11:07:29 | INFO | valid | {"epoch": 6, "valid_loss": "3.071", "valid_nll_loss": "1.235", "valid_ppl": "2.35", "valid_bleu": "51.24", "valid_wps": "197.2", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "9816", "valid_best_bleu": "51.24"}
2022-11-12 11:07:29 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 11:08:11 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 6 @ 9816 updates, score 51.24) (writing took 42.12298410385847 seconds)
2022-11-12 11:08:11 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-11-12 11:08:11 | INFO | train | {"epoch": 6, "train_loss": "3.061", "train_nll_loss": "1.276", "train_ppl": "2.42", "train_wps": "1034.6", "train_ups": "0.24", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "9816", "train_lr": "4.9534e-05", "train_gnorm": "1.494", "train_train_wall": "2285", "train_wall": "41404"}
2022-11-12 11:08:11 | INFO | fairseq.trainer | begin training epoch 7
2022-11-12 11:10:11 | INFO | train_inner | {"epoch": 7, "update": 6.051, "loss": "2.934", "nll_loss": "1.132", "ppl": "2.19", "wps": "93.7", "ups": "0.02", "wpb": "4404.9", "bsz": "31.7", "num_updates": "9900", "lr": "4.95298e-05", "gnorm": "1.429", "train_wall": "140", "wall": "41523"}
2022-11-12 11:12:27 | INFO | train_inner | {"epoch": 7, "update": 6.112, "loss": "2.903", "nll_loss": "1.097", "ppl": "2.14", "wps": "3124.5", "ups": "0.74", "wpb": "4245.9", "bsz": "32", "num_updates": "10000", "lr": "4.95248e-05", "gnorm": "1.456", "train_wall": "135", "wall": "41659"}
2022-11-12 11:14:45 | INFO | train_inner | {"epoch": 7, "update": 6.174, "loss": "2.904", "nll_loss": "1.098", "ppl": "2.14", "wps": "3100.7", "ups": "0.73", "wpb": "4274", "bsz": "32", "num_updates": "10100", "lr": "4.95198e-05", "gnorm": "1.424", "train_wall": "137", "wall": "41797"}
2022-11-12 11:17:05 | INFO | train_inner | {"epoch": 7, "update": 6.235, "loss": "2.928", "nll_loss": "1.125", "ppl": "2.18", "wps": "3106.4", "ups": "0.71", "wpb": "4357.8", "bsz": "32", "num_updates": "10200", "lr": "4.95148e-05", "gnorm": "1.447", "train_wall": "140", "wall": "41937"}
2022-11-12 11:19:27 | INFO | train_inner | {"epoch": 7, "update": 6.296, "loss": "2.932", "nll_loss": "1.132", "ppl": "2.19", "wps": "3097.3", "ups": "0.71", "wpb": "4392.4", "bsz": "32", "num_updates": "10300", "lr": "4.95098e-05", "gnorm": "1.428", "train_wall": "141", "wall": "42079"}
2022-11-12 11:21:45 | INFO | train_inner | {"epoch": 7, "update": 6.357, "loss": "2.928", "nll_loss": "1.126", "ppl": "2.18", "wps": "3083.2", "ups": "0.72", "wpb": "4269.2", "bsz": "32", "num_updates": "10400", "lr": "4.95048e-05", "gnorm": "1.467", "train_wall": "138", "wall": "42217"}
2022-11-12 11:24:03 | INFO | train_inner | {"epoch": 7, "update": 6.418, "loss": "2.915", "nll_loss": "1.112", "ppl": "2.16", "wps": "3084.3", "ups": "0.72", "wpb": "4259.8", "bsz": "32", "num_updates": "10500", "lr": "4.94997e-05", "gnorm": "1.476", "train_wall": "138", "wall": "42356"}
2022-11-12 11:26:23 | INFO | train_inner | {"epoch": 7, "update": 6.479, "loss": "2.902", "nll_loss": "1.097", "ppl": "2.14", "wps": "3113.8", "ups": "0.72", "wpb": "4351.6", "bsz": "32", "num_updates": "10600", "lr": "4.94947e-05", "gnorm": "1.44", "train_wall": "139", "wall": "42495"}
2022-11-12 11:28:43 | INFO | train_inner | {"epoch": 7, "update": 6.54, "loss": "2.919", "nll_loss": "1.116", "ppl": "2.17", "wps": "3089.1", "ups": "0.72", "wpb": "4313.6", "bsz": "32", "num_updates": "10700", "lr": "4.94897e-05", "gnorm": "1.438", "train_wall": "139", "wall": "42635"}
2022-11-12 11:31:02 | INFO | train_inner | {"epoch": 7, "update": 6.601, "loss": "2.905", "nll_loss": "1.101", "ppl": "2.14", "wps": "3076.2", "ups": "0.72", "wpb": "4285.4", "bsz": "32", "num_updates": "10800", "lr": "4.94847e-05", "gnorm": "1.471", "train_wall": "139", "wall": "42774"}
2022-11-12 11:33:24 | INFO | train_inner | {"epoch": 7, "update": 6.663, "loss": "2.906", "nll_loss": "1.101", "ppl": "2.15", "wps": "3094.7", "ups": "0.71", "wpb": "4389", "bsz": "32", "num_updates": "10900", "lr": "4.94797e-05", "gnorm": "1.432", "train_wall": "141", "wall": "42916"}
2022-11-12 11:35:45 | INFO | train_inner | {"epoch": 7, "update": 6.724, "loss": "2.915", "nll_loss": "1.112", "ppl": "2.16", "wps": "3095.7", "ups": "0.71", "wpb": "4372.1", "bsz": "32", "num_updates": "11000", "lr": "4.94747e-05", "gnorm": "1.422", "train_wall": "141", "wall": "43057"}
2022-11-12 11:38:06 | INFO | train_inner | {"epoch": 7, "update": 6.785, "loss": "2.943", "nll_loss": "1.143", "ppl": "2.21", "wps": "3092", "ups": "0.71", "wpb": "4356.6", "bsz": "32", "num_updates": "11100", "lr": "4.94697e-05", "gnorm": "1.468", "train_wall": "140", "wall": "43198"}
2022-11-12 11:40:27 | INFO | train_inner | {"epoch": 7, "update": 6.846, "loss": "2.948", "nll_loss": "1.149", "ppl": "2.22", "wps": "3084", "ups": "0.71", "wpb": "4344.6", "bsz": "32", "num_updates": "11200", "lr": "4.94647e-05", "gnorm": "1.529", "train_wall": "140", "wall": "43339"}
2022-11-12 11:42:48 | INFO | train_inner | {"epoch": 7, "update": 6.907, "loss": "2.899", "nll_loss": "1.093", "ppl": "2.13", "wps": "3100.8", "ups": "0.71", "wpb": "4386.4", "bsz": "32", "num_updates": "11300", "lr": "4.94597e-05", "gnorm": "1.425", "train_wall": "141", "wall": "43481"}
2022-11-12 11:45:08 | INFO | train_inner | {"epoch": 7, "update": 6.968, "loss": "2.904", "nll_loss": "1.099", "ppl": "2.14", "wps": "3105.7", "ups": "0.72", "wpb": "4336.6", "bsz": "32", "num_updates": "11400", "lr": "4.94547e-05", "gnorm": "1.452", "train_wall": "139", "wall": "43620"}
2022-11-12 11:46:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-12 12:59:17 | INFO | valid | {"epoch": 7, "valid_loss": "2.962", "valid_nll_loss": "1.099", "valid_ppl": "2.14", "valid_bleu": "53.2", "valid_wps": "203.7", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "11452", "valid_best_bleu": "53.2"}
2022-11-12 12:59:17 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 13:00:01 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 7 @ 11452 updates, score 53.2) (writing took 44.56042840424925 seconds)
2022-11-12 13:00:01 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-11-12 13:00:01 | INFO | train | {"epoch": 7, "train_loss": "2.917", "train_nll_loss": "1.113", "train_ppl": "2.16", "train_wps": "1057", "train_ups": "0.24", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "11452", "train_lr": "4.94521e-05", "train_gnorm": "1.45", "train_train_wall": "2281", "train_wall": "48114"}
2022-11-12 13:00:01 | INFO | fairseq.trainer | begin training epoch 8
2022-11-12 13:01:07 | INFO | train_inner | {"epoch": 8, "update": 7.029, "loss": "2.854", "nll_loss": "1.042", "ppl": "2.06", "wps": "94.6", "ups": "0.02", "wpb": "4312.6", "bsz": "31.7", "num_updates": "11500", "lr": "4.94497e-05", "gnorm": "1.428", "train_wall": "138", "wall": "48180"}
2022-11-12 13:03:26 | INFO | train_inner | {"epoch": 8, "update": 7.09, "loss": "2.802", "nll_loss": "0.983", "ppl": "1.98", "wps": "3132.9", "ups": "0.72", "wpb": "4345.5", "bsz": "32", "num_updates": "11600", "lr": "4.94447e-05", "gnorm": "1.389", "train_wall": "138", "wall": "48318"}
2022-11-12 13:05:45 | INFO | train_inner | {"epoch": 8, "update": 7.152, "loss": "2.815", "nll_loss": "0.998", "ppl": "2", "wps": "3113.7", "ups": "0.72", "wpb": "4323.6", "bsz": "32", "num_updates": "11700", "lr": "4.94397e-05", "gnorm": "1.408", "train_wall": "138", "wall": "48457"}
2022-11-12 13:08:04 | INFO | train_inner | {"epoch": 8, "update": 7.213, "loss": "2.788", "nll_loss": "0.967", "ppl": "1.95", "wps": "3092.6", "ups": "0.72", "wpb": "4299.7", "bsz": "32", "num_updates": "11800", "lr": "4.94347e-05", "gnorm": "1.381", "train_wall": "139", "wall": "48596"}
2022-11-12 13:10:24 | INFO | train_inner | {"epoch": 8, "update": 7.274, "loss": "2.809", "nll_loss": "0.991", "ppl": "1.99", "wps": "3090.1", "ups": "0.71", "wpb": "4325.3", "bsz": "32", "num_updates": "11900", "lr": "4.94297e-05", "gnorm": "1.385", "train_wall": "139", "wall": "48736"}
2022-11-12 13:12:44 | INFO | train_inner | {"epoch": 8, "update": 7.335, "loss": "2.811", "nll_loss": "0.994", "ppl": "1.99", "wps": "3042.4", "ups": "0.71", "wpb": "4270.1", "bsz": "32", "num_updates": "12000", "lr": "4.94247e-05", "gnorm": "1.388", "train_wall": "140", "wall": "48877"}
2022-11-12 13:15:10 | INFO | train_inner | {"epoch": 8, "update": 7.396, "loss": "2.806", "nll_loss": "0.988", "ppl": "1.98", "wps": "3064.7", "ups": "0.69", "wpb": "4467.6", "bsz": "32", "num_updates": "12100", "lr": "4.94197e-05", "gnorm": "1.383", "train_wall": "145", "wall": "49022"}
2022-11-12 13:17:35 | INFO | train_inner | {"epoch": 8, "update": 7.457, "loss": "2.819", "nll_loss": "1.003", "ppl": "2", "wps": "3070.4", "ups": "0.69", "wpb": "4447.6", "bsz": "32", "num_updates": "12200", "lr": "4.94147e-05", "gnorm": "1.383", "train_wall": "144", "wall": "49167"}
2022-11-12 13:19:55 | INFO | train_inner | {"epoch": 8, "update": 7.518, "loss": "2.792", "nll_loss": "0.972", "ppl": "1.96", "wps": "3089", "ups": "0.72", "wpb": "4311.6", "bsz": "32", "num_updates": "12300", "lr": "4.94097e-05", "gnorm": "1.395", "train_wall": "139", "wall": "49307"}
2022-11-12 13:22:13 | INFO | train_inner | {"epoch": 8, "update": 7.579, "loss": "2.82", "nll_loss": "1.005", "ppl": "2.01", "wps": "3099.6", "ups": "0.72", "wpb": "4291.9", "bsz": "32", "num_updates": "12400", "lr": "4.94047e-05", "gnorm": "1.402", "train_wall": "138", "wall": "49445"}
2022-11-12 13:24:35 | INFO | train_inner | {"epoch": 8, "update": 7.641, "loss": "2.809", "nll_loss": "0.992", "ppl": "1.99", "wps": "3091.7", "ups": "0.7", "wpb": "4405.2", "bsz": "32", "num_updates": "12500", "lr": "4.93997e-05", "gnorm": "1.398", "train_wall": "142", "wall": "49588"}
2022-11-12 13:26:59 | INFO | train_inner | {"epoch": 8, "update": 7.702, "loss": "2.799", "nll_loss": "0.981", "ppl": "1.97", "wps": "3057.7", "ups": "0.69", "wpb": "4403.7", "bsz": "32", "num_updates": "12600", "lr": "4.93947e-05", "gnorm": "1.371", "train_wall": "144", "wall": "49732"}
2022-11-12 13:29:18 | INFO | train_inner | {"epoch": 8, "update": 7.763, "loss": "2.79", "nll_loss": "0.97", "ppl": "1.96", "wps": "3085.3", "ups": "0.72", "wpb": "4262.7", "bsz": "32", "num_updates": "12700", "lr": "4.93897e-05", "gnorm": "1.398", "train_wall": "138", "wall": "49870"}
2022-11-12 13:31:36 | INFO | train_inner | {"epoch": 8, "update": 7.824, "loss": "2.784", "nll_loss": "0.964", "ppl": "1.95", "wps": "3093", "ups": "0.72", "wpb": "4292.4", "bsz": "32", "num_updates": "12800", "lr": "4.93847e-05", "gnorm": "1.383", "train_wall": "138", "wall": "50009"}
2022-11-12 13:33:55 | INFO | train_inner | {"epoch": 8, "update": 7.885, "loss": "2.803", "nll_loss": "0.985", "ppl": "1.98", "wps": "3096.7", "ups": "0.72", "wpb": "4296.7", "bsz": "32", "num_updates": "12900", "lr": "4.93797e-05", "gnorm": "1.385", "train_wall": "138", "wall": "50147"}
2022-11-12 13:36:16 | INFO | train_inner | {"epoch": 8, "update": 7.946, "loss": "2.794", "nll_loss": "0.975", "ppl": "1.97", "wps": "3105.1", "ups": "0.71", "wpb": "4369.2", "bsz": "32", "num_updates": "13000", "lr": "4.93747e-05", "gnorm": "1.39", "train_wall": "140", "wall": "50288"}
2022-11-12 13:38:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-12 14:49:47 | INFO | valid | {"epoch": 8, "valid_loss": "2.892", "valid_nll_loss": "1.022", "valid_ppl": "2.03", "valid_bleu": "53.58", "valid_wps": "207.8", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "13088", "valid_best_bleu": "53.58"}
2022-11-12 14:49:47 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 14:50:26 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 8 @ 13088 updates, score 53.58) (writing took 38.46176693588495 seconds)
2022-11-12 14:50:26 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-11-12 14:50:26 | INFO | train | {"epoch": 8, "train_loss": "2.802", "train_nll_loss": "0.984", "train_ppl": "1.98", "train_wps": "1070.7", "train_ups": "0.25", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "13088", "train_lr": "4.93703e-05", "train_gnorm": "1.39", "train_train_wall": "2288", "train_wall": "54738"}
2022-11-12 14:50:26 | INFO | fairseq.trainer | begin training epoch 9
2022-11-12 14:50:42 | INFO | train_inner | {"epoch": 9, "update": 8.007, "loss": "2.789", "nll_loss": "0.971", "ppl": "1.96", "wps": "95.3", "ups": "0.02", "wpb": "4255.7", "bsz": "31.7", "num_updates": "13100", "lr": "4.93697e-05", "gnorm": "1.402", "train_wall": "137", "wall": "54754"}
2022-11-12 14:52:59 | INFO | train_inner | {"epoch": 9, "update": 8.068, "loss": "2.708", "nll_loss": "0.877", "ppl": "1.84", "wps": "3164.5", "ups": "0.73", "wpb": "4341.6", "bsz": "32", "num_updates": "13200", "lr": "4.93647e-05", "gnorm": "1.335", "train_wall": "137", "wall": "54891"}
2022-11-12 14:55:14 | INFO | train_inner | {"epoch": 9, "update": 8.13, "loss": "2.722", "nll_loss": "0.893", "ppl": "1.86", "wps": "3130.7", "ups": "0.74", "wpb": "4233.2", "bsz": "32", "num_updates": "13300", "lr": "4.93597e-05", "gnorm": "1.385", "train_wall": "135", "wall": "55027"}
2022-11-12 14:57:32 | INFO | train_inner | {"epoch": 9, "update": 8.191, "loss": "2.697", "nll_loss": "0.865", "ppl": "1.82", "wps": "3111.3", "ups": "0.73", "wpb": "4280.1", "bsz": "32", "num_updates": "13400", "lr": "4.93547e-05", "gnorm": "1.361", "train_wall": "137", "wall": "55164"}
2022-11-12 14:59:51 | INFO | train_inner | {"epoch": 9, "update": 8.252, "loss": "2.707", "nll_loss": "0.877", "ppl": "1.84", "wps": "3088.4", "ups": "0.72", "wpb": "4297.7", "bsz": "32", "num_updates": "13500", "lr": "4.93497e-05", "gnorm": "1.345", "train_wall": "139", "wall": "55303"}
2022-11-12 15:02:11 | INFO | train_inner | {"epoch": 9, "update": 8.313, "loss": "2.707", "nll_loss": "0.876", "ppl": "1.84", "wps": "3075.5", "ups": "0.72", "wpb": "4295", "bsz": "32", "num_updates": "13600", "lr": "4.93447e-05", "gnorm": "1.36", "train_wall": "139", "wall": "55443"}
2022-11-12 15:04:30 | INFO | train_inner | {"epoch": 9, "update": 8.374, "loss": "2.699", "nll_loss": "0.868", "ppl": "1.83", "wps": "3101.9", "ups": "0.72", "wpb": "4335.9", "bsz": "32", "num_updates": "13700", "lr": "4.93397e-05", "gnorm": "1.33", "train_wall": "139", "wall": "55583"}
2022-11-12 15:06:51 | INFO | train_inner | {"epoch": 9, "update": 8.435, "loss": "2.703", "nll_loss": "0.872", "ppl": "1.83", "wps": "3091.6", "ups": "0.71", "wpb": "4329.2", "bsz": "32", "num_updates": "13800", "lr": "4.93347e-05", "gnorm": "1.329", "train_wall": "140", "wall": "55723"}
2022-11-12 15:09:11 | INFO | train_inner | {"epoch": 9, "update": 8.496, "loss": "2.703", "nll_loss": "0.872", "ppl": "1.83", "wps": "3101.7", "ups": "0.71", "wpb": "4358.5", "bsz": "32", "num_updates": "13900", "lr": "4.93297e-05", "gnorm": "1.337", "train_wall": "140", "wall": "55863"}
2022-11-12 15:11:31 | INFO | train_inner | {"epoch": 9, "update": 8.557, "loss": "2.695", "nll_loss": "0.863", "ppl": "1.82", "wps": "3105.7", "ups": "0.72", "wpb": "4335.4", "bsz": "32", "num_updates": "14000", "lr": "4.93247e-05", "gnorm": "1.347", "train_wall": "139", "wall": "56003"}
2022-11-12 15:13:52 | INFO | train_inner | {"epoch": 9, "update": 8.619, "loss": "2.697", "nll_loss": "0.866", "ppl": "1.82", "wps": "3094.5", "ups": "0.71", "wpb": "4385.7", "bsz": "32", "num_updates": "14100", "lr": "4.93197e-05", "gnorm": "1.333", "train_wall": "141", "wall": "56145"}
2022-11-12 15:16:13 | INFO | train_inner | {"epoch": 9, "update": 8.68, "loss": "2.7", "nll_loss": "0.869", "ppl": "1.83", "wps": "3108.3", "ups": "0.71", "wpb": "4370.7", "bsz": "32", "num_updates": "14200", "lr": "4.93147e-05", "gnorm": "1.331", "train_wall": "140", "wall": "56285"}
2022-11-12 15:18:33 | INFO | train_inner | {"epoch": 9, "update": 8.741, "loss": "2.721", "nll_loss": "0.893", "ppl": "1.86", "wps": "3076.4", "ups": "0.71", "wpb": "4312.6", "bsz": "32", "num_updates": "14300", "lr": "4.93097e-05", "gnorm": "1.371", "train_wall": "140", "wall": "56425"}
2022-11-12 15:20:53 | INFO | train_inner | {"epoch": 9, "update": 8.802, "loss": "2.709", "nll_loss": "0.879", "ppl": "1.84", "wps": "3095", "ups": "0.71", "wpb": "4336.5", "bsz": "32", "num_updates": "14400", "lr": "4.93047e-05", "gnorm": "1.352", "train_wall": "140", "wall": "56566"}
2022-11-12 15:23:15 | INFO | train_inner | {"epoch": 9, "update": 8.863, "loss": "2.707", "nll_loss": "0.877", "ppl": "1.84", "wps": "3098.2", "ups": "0.71", "wpb": "4382.9", "bsz": "32", "num_updates": "14500", "lr": "4.92996e-05", "gnorm": "1.33", "train_wall": "141", "wall": "56707"}
2022-11-12 15:25:34 | INFO | train_inner | {"epoch": 9, "update": 8.924, "loss": "2.701", "nll_loss": "0.871", "ppl": "1.83", "wps": "3106.6", "ups": "0.72", "wpb": "4316.7", "bsz": "32", "num_updates": "14600", "lr": "4.92946e-05", "gnorm": "1.333", "train_wall": "139", "wall": "56846"}
2022-11-12 15:27:57 | INFO | train_inner | {"epoch": 9, "update": 8.985, "loss": "2.735", "nll_loss": "0.91", "ppl": "1.88", "wps": "3109.4", "ups": "0.7", "wpb": "4467.2", "bsz": "32", "num_updates": "14700", "lr": "4.92896e-05", "gnorm": "1.355", "train_wall": "143", "wall": "56990"}
2022-11-12 15:28:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-12 16:43:24 | INFO | valid | {"epoch": 9, "valid_loss": "2.829", "valid_nll_loss": "0.953", "valid_ppl": "1.94", "valid_bleu": "58.04", "valid_wps": "198.4", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "14724", "valid_best_bleu": "58.04"}
2022-11-12 16:43:24 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 16:44:04 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 9 @ 14724 updates, score 58.04) (writing took 40.35855841496959 seconds)
2022-11-12 16:44:04 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-11-12 16:44:04 | INFO | train | {"epoch": 9, "train_loss": "2.707", "train_nll_loss": "0.877", "train_ppl": "1.84", "train_wps": "1040.2", "train_ups": "0.24", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "14724", "train_lr": "4.92884e-05", "train_gnorm": "1.347", "train_train_wall": "2278", "train_wall": "61556"}
2022-11-12 16:44:04 | INFO | fairseq.trainer | begin training epoch 10
2022-11-12 16:45:48 | INFO | train_inner | {"epoch": 10, "update": 9.046, "loss": "2.631", "nll_loss": "0.79", "ppl": "1.73", "wps": "92.3", "ups": "0.02", "wpb": "4311.1", "bsz": "31.7", "num_updates": "14800", "lr": "4.92846e-05", "gnorm": "1.289", "train_wall": "136", "wall": "61660"}
2022-11-12 16:48:03 | INFO | train_inner | {"epoch": 10, "update": 9.108, "loss": "2.61", "nll_loss": "0.766", "ppl": "1.7", "wps": "3146", "ups": "0.74", "wpb": "4264.9", "bsz": "32", "num_updates": "14900", "lr": "4.92796e-05", "gnorm": "1.321", "train_wall": "135", "wall": "61796"}
2022-11-12 16:50:24 | INFO | train_inner | {"epoch": 10, "update": 9.169, "loss": "2.639", "nll_loss": "0.8", "ppl": "1.74", "wps": "3127.7", "ups": "0.71", "wpb": "4409.5", "bsz": "32", "num_updates": "15000", "lr": "4.92746e-05", "gnorm": "1.318", "train_wall": "141", "wall": "61937"}
2022-11-12 16:52:44 | INFO | train_inner | {"epoch": 10, "update": 9.23, "loss": "2.625", "nll_loss": "0.785", "ppl": "1.72", "wps": "3092", "ups": "0.72", "wpb": "4309.1", "bsz": "32", "num_updates": "15100", "lr": "4.92696e-05", "gnorm": "1.311", "train_wall": "139", "wall": "62076"}
2022-11-12 16:55:06 | INFO | train_inner | {"epoch": 10, "update": 9.291, "loss": "2.643", "nll_loss": "0.805", "ppl": "1.75", "wps": "3102.1", "ups": "0.7", "wpb": "4419", "bsz": "32", "num_updates": "15200", "lr": "4.92646e-05", "gnorm": "1.302", "train_wall": "142", "wall": "62219"}
2022-11-12 16:57:27 | INFO | train_inner | {"epoch": 10, "update": 9.352, "loss": "2.624", "nll_loss": "0.784", "ppl": "1.72", "wps": "3084", "ups": "0.71", "wpb": "4326.9", "bsz": "32", "num_updates": "15300", "lr": "4.92596e-05", "gnorm": "1.307", "train_wall": "140", "wall": "62359"}
2022-11-12 16:59:47 | INFO | train_inner | {"epoch": 10, "update": 9.413, "loss": "2.648", "nll_loss": "0.811", "ppl": "1.75", "wps": "3094.5", "ups": "0.71", "wpb": "4333.6", "bsz": "32", "num_updates": "15400", "lr": "4.92546e-05", "gnorm": "1.325", "train_wall": "140", "wall": "62499"}
2022-11-12 17:02:04 | INFO | train_inner | {"epoch": 10, "update": 9.474, "loss": "2.629", "nll_loss": "0.789", "ppl": "1.73", "wps": "3087.4", "ups": "0.73", "wpb": "4242.8", "bsz": "32", "num_updates": "15500", "lr": "4.92496e-05", "gnorm": "1.314", "train_wall": "137", "wall": "62636"}
2022-11-12 17:04:25 | INFO | train_inner | {"epoch": 10, "update": 9.535, "loss": "2.616", "nll_loss": "0.774", "ppl": "1.71", "wps": "3117.6", "ups": "0.71", "wpb": "4395.9", "bsz": "32", "num_updates": "15600", "lr": "4.92446e-05", "gnorm": "1.275", "train_wall": "141", "wall": "62777"}
2022-11-12 17:06:44 | INFO | train_inner | {"epoch": 10, "update": 9.597, "loss": "2.623", "nll_loss": "0.783", "ppl": "1.72", "wps": "3098.8", "ups": "0.72", "wpb": "4314.2", "bsz": "32", "num_updates": "15700", "lr": "4.92396e-05", "gnorm": "1.319", "train_wall": "139", "wall": "62916"}
2022-11-12 17:09:06 | INFO | train_inner | {"epoch": 10, "update": 9.658, "loss": "2.63", "nll_loss": "0.79", "ppl": "1.73", "wps": "3112.5", "ups": "0.7", "wpb": "4417.8", "bsz": "32", "num_updates": "15800", "lr": "4.92346e-05", "gnorm": "1.304", "train_wall": "142", "wall": "63058"}
2022-11-12 17:11:27 | INFO | train_inner | {"epoch": 10, "update": 9.719, "loss": "2.626", "nll_loss": "0.786", "ppl": "1.72", "wps": "3096.4", "ups": "0.71", "wpb": "4370.2", "bsz": "32", "num_updates": "15900", "lr": "4.92296e-05", "gnorm": "1.297", "train_wall": "141", "wall": "63200"}
2022-11-12 17:13:47 | INFO | train_inner | {"epoch": 10, "update": 9.78, "loss": "2.618", "nll_loss": "0.777", "ppl": "1.71", "wps": "3075.2", "ups": "0.72", "wpb": "4286.3", "bsz": "32", "num_updates": "16000", "lr": "4.92246e-05", "gnorm": "1.307", "train_wall": "139", "wall": "63339"}
2022-11-12 17:16:06 | INFO | train_inner | {"epoch": 10, "update": 9.841, "loss": "2.622", "nll_loss": "0.782", "ppl": "1.72", "wps": "3111", "ups": "0.72", "wpb": "4340.6", "bsz": "32", "num_updates": "16100", "lr": "4.92196e-05", "gnorm": "1.296", "train_wall": "139", "wall": "63478"}
2022-11-12 17:18:26 | INFO | train_inner | {"epoch": 10, "update": 9.902, "loss": "2.622", "nll_loss": "0.782", "ppl": "1.72", "wps": "3093.4", "ups": "0.72", "wpb": "4312.8", "bsz": "32", "num_updates": "16200", "lr": "4.92146e-05", "gnorm": "1.329", "train_wall": "139", "wall": "63618"}
2022-11-12 17:20:45 | INFO | train_inner | {"epoch": 10, "update": 9.963, "loss": "2.629", "nll_loss": "0.789", "ppl": "1.73", "wps": "3103.6", "ups": "0.72", "wpb": "4325.7", "bsz": "32", "num_updates": "16300", "lr": "4.92096e-05", "gnorm": "1.321", "train_wall": "139", "wall": "63757"}
2022-11-12 17:22:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-12 18:36:59 | INFO | valid | {"epoch": 10, "valid_loss": "2.763", "valid_nll_loss": "0.885", "valid_ppl": "1.85", "valid_bleu": "59.89", "valid_wps": "198.5", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "16360", "valid_best_bleu": "59.89"}
2022-11-12 18:36:59 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 18:37:37 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 10 @ 16360 updates, score 59.89) (writing took 37.68804838415235 seconds)
2022-11-12 18:37:37 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-11-12 18:37:37 | INFO | train | {"epoch": 10, "train_loss": "2.625", "train_nll_loss": "0.785", "train_ppl": "1.72", "train_wps": "1041.1", "train_ups": "0.24", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "16360", "train_lr": "4.92066e-05", "train_gnorm": "1.307", "train_train_wall": "2276", "train_wall": "68369"}
2022-11-12 18:37:37 | INFO | fairseq.trainer | begin training epoch 11
2022-11-12 18:38:33 | INFO | train_inner | {"epoch": 11, "update": 10.024, "loss": "2.598", "nll_loss": "0.754", "ppl": "1.69", "wps": "93", "ups": "0.02", "wpb": "4340.1", "bsz": "31.7", "num_updates": "16400", "lr": "4.92046e-05", "gnorm": "1.318", "train_wall": "138", "wall": "68425"}
2022-11-12 18:40:51 | INFO | train_inner | {"epoch": 11, "update": 10.086, "loss": "2.554", "nll_loss": "0.703", "ppl": "1.63", "wps": "3153.1", "ups": "0.72", "wpb": "4369.1", "bsz": "32", "num_updates": "16500", "lr": "4.91996e-05", "gnorm": "1.272", "train_wall": "138", "wall": "68563"}
2022-11-12 18:43:08 | INFO | train_inner | {"epoch": 11, "update": 10.147, "loss": "2.539", "nll_loss": "0.688", "ppl": "1.61", "wps": "3119.1", "ups": "0.73", "wpb": "4272.4", "bsz": "32", "num_updates": "16600", "lr": "4.91946e-05", "gnorm": "1.253", "train_wall": "137", "wall": "68700"}
2022-11-12 18:45:29 | INFO | train_inner | {"epoch": 11, "update": 10.208, "loss": "2.59", "nll_loss": "0.745", "ppl": "1.68", "wps": "3111.9", "ups": "0.71", "wpb": "4387.5", "bsz": "32", "num_updates": "16700", "lr": "4.91896e-05", "gnorm": "1.287", "train_wall": "140", "wall": "68841"}
2022-11-12 18:47:49 | INFO | train_inner | {"epoch": 11, "update": 10.269, "loss": "2.558", "nll_loss": "0.709", "ppl": "1.63", "wps": "3098.7", "ups": "0.72", "wpb": "4327", "bsz": "32", "num_updates": "16800", "lr": "4.91846e-05", "gnorm": "1.255", "train_wall": "139", "wall": "68981"}
2022-11-12 18:50:09 | INFO | train_inner | {"epoch": 11, "update": 10.33, "loss": "2.549", "nll_loss": "0.699", "ppl": "1.62", "wps": "3112.6", "ups": "0.71", "wpb": "4370", "bsz": "32", "num_updates": "16900", "lr": "4.91796e-05", "gnorm": "1.253", "train_wall": "140", "wall": "69121"}
2022-11-12 18:52:29 | INFO | train_inner | {"epoch": 11, "update": 10.391, "loss": "2.543", "nll_loss": "0.692", "ppl": "1.62", "wps": "3090.6", "ups": "0.72", "wpb": "4320.7", "bsz": "32", "num_updates": "17000", "lr": "4.91746e-05", "gnorm": "1.257", "train_wall": "139", "wall": "69261"}
2022-11-12 18:54:47 | INFO | train_inner | {"epoch": 11, "update": 10.452, "loss": "2.546", "nll_loss": "0.697", "ppl": "1.62", "wps": "3095.9", "ups": "0.72", "wpb": "4271.8", "bsz": "32", "num_updates": "17100", "lr": "4.91696e-05", "gnorm": "1.271", "train_wall": "138", "wall": "69399"}
2022-11-12 18:57:07 | INFO | train_inner | {"epoch": 11, "update": 10.513, "loss": "2.557", "nll_loss": "0.709", "ppl": "1.63", "wps": "3101.9", "ups": "0.71", "wpb": "4355.4", "bsz": "32", "num_updates": "17200", "lr": "4.91646e-05", "gnorm": "1.263", "train_wall": "140", "wall": "69540"}
2022-11-12 18:59:27 | INFO | train_inner | {"epoch": 11, "update": 10.575, "loss": "2.567", "nll_loss": "0.72", "ppl": "1.65", "wps": "3093.8", "ups": "0.72", "wpb": "4323.7", "bsz": "32", "num_updates": "17300", "lr": "4.91596e-05", "gnorm": "1.271", "train_wall": "139", "wall": "69679"}
2022-11-12 19:01:49 | INFO | train_inner | {"epoch": 11, "update": 10.636, "loss": "2.554", "nll_loss": "0.705", "ppl": "1.63", "wps": "3099.2", "ups": "0.7", "wpb": "4402.7", "bsz": "32", "num_updates": "17400", "lr": "4.91546e-05", "gnorm": "1.251", "train_wall": "142", "wall": "69821"}
2022-11-12 19:04:07 | INFO | train_inner | {"epoch": 11, "update": 10.697, "loss": "2.548", "nll_loss": "0.698", "ppl": "1.62", "wps": "3094.1", "ups": "0.73", "wpb": "4265.9", "bsz": "32", "num_updates": "17500", "lr": "4.91496e-05", "gnorm": "1.271", "train_wall": "137", "wall": "69959"}
2022-11-12 19:06:27 | INFO | train_inner | {"epoch": 11, "update": 10.758, "loss": "2.543", "nll_loss": "0.692", "ppl": "1.62", "wps": "3112.5", "ups": "0.71", "wpb": "4354.3", "bsz": "32", "num_updates": "17600", "lr": "4.91446e-05", "gnorm": "1.256", "train_wall": "139", "wall": "70099"}
2022-11-12 19:08:48 | INFO | train_inner | {"epoch": 11, "update": 10.819, "loss": "2.557", "nll_loss": "0.709", "ppl": "1.63", "wps": "3065.2", "ups": "0.71", "wpb": "4330.4", "bsz": "32", "num_updates": "17700", "lr": "4.91396e-05", "gnorm": "1.262", "train_wall": "141", "wall": "70240"}
2022-11-12 19:11:09 | INFO | train_inner | {"epoch": 11, "update": 10.88, "loss": "2.574", "nll_loss": "0.728", "ppl": "1.66", "wps": "3072.9", "ups": "0.71", "wpb": "4326.5", "bsz": "32", "num_updates": "17800", "lr": "4.91346e-05", "gnorm": "1.267", "train_wall": "140", "wall": "70381"}
2022-11-12 19:13:31 | INFO | train_inner | {"epoch": 11, "update": 10.941, "loss": "2.559", "nll_loss": "0.712", "ppl": "1.64", "wps": "3090", "ups": "0.71", "wpb": "4376.1", "bsz": "32", "num_updates": "17900", "lr": "4.91296e-05", "gnorm": "1.259", "train_wall": "141", "wall": "70523"}
2022-11-12 19:15:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-12 20:24:44 | INFO | valid | {"epoch": 11, "valid_loss": "2.732", "valid_nll_loss": "0.85", "valid_ppl": "1.8", "valid_bleu": "61.06", "valid_wps": "215.3", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "17996", "valid_best_bleu": "61.06"}
2022-11-12 20:24:44 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 20:25:22 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 11 @ 17996 updates, score 61.06) (writing took 37.738357808906585 seconds)
2022-11-12 20:25:22 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-11-12 20:25:22 | INFO | train | {"epoch": 11, "train_loss": "2.557", "train_nll_loss": "0.708", "train_ppl": "1.63", "train_wps": "1097", "train_ups": "0.25", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "17996", "train_lr": "4.91248e-05", "train_gnorm": "1.266", "train_train_wall": "2280", "train_wall": "74834"}
2022-11-12 20:25:22 | INFO | fairseq.trainer | begin training epoch 12
2022-11-12 20:25:27 | INFO | train_inner | {"epoch": 12, "update": 11.002, "loss": "2.557", "nll_loss": "0.708", "ppl": "1.63", "wps": "98.7", "ups": "0.02", "wpb": "4261.1", "bsz": "31.7", "num_updates": "18000", "lr": "4.91246e-05", "gnorm": "1.297", "train_wall": "138", "wall": "74839"}
2022-11-12 20:27:43 | INFO | train_inner | {"epoch": 12, "update": 11.064, "loss": "2.474", "nll_loss": "0.614", "ppl": "1.53", "wps": "3158", "ups": "0.74", "wpb": "4282.1", "bsz": "32", "num_updates": "18100", "lr": "4.91196e-05", "gnorm": "1.19", "train_wall": "135", "wall": "74975"}
2022-11-12 20:30:01 | INFO | train_inner | {"epoch": 12, "update": 11.125, "loss": "2.496", "nll_loss": "0.639", "ppl": "1.56", "wps": "3130.9", "ups": "0.73", "wpb": "4313.3", "bsz": "32", "num_updates": "18200", "lr": "4.91146e-05", "gnorm": "1.228", "train_wall": "137", "wall": "75113"}
2022-11-12 20:32:19 | INFO | train_inner | {"epoch": 12, "update": 11.186, "loss": "2.494", "nll_loss": "0.637", "ppl": "1.56", "wps": "3103.9", "ups": "0.72", "wpb": "4300.8", "bsz": "32", "num_updates": "18300", "lr": "4.91096e-05", "gnorm": "1.218", "train_wall": "138", "wall": "75251"}
2022-11-12 20:34:39 | INFO | train_inner | {"epoch": 12, "update": 11.247, "loss": "2.493", "nll_loss": "0.636", "ppl": "1.55", "wps": "3106.4", "ups": "0.72", "wpb": "4336.6", "bsz": "32", "num_updates": "18400", "lr": "4.91046e-05", "gnorm": "1.229", "train_wall": "139", "wall": "75391"}
2022-11-12 20:36:58 | INFO | train_inner | {"epoch": 12, "update": 11.308, "loss": "2.484", "nll_loss": "0.625", "ppl": "1.54", "wps": "3097.2", "ups": "0.72", "wpb": "4303.9", "bsz": "32", "num_updates": "18500", "lr": "4.90995e-05", "gnorm": "1.205", "train_wall": "138", "wall": "75530"}
2022-11-12 20:39:19 | INFO | train_inner | {"epoch": 12, "update": 11.369, "loss": "2.484", "nll_loss": "0.626", "ppl": "1.54", "wps": "3105.6", "ups": "0.71", "wpb": "4372.1", "bsz": "32", "num_updates": "18600", "lr": "4.90945e-05", "gnorm": "1.218", "train_wall": "140", "wall": "75671"}
2022-11-12 20:41:39 | INFO | train_inner | {"epoch": 12, "update": 11.43, "loss": "2.521", "nll_loss": "0.668", "ppl": "1.59", "wps": "3081.1", "ups": "0.71", "wpb": "4327.9", "bsz": "32", "num_updates": "18700", "lr": "4.90895e-05", "gnorm": "1.278", "train_wall": "140", "wall": "75811"}
2022-11-12 20:44:00 | INFO | train_inner | {"epoch": 12, "update": 11.491, "loss": "2.525", "nll_loss": "0.672", "ppl": "1.59", "wps": "3101.9", "ups": "0.71", "wpb": "4371.7", "bsz": "32", "num_updates": "18800", "lr": "4.90845e-05", "gnorm": "1.274", "train_wall": "141", "wall": "75952"}
2022-11-12 20:46:18 | INFO | train_inner | {"epoch": 12, "update": 11.553, "loss": "2.498", "nll_loss": "0.643", "ppl": "1.56", "wps": "3096.6", "ups": "0.72", "wpb": "4284.2", "bsz": "32", "num_updates": "18900", "lr": "4.90795e-05", "gnorm": "1.242", "train_wall": "138", "wall": "76091"}
2022-11-12 20:48:41 | INFO | train_inner | {"epoch": 12, "update": 11.614, "loss": "2.493", "nll_loss": "0.637", "ppl": "1.56", "wps": "3108", "ups": "0.7", "wpb": "4430.7", "bsz": "32", "num_updates": "19000", "lr": "4.90745e-05", "gnorm": "1.217", "train_wall": "142", "wall": "76233"}
2022-11-12 20:51:00 | INFO | train_inner | {"epoch": 12, "update": 11.675, "loss": "2.485", "nll_loss": "0.627", "ppl": "1.54", "wps": "3104.4", "ups": "0.72", "wpb": "4332.9", "bsz": "32", "num_updates": "19100", "lr": "4.90695e-05", "gnorm": "1.223", "train_wall": "139", "wall": "76373"}
2022-11-12 20:53:21 | INFO | train_inner | {"epoch": 12, "update": 11.736, "loss": "2.496", "nll_loss": "0.64", "ppl": "1.56", "wps": "3093.8", "ups": "0.71", "wpb": "4356.5", "bsz": "32", "num_updates": "19200", "lr": "4.90645e-05", "gnorm": "1.224", "train_wall": "140", "wall": "76513"}
2022-11-12 20:55:41 | INFO | train_inner | {"epoch": 12, "update": 11.797, "loss": "2.498", "nll_loss": "0.642", "ppl": "1.56", "wps": "3099.6", "ups": "0.72", "wpb": "4327.3", "bsz": "32", "num_updates": "19300", "lr": "4.90595e-05", "gnorm": "1.258", "train_wall": "139", "wall": "76653"}
2022-11-12 20:58:02 | INFO | train_inner | {"epoch": 12, "update": 11.858, "loss": "2.523", "nll_loss": "0.671", "ppl": "1.59", "wps": "3096.9", "ups": "0.71", "wpb": "4366.5", "bsz": "32", "num_updates": "19400", "lr": "4.90545e-05", "gnorm": "1.259", "train_wall": "141", "wall": "76794"}
2022-11-12 21:00:23 | INFO | train_inner | {"epoch": 12, "update": 11.919, "loss": "2.501", "nll_loss": "0.646", "ppl": "1.56", "wps": "3082.5", "ups": "0.71", "wpb": "4349.4", "bsz": "32", "num_updates": "19500", "lr": "4.90495e-05", "gnorm": "1.246", "train_wall": "141", "wall": "76935"}
2022-11-12 21:02:43 | INFO | train_inner | {"epoch": 12, "update": 11.98, "loss": "2.487", "nll_loss": "0.631", "ppl": "1.55", "wps": "3102.7", "ups": "0.71", "wpb": "4360.5", "bsz": "32", "num_updates": "19600", "lr": "4.90445e-05", "gnorm": "1.221", "train_wall": "140", "wall": "77076"}
2022-11-12 21:03:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-12 22:15:05 | INFO | valid | {"epoch": 12, "valid_loss": "2.707", "valid_nll_loss": "0.815", "valid_ppl": "1.76", "valid_bleu": "63.55", "valid_wps": "207.4", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "19632", "valid_best_bleu": "63.55"}
2022-11-12 22:15:05 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-12 22:15:43 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 12 @ 19632 updates, score 63.55) (writing took 37.603204023092985 seconds)
2022-11-12 22:15:43 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-11-12 22:15:43 | INFO | train | {"epoch": 12, "train_loss": "2.497", "train_nll_loss": "0.641", "train_ppl": "1.56", "train_wps": "1071.3", "train_ups": "0.25", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "19632", "train_lr": "4.90429e-05", "train_gnorm": "1.235", "train_train_wall": "2278", "train_wall": "81455"}
2022-11-12 22:15:43 | INFO | fairseq.trainer | begin training epoch 13
2022-11-12 22:17:16 | INFO | train_inner | {"epoch": 13, "update": 12.042, "loss": "2.446", "nll_loss": "0.583", "ppl": "1.5", "wps": "95.7", "ups": "0.02", "wpb": "4280.5", "bsz": "31.7", "num_updates": "19700", "lr": "4.90395e-05", "gnorm": "1.205", "train_wall": "136", "wall": "81548"}
2022-11-12 22:19:34 | INFO | train_inner | {"epoch": 13, "update": 12.103, "loss": "2.422", "nll_loss": "0.556", "ppl": "1.47", "wps": "3135.2", "ups": "0.72", "wpb": "4344.9", "bsz": "32", "num_updates": "19800", "lr": "4.90345e-05", "gnorm": "1.165", "train_wall": "138", "wall": "81687"}
2022-11-12 22:21:52 | INFO | train_inner | {"epoch": 13, "update": 12.164, "loss": "2.449", "nll_loss": "0.587", "ppl": "1.5", "wps": "3088.7", "ups": "0.73", "wpb": "4243.4", "bsz": "32", "num_updates": "19900", "lr": "4.90295e-05", "gnorm": "1.216", "train_wall": "137", "wall": "81824"}
2022-11-12 22:24:13 | INFO | train_inner | {"epoch": 13, "update": 12.225, "loss": "2.451", "nll_loss": "0.59", "ppl": "1.5", "wps": "3096.9", "ups": "0.71", "wpb": "4371.6", "bsz": "32", "num_updates": "20000", "lr": "4.90245e-05", "gnorm": "1.202", "train_wall": "141", "wall": "81965"}
2022-11-12 22:26:31 | INFO | train_inner | {"epoch": 13, "update": 12.286, "loss": "2.439", "nll_loss": "0.575", "ppl": "1.49", "wps": "3097.7", "ups": "0.72", "wpb": "4273.3", "bsz": "32", "num_updates": "20100", "lr": "4.90195e-05", "gnorm": "1.201", "train_wall": "137", "wall": "82103"}
2022-11-12 22:28:55 | INFO | train_inner | {"epoch": 13, "update": 12.347, "loss": "2.436", "nll_loss": "0.572", "ppl": "1.49", "wps": "3059", "ups": "0.7", "wpb": "4397.3", "bsz": "32", "num_updates": "20200", "lr": "4.90145e-05", "gnorm": "1.179", "train_wall": "143", "wall": "82247"}
2022-11-12 22:31:15 | INFO | train_inner | {"epoch": 13, "update": 12.408, "loss": "2.435", "nll_loss": "0.572", "ppl": "1.49", "wps": "3032.6", "ups": "0.71", "wpb": "4258.2", "bsz": "32", "num_updates": "20300", "lr": "4.90095e-05", "gnorm": "1.199", "train_wall": "140", "wall": "82387"}
2022-11-12 22:33:36 | INFO | train_inner | {"epoch": 13, "update": 12.469, "loss": "2.438", "nll_loss": "0.575", "ppl": "1.49", "wps": "3029.4", "ups": "0.71", "wpb": "4274", "bsz": "32", "num_updates": "20400", "lr": "4.90045e-05", "gnorm": "1.201", "train_wall": "141", "wall": "82528"}
2022-11-12 22:35:56 | INFO | train_inner | {"epoch": 13, "update": 12.531, "loss": "2.442", "nll_loss": "0.58", "ppl": "1.49", "wps": "3092.8", "ups": "0.72", "wpb": "4323.6", "bsz": "32", "num_updates": "20500", "lr": "4.89995e-05", "gnorm": "1.189", "train_wall": "139", "wall": "82668"}
2022-11-12 22:38:15 | INFO | train_inner | {"epoch": 13, "update": 12.592, "loss": "2.446", "nll_loss": "0.584", "ppl": "1.5", "wps": "3083.6", "ups": "0.72", "wpb": "4297.4", "bsz": "32", "num_updates": "20600", "lr": "4.89945e-05", "gnorm": "1.203", "train_wall": "139", "wall": "82807"}
2022-11-12 22:40:35 | INFO | train_inner | {"epoch": 13, "update": 12.653, "loss": "2.443", "nll_loss": "0.58", "ppl": "1.5", "wps": "3106.9", "ups": "0.71", "wpb": "4355.4", "bsz": "32", "num_updates": "20700", "lr": "4.89895e-05", "gnorm": "1.191", "train_wall": "140", "wall": "82948"}
2022-11-12 22:42:58 | INFO | train_inner | {"epoch": 13, "update": 12.714, "loss": "2.452", "nll_loss": "0.591", "ppl": "1.51", "wps": "3120.5", "ups": "0.7", "wpb": "4440.1", "bsz": "32", "num_updates": "20800", "lr": "4.89845e-05", "gnorm": "1.193", "train_wall": "142", "wall": "83090"}
2022-11-12 22:45:19 | INFO | train_inner | {"epoch": 13, "update": 12.775, "loss": "2.464", "nll_loss": "0.605", "ppl": "1.52", "wps": "3106.7", "ups": "0.71", "wpb": "4399.4", "bsz": "32", "num_updates": "20900", "lr": "4.89795e-05", "gnorm": "1.214", "train_wall": "141", "wall": "83232"}
2022-11-12 22:47:38 | INFO | train_inner | {"epoch": 13, "update": 12.836, "loss": "2.453", "nll_loss": "0.592", "ppl": "1.51", "wps": "3106.6", "ups": "0.72", "wpb": "4318.5", "bsz": "32", "num_updates": "21000", "lr": "4.89745e-05", "gnorm": "1.225", "train_wall": "139", "wall": "83371"}
2022-11-12 22:50:01 | INFO | train_inner | {"epoch": 13, "update": 12.897, "loss": "2.487", "nll_loss": "0.631", "ppl": "1.55", "wps": "3094.3", "ups": "0.7", "wpb": "4404.7", "bsz": "32", "num_updates": "21100", "lr": "4.89695e-05", "gnorm": "1.232", "train_wall": "142", "wall": "83513"}
2022-11-12 22:52:22 | INFO | train_inner | {"epoch": 13, "update": 12.958, "loss": "2.448", "nll_loss": "0.587", "ppl": "1.5", "wps": "3084.6", "ups": "0.71", "wpb": "4352.7", "bsz": "32", "num_updates": "21200", "lr": "4.89645e-05", "gnorm": "1.205", "train_wall": "141", "wall": "83654"}
2022-11-12 22:53:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 00:05:33 | INFO | valid | {"epoch": 13, "valid_loss": "2.666", "valid_nll_loss": "0.772", "valid_ppl": "1.71", "valid_bleu": "63.64", "valid_wps": "207.5", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "21268", "valid_best_bleu": "63.64"}
2022-11-13 00:05:33 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 00:06:13 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 13 @ 21268 updates, score 63.64) (writing took 40.66524562705308 seconds)
2022-11-13 00:06:13 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-11-13 00:06:13 | INFO | train | {"epoch": 13, "train_loss": "2.447", "train_nll_loss": "0.585", "train_ppl": "1.5", "train_wps": "1069.7", "train_ups": "0.25", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "21268", "train_lr": "4.89611e-05", "train_gnorm": "1.201", "train_train_wall": "2286", "train_wall": "88086"}
2022-11-13 00:06:13 | INFO | fairseq.trainer | begin training epoch 14
2022-11-13 00:06:59 | INFO | train_inner | {"epoch": 14, "update": 13.02, "loss": "2.437", "nll_loss": "0.574", "ppl": "1.49", "wps": "97.7", "ups": "0.02", "wpb": "4372.4", "bsz": "31.7", "num_updates": "21300", "lr": "4.89595e-05", "gnorm": "1.214", "train_wall": "140", "wall": "88131"}
2022-11-13 00:09:16 | INFO | train_inner | {"epoch": 14, "update": 13.081, "loss": "2.403", "nll_loss": "0.535", "ppl": "1.45", "wps": "3152.4", "ups": "0.73", "wpb": "4325.2", "bsz": "32", "num_updates": "21400", "lr": "4.89545e-05", "gnorm": "1.128", "train_wall": "137", "wall": "88269"}
2022-11-13 00:11:33 | INFO | train_inner | {"epoch": 14, "update": 13.142, "loss": "2.391", "nll_loss": "0.522", "ppl": "1.44", "wps": "3118.5", "ups": "0.73", "wpb": "4261.9", "bsz": "32", "num_updates": "21500", "lr": "4.89495e-05", "gnorm": "1.15", "train_wall": "136", "wall": "88405"}
2022-11-13 00:13:52 | INFO | train_inner | {"epoch": 14, "update": 13.203, "loss": "2.39", "nll_loss": "0.521", "ppl": "1.43", "wps": "3108.8", "ups": "0.72", "wpb": "4317.7", "bsz": "32", "num_updates": "21600", "lr": "4.89445e-05", "gnorm": "1.151", "train_wall": "138", "wall": "88544"}
2022-11-13 00:16:11 | INFO | train_inner | {"epoch": 14, "update": 13.264, "loss": "2.421", "nll_loss": "0.557", "ppl": "1.47", "wps": "3098.3", "ups": "0.72", "wpb": "4310.7", "bsz": "32", "num_updates": "21700", "lr": "4.89395e-05", "gnorm": "1.187", "train_wall": "139", "wall": "88683"}
2022-11-13 00:18:31 | INFO | train_inner | {"epoch": 14, "update": 13.325, "loss": "2.386", "nll_loss": "0.517", "ppl": "1.43", "wps": "3108.1", "ups": "0.72", "wpb": "4339.5", "bsz": "32", "num_updates": "21800", "lr": "4.89345e-05", "gnorm": "1.142", "train_wall": "139", "wall": "88823"}
2022-11-13 00:20:52 | INFO | train_inner | {"epoch": 14, "update": 13.386, "loss": "2.399", "nll_loss": "0.531", "ppl": "1.44", "wps": "3095.2", "ups": "0.71", "wpb": "4366", "bsz": "32", "num_updates": "21900", "lr": "4.89295e-05", "gnorm": "1.162", "train_wall": "141", "wall": "88964"}
2022-11-13 00:23:13 | INFO | train_inner | {"epoch": 14, "update": 13.447, "loss": "2.401", "nll_loss": "0.534", "ppl": "1.45", "wps": "3086.8", "ups": "0.71", "wpb": "4368.8", "bsz": "32", "num_updates": "22000", "lr": "4.89245e-05", "gnorm": "1.159", "train_wall": "141", "wall": "89106"}
2022-11-13 00:25:35 | INFO | train_inner | {"epoch": 14, "update": 13.509, "loss": "2.404", "nll_loss": "0.537", "ppl": "1.45", "wps": "3094.9", "ups": "0.71", "wpb": "4370.6", "bsz": "32", "num_updates": "22100", "lr": "4.89195e-05", "gnorm": "1.159", "train_wall": "141", "wall": "89247"}
2022-11-13 00:27:54 | INFO | train_inner | {"epoch": 14, "update": 13.57, "loss": "2.394", "nll_loss": "0.526", "ppl": "1.44", "wps": "3110.1", "ups": "0.72", "wpb": "4325.3", "bsz": "32", "num_updates": "22200", "lr": "4.89145e-05", "gnorm": "1.16", "train_wall": "139", "wall": "89386"}
2022-11-13 00:30:13 | INFO | train_inner | {"epoch": 14, "update": 13.631, "loss": "2.398", "nll_loss": "0.531", "ppl": "1.44", "wps": "3104.6", "ups": "0.72", "wpb": "4317.2", "bsz": "32", "num_updates": "22300", "lr": "4.89095e-05", "gnorm": "1.152", "train_wall": "139", "wall": "89525"}
2022-11-13 00:32:33 | INFO | train_inner | {"epoch": 14, "update": 13.692, "loss": "2.404", "nll_loss": "0.537", "ppl": "1.45", "wps": "3105.8", "ups": "0.71", "wpb": "4368.1", "bsz": "32", "num_updates": "22400", "lr": "4.89045e-05", "gnorm": "1.168", "train_wall": "140", "wall": "89666"}
2022-11-13 00:34:55 | INFO | train_inner | {"epoch": 14, "update": 13.753, "loss": "2.434", "nll_loss": "0.572", "ppl": "1.49", "wps": "3090.5", "ups": "0.71", "wpb": "4381.9", "bsz": "32", "num_updates": "22500", "lr": "4.88994e-05", "gnorm": "1.184", "train_wall": "141", "wall": "89807"}
2022-11-13 00:37:15 | INFO | train_inner | {"epoch": 14, "update": 13.814, "loss": "2.409", "nll_loss": "0.543", "ppl": "1.46", "wps": "3095.2", "ups": "0.72", "wpb": "4317.3", "bsz": "32", "num_updates": "22600", "lr": "4.88944e-05", "gnorm": "1.184", "train_wall": "139", "wall": "89947"}
2022-11-13 00:39:36 | INFO | train_inner | {"epoch": 14, "update": 13.875, "loss": "2.404", "nll_loss": "0.538", "ppl": "1.45", "wps": "3088.3", "ups": "0.71", "wpb": "4375.1", "bsz": "32", "num_updates": "22700", "lr": "4.88894e-05", "gnorm": "1.167", "train_wall": "141", "wall": "90089"}
2022-11-13 00:41:56 | INFO | train_inner | {"epoch": 14, "update": 13.936, "loss": "2.408", "nll_loss": "0.543", "ppl": "1.46", "wps": "3086.3", "ups": "0.71", "wpb": "4319.6", "bsz": "32", "num_updates": "22800", "lr": "4.88844e-05", "gnorm": "1.172", "train_wall": "140", "wall": "90228"}
2022-11-13 00:44:15 | INFO | train_inner | {"epoch": 14, "update": 13.998, "loss": "2.409", "nll_loss": "0.544", "ppl": "1.46", "wps": "3095.3", "ups": "0.72", "wpb": "4297.1", "bsz": "32", "num_updates": "22900", "lr": "4.88794e-05", "gnorm": "1.182", "train_wall": "138", "wall": "90367"}
2022-11-13 00:44:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 01:52:06 | INFO | valid | {"epoch": 14, "valid_loss": "2.655", "valid_nll_loss": "0.76", "valid_ppl": "1.69", "valid_bleu": "65.83", "valid_wps": "219.2", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "22904", "valid_best_bleu": "65.83"}
2022-11-13 01:52:06 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 01:52:46 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 14 @ 22904 updates, score 65.83) (writing took 39.687888618092984 seconds)
2022-11-13 01:52:46 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-11-13 01:52:46 | INFO | train | {"epoch": 14, "train_loss": "2.403", "train_nll_loss": "0.537", "train_ppl": "1.45", "train_wps": "1109.6", "train_ups": "0.26", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "22904", "train_lr": "4.88792e-05", "train_gnorm": "1.164", "train_train_wall": "2278", "train_wall": "94478"}
2022-11-13 01:52:46 | INFO | fairseq.trainer | begin training epoch 15
2022-11-13 01:54:58 | INFO | train_inner | {"epoch": 15, "update": 14.059, "loss": "2.357", "nll_loss": "0.484", "ppl": "1.4", "wps": "101.1", "ups": "0.02", "wpb": "4287.4", "bsz": "31.7", "num_updates": "23000", "lr": "4.88744e-05", "gnorm": "1.136", "train_wall": "136", "wall": "94610"}
2022-11-13 01:57:15 | INFO | train_inner | {"epoch": 15, "update": 14.12, "loss": "2.356", "nll_loss": "0.483", "ppl": "1.4", "wps": "3150.4", "ups": "0.73", "wpb": "4317.6", "bsz": "32", "num_updates": "23100", "lr": "4.88694e-05", "gnorm": "1.101", "train_wall": "137", "wall": "94747"}
2022-11-13 01:59:34 | INFO | train_inner | {"epoch": 15, "update": 14.181, "loss": "2.359", "nll_loss": "0.487", "ppl": "1.4", "wps": "3125.3", "ups": "0.72", "wpb": "4358.8", "bsz": "32", "num_updates": "23200", "lr": "4.88644e-05", "gnorm": "1.111", "train_wall": "139", "wall": "94886"}
2022-11-13 02:01:55 | INFO | train_inner | {"epoch": 15, "update": 14.242, "loss": "2.357", "nll_loss": "0.484", "ppl": "1.4", "wps": "3108.3", "ups": "0.71", "wpb": "4365", "bsz": "32", "num_updates": "23300", "lr": "4.88594e-05", "gnorm": "1.119", "train_wall": "140", "wall": "95027"}
2022-11-13 02:04:16 | INFO | train_inner | {"epoch": 15, "update": 14.303, "loss": "2.36", "nll_loss": "0.488", "ppl": "1.4", "wps": "3104.8", "ups": "0.71", "wpb": "4403.2", "bsz": "32", "num_updates": "23400", "lr": "4.88544e-05", "gnorm": "1.13", "train_wall": "141", "wall": "95169"}
2022-11-13 02:06:34 | INFO | train_inner | {"epoch": 15, "update": 14.364, "loss": "2.353", "nll_loss": "0.48", "ppl": "1.39", "wps": "3081", "ups": "0.73", "wpb": "4242", "bsz": "32", "num_updates": "23500", "lr": "4.88494e-05", "gnorm": "1.128", "train_wall": "137", "wall": "95306"}
2022-11-13 02:08:56 | INFO | train_inner | {"epoch": 15, "update": 14.425, "loss": "2.367", "nll_loss": "0.496", "ppl": "1.41", "wps": "3091.3", "ups": "0.7", "wpb": "4393.5", "bsz": "32", "num_updates": "23600", "lr": "4.88444e-05", "gnorm": "1.132", "train_wall": "142", "wall": "95448"}
2022-11-13 02:11:15 | INFO | train_inner | {"epoch": 15, "update": 14.487, "loss": "2.382", "nll_loss": "0.513", "ppl": "1.43", "wps": "3103.6", "ups": "0.72", "wpb": "4321.2", "bsz": "32", "num_updates": "23700", "lr": "4.88394e-05", "gnorm": "1.151", "train_wall": "139", "wall": "95588"}
2022-11-13 02:13:34 | INFO | train_inner | {"epoch": 15, "update": 14.548, "loss": "2.369", "nll_loss": "0.498", "ppl": "1.41", "wps": "3084.6", "ups": "0.72", "wpb": "4286.1", "bsz": "32", "num_updates": "23800", "lr": "4.88344e-05", "gnorm": "1.156", "train_wall": "139", "wall": "95727"}
2022-11-13 02:15:53 | INFO | train_inner | {"epoch": 15, "update": 14.609, "loss": "2.376", "nll_loss": "0.506", "ppl": "1.42", "wps": "3076.5", "ups": "0.72", "wpb": "4261", "bsz": "32", "num_updates": "23900", "lr": "4.88294e-05", "gnorm": "1.166", "train_wall": "138", "wall": "95865"}
2022-11-13 02:18:14 | INFO | train_inner | {"epoch": 15, "update": 14.67, "loss": "2.377", "nll_loss": "0.507", "ppl": "1.42", "wps": "3103.4", "ups": "0.71", "wpb": "4363.9", "bsz": "32", "num_updates": "24000", "lr": "4.88244e-05", "gnorm": "1.153", "train_wall": "140", "wall": "96006"}
2022-11-13 02:20:37 | INFO | train_inner | {"epoch": 15, "update": 14.731, "loss": "2.382", "nll_loss": "0.513", "ppl": "1.43", "wps": "3106.3", "ups": "0.7", "wpb": "4446.3", "bsz": "32", "num_updates": "24100", "lr": "4.88194e-05", "gnorm": "1.132", "train_wall": "143", "wall": "96149"}
2022-11-13 02:22:58 | INFO | train_inner | {"epoch": 15, "update": 14.792, "loss": "2.358", "nll_loss": "0.486", "ppl": "1.4", "wps": "3086.1", "ups": "0.71", "wpb": "4361", "bsz": "32", "num_updates": "24200", "lr": "4.88144e-05", "gnorm": "1.125", "train_wall": "141", "wall": "96290"}
2022-11-13 02:25:17 | INFO | train_inner | {"epoch": 15, "update": 14.853, "loss": "2.365", "nll_loss": "0.495", "ppl": "1.41", "wps": "3097.2", "ups": "0.72", "wpb": "4318", "bsz": "32", "num_updates": "24300", "lr": "4.88094e-05", "gnorm": "1.139", "train_wall": "139", "wall": "96430"}
2022-11-13 02:27:39 | INFO | train_inner | {"epoch": 15, "update": 14.914, "loss": "2.376", "nll_loss": "0.507", "ppl": "1.42", "wps": "3126", "ups": "0.71", "wpb": "4418.7", "bsz": "32", "num_updates": "24400", "lr": "4.88044e-05", "gnorm": "1.122", "train_wall": "141", "wall": "96571"}
2022-11-13 02:29:57 | INFO | train_inner | {"epoch": 15, "update": 14.976, "loss": "2.366", "nll_loss": "0.496", "ppl": "1.41", "wps": "3087.9", "ups": "0.73", "wpb": "4255.1", "bsz": "32", "num_updates": "24500", "lr": "4.87994e-05", "gnorm": "1.147", "train_wall": "137", "wall": "96709"}
2022-11-13 02:30:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 03:37:10 | INFO | valid | {"epoch": 15, "valid_loss": "2.639", "valid_nll_loss": "0.742", "valid_ppl": "1.67", "valid_bleu": "64.86", "valid_wps": "224", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "24540", "valid_best_bleu": "65.83"}
2022-11-13 03:37:10 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 03:37:34 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_last.pt (epoch 15 @ 24540 updates, score 64.86) (writing took 24.082524394150823 seconds)
2022-11-13 03:37:34 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-11-13 03:37:34 | INFO | train | {"epoch": 15, "train_loss": "2.366", "train_nll_loss": "0.495", "train_ppl": "1.41", "train_wps": "1128", "train_ups": "0.26", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "24540", "train_lr": "4.87974e-05", "train_gnorm": "1.134", "train_train_wall": "2277", "train_wall": "100766"}
2022-11-13 03:37:34 | INFO | fairseq.trainer | begin training epoch 16
2022-11-13 03:38:57 | INFO | train_inner | {"epoch": 16, "update": 15.037, "loss": "2.344", "nll_loss": "0.47", "ppl": "1.39", "wps": "103.9", "ups": "0.02", "wpb": "4301.9", "bsz": "31.7", "num_updates": "24600", "lr": "4.87944e-05", "gnorm": "1.119", "train_wall": "136", "wall": "100849"}
2022-11-13 03:41:15 | INFO | train_inner | {"epoch": 16, "update": 15.098, "loss": "2.317", "nll_loss": "0.44", "ppl": "1.36", "wps": "3121.8", "ups": "0.72", "wpb": "4323.3", "bsz": "32", "num_updates": "24700", "lr": "4.87894e-05", "gnorm": "1.077", "train_wall": "138", "wall": "100988"}
2022-11-13 03:43:34 | INFO | train_inner | {"epoch": 16, "update": 15.159, "loss": "2.317", "nll_loss": "0.44", "ppl": "1.36", "wps": "3110.6", "ups": "0.72", "wpb": "4296.6", "bsz": "32", "num_updates": "24800", "lr": "4.87844e-05", "gnorm": "1.088", "train_wall": "138", "wall": "101126"}
2022-11-13 03:45:54 | INFO | train_inner | {"epoch": 16, "update": 15.22, "loss": "2.324", "nll_loss": "0.448", "ppl": "1.36", "wps": "3106.8", "ups": "0.71", "wpb": "4348.4", "bsz": "32", "num_updates": "24900", "lr": "4.87794e-05", "gnorm": "1.08", "train_wall": "140", "wall": "101266"}
2022-11-13 03:48:13 | INFO | train_inner | {"epoch": 16, "update": 15.281, "loss": "2.321", "nll_loss": "0.445", "ppl": "1.36", "wps": "3082.3", "ups": "0.72", "wpb": "4308.1", "bsz": "32", "num_updates": "25000", "lr": "4.87744e-05", "gnorm": "1.083", "train_wall": "139", "wall": "101406"}
2022-11-13 03:50:35 | INFO | train_inner | {"epoch": 16, "update": 15.342, "loss": "2.343", "nll_loss": "0.469", "ppl": "1.38", "wps": "3070.3", "ups": "0.7", "wpb": "4359.8", "bsz": "32", "num_updates": "25100", "lr": "4.87694e-05", "gnorm": "1.121", "train_wall": "142", "wall": "101548"}
2022-11-13 03:52:54 | INFO | train_inner | {"epoch": 16, "update": 15.403, "loss": "2.329", "nll_loss": "0.454", "ppl": "1.37", "wps": "3092.4", "ups": "0.72", "wpb": "4289.6", "bsz": "32", "num_updates": "25200", "lr": "4.87644e-05", "gnorm": "1.108", "train_wall": "138", "wall": "101686"}
2022-11-13 03:55:13 | INFO | train_inner | {"epoch": 16, "update": 15.465, "loss": "2.352", "nll_loss": "0.48", "ppl": "1.39", "wps": "3081.5", "ups": "0.72", "wpb": "4283.3", "bsz": "32", "num_updates": "25300", "lr": "4.87594e-05", "gnorm": "1.126", "train_wall": "138", "wall": "101825"}
2022-11-13 03:57:34 | INFO | train_inner | {"epoch": 16, "update": 15.526, "loss": "2.327", "nll_loss": "0.452", "ppl": "1.37", "wps": "3095.1", "ups": "0.71", "wpb": "4362.3", "bsz": "32", "num_updates": "25400", "lr": "4.87544e-05", "gnorm": "1.101", "train_wall": "141", "wall": "101966"}
2022-11-13 03:59:55 | INFO | train_inner | {"epoch": 16, "update": 15.587, "loss": "2.327", "nll_loss": "0.452", "ppl": "1.37", "wps": "3103", "ups": "0.71", "wpb": "4361.2", "bsz": "32", "num_updates": "25500", "lr": "4.87494e-05", "gnorm": "1.102", "train_wall": "140", "wall": "102107"}
2022-11-13 04:02:16 | INFO | train_inner | {"epoch": 16, "update": 15.648, "loss": "2.358", "nll_loss": "0.488", "ppl": "1.4", "wps": "3101.4", "ups": "0.71", "wpb": "4392.7", "bsz": "32", "num_updates": "25600", "lr": "4.87444e-05", "gnorm": "1.114", "train_wall": "141", "wall": "102248"}
2022-11-13 04:04:38 | INFO | train_inner | {"epoch": 16, "update": 15.709, "loss": "2.373", "nll_loss": "0.504", "ppl": "1.42", "wps": "3105.5", "ups": "0.71", "wpb": "4400.2", "bsz": "32", "num_updates": "25700", "lr": "4.87394e-05", "gnorm": "1.153", "train_wall": "141", "wall": "102390"}
2022-11-13 04:06:57 | INFO | train_inner | {"epoch": 16, "update": 15.77, "loss": "2.336", "nll_loss": "0.462", "ppl": "1.38", "wps": "3096.1", "ups": "0.72", "wpb": "4304.3", "bsz": "32", "num_updates": "25800", "lr": "4.87344e-05", "gnorm": "1.112", "train_wall": "139", "wall": "102529"}
2022-11-13 04:09:17 | INFO | train_inner | {"epoch": 16, "update": 15.831, "loss": "2.332", "nll_loss": "0.458", "ppl": "1.37", "wps": "3082.1", "ups": "0.71", "wpb": "4313.2", "bsz": "32", "num_updates": "25900", "lr": "4.87294e-05", "gnorm": "1.112", "train_wall": "139", "wall": "102669"}
2022-11-13 04:11:35 | INFO | train_inner | {"epoch": 16, "update": 15.892, "loss": "2.334", "nll_loss": "0.461", "ppl": "1.38", "wps": "3113", "ups": "0.72", "wpb": "4312.9", "bsz": "32", "num_updates": "26000", "lr": "4.87244e-05", "gnorm": "1.115", "train_wall": "138", "wall": "102808"}
2022-11-13 04:13:56 | INFO | train_inner | {"epoch": 16, "update": 15.954, "loss": "2.346", "nll_loss": "0.474", "ppl": "1.39", "wps": "3106.8", "ups": "0.71", "wpb": "4359", "bsz": "32", "num_updates": "26100", "lr": "4.87194e-05", "gnorm": "1.136", "train_wall": "140", "wall": "102948"}
2022-11-13 04:15:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 05:23:08 | INFO | valid | {"epoch": 16, "valid_loss": "2.629", "valid_nll_loss": "0.728", "valid_ppl": "1.66", "valid_bleu": "65.78", "valid_wps": "220.4", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "26176", "valid_best_bleu": "65.83"}
2022-11-13 05:23:08 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 05:23:31 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_last.pt (epoch 16 @ 26176 updates, score 65.78) (writing took 23.36958294082433 seconds)
2022-11-13 05:23:31 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-11-13 05:23:31 | INFO | train | {"epoch": 16, "train_loss": "2.336", "train_nll_loss": "0.462", "train_ppl": "1.38", "train_wps": "1115.6", "train_ups": "0.26", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "26176", "train_lr": "4.87156e-05", "train_gnorm": "1.111", "train_train_wall": "2280", "train_wall": "107124"}
2022-11-13 05:23:31 | INFO | fairseq.trainer | begin training epoch 17
2022-11-13 05:24:05 | INFO | train_inner | {"epoch": 17, "update": 16.015, "loss": "2.324", "nll_loss": "0.449", "ppl": "1.37", "wps": "102.8", "ups": "0.02", "wpb": "4327.1", "bsz": "31.7", "num_updates": "26200", "lr": "4.87144e-05", "gnorm": "1.147", "train_wall": "139", "wall": "107157"}
2022-11-13 05:26:22 | INFO | train_inner | {"epoch": 17, "update": 16.076, "loss": "2.294", "nll_loss": "0.414", "ppl": "1.33", "wps": "3130.7", "ups": "0.73", "wpb": "4305.2", "bsz": "32", "num_updates": "26300", "lr": "4.87094e-05", "gnorm": "1.055", "train_wall": "137", "wall": "107295"}
2022-11-13 05:28:44 | INFO | train_inner | {"epoch": 17, "update": 16.137, "loss": "2.298", "nll_loss": "0.42", "ppl": "1.34", "wps": "3120.5", "ups": "0.71", "wpb": "4409.8", "bsz": "32", "num_updates": "26400", "lr": "4.87044e-05", "gnorm": "1.06", "train_wall": "141", "wall": "107436"}
2022-11-13 05:31:02 | INFO | train_inner | {"epoch": 17, "update": 16.198, "loss": "2.301", "nll_loss": "0.424", "ppl": "1.34", "wps": "3092.5", "ups": "0.72", "wpb": "4268.4", "bsz": "32", "num_updates": "26500", "lr": "4.86993e-05", "gnorm": "1.07", "train_wall": "138", "wall": "107574"}
2022-11-13 05:33:20 | INFO | train_inner | {"epoch": 17, "update": 16.259, "loss": "2.301", "nll_loss": "0.423", "ppl": "1.34", "wps": "3091.4", "ups": "0.72", "wpb": "4276.3", "bsz": "32", "num_updates": "26600", "lr": "4.86943e-05", "gnorm": "1.079", "train_wall": "138", "wall": "107712"}
2022-11-13 05:35:39 | INFO | train_inner | {"epoch": 17, "update": 16.32, "loss": "2.298", "nll_loss": "0.419", "ppl": "1.34", "wps": "3096.4", "ups": "0.72", "wpb": "4295.3", "bsz": "32", "num_updates": "26700", "lr": "4.86893e-05", "gnorm": "1.102", "train_wall": "138", "wall": "107851"}
2022-11-13 05:37:59 | INFO | train_inner | {"epoch": 17, "update": 16.381, "loss": "2.321", "nll_loss": "0.446", "ppl": "1.36", "wps": "3096.2", "ups": "0.71", "wpb": "4352", "bsz": "32", "num_updates": "26800", "lr": "4.86843e-05", "gnorm": "1.101", "train_wall": "140", "wall": "107991"}
2022-11-13 05:40:18 | INFO | train_inner | {"epoch": 17, "update": 16.443, "loss": "2.318", "nll_loss": "0.442", "ppl": "1.36", "wps": "3070", "ups": "0.72", "wpb": "4253.6", "bsz": "32", "num_updates": "26900", "lr": "4.86793e-05", "gnorm": "1.101", "train_wall": "138", "wall": "108130"}
2022-11-13 05:42:39 | INFO | train_inner | {"epoch": 17, "update": 16.504, "loss": "2.305", "nll_loss": "0.428", "ppl": "1.35", "wps": "3085.5", "ups": "0.71", "wpb": "4352.5", "bsz": "32", "num_updates": "27000", "lr": "4.86743e-05", "gnorm": "1.103", "train_wall": "141", "wall": "108271"}
2022-11-13 05:44:59 | INFO | train_inner | {"epoch": 17, "update": 16.565, "loss": "2.309", "nll_loss": "0.433", "ppl": "1.35", "wps": "3099.1", "ups": "0.71", "wpb": "4343.1", "bsz": "32", "num_updates": "27100", "lr": "4.86693e-05", "gnorm": "1.083", "train_wall": "140", "wall": "108411"}
2022-11-13 05:47:23 | INFO | train_inner | {"epoch": 17, "update": 16.626, "loss": "2.314", "nll_loss": "0.439", "ppl": "1.36", "wps": "3107.4", "ups": "0.7", "wpb": "4461.4", "bsz": "32", "num_updates": "27200", "lr": "4.86643e-05", "gnorm": "1.077", "train_wall": "143", "wall": "108555"}
2022-11-13 05:49:43 | INFO | train_inner | {"epoch": 17, "update": 16.687, "loss": "2.313", "nll_loss": "0.437", "ppl": "1.35", "wps": "3080.8", "ups": "0.71", "wpb": "4312.4", "bsz": "32", "num_updates": "27300", "lr": "4.86593e-05", "gnorm": "1.11", "train_wall": "140", "wall": "108695"}
2022-11-13 05:52:04 | INFO | train_inner | {"epoch": 17, "update": 16.748, "loss": "2.323", "nll_loss": "0.449", "ppl": "1.36", "wps": "3097.2", "ups": "0.71", "wpb": "4379.8", "bsz": "32", "num_updates": "27400", "lr": "4.86543e-05", "gnorm": "1.095", "train_wall": "141", "wall": "108836"}
2022-11-13 05:54:25 | INFO | train_inner | {"epoch": 17, "update": 16.809, "loss": "2.322", "nll_loss": "0.447", "ppl": "1.36", "wps": "3085.9", "ups": "0.71", "wpb": "4366.5", "bsz": "32", "num_updates": "27500", "lr": "4.86493e-05", "gnorm": "1.116", "train_wall": "141", "wall": "108978"}
2022-11-13 05:56:46 | INFO | train_inner | {"epoch": 17, "update": 16.87, "loss": "2.313", "nll_loss": "0.437", "ppl": "1.35", "wps": "3078.6", "ups": "0.71", "wpb": "4315.7", "bsz": "32", "num_updates": "27600", "lr": "4.86443e-05", "gnorm": "1.085", "train_wall": "140", "wall": "109118"}
2022-11-13 05:59:06 | INFO | train_inner | {"epoch": 17, "update": 16.932, "loss": "2.311", "nll_loss": "0.435", "ppl": "1.35", "wps": "3098.1", "ups": "0.71", "wpb": "4346", "bsz": "32", "num_updates": "27700", "lr": "4.86393e-05", "gnorm": "1.1", "train_wall": "140", "wall": "109258"}
2022-11-13 06:01:26 | INFO | train_inner | {"epoch": 17, "update": 16.993, "loss": "2.309", "nll_loss": "0.432", "ppl": "1.35", "wps": "3102.9", "ups": "0.71", "wpb": "4359.3", "bsz": "32", "num_updates": "27800", "lr": "4.86343e-05", "gnorm": "1.069", "train_wall": "140", "wall": "109399"}
2022-11-13 06:01:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 07:09:36 | INFO | valid | {"epoch": 17, "valid_loss": "2.636", "valid_nll_loss": "0.741", "valid_ppl": "1.67", "valid_bleu": "66.41", "valid_wps": "218.8", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "27812", "valid_best_bleu": "66.41"}
2022-11-13 07:09:36 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 07:10:16 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 17 @ 27812 updates, score 66.41) (writing took 39.73926429729909 seconds)
2022-11-13 07:10:16 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-11-13 07:10:16 | INFO | train | {"epoch": 17, "train_loss": "2.309", "train_nll_loss": "0.433", "train_ppl": "1.35", "train_wps": "1107.5", "train_ups": "0.26", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "27812", "train_lr": "4.86337e-05", "train_gnorm": "1.088", "train_train_wall": "2283", "train_wall": "113528"}
2022-11-13 07:10:16 | INFO | fairseq.trainer | begin training epoch 18
2022-11-13 07:12:16 | INFO | train_inner | {"epoch": 18, "update": 17.054, "loss": "2.277", "nll_loss": "0.397", "ppl": "1.32", "wps": "100.5", "ups": "0.02", "wpb": "4270.8", "bsz": "31.7", "num_updates": "27900", "lr": "4.86293e-05", "gnorm": "1.052", "train_wall": "135", "wall": "113648"}
2022-11-13 07:14:37 | INFO | train_inner | {"epoch": 18, "update": 17.115, "loss": "2.282", "nll_loss": "0.402", "ppl": "1.32", "wps": "3144.8", "ups": "0.71", "wpb": "4417.5", "bsz": "32", "num_updates": "28000", "lr": "4.86243e-05", "gnorm": "1.021", "train_wall": "140", "wall": "113789"}
2022-11-13 07:16:55 | INFO | train_inner | {"epoch": 18, "update": 17.176, "loss": "2.284", "nll_loss": "0.404", "ppl": "1.32", "wps": "3115.8", "ups": "0.72", "wpb": "4326.3", "bsz": "32", "num_updates": "28100", "lr": "4.86193e-05", "gnorm": "1.066", "train_wall": "138", "wall": "113928"}
2022-11-13 07:19:13 | INFO | train_inner | {"epoch": 18, "update": 17.237, "loss": "2.272", "nll_loss": "0.391", "ppl": "1.31", "wps": "3105.5", "ups": "0.73", "wpb": "4275", "bsz": "32", "num_updates": "28200", "lr": "4.86143e-05", "gnorm": "1.033", "train_wall": "137", "wall": "114065"}
2022-11-13 07:21:30 | INFO | train_inner | {"epoch": 18, "update": 17.298, "loss": "2.285", "nll_loss": "0.406", "ppl": "1.32", "wps": "3089.7", "ups": "0.73", "wpb": "4244.3", "bsz": "32", "num_updates": "28300", "lr": "4.86093e-05", "gnorm": "1.075", "train_wall": "137", "wall": "114203"}
2022-11-13 07:23:52 | INFO | train_inner | {"epoch": 18, "update": 17.359, "loss": "2.28", "nll_loss": "0.4", "ppl": "1.32", "wps": "3101.2", "ups": "0.71", "wpb": "4390.8", "bsz": "32", "num_updates": "28400", "lr": "4.86043e-05", "gnorm": "1.057", "train_wall": "141", "wall": "114344"}
2022-11-13 07:26:12 | INFO | train_inner | {"epoch": 18, "update": 17.421, "loss": "2.281", "nll_loss": "0.401", "ppl": "1.32", "wps": "3096.3", "ups": "0.72", "wpb": "4330.3", "bsz": "32", "num_updates": "28500", "lr": "4.85993e-05", "gnorm": "1.039", "train_wall": "139", "wall": "114484"}
2022-11-13 07:28:33 | INFO | train_inner | {"epoch": 18, "update": 17.482, "loss": "2.276", "nll_loss": "0.395", "ppl": "1.32", "wps": "3112.1", "ups": "0.71", "wpb": "4379.7", "bsz": "32", "num_updates": "28600", "lr": "4.85943e-05", "gnorm": "1.04", "train_wall": "140", "wall": "114625"}
2022-11-13 07:30:54 | INFO | train_inner | {"epoch": 18, "update": 17.543, "loss": "2.288", "nll_loss": "0.41", "ppl": "1.33", "wps": "3104.7", "ups": "0.71", "wpb": "4380.1", "bsz": "32", "num_updates": "28700", "lr": "4.85893e-05", "gnorm": "1.066", "train_wall": "141", "wall": "114766"}
2022-11-13 07:33:13 | INFO | train_inner | {"epoch": 18, "update": 17.604, "loss": "2.281", "nll_loss": "0.401", "ppl": "1.32", "wps": "3099.2", "ups": "0.72", "wpb": "4330", "bsz": "32", "num_updates": "28800", "lr": "4.85843e-05", "gnorm": "1.052", "train_wall": "139", "wall": "114906"}
2022-11-13 07:35:33 | INFO | train_inner | {"epoch": 18, "update": 17.665, "loss": "2.323", "nll_loss": "0.449", "ppl": "1.36", "wps": "3090.6", "ups": "0.71", "wpb": "4326.6", "bsz": "32", "num_updates": "28900", "lr": "4.85793e-05", "gnorm": "1.144", "train_wall": "140", "wall": "115046"}
2022-11-13 07:37:52 | INFO | train_inner | {"epoch": 18, "update": 17.726, "loss": "2.3", "nll_loss": "0.423", "ppl": "1.34", "wps": "3108.7", "ups": "0.72", "wpb": "4320", "bsz": "32", "num_updates": "29000", "lr": "4.85743e-05", "gnorm": "1.076", "train_wall": "139", "wall": "115185"}
2022-11-13 07:40:15 | INFO | train_inner | {"epoch": 18, "update": 17.787, "loss": "2.29", "nll_loss": "0.412", "ppl": "1.33", "wps": "3091.8", "ups": "0.7", "wpb": "4402.6", "bsz": "32", "num_updates": "29100", "lr": "4.85693e-05", "gnorm": "1.064", "train_wall": "142", "wall": "115327"}
2022-11-13 07:42:34 | INFO | train_inner | {"epoch": 18, "update": 17.848, "loss": "2.286", "nll_loss": "0.407", "ppl": "1.33", "wps": "3092.8", "ups": "0.72", "wpb": "4299.6", "bsz": "32", "num_updates": "29200", "lr": "4.85643e-05", "gnorm": "1.079", "train_wall": "139", "wall": "115466"}
2022-11-13 07:44:54 | INFO | train_inner | {"epoch": 18, "update": 17.91, "loss": "2.286", "nll_loss": "0.407", "ppl": "1.33", "wps": "3100.2", "ups": "0.71", "wpb": "4358.8", "bsz": "32", "num_updates": "29300", "lr": "4.85593e-05", "gnorm": "1.052", "train_wall": "140", "wall": "115607"}
2022-11-13 07:47:14 | INFO | train_inner | {"epoch": 18, "update": 17.971, "loss": "2.299", "nll_loss": "0.422", "ppl": "1.34", "wps": "3081.2", "ups": "0.72", "wpb": "4303.4", "bsz": "32", "num_updates": "29400", "lr": "4.85543e-05", "gnorm": "1.071", "train_wall": "139", "wall": "115746"}
2022-11-13 07:48:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 08:54:10 | INFO | valid | {"epoch": 18, "valid_loss": "2.631", "valid_nll_loss": "0.732", "valid_ppl": "1.66", "valid_bleu": "65.51", "valid_wps": "225.7", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "29448", "valid_best_bleu": "66.41"}
2022-11-13 08:54:10 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 08:54:33 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_last.pt (epoch 18 @ 29448 updates, score 65.51) (writing took 22.935750645119697 seconds)
2022-11-13 08:54:33 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-11-13 08:54:33 | INFO | train | {"epoch": 18, "train_loss": "2.287", "train_nll_loss": "0.408", "train_ppl": "1.33", "train_wps": "1133.6", "train_ups": "0.26", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "29448", "train_lr": "4.85519e-05", "train_gnorm": "1.063", "train_train_wall": "2277", "train_wall": "119785"}
2022-11-13 08:54:33 | INFO | fairseq.trainer | begin training epoch 19
2022-11-13 08:55:45 | INFO | train_inner | {"epoch": 19, "update": 18.032, "loss": "2.29", "nll_loss": "0.411", "ppl": "1.33", "wps": "105", "ups": "0.02", "wpb": "4316.6", "bsz": "31.7", "num_updates": "29500", "lr": "4.85493e-05", "gnorm": "1.084", "train_wall": "138", "wall": "119857"}
2022-11-13 08:58:05 | INFO | train_inner | {"epoch": 19, "update": 18.093, "loss": "2.25", "nll_loss": "0.367", "ppl": "1.29", "wps": "3159", "ups": "0.71", "wpb": "4438.8", "bsz": "32", "num_updates": "29600", "lr": "4.85443e-05", "gnorm": "0.988", "train_wall": "140", "wall": "119998"}
2022-11-13 09:00:24 | INFO | train_inner | {"epoch": 19, "update": 18.154, "loss": "2.252", "nll_loss": "0.369", "ppl": "1.29", "wps": "3119.7", "ups": "0.72", "wpb": "4308.1", "bsz": "32", "num_updates": "29700", "lr": "4.85393e-05", "gnorm": "1.018", "train_wall": "138", "wall": "120136"}
2022-11-13 09:02:45 | INFO | train_inner | {"epoch": 19, "update": 18.215, "loss": "2.259", "nll_loss": "0.377", "ppl": "1.3", "wps": "3108", "ups": "0.71", "wpb": "4400.3", "bsz": "32", "num_updates": "29800", "lr": "4.85343e-05", "gnorm": "1.004", "train_wall": "141", "wall": "120277"}
2022-11-13 09:05:04 | INFO | train_inner | {"epoch": 19, "update": 18.276, "loss": "2.259", "nll_loss": "0.377", "ppl": "1.3", "wps": "3098", "ups": "0.72", "wpb": "4289.9", "bsz": "32", "num_updates": "29900", "lr": "4.85293e-05", "gnorm": "1.04", "train_wall": "138", "wall": "120416"}
2022-11-13 09:07:22 | INFO | train_inner | {"epoch": 19, "update": 18.337, "loss": "2.261", "nll_loss": "0.379", "ppl": "1.3", "wps": "3096.9", "ups": "0.72", "wpb": "4279.9", "bsz": "32", "num_updates": "30000", "lr": "4.85243e-05", "gnorm": "1.043", "train_wall": "138", "wall": "120554"}
2022-11-13 09:09:44 | INFO | train_inner | {"epoch": 19, "update": 18.399, "loss": "2.263", "nll_loss": "0.382", "ppl": "1.3", "wps": "3104.6", "ups": "0.7", "wpb": "4404.2", "bsz": "32", "num_updates": "30100", "lr": "4.85193e-05", "gnorm": "1.045", "train_wall": "141", "wall": "120696"}
2022-11-13 09:12:04 | INFO | train_inner | {"epoch": 19, "update": 18.46, "loss": "2.28", "nll_loss": "0.402", "ppl": "1.32", "wps": "3089.6", "ups": "0.71", "wpb": "4332", "bsz": "32", "num_updates": "30200", "lr": "4.85143e-05", "gnorm": "1.059", "train_wall": "140", "wall": "120836"}
2022-11-13 09:14:23 | INFO | train_inner | {"epoch": 19, "update": 18.521, "loss": "2.28", "nll_loss": "0.401", "ppl": "1.32", "wps": "3090.4", "ups": "0.72", "wpb": "4312.9", "bsz": "32", "num_updates": "30300", "lr": "4.85093e-05", "gnorm": "1.07", "train_wall": "139", "wall": "120976"}
2022-11-13 09:16:45 | INFO | train_inner | {"epoch": 19, "update": 18.582, "loss": "2.265", "nll_loss": "0.384", "ppl": "1.31", "wps": "3109.2", "ups": "0.7", "wpb": "4411.1", "bsz": "32", "num_updates": "30400", "lr": "4.85043e-05", "gnorm": "1.022", "train_wall": "141", "wall": "121118"}
2022-11-13 09:19:05 | INFO | train_inner | {"epoch": 19, "update": 18.643, "loss": "2.256", "nll_loss": "0.374", "ppl": "1.3", "wps": "3101.4", "ups": "0.72", "wpb": "4331.3", "bsz": "32", "num_updates": "30500", "lr": "4.84992e-05", "gnorm": "1.026", "train_wall": "139", "wall": "121257"}
2022-11-13 09:21:24 | INFO | train_inner | {"epoch": 19, "update": 18.704, "loss": "2.267", "nll_loss": "0.387", "ppl": "1.31", "wps": "3084.8", "ups": "0.72", "wpb": "4283.8", "bsz": "32", "num_updates": "30600", "lr": "4.84942e-05", "gnorm": "1.044", "train_wall": "138", "wall": "121396"}
2022-11-13 09:23:44 | INFO | train_inner | {"epoch": 19, "update": 18.765, "loss": "2.278", "nll_loss": "0.4", "ppl": "1.32", "wps": "3092.5", "ups": "0.71", "wpb": "4336.4", "bsz": "32", "num_updates": "30700", "lr": "4.84892e-05", "gnorm": "1.067", "train_wall": "140", "wall": "121536"}
2022-11-13 09:26:04 | INFO | train_inner | {"epoch": 19, "update": 18.826, "loss": "2.269", "nll_loss": "0.389", "ppl": "1.31", "wps": "3104.4", "ups": "0.72", "wpb": "4338.6", "bsz": "32", "num_updates": "30800", "lr": "4.84842e-05", "gnorm": "1.037", "train_wall": "139", "wall": "121676"}
2022-11-13 09:28:24 | INFO | train_inner | {"epoch": 19, "update": 18.888, "loss": "2.282", "nll_loss": "0.404", "ppl": "1.32", "wps": "3098.3", "ups": "0.72", "wpb": "4331.2", "bsz": "32", "num_updates": "30900", "lr": "4.84792e-05", "gnorm": "1.055", "train_wall": "139", "wall": "121816"}
2022-11-13 09:30:42 | INFO | train_inner | {"epoch": 19, "update": 18.949, "loss": "2.268", "nll_loss": "0.389", "ppl": "1.31", "wps": "3086.9", "ups": "0.72", "wpb": "4282.3", "bsz": "32", "num_updates": "31000", "lr": "4.84742e-05", "gnorm": "1.044", "train_wall": "138", "wall": "121955"}
2022-11-13 09:32:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 10:39:22 | INFO | valid | {"epoch": 19, "valid_loss": "2.607", "valid_nll_loss": "0.712", "valid_ppl": "1.64", "valid_bleu": "67.61", "valid_wps": "222.7", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "31084", "valid_best_bleu": "67.61"}
2022-11-13 10:39:22 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 10:39:58 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 19 @ 31084 updates, score 67.61) (writing took 36.40142562426627 seconds)
2022-11-13 10:39:58 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-11-13 10:39:58 | INFO | train | {"epoch": 19, "train_loss": "2.266", "train_nll_loss": "0.386", "train_ppl": "1.31", "train_wps": "1121.3", "train_ups": "0.26", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "31084", "train_lr": "4.847e-05", "train_gnorm": "1.038", "train_train_wall": "2278", "train_wall": "126110"}
2022-11-13 10:39:58 | INFO | fairseq.trainer | begin training epoch 20
2022-11-13 10:40:20 | INFO | train_inner | {"epoch": 20, "update": 19.01, "loss": "2.263", "nll_loss": "0.382", "ppl": "1.3", "wps": "102", "ups": "0.02", "wpb": "4259.3", "bsz": "31.7", "num_updates": "31100", "lr": "4.84692e-05", "gnorm": "1.056", "train_wall": "137", "wall": "126132"}
2022-11-13 10:42:39 | INFO | train_inner | {"epoch": 20, "update": 19.071, "loss": "2.238", "nll_loss": "0.354", "ppl": "1.28", "wps": "3143", "ups": "0.72", "wpb": "4367.1", "bsz": "32", "num_updates": "31200", "lr": "4.84642e-05", "gnorm": "0.968", "train_wall": "138", "wall": "126271"}
2022-11-13 10:44:58 | INFO | train_inner | {"epoch": 20, "update": 19.132, "loss": "2.233", "nll_loss": "0.349", "ppl": "1.27", "wps": "3141.1", "ups": "0.72", "wpb": "4373.1", "bsz": "32", "num_updates": "31300", "lr": "4.84592e-05", "gnorm": "0.979", "train_wall": "139", "wall": "126410"}
2022-11-13 10:47:18 | INFO | train_inner | {"epoch": 20, "update": 19.193, "loss": "2.25", "nll_loss": "0.367", "ppl": "1.29", "wps": "3102.2", "ups": "0.71", "wpb": "4345.9", "bsz": "32", "num_updates": "31400", "lr": "4.84542e-05", "gnorm": "1.018", "train_wall": "140", "wall": "126550"}
2022-11-13 10:49:37 | INFO | train_inner | {"epoch": 20, "update": 19.254, "loss": "2.254", "nll_loss": "0.372", "ppl": "1.29", "wps": "3090.8", "ups": "0.72", "wpb": "4282", "bsz": "32", "num_updates": "31500", "lr": "4.84492e-05", "gnorm": "1.017", "train_wall": "138", "wall": "126689"}
2022-11-13 10:51:56 | INFO | train_inner | {"epoch": 20, "update": 19.315, "loss": "2.246", "nll_loss": "0.364", "ppl": "1.29", "wps": "3093", "ups": "0.72", "wpb": "4315.9", "bsz": "32", "num_updates": "31600", "lr": "4.84442e-05", "gnorm": "1.013", "train_wall": "139", "wall": "126828"}
2022-11-13 10:54:15 | INFO | train_inner | {"epoch": 20, "update": 19.377, "loss": "2.242", "nll_loss": "0.359", "ppl": "1.28", "wps": "3087", "ups": "0.72", "wpb": "4281.8", "bsz": "32", "num_updates": "31700", "lr": "4.84392e-05", "gnorm": "1.013", "train_wall": "138", "wall": "126967"}
2022-11-13 10:56:37 | INFO | train_inner | {"epoch": 20, "update": 19.438, "loss": "2.263", "nll_loss": "0.382", "ppl": "1.3", "wps": "3077", "ups": "0.7", "wpb": "4385.7", "bsz": "32", "num_updates": "31800", "lr": "4.84342e-05", "gnorm": "1.043", "train_wall": "142", "wall": "127110"}
2022-11-13 10:58:56 | INFO | train_inner | {"epoch": 20, "update": 19.499, "loss": "2.239", "nll_loss": "0.356", "ppl": "1.28", "wps": "3089.6", "ups": "0.72", "wpb": "4290.7", "bsz": "32", "num_updates": "31900", "lr": "4.84292e-05", "gnorm": "1.004", "train_wall": "138", "wall": "127249"}
2022-11-13 11:01:17 | INFO | train_inner | {"epoch": 20, "update": 19.56, "loss": "2.263", "nll_loss": "0.382", "ppl": "1.3", "wps": "3071.7", "ups": "0.71", "wpb": "4319.2", "bsz": "32", "num_updates": "32000", "lr": "4.84242e-05", "gnorm": "1.045", "train_wall": "140", "wall": "127389"}
2022-11-13 11:03:36 | INFO | train_inner | {"epoch": 20, "update": 19.621, "loss": "2.249", "nll_loss": "0.367", "ppl": "1.29", "wps": "3087.7", "ups": "0.72", "wpb": "4309.6", "bsz": "32", "num_updates": "32100", "lr": "4.84192e-05", "gnorm": "1.028", "train_wall": "139", "wall": "127529"}
2022-11-13 11:05:54 | INFO | train_inner | {"epoch": 20, "update": 19.682, "loss": "2.247", "nll_loss": "0.364", "ppl": "1.29", "wps": "3107.7", "ups": "0.72", "wpb": "4288", "bsz": "32", "num_updates": "32200", "lr": "4.84142e-05", "gnorm": "1.028", "train_wall": "138", "wall": "127667"}
2022-11-13 11:08:15 | INFO | train_inner | {"epoch": 20, "update": 19.743, "loss": "2.248", "nll_loss": "0.366", "ppl": "1.29", "wps": "3104.5", "ups": "0.71", "wpb": "4360.1", "bsz": "32", "num_updates": "32300", "lr": "4.84092e-05", "gnorm": "1.026", "train_wall": "140", "wall": "127807"}
2022-11-13 11:10:34 | INFO | train_inner | {"epoch": 20, "update": 19.804, "loss": "2.247", "nll_loss": "0.365", "ppl": "1.29", "wps": "3097", "ups": "0.72", "wpb": "4309.5", "bsz": "32", "num_updates": "32400", "lr": "4.84042e-05", "gnorm": "1.036", "train_wall": "139", "wall": "127946"}
2022-11-13 11:12:57 | INFO | train_inner | {"epoch": 20, "update": 19.866, "loss": "2.248", "nll_loss": "0.366", "ppl": "1.29", "wps": "3099.7", "ups": "0.7", "wpb": "4421", "bsz": "32", "num_updates": "32500", "lr": "4.83992e-05", "gnorm": "1.018", "train_wall": "142", "wall": "128089"}
2022-11-13 11:15:18 | INFO | train_inner | {"epoch": 20, "update": 19.927, "loss": "2.253", "nll_loss": "0.372", "ppl": "1.29", "wps": "3099.4", "ups": "0.71", "wpb": "4376.7", "bsz": "32", "num_updates": "32600", "lr": "4.83942e-05", "gnorm": "1.037", "train_wall": "141", "wall": "128230"}
2022-11-13 11:17:38 | INFO | train_inner | {"epoch": 20, "update": 19.988, "loss": "2.267", "nll_loss": "0.388", "ppl": "1.31", "wps": "3103.5", "ups": "0.71", "wpb": "4360.9", "bsz": "32", "num_updates": "32700", "lr": "4.83892e-05", "gnorm": "1.064", "train_wall": "140", "wall": "128371"}
2022-11-13 11:18:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 12:28:21 | INFO | valid | {"epoch": 20, "valid_loss": "2.614", "valid_nll_loss": "0.719", "valid_ppl": "1.65", "valid_bleu": "68.15", "valid_wps": "211.5", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "32720", "valid_best_bleu": "68.15"}
2022-11-13 12:28:21 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 12:28:58 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 20 @ 32720 updates, score 68.15) (writing took 36.980780180078 seconds)
2022-11-13 12:28:58 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-11-13 12:28:58 | INFO | train | {"epoch": 20, "train_loss": "2.249", "train_nll_loss": "0.367", "train_ppl": "1.29", "train_wps": "1084.5", "train_ups": "0.25", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "32720", "train_lr": "4.83882e-05", "train_gnorm": "1.023", "train_train_wall": "2280", "train_wall": "132650"}
2022-11-13 12:28:58 | INFO | fairseq.trainer | begin training epoch 21
2022-11-13 12:30:48 | INFO | train_inner | {"epoch": 21, "update": 20.049, "loss": "2.261", "nll_loss": "0.38", "ppl": "1.3", "wps": "98.5", "ups": "0.02", "wpb": "4325", "bsz": "31.7", "num_updates": "32800", "lr": "4.83842e-05", "gnorm": "1.078", "train_wall": "137", "wall": "132761"}
2022-11-13 12:33:06 | INFO | train_inner | {"epoch": 21, "update": 20.11, "loss": "2.226", "nll_loss": "0.342", "ppl": "1.27", "wps": "3129.6", "ups": "0.73", "wpb": "4297.2", "bsz": "32", "num_updates": "32900", "lr": "4.83792e-05", "gnorm": "0.975", "train_wall": "137", "wall": "132898"}
2022-11-13 12:35:25 | INFO | train_inner | {"epoch": 21, "update": 20.171, "loss": "2.221", "nll_loss": "0.336", "ppl": "1.26", "wps": "3122.6", "ups": "0.72", "wpb": "4366.3", "bsz": "32", "num_updates": "33000", "lr": "4.83742e-05", "gnorm": "0.971", "train_wall": "139", "wall": "133038"}
2022-11-13 12:37:45 | INFO | train_inner | {"epoch": 21, "update": 20.232, "loss": "2.222", "nll_loss": "0.337", "ppl": "1.26", "wps": "3105.3", "ups": "0.72", "wpb": "4342.2", "bsz": "32", "num_updates": "33100", "lr": "4.83692e-05", "gnorm": "0.979", "train_wall": "139", "wall": "133178"}
2022-11-13 12:40:06 | INFO | train_inner | {"epoch": 21, "update": 20.293, "loss": "2.228", "nll_loss": "0.343", "ppl": "1.27", "wps": "3091.5", "ups": "0.71", "wpb": "4335.7", "bsz": "32", "num_updates": "33200", "lr": "4.83642e-05", "gnorm": "0.999", "train_wall": "140", "wall": "133318"}
2022-11-13 12:42:25 | INFO | train_inner | {"epoch": 21, "update": 20.355, "loss": "2.231", "nll_loss": "0.347", "ppl": "1.27", "wps": "3084.2", "ups": "0.72", "wpb": "4310.9", "bsz": "32", "num_updates": "33300", "lr": "4.83592e-05", "gnorm": "1.013", "train_wall": "139", "wall": "133458"}
2022-11-13 12:44:45 | INFO | train_inner | {"epoch": 21, "update": 20.416, "loss": "2.23", "nll_loss": "0.346", "ppl": "1.27", "wps": "3084.9", "ups": "0.72", "wpb": "4294.6", "bsz": "32", "num_updates": "33400", "lr": "4.83542e-05", "gnorm": "0.986", "train_wall": "139", "wall": "133597"}
2022-11-13 12:47:05 | INFO | train_inner | {"epoch": 21, "update": 20.477, "loss": "2.244", "nll_loss": "0.362", "ppl": "1.29", "wps": "3109.4", "ups": "0.71", "wpb": "4377.4", "bsz": "32", "num_updates": "33500", "lr": "4.83492e-05", "gnorm": "1.01", "train_wall": "140", "wall": "133738"}
2022-11-13 12:49:24 | INFO | train_inner | {"epoch": 21, "update": 20.538, "loss": "2.229", "nll_loss": "0.344", "ppl": "1.27", "wps": "3097", "ups": "0.72", "wpb": "4298.5", "bsz": "32", "num_updates": "33600", "lr": "4.83442e-05", "gnorm": "1.029", "train_wall": "138", "wall": "133876"}
2022-11-13 12:51:46 | INFO | train_inner | {"epoch": 21, "update": 20.599, "loss": "2.244", "nll_loss": "0.362", "ppl": "1.28", "wps": "3090.9", "ups": "0.71", "wpb": "4382.9", "bsz": "32", "num_updates": "33700", "lr": "4.83392e-05", "gnorm": "1.005", "train_wall": "141", "wall": "134018"}
2022-11-13 12:54:07 | INFO | train_inner | {"epoch": 21, "update": 20.66, "loss": "2.238", "nll_loss": "0.355", "ppl": "1.28", "wps": "3096.8", "ups": "0.71", "wpb": "4366.1", "bsz": "32", "num_updates": "33800", "lr": "4.83342e-05", "gnorm": "1.017", "train_wall": "141", "wall": "134159"}
2022-11-13 12:56:29 | INFO | train_inner | {"epoch": 21, "update": 20.721, "loss": "2.241", "nll_loss": "0.359", "ppl": "1.28", "wps": "3088.7", "ups": "0.71", "wpb": "4379.7", "bsz": "32", "num_updates": "33900", "lr": "4.83292e-05", "gnorm": "1.004", "train_wall": "141", "wall": "134301"}
2022-11-13 12:58:50 | INFO | train_inner | {"epoch": 21, "update": 20.782, "loss": "2.239", "nll_loss": "0.356", "ppl": "1.28", "wps": "3085.6", "ups": "0.71", "wpb": "4349.1", "bsz": "32", "num_updates": "34000", "lr": "4.83242e-05", "gnorm": "1.02", "train_wall": "140", "wall": "134442"}
2022-11-13 13:01:08 | INFO | train_inner | {"epoch": 21, "update": 20.844, "loss": "2.227", "nll_loss": "0.344", "ppl": "1.27", "wps": "3088.6", "ups": "0.72", "wpb": "4275.6", "bsz": "32", "num_updates": "34100", "lr": "4.83192e-05", "gnorm": "0.995", "train_wall": "138", "wall": "134580"}
2022-11-13 13:03:28 | INFO | train_inner | {"epoch": 21, "update": 20.905, "loss": "2.234", "nll_loss": "0.35", "ppl": "1.27", "wps": "3078", "ups": "0.71", "wpb": "4315.3", "bsz": "32", "num_updates": "34200", "lr": "4.83142e-05", "gnorm": "1.011", "train_wall": "140", "wall": "134721"}
2022-11-13 13:05:48 | INFO | train_inner | {"epoch": 21, "update": 20.966, "loss": "2.238", "nll_loss": "0.356", "ppl": "1.28", "wps": "3100.1", "ups": "0.72", "wpb": "4327.5", "bsz": "32", "num_updates": "34300", "lr": "4.83092e-05", "gnorm": "1.041", "train_wall": "139", "wall": "134860"}
2022-11-13 13:07:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 14:15:54 | INFO | valid | {"epoch": 21, "valid_loss": "2.612", "valid_nll_loss": "0.717", "valid_ppl": "1.64", "valid_bleu": "68.49", "valid_wps": "216", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "34356", "valid_best_bleu": "68.49"}
2022-11-13 14:15:54 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 14:16:33 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 21 @ 34356 updates, score 68.49) (writing took 39.34839865518734 seconds)
2022-11-13 14:16:33 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-11-13 14:16:33 | INFO | train | {"epoch": 21, "train_loss": "2.234", "train_nll_loss": "0.351", "train_ppl": "1.28", "train_wps": "1098.7", "train_ups": "0.25", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "34356", "train_lr": "4.83064e-05", "train_gnorm": "1.007", "train_train_wall": "2281", "train_wall": "139106"}
2022-11-13 14:16:33 | INFO | fairseq.trainer | begin training epoch 22
2022-11-13 14:17:34 | INFO | train_inner | {"epoch": 22, "update": 21.027, "loss": "2.222", "nll_loss": "0.338", "ppl": "1.26", "wps": "100.6", "ups": "0.02", "wpb": "4331.9", "bsz": "31.7", "num_updates": "34400", "lr": "4.83042e-05", "gnorm": "1.012", "train_wall": "138", "wall": "139166"}
2022-11-13 14:19:54 | INFO | train_inner | {"epoch": 22, "update": 21.088, "loss": "2.209", "nll_loss": "0.322", "ppl": "1.25", "wps": "3146.6", "ups": "0.71", "wpb": "4408.9", "bsz": "32", "num_updates": "34500", "lr": "4.82991e-05", "gnorm": "0.953", "train_wall": "140", "wall": "139306"}
2022-11-13 14:22:12 | INFO | train_inner | {"epoch": 22, "update": 21.149, "loss": "2.21", "nll_loss": "0.323", "ppl": "1.25", "wps": "3113.1", "ups": "0.73", "wpb": "4293.4", "bsz": "32", "num_updates": "34600", "lr": "4.82941e-05", "gnorm": "0.963", "train_wall": "137", "wall": "139444"}
2022-11-13 14:24:30 | INFO | train_inner | {"epoch": 22, "update": 21.21, "loss": "2.212", "nll_loss": "0.327", "ppl": "1.25", "wps": "3105.6", "ups": "0.72", "wpb": "4307.7", "bsz": "32", "num_updates": "34700", "lr": "4.82891e-05", "gnorm": "0.978", "train_wall": "138", "wall": "139582"}
2022-11-13 14:26:51 | INFO | train_inner | {"epoch": 22, "update": 21.271, "loss": "2.212", "nll_loss": "0.327", "ppl": "1.25", "wps": "3108.8", "ups": "0.71", "wpb": "4379.1", "bsz": "32", "num_updates": "34800", "lr": "4.82841e-05", "gnorm": "0.966", "train_wall": "140", "wall": "139723"}
2022-11-13 14:29:09 | INFO | train_inner | {"epoch": 22, "update": 21.333, "loss": "2.223", "nll_loss": "0.338", "ppl": "1.26", "wps": "3093.5", "ups": "0.73", "wpb": "4254", "bsz": "32", "num_updates": "34900", "lr": "4.82791e-05", "gnorm": "0.98", "train_wall": "137", "wall": "139861"}
2022-11-13 14:31:27 | INFO | train_inner | {"epoch": 22, "update": 21.394, "loss": "2.23", "nll_loss": "0.347", "ppl": "1.27", "wps": "3082", "ups": "0.72", "wpb": "4275.5", "bsz": "32", "num_updates": "35000", "lr": "4.82741e-05", "gnorm": "1.014", "train_wall": "138", "wall": "140000"}
2022-11-13 14:33:48 | INFO | train_inner | {"epoch": 22, "update": 21.455, "loss": "2.219", "nll_loss": "0.335", "ppl": "1.26", "wps": "3095", "ups": "0.71", "wpb": "4345.5", "bsz": "32", "num_updates": "35100", "lr": "4.82691e-05", "gnorm": "0.993", "train_wall": "140", "wall": "140140"}
2022-11-13 14:36:08 | INFO | train_inner | {"epoch": 22, "update": 21.516, "loss": "2.218", "nll_loss": "0.333", "ppl": "1.26", "wps": "3081.9", "ups": "0.71", "wpb": "4310.7", "bsz": "32", "num_updates": "35200", "lr": "4.82641e-05", "gnorm": "0.983", "train_wall": "139", "wall": "140280"}
2022-11-13 14:38:30 | INFO | train_inner | {"epoch": 22, "update": 21.577, "loss": "2.228", "nll_loss": "0.344", "ppl": "1.27", "wps": "3103", "ups": "0.7", "wpb": "4422.9", "bsz": "32", "num_updates": "35300", "lr": "4.82591e-05", "gnorm": "0.987", "train_wall": "142", "wall": "140422"}
2022-11-13 14:40:52 | INFO | train_inner | {"epoch": 22, "update": 21.638, "loss": "2.226", "nll_loss": "0.342", "ppl": "1.27", "wps": "3103.1", "ups": "0.71", "wpb": "4400.4", "bsz": "32", "num_updates": "35400", "lr": "4.82541e-05", "gnorm": "0.996", "train_wall": "141", "wall": "140564"}
2022-11-13 14:43:09 | INFO | train_inner | {"epoch": 22, "update": 21.699, "loss": "2.219", "nll_loss": "0.335", "ppl": "1.26", "wps": "3072.2", "ups": "0.73", "wpb": "4205.6", "bsz": "32", "num_updates": "35500", "lr": "4.82491e-05", "gnorm": "1.008", "train_wall": "136", "wall": "140701"}
2022-11-13 14:45:30 | INFO | train_inner | {"epoch": 22, "update": 21.76, "loss": "2.228", "nll_loss": "0.345", "ppl": "1.27", "wps": "3086.5", "ups": "0.71", "wpb": "4361.1", "bsz": "32", "num_updates": "35600", "lr": "4.82441e-05", "gnorm": "1.027", "train_wall": "141", "wall": "140842"}
2022-11-13 14:47:51 | INFO | train_inner | {"epoch": 22, "update": 21.822, "loss": "2.221", "nll_loss": "0.337", "ppl": "1.26", "wps": "3106.8", "ups": "0.71", "wpb": "4364.9", "bsz": "32", "num_updates": "35700", "lr": "4.82391e-05", "gnorm": "1.004", "train_wall": "140", "wall": "140983"}
2022-11-13 14:50:13 | INFO | train_inner | {"epoch": 22, "update": 21.883, "loss": "2.233", "nll_loss": "0.351", "ppl": "1.28", "wps": "3112.2", "ups": "0.7", "wpb": "4439.1", "bsz": "32", "num_updates": "35800", "lr": "4.82341e-05", "gnorm": "0.998", "train_wall": "142", "wall": "141126"}
2022-11-13 14:52:32 | INFO | train_inner | {"epoch": 22, "update": 21.944, "loss": "2.223", "nll_loss": "0.339", "ppl": "1.26", "wps": "3099.5", "ups": "0.72", "wpb": "4295.1", "bsz": "32", "num_updates": "35900", "lr": "4.82291e-05", "gnorm": "1", "train_wall": "138", "wall": "141264"}
2022-11-13 14:54:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 16:02:04 | INFO | valid | {"epoch": 22, "valid_loss": "2.625", "valid_nll_loss": "0.738", "valid_ppl": "1.67", "valid_bleu": "68.21", "valid_wps": "220.5", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "35992", "valid_best_bleu": "68.49"}
2022-11-13 16:02:04 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 16:02:26 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_last.pt (epoch 22 @ 35992 updates, score 68.21) (writing took 22.15799668384716 seconds)
2022-11-13 16:02:26 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-11-13 16:02:26 | INFO | train | {"epoch": 22, "train_loss": "2.22", "train_nll_loss": "0.336", "train_ppl": "1.26", "train_wps": "1116.4", "train_ups": "0.26", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "35992", "train_lr": "4.82245e-05", "train_gnorm": "0.992", "train_train_wall": "2279", "train_wall": "145458"}
2022-11-13 16:02:26 | INFO | fairseq.trainer | begin training epoch 23
2022-11-13 16:02:37 | INFO | train_inner | {"epoch": 23, "update": 22.005, "loss": "2.221", "nll_loss": "0.337", "ppl": "1.26", "wps": "102.1", "ups": "0.02", "wpb": "4295.1", "bsz": "31.7", "num_updates": "36000", "lr": "4.82241e-05", "gnorm": "1.025", "train_wall": "139", "wall": "145469"}
2022-11-13 16:04:56 | INFO | train_inner | {"epoch": 23, "update": 22.066, "loss": "2.198", "nll_loss": "0.311", "ppl": "1.24", "wps": "3142", "ups": "0.72", "wpb": "4378.7", "bsz": "32", "num_updates": "36100", "lr": "4.82191e-05", "gnorm": "0.946", "train_wall": "139", "wall": "145608"}
2022-11-13 16:07:14 | INFO | train_inner | {"epoch": 23, "update": 22.127, "loss": "2.208", "nll_loss": "0.323", "ppl": "1.25", "wps": "3138.1", "ups": "0.72", "wpb": "4329", "bsz": "32", "num_updates": "36200", "lr": "4.82141e-05", "gnorm": "0.96", "train_wall": "138", "wall": "145746"}
2022-11-13 16:09:33 | INFO | train_inner | {"epoch": 23, "update": 22.188, "loss": "2.205", "nll_loss": "0.319", "ppl": "1.25", "wps": "3104", "ups": "0.72", "wpb": "4306.6", "bsz": "32", "num_updates": "36300", "lr": "4.82091e-05", "gnorm": "0.965", "train_wall": "138", "wall": "145885"}
2022-11-13 16:11:52 | INFO | train_inner | {"epoch": 23, "update": 22.249, "loss": "2.202", "nll_loss": "0.315", "ppl": "1.24", "wps": "3089.6", "ups": "0.72", "wpb": "4298.9", "bsz": "32", "num_updates": "36400", "lr": "4.82041e-05", "gnorm": "0.968", "train_wall": "139", "wall": "146024"}
2022-11-13 16:14:15 | INFO | train_inner | {"epoch": 23, "update": 22.311, "loss": "2.201", "nll_loss": "0.315", "ppl": "1.24", "wps": "3072.9", "ups": "0.7", "wpb": "4398.2", "bsz": "32", "num_updates": "36500", "lr": "4.81991e-05", "gnorm": "0.954", "train_wall": "143", "wall": "146167"}
2022-11-13 16:16:35 | INFO | train_inner | {"epoch": 23, "update": 22.372, "loss": "2.204", "nll_loss": "0.318", "ppl": "1.25", "wps": "3082", "ups": "0.71", "wpb": "4312.4", "bsz": "32", "num_updates": "36600", "lr": "4.81941e-05", "gnorm": "0.977", "train_wall": "139", "wall": "146307"}
2022-11-13 16:18:55 | INFO | train_inner | {"epoch": 23, "update": 22.433, "loss": "2.205", "nll_loss": "0.32", "ppl": "1.25", "wps": "3103.8", "ups": "0.71", "wpb": "4341.2", "bsz": "32", "num_updates": "36700", "lr": "4.81891e-05", "gnorm": "0.972", "train_wall": "139", "wall": "146447"}
2022-11-13 16:21:11 | INFO | train_inner | {"epoch": 23, "update": 22.494, "loss": "2.206", "nll_loss": "0.32", "ppl": "1.25", "wps": "3082.2", "ups": "0.74", "wpb": "4184.3", "bsz": "32", "num_updates": "36800", "lr": "4.81841e-05", "gnorm": "0.986", "train_wall": "135", "wall": "146583"}
2022-11-13 16:23:31 | INFO | train_inner | {"epoch": 23, "update": 22.555, "loss": "2.206", "nll_loss": "0.321", "ppl": "1.25", "wps": "3102.6", "ups": "0.71", "wpb": "4341.7", "bsz": "32", "num_updates": "36900", "lr": "4.81791e-05", "gnorm": "0.969", "train_wall": "139", "wall": "146723"}
2022-11-13 16:25:51 | INFO | train_inner | {"epoch": 23, "update": 22.616, "loss": "2.209", "nll_loss": "0.324", "ppl": "1.25", "wps": "3108.7", "ups": "0.71", "wpb": "4362.1", "bsz": "32", "num_updates": "37000", "lr": "4.81741e-05", "gnorm": "0.971", "train_wall": "140", "wall": "146863"}
2022-11-13 16:28:13 | INFO | train_inner | {"epoch": 23, "update": 22.677, "loss": "2.207", "nll_loss": "0.322", "ppl": "1.25", "wps": "3098.9", "ups": "0.71", "wpb": "4386.3", "bsz": "32", "num_updates": "37100", "lr": "4.81691e-05", "gnorm": "0.974", "train_wall": "141", "wall": "147005"}
2022-11-13 16:30:31 | INFO | train_inner | {"epoch": 23, "update": 22.738, "loss": "2.208", "nll_loss": "0.323", "ppl": "1.25", "wps": "3087.7", "ups": "0.72", "wpb": "4276.2", "bsz": "32", "num_updates": "37200", "lr": "4.81641e-05", "gnorm": "0.982", "train_wall": "138", "wall": "147143"}
2022-11-13 16:32:54 | INFO | train_inner | {"epoch": 23, "update": 22.8, "loss": "2.241", "nll_loss": "0.361", "ppl": "1.28", "wps": "3098.7", "ups": "0.7", "wpb": "4435.5", "bsz": "32", "num_updates": "37300", "lr": "4.81591e-05", "gnorm": "1.031", "train_wall": "143", "wall": "147286"}
2022-11-13 16:35:13 | INFO | train_inner | {"epoch": 23, "update": 22.861, "loss": "2.215", "nll_loss": "0.331", "ppl": "1.26", "wps": "3083.3", "ups": "0.72", "wpb": "4273.7", "bsz": "32", "num_updates": "37400", "lr": "4.81541e-05", "gnorm": "0.987", "train_wall": "138", "wall": "147425"}
2022-11-13 16:37:35 | INFO | train_inner | {"epoch": 23, "update": 22.922, "loss": "2.21", "nll_loss": "0.325", "ppl": "1.25", "wps": "3087.6", "ups": "0.7", "wpb": "4400", "bsz": "32", "num_updates": "37500", "lr": "4.81491e-05", "gnorm": "0.973", "train_wall": "142", "wall": "147568"}
2022-11-13 16:39:58 | INFO | train_inner | {"epoch": 23, "update": 22.983, "loss": "2.21", "nll_loss": "0.326", "ppl": "1.25", "wps": "3098.9", "ups": "0.7", "wpb": "4416.6", "bsz": "32", "num_updates": "37600", "lr": "4.81441e-05", "gnorm": "0.976", "train_wall": "142", "wall": "147710"}
2022-11-13 16:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 17:47:45 | INFO | valid | {"epoch": 23, "valid_loss": "2.625", "valid_nll_loss": "0.734", "valid_ppl": "1.66", "valid_bleu": "68.65", "valid_wps": "221.2", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "37628", "valid_best_bleu": "68.65"}
2022-11-13 17:47:45 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 17:48:22 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 23 @ 37628 updates, score 68.65) (writing took 37.282444125041366 seconds)
2022-11-13 17:48:22 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-11-13 17:48:22 | INFO | train | {"epoch": 23, "train_loss": "2.208", "train_nll_loss": "0.323", "train_ppl": "1.25", "train_wps": "1115.9", "train_ups": "0.26", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "37628", "train_lr": "4.81427e-05", "train_gnorm": "0.976", "train_train_wall": "2281", "train_wall": "151814"}
2022-11-13 17:48:22 | INFO | fairseq.trainer | begin training epoch 24
2022-11-13 17:50:03 | INFO | train_inner | {"epoch": 24, "update": 23.044, "loss": "2.194", "nll_loss": "0.307", "ppl": "1.24", "wps": "103.6", "ups": "0.02", "wpb": "4354.4", "bsz": "31.7", "num_updates": "37700", "lr": "4.81391e-05", "gnorm": "0.967", "train_wall": "137", "wall": "151915"}
2022-11-13 17:52:21 | INFO | train_inner | {"epoch": 24, "update": 23.105, "loss": "2.195", "nll_loss": "0.308", "ppl": "1.24", "wps": "3147.4", "ups": "0.72", "wpb": "4351.4", "bsz": "32", "num_updates": "37800", "lr": "4.81341e-05", "gnorm": "0.936", "train_wall": "138", "wall": "152053"}
2022-11-13 17:54:38 | INFO | train_inner | {"epoch": 24, "update": 23.166, "loss": "2.196", "nll_loss": "0.309", "ppl": "1.24", "wps": "3094.4", "ups": "0.73", "wpb": "4246.3", "bsz": "32", "num_updates": "37900", "lr": "4.81291e-05", "gnorm": "0.958", "train_wall": "137", "wall": "152191"}
2022-11-13 17:56:58 | INFO | train_inner | {"epoch": 24, "update": 23.227, "loss": "2.192", "nll_loss": "0.306", "ppl": "1.24", "wps": "3114", "ups": "0.71", "wpb": "4357.6", "bsz": "32", "num_updates": "38000", "lr": "4.81241e-05", "gnorm": "0.952", "train_wall": "140", "wall": "152331"}
2022-11-13 17:59:17 | INFO | train_inner | {"epoch": 24, "update": 23.289, "loss": "2.192", "nll_loss": "0.306", "ppl": "1.24", "wps": "3106.3", "ups": "0.72", "wpb": "4323.8", "bsz": "32", "num_updates": "38100", "lr": "4.81191e-05", "gnorm": "0.951", "train_wall": "139", "wall": "152470"}
2022-11-13 18:01:39 | INFO | train_inner | {"epoch": 24, "update": 23.35, "loss": "2.206", "nll_loss": "0.321", "ppl": "1.25", "wps": "3071.1", "ups": "0.7", "wpb": "4361.4", "bsz": "32", "num_updates": "38200", "lr": "4.81141e-05", "gnorm": "0.967", "train_wall": "142", "wall": "152612"}
2022-11-13 18:03:59 | INFO | train_inner | {"epoch": 24, "update": 23.411, "loss": "2.193", "nll_loss": "0.307", "ppl": "1.24", "wps": "3063.3", "ups": "0.72", "wpb": "4272.9", "bsz": "32", "num_updates": "38300", "lr": "4.81091e-05", "gnorm": "0.961", "train_wall": "139", "wall": "152751"}
2022-11-13 18:06:18 | INFO | train_inner | {"epoch": 24, "update": 23.472, "loss": "2.193", "nll_loss": "0.306", "ppl": "1.24", "wps": "3091.4", "ups": "0.72", "wpb": "4297.4", "bsz": "32", "num_updates": "38400", "lr": "4.81041e-05", "gnorm": "0.955", "train_wall": "139", "wall": "152890"}
2022-11-13 18:08:39 | INFO | train_inner | {"epoch": 24, "update": 23.533, "loss": "2.208", "nll_loss": "0.324", "ppl": "1.25", "wps": "3091.8", "ups": "0.71", "wpb": "4347", "bsz": "32", "num_updates": "38500", "lr": "4.8099e-05", "gnorm": "0.974", "train_wall": "140", "wall": "153031"}
2022-11-13 18:10:58 | INFO | train_inner | {"epoch": 24, "update": 23.594, "loss": "2.189", "nll_loss": "0.302", "ppl": "1.23", "wps": "3117.1", "ups": "0.72", "wpb": "4338.8", "bsz": "32", "num_updates": "38600", "lr": "4.8094e-05", "gnorm": "0.934", "train_wall": "139", "wall": "153170"}
2022-11-13 18:13:18 | INFO | train_inner | {"epoch": 24, "update": 23.655, "loss": "2.199", "nll_loss": "0.313", "ppl": "1.24", "wps": "3087.6", "ups": "0.71", "wpb": "4322.1", "bsz": "32", "num_updates": "38700", "lr": "4.8089e-05", "gnorm": "0.954", "train_wall": "140", "wall": "153310"}
2022-11-13 18:15:39 | INFO | train_inner | {"epoch": 24, "update": 23.716, "loss": "2.196", "nll_loss": "0.31", "ppl": "1.24", "wps": "3085.3", "ups": "0.71", "wpb": "4367.9", "bsz": "32", "num_updates": "38800", "lr": "4.8084e-05", "gnorm": "0.956", "train_wall": "141", "wall": "153452"}
2022-11-13 18:18:01 | INFO | train_inner | {"epoch": 24, "update": 23.778, "loss": "2.212", "nll_loss": "0.328", "ppl": "1.26", "wps": "3074.9", "ups": "0.7", "wpb": "4365.9", "bsz": "32", "num_updates": "38900", "lr": "4.8079e-05", "gnorm": "1.011", "train_wall": "141", "wall": "153594"}
2022-11-13 18:20:24 | INFO | train_inner | {"epoch": 24, "update": 23.839, "loss": "2.205", "nll_loss": "0.32", "ppl": "1.25", "wps": "3110.3", "ups": "0.7", "wpb": "4424.8", "bsz": "32", "num_updates": "39000", "lr": "4.8074e-05", "gnorm": "0.964", "train_wall": "142", "wall": "153736"}
2022-11-13 18:22:42 | INFO | train_inner | {"epoch": 24, "update": 23.9, "loss": "2.205", "nll_loss": "0.321", "ppl": "1.25", "wps": "3088.9", "ups": "0.72", "wpb": "4290.4", "bsz": "32", "num_updates": "39100", "lr": "4.8069e-05", "gnorm": "0.976", "train_wall": "138", "wall": "153875"}
2022-11-13 18:25:01 | INFO | train_inner | {"epoch": 24, "update": 23.961, "loss": "2.194", "nll_loss": "0.309", "ppl": "1.24", "wps": "3101.4", "ups": "0.72", "wpb": "4307.4", "bsz": "32", "num_updates": "39200", "lr": "4.8064e-05", "gnorm": "0.951", "train_wall": "138", "wall": "154014"}
2022-11-13 18:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 19:34:24 | INFO | valid | {"epoch": 24, "valid_loss": "2.626", "valid_nll_loss": "0.737", "valid_ppl": "1.67", "valid_bleu": "68.15", "valid_wps": "218.8", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "39264", "valid_best_bleu": "68.65"}
2022-11-13 19:34:24 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 19:34:47 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_last.pt (epoch 24 @ 39264 updates, score 68.15) (writing took 22.611047158017755 seconds)
2022-11-13 19:34:47 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-11-13 19:34:47 | INFO | train | {"epoch": 24, "train_loss": "2.198", "train_nll_loss": "0.312", "train_ppl": "1.24", "train_wps": "1110.9", "train_ups": "0.26", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "39264", "train_lr": "4.80608e-05", "train_gnorm": "0.96", "train_train_wall": "2280", "train_wall": "158199"}
2022-11-13 19:34:47 | INFO | fairseq.trainer | begin training epoch 25
2022-11-13 19:35:35 | INFO | train_inner | {"epoch": 25, "update": 24.022, "loss": "2.198", "nll_loss": "0.313", "ppl": "1.24", "wps": "101", "ups": "0.02", "wpb": "4277.4", "bsz": "31.7", "num_updates": "39300", "lr": "4.8059e-05", "gnorm": "0.984", "train_wall": "136", "wall": "158247"}
2022-11-13 19:37:53 | INFO | train_inner | {"epoch": 25, "update": 24.083, "loss": "2.172", "nll_loss": "0.283", "ppl": "1.22", "wps": "3110.3", "ups": "0.73", "wpb": "4282.5", "bsz": "32", "num_updates": "39400", "lr": "4.8054e-05", "gnorm": "0.914", "train_wall": "137", "wall": "158385"}
2022-11-13 19:40:12 | INFO | train_inner | {"epoch": 25, "update": 24.144, "loss": "2.194", "nll_loss": "0.308", "ppl": "1.24", "wps": "3117.9", "ups": "0.72", "wpb": "4324.2", "bsz": "32", "num_updates": "39500", "lr": "4.8049e-05", "gnorm": "0.972", "train_wall": "138", "wall": "158524"}
2022-11-13 19:42:31 | INFO | train_inner | {"epoch": 25, "update": 24.205, "loss": "2.188", "nll_loss": "0.301", "ppl": "1.23", "wps": "3086.6", "ups": "0.72", "wpb": "4306.8", "bsz": "32", "num_updates": "39600", "lr": "4.8044e-05", "gnorm": "0.945", "train_wall": "139", "wall": "158663"}
2022-11-13 19:44:54 | INFO | train_inner | {"epoch": 25, "update": 24.267, "loss": "2.182", "nll_loss": "0.294", "ppl": "1.23", "wps": "3101.7", "ups": "0.7", "wpb": "4416.6", "bsz": "32", "num_updates": "39700", "lr": "4.8039e-05", "gnorm": "0.937", "train_wall": "142", "wall": "158806"}
2022-11-13 19:47:14 | INFO | train_inner | {"epoch": 25, "update": 24.328, "loss": "2.184", "nll_loss": "0.297", "ppl": "1.23", "wps": "3097.2", "ups": "0.71", "wpb": "4350.4", "bsz": "32", "num_updates": "39800", "lr": "4.8034e-05", "gnorm": "0.944", "train_wall": "140", "wall": "158946"}
2022-11-13 19:49:32 | INFO | train_inner | {"epoch": 25, "update": 24.389, "loss": "2.183", "nll_loss": "0.296", "ppl": "1.23", "wps": "3066.2", "ups": "0.73", "wpb": "4217", "bsz": "32", "num_updates": "39900", "lr": "4.8029e-05", "gnorm": "0.94", "train_wall": "137", "wall": "159084"}
2022-11-13 19:51:54 | INFO | train_inner | {"epoch": 25, "update": 24.45, "loss": "2.182", "nll_loss": "0.295", "ppl": "1.23", "wps": "3101.4", "ups": "0.7", "wpb": "4418", "bsz": "32", "num_updates": "40000", "lr": "4.8024e-05", "gnorm": "0.935", "train_wall": "142", "wall": "159226"}
2022-11-13 19:54:13 | INFO | train_inner | {"epoch": 25, "update": 24.511, "loss": "2.201", "nll_loss": "0.316", "ppl": "1.24", "wps": "3082.2", "ups": "0.72", "wpb": "4284.4", "bsz": "32", "num_updates": "40100", "lr": "4.8019e-05", "gnorm": "0.965", "train_wall": "139", "wall": "159365"}
2022-11-13 19:56:32 | INFO | train_inner | {"epoch": 25, "update": 24.572, "loss": "2.185", "nll_loss": "0.298", "ppl": "1.23", "wps": "3077.6", "ups": "0.72", "wpb": "4266.2", "bsz": "32", "num_updates": "40200", "lr": "4.8014e-05", "gnorm": "0.938", "train_wall": "138", "wall": "159504"}
2022-11-13 19:58:53 | INFO | train_inner | {"epoch": 25, "update": 24.633, "loss": "2.186", "nll_loss": "0.3", "ppl": "1.23", "wps": "3088.3", "ups": "0.71", "wpb": "4357.1", "bsz": "32", "num_updates": "40300", "lr": "4.8009e-05", "gnorm": "0.939", "train_wall": "140", "wall": "159645"}
2022-11-13 20:01:16 | INFO | train_inner | {"epoch": 25, "update": 24.694, "loss": "2.207", "nll_loss": "0.323", "ppl": "1.25", "wps": "3104.4", "ups": "0.7", "wpb": "4434.1", "bsz": "32", "num_updates": "40400", "lr": "4.8004e-05", "gnorm": "0.987", "train_wall": "142", "wall": "159788"}
2022-11-13 20:03:38 | INFO | train_inner | {"epoch": 25, "update": 24.756, "loss": "2.188", "nll_loss": "0.302", "ppl": "1.23", "wps": "3090.1", "ups": "0.7", "wpb": "4387.5", "bsz": "32", "num_updates": "40500", "lr": "4.7999e-05", "gnorm": "0.953", "train_wall": "141", "wall": "159930"}
2022-11-13 20:05:56 | INFO | train_inner | {"epoch": 25, "update": 24.817, "loss": "2.191", "nll_loss": "0.305", "ppl": "1.24", "wps": "3089.5", "ups": "0.72", "wpb": "4275.1", "bsz": "32", "num_updates": "40600", "lr": "4.7994e-05", "gnorm": "0.972", "train_wall": "138", "wall": "160068"}
2022-11-13 20:08:19 | INFO | train_inner | {"epoch": 25, "update": 24.878, "loss": "2.195", "nll_loss": "0.309", "ppl": "1.24", "wps": "3106.1", "ups": "0.7", "wpb": "4431.9", "bsz": "32", "num_updates": "40700", "lr": "4.7989e-05", "gnorm": "0.959", "train_wall": "142", "wall": "160211"}
2022-11-13 20:10:39 | INFO | train_inner | {"epoch": 25, "update": 24.939, "loss": "2.19", "nll_loss": "0.304", "ppl": "1.23", "wps": "3084.5", "ups": "0.71", "wpb": "4320.6", "bsz": "32", "num_updates": "40800", "lr": "4.7984e-05", "gnorm": "0.972", "train_wall": "140", "wall": "160351"}
2022-11-13 20:12:58 | INFO | train_inner | {"epoch": 25, "update": 25.0, "loss": "2.189", "nll_loss": "0.303", "ppl": "1.23", "wps": "3097.9", "ups": "0.72", "wpb": "4327", "bsz": "31.7", "num_updates": "40900", "lr": "4.7979e-05", "gnorm": "0.977", "train_wall": "139", "wall": "160491"}
2022-11-13 20:12:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 21:22:09 | INFO | valid | {"epoch": 25, "valid_loss": "2.621", "valid_nll_loss": "0.726", "valid_ppl": "1.65", "valid_bleu": "68.89", "valid_wps": "214.8", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "40900", "valid_best_bleu": "68.89"}
2022-11-13 21:22:09 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 21:22:47 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 25 @ 40900 updates, score 68.89) (writing took 37.37679847003892 seconds)
2022-11-13 21:22:47 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-11-13 21:22:47 | INFO | train | {"epoch": 25, "train_loss": "2.189", "train_nll_loss": "0.302", "train_ppl": "1.23", "train_wps": "1094.6", "train_ups": "0.25", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "40900", "train_lr": "4.7979e-05", "train_gnorm": "0.953", "train_train_wall": "2281", "train_wall": "164679"}
2022-11-13 21:22:47 | INFO | fairseq.trainer | begin training epoch 26
2022-11-13 21:25:05 | INFO | train_inner | {"epoch": 26, "update": 25.061, "loss": "2.173", "nll_loss": "0.285", "ppl": "1.22", "wps": "100", "ups": "0.02", "wpb": "4326.2", "bsz": "32", "num_updates": "41000", "lr": "4.7974e-05", "gnorm": "0.9", "train_wall": "137", "wall": "164817"}
2022-11-13 21:27:23 | INFO | train_inner | {"epoch": 26, "update": 25.122, "loss": "2.169", "nll_loss": "0.28", "ppl": "1.21", "wps": "3123.1", "ups": "0.72", "wpb": "4325.2", "bsz": "32", "num_updates": "41100", "lr": "4.7969e-05", "gnorm": "0.903", "train_wall": "138", "wall": "164955"}
2022-11-13 21:29:44 | INFO | train_inner | {"epoch": 26, "update": 25.183, "loss": "2.173", "nll_loss": "0.285", "ppl": "1.22", "wps": "3093.7", "ups": "0.71", "wpb": "4370.9", "bsz": "32", "num_updates": "41200", "lr": "4.7964e-05", "gnorm": "0.915", "train_wall": "141", "wall": "165097"}
2022-11-13 21:32:06 | INFO | train_inner | {"epoch": 26, "update": 25.244, "loss": "2.194", "nll_loss": "0.309", "ppl": "1.24", "wps": "3089", "ups": "0.71", "wpb": "4361.7", "bsz": "32", "num_updates": "41300", "lr": "4.7959e-05", "gnorm": "0.965", "train_wall": "141", "wall": "165238"}
2022-11-13 21:34:26 | INFO | train_inner | {"epoch": 26, "update": 25.306, "loss": "2.173", "nll_loss": "0.285", "ppl": "1.22", "wps": "3071.4", "ups": "0.71", "wpb": "4304.3", "bsz": "32", "num_updates": "41400", "lr": "4.7954e-05", "gnorm": "0.932", "train_wall": "139", "wall": "165378"}
2022-11-13 21:36:45 | INFO | train_inner | {"epoch": 26, "update": 25.367, "loss": "2.173", "nll_loss": "0.285", "ppl": "1.22", "wps": "3098.8", "ups": "0.72", "wpb": "4328.4", "bsz": "32", "num_updates": "41500", "lr": "4.7949e-05", "gnorm": "0.917", "train_wall": "139", "wall": "165518"}
2022-11-13 21:39:07 | INFO | train_inner | {"epoch": 26, "update": 25.428, "loss": "2.18", "nll_loss": "0.294", "ppl": "1.23", "wps": "3079.2", "ups": "0.71", "wpb": "4360.4", "bsz": "32", "num_updates": "41600", "lr": "4.7944e-05", "gnorm": "0.924", "train_wall": "141", "wall": "165659"}
2022-11-13 21:41:27 | INFO | train_inner | {"epoch": 26, "update": 25.489, "loss": "2.174", "nll_loss": "0.287", "ppl": "1.22", "wps": "3088", "ups": "0.71", "wpb": "4334.1", "bsz": "32", "num_updates": "41700", "lr": "4.7939e-05", "gnorm": "0.918", "train_wall": "140", "wall": "165800"}
2022-11-13 21:43:47 | INFO | train_inner | {"epoch": 26, "update": 25.55, "loss": "2.179", "nll_loss": "0.292", "ppl": "1.22", "wps": "3099.7", "ups": "0.72", "wpb": "4335.3", "bsz": "32", "num_updates": "41800", "lr": "4.7934e-05", "gnorm": "0.942", "train_wall": "139", "wall": "165940"}
2022-11-13 21:46:05 | INFO | train_inner | {"epoch": 26, "update": 25.611, "loss": "2.176", "nll_loss": "0.289", "ppl": "1.22", "wps": "3078", "ups": "0.72", "wpb": "4246.7", "bsz": "32", "num_updates": "41900", "lr": "4.7929e-05", "gnorm": "0.947", "train_wall": "137", "wall": "166077"}
2022-11-13 21:48:26 | INFO | train_inner | {"epoch": 26, "update": 25.672, "loss": "2.181", "nll_loss": "0.294", "ppl": "1.23", "wps": "3093.8", "ups": "0.71", "wpb": "4340.9", "bsz": "32", "num_updates": "42000", "lr": "4.7924e-05", "gnorm": "0.928", "train_wall": "140", "wall": "166218"}
2022-11-13 21:50:46 | INFO | train_inner | {"epoch": 26, "update": 25.733, "loss": "2.181", "nll_loss": "0.295", "ppl": "1.23", "wps": "3077.9", "ups": "0.71", "wpb": "4336.2", "bsz": "32", "num_updates": "42100", "lr": "4.7919e-05", "gnorm": "0.932", "train_wall": "140", "wall": "166359"}
2022-11-13 21:53:06 | INFO | train_inner | {"epoch": 26, "update": 25.795, "loss": "2.194", "nll_loss": "0.31", "ppl": "1.24", "wps": "3096.1", "ups": "0.72", "wpb": "4309.8", "bsz": "32", "num_updates": "42200", "lr": "4.7914e-05", "gnorm": "0.955", "train_wall": "139", "wall": "166498"}
2022-11-13 21:55:28 | INFO | train_inner | {"epoch": 26, "update": 25.856, "loss": "2.182", "nll_loss": "0.295", "ppl": "1.23", "wps": "3097.4", "ups": "0.7", "wpb": "4401.9", "bsz": "32", "num_updates": "42300", "lr": "4.7909e-05", "gnorm": "0.934", "train_wall": "142", "wall": "166640"}
2022-11-13 21:57:51 | INFO | train_inner | {"epoch": 26, "update": 25.917, "loss": "2.192", "nll_loss": "0.307", "ppl": "1.24", "wps": "3073.8", "ups": "0.7", "wpb": "4403.4", "bsz": "32", "num_updates": "42400", "lr": "4.7904e-05", "gnorm": "0.945", "train_wall": "143", "wall": "166783"}
2022-11-13 22:00:10 | INFO | train_inner | {"epoch": 26, "update": 25.978, "loss": "2.179", "nll_loss": "0.292", "ppl": "1.22", "wps": "3088.1", "ups": "0.72", "wpb": "4298.8", "bsz": "32", "num_updates": "42500", "lr": "4.78989e-05", "gnorm": "0.951", "train_wall": "139", "wall": "166922"}
2022-11-13 22:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-13 23:08:35 | INFO | valid | {"epoch": 26, "valid_loss": "2.626", "valid_nll_loss": "0.733", "valid_ppl": "1.66", "valid_bleu": "69.51", "valid_wps": "219.8", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "42536", "valid_best_bleu": "69.51"}
2022-11-13 23:08:35 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-13 23:09:10 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 26 @ 42536 updates, score 69.51) (writing took 35.214059758000076 seconds)
2022-11-13 23:09:10 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-11-13 23:09:10 | INFO | train | {"epoch": 26, "train_loss": "2.18", "train_nll_loss": "0.293", "train_ppl": "1.23", "train_wps": "1111.1", "train_ups": "0.26", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "42536", "train_lr": "4.78971e-05", "train_gnorm": "0.933", "train_train_wall": "2283", "train_wall": "171062"}
2022-11-13 23:09:10 | INFO | fairseq.trainer | begin training epoch 27
2022-11-13 23:10:39 | INFO | train_inner | {"epoch": 27, "update": 26.039, "loss": "2.174", "nll_loss": "0.287", "ppl": "1.22", "wps": "102", "ups": "0.02", "wpb": "4315", "bsz": "31.7", "num_updates": "42600", "lr": "4.78939e-05", "gnorm": "0.954", "train_wall": "137", "wall": "171151"}
2022-11-13 23:12:56 | INFO | train_inner | {"epoch": 27, "update": 26.1, "loss": "2.165", "nll_loss": "0.277", "ppl": "1.21", "wps": "3126.5", "ups": "0.73", "wpb": "4301.4", "bsz": "32", "num_updates": "42700", "lr": "4.78889e-05", "gnorm": "0.909", "train_wall": "137", "wall": "171289"}
2022-11-13 23:15:19 | INFO | train_inner | {"epoch": 27, "update": 26.161, "loss": "2.173", "nll_loss": "0.286", "ppl": "1.22", "wps": "3117.5", "ups": "0.7", "wpb": "4432.1", "bsz": "32", "num_updates": "42800", "lr": "4.78839e-05", "gnorm": "0.9", "train_wall": "142", "wall": "171431"}
2022-11-13 23:17:42 | INFO | train_inner | {"epoch": 27, "update": 26.222, "loss": "2.179", "nll_loss": "0.292", "ppl": "1.22", "wps": "3099.5", "ups": "0.7", "wpb": "4430.3", "bsz": "32", "num_updates": "42900", "lr": "4.78789e-05", "gnorm": "0.933", "train_wall": "142", "wall": "171574"}
2022-11-13 23:20:03 | INFO | train_inner | {"epoch": 27, "update": 26.284, "loss": "2.168", "nll_loss": "0.28", "ppl": "1.21", "wps": "3088.9", "ups": "0.71", "wpb": "4369.8", "bsz": "32", "num_updates": "43000", "lr": "4.78739e-05", "gnorm": "0.942", "train_wall": "141", "wall": "171715"}
2022-11-13 23:22:25 | INFO | train_inner | {"epoch": 27, "update": 26.345, "loss": "2.183", "nll_loss": "0.298", "ppl": "1.23", "wps": "3034.6", "ups": "0.71", "wpb": "4302.7", "bsz": "32", "num_updates": "43100", "lr": "4.78689e-05", "gnorm": "0.961", "train_wall": "141", "wall": "171857"}
2022-11-13 23:24:45 | INFO | train_inner | {"epoch": 27, "update": 26.406, "loss": "2.169", "nll_loss": "0.282", "ppl": "1.22", "wps": "3055.5", "ups": "0.72", "wpb": "4268.1", "bsz": "32", "num_updates": "43200", "lr": "4.78639e-05", "gnorm": "0.93", "train_wall": "139", "wall": "171997"}
2022-11-13 23:27:06 | INFO | train_inner | {"epoch": 27, "update": 26.467, "loss": "2.166", "nll_loss": "0.279", "ppl": "1.21", "wps": "3102.4", "ups": "0.7", "wpb": "4401.6", "bsz": "32", "num_updates": "43300", "lr": "4.78589e-05", "gnorm": "0.898", "train_wall": "141", "wall": "172139"}
2022-11-13 23:29:28 | INFO | train_inner | {"epoch": 27, "update": 26.528, "loss": "2.168", "nll_loss": "0.28", "ppl": "1.21", "wps": "3086", "ups": "0.71", "wpb": "4377.1", "bsz": "32", "num_updates": "43400", "lr": "4.78539e-05", "gnorm": "0.928", "train_wall": "141", "wall": "172280"}
2022-11-13 23:31:48 | INFO | train_inner | {"epoch": 27, "update": 26.589, "loss": "2.17", "nll_loss": "0.283", "ppl": "1.22", "wps": "3079.7", "ups": "0.71", "wpb": "4313.3", "bsz": "32", "num_updates": "43500", "lr": "4.78489e-05", "gnorm": "0.922", "train_wall": "140", "wall": "172421"}
2022-11-13 23:34:08 | INFO | train_inner | {"epoch": 27, "update": 26.65, "loss": "2.168", "nll_loss": "0.281", "ppl": "1.21", "wps": "3088", "ups": "0.71", "wpb": "4319.2", "bsz": "32", "num_updates": "43600", "lr": "4.78439e-05", "gnorm": "0.931", "train_wall": "139", "wall": "172560"}
2022-11-13 23:36:28 | INFO | train_inner | {"epoch": 27, "update": 26.711, "loss": "2.173", "nll_loss": "0.286", "ppl": "1.22", "wps": "3091.5", "ups": "0.71", "wpb": "4338.2", "bsz": "32", "num_updates": "43700", "lr": "4.78389e-05", "gnorm": "0.942", "train_wall": "140", "wall": "172701"}
2022-11-13 23:38:48 | INFO | train_inner | {"epoch": 27, "update": 26.773, "loss": "2.172", "nll_loss": "0.285", "ppl": "1.22", "wps": "3092.9", "ups": "0.72", "wpb": "4307.7", "bsz": "32", "num_updates": "43800", "lr": "4.78339e-05", "gnorm": "0.945", "train_wall": "139", "wall": "172840"}
2022-11-13 23:41:10 | INFO | train_inner | {"epoch": 27, "update": 26.834, "loss": "2.183", "nll_loss": "0.297", "ppl": "1.23", "wps": "3091.5", "ups": "0.7", "wpb": "4396.4", "bsz": "32", "num_updates": "43900", "lr": "4.78289e-05", "gnorm": "0.968", "train_wall": "141", "wall": "172982"}
2022-11-13 23:43:27 | INFO | train_inner | {"epoch": 27, "update": 26.895, "loss": "2.173", "nll_loss": "0.286", "ppl": "1.22", "wps": "3086.8", "ups": "0.73", "wpb": "4241.1", "bsz": "32", "num_updates": "44000", "lr": "4.78239e-05", "gnorm": "0.942", "train_wall": "137", "wall": "173120"}
2022-11-13 23:45:48 | INFO | train_inner | {"epoch": 27, "update": 26.956, "loss": "2.181", "nll_loss": "0.296", "ppl": "1.23", "wps": "3092.8", "ups": "0.71", "wpb": "4333.9", "bsz": "32", "num_updates": "44100", "lr": "4.78189e-05", "gnorm": "0.948", "train_wall": "140", "wall": "173260"}
2022-11-13 23:47:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-14 00:55:53 | INFO | valid | {"epoch": 27, "valid_loss": "2.63", "valid_nll_loss": "0.735", "valid_ppl": "1.66", "valid_bleu": "68.83", "valid_wps": "217.1", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "44172", "valid_best_bleu": "69.51"}
2022-11-14 00:55:53 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-14 00:56:15 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_last.pt (epoch 27 @ 44172 updates, score 68.83) (writing took 21.52261994406581 seconds)
2022-11-14 00:56:15 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-11-14 00:56:15 | INFO | train | {"epoch": 27, "train_loss": "2.173", "train_nll_loss": "0.286", "train_ppl": "1.22", "train_wps": "1104", "train_ups": "0.25", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "44172", "train_lr": "4.78153e-05", "train_gnorm": "0.935", "train_train_wall": "2286", "train_wall": "177487"}
2022-11-14 00:56:15 | INFO | fairseq.trainer | begin training epoch 28
2022-11-14 00:56:55 | INFO | train_inner | {"epoch": 28, "update": 27.017, "loss": "2.187", "nll_loss": "0.302", "ppl": "1.23", "wps": "100.1", "ups": "0.02", "wpb": "4272.6", "bsz": "31.7", "num_updates": "44200", "lr": "4.78139e-05", "gnorm": "0.972", "train_wall": "138", "wall": "177527"}
2022-11-14 00:59:12 | INFO | train_inner | {"epoch": 28, "update": 27.078, "loss": "2.156", "nll_loss": "0.267", "ppl": "1.2", "wps": "3103.1", "ups": "0.73", "wpb": "4244.4", "bsz": "32", "num_updates": "44300", "lr": "4.78089e-05", "gnorm": "0.907", "train_wall": "136", "wall": "177664"}
2022-11-14 01:01:32 | INFO | train_inner | {"epoch": 28, "update": 27.139, "loss": "2.155", "nll_loss": "0.266", "ppl": "1.2", "wps": "3120.4", "ups": "0.71", "wpb": "4378.6", "bsz": "32", "num_updates": "44400", "lr": "4.78039e-05", "gnorm": "0.872", "train_wall": "140", "wall": "177804"}
2022-11-14 01:03:54 | INFO | train_inner | {"epoch": 28, "update": 27.2, "loss": "2.162", "nll_loss": "0.275", "ppl": "1.21", "wps": "3106.2", "ups": "0.71", "wpb": "4401.8", "bsz": "32", "num_updates": "44500", "lr": "4.77989e-05", "gnorm": "0.917", "train_wall": "141", "wall": "177946"}
2022-11-14 01:06:16 | INFO | train_inner | {"epoch": 28, "update": 27.262, "loss": "2.17", "nll_loss": "0.283", "ppl": "1.22", "wps": "3110", "ups": "0.7", "wpb": "4418.8", "bsz": "32", "num_updates": "44600", "lr": "4.77939e-05", "gnorm": "0.917", "train_wall": "141", "wall": "178088"}
2022-11-14 01:08:37 | INFO | train_inner | {"epoch": 28, "update": 27.323, "loss": "2.178", "nll_loss": "0.292", "ppl": "1.22", "wps": "3093.9", "ups": "0.71", "wpb": "4378.1", "bsz": "32", "num_updates": "44700", "lr": "4.77889e-05", "gnorm": "0.954", "train_wall": "141", "wall": "178230"}
2022-11-14 01:11:00 | INFO | train_inner | {"epoch": 28, "update": 27.384, "loss": "2.16", "nll_loss": "0.272", "ppl": "1.21", "wps": "3058.5", "ups": "0.7", "wpb": "4368.2", "bsz": "32", "num_updates": "44800", "lr": "4.77839e-05", "gnorm": "0.908", "train_wall": "142", "wall": "178372"}
2022-11-14 01:13:24 | INFO | train_inner | {"epoch": 28, "update": 27.445, "loss": "2.157", "nll_loss": "0.269", "ppl": "1.2", "wps": "3035.8", "ups": "0.7", "wpb": "4360.1", "bsz": "32", "num_updates": "44900", "lr": "4.77789e-05", "gnorm": "0.884", "train_wall": "143", "wall": "178516"}
2022-11-14 01:15:48 | INFO | train_inner | {"epoch": 28, "update": 27.506, "loss": "2.169", "nll_loss": "0.282", "ppl": "1.22", "wps": "3043.6", "ups": "0.69", "wpb": "4381.4", "bsz": "32", "num_updates": "45000", "lr": "4.77739e-05", "gnorm": "0.92", "train_wall": "143", "wall": "178660"}
2022-11-14 01:18:10 | INFO | train_inner | {"epoch": 28, "update": 27.567, "loss": "2.163", "nll_loss": "0.275", "ppl": "1.21", "wps": "3079.5", "ups": "0.7", "wpb": "4370.1", "bsz": "32", "num_updates": "45100", "lr": "4.77689e-05", "gnorm": "0.905", "train_wall": "141", "wall": "178802"}
2022-11-14 01:20:28 | INFO | train_inner | {"epoch": 28, "update": 27.628, "loss": "2.165", "nll_loss": "0.278", "ppl": "1.21", "wps": "3075.5", "ups": "0.72", "wpb": "4264.1", "bsz": "32", "num_updates": "45200", "lr": "4.77639e-05", "gnorm": "0.939", "train_wall": "138", "wall": "178941"}
2022-11-14 01:22:49 | INFO | train_inner | {"epoch": 28, "update": 27.689, "loss": "2.166", "nll_loss": "0.279", "ppl": "1.21", "wps": "3060.2", "ups": "0.71", "wpb": "4304.9", "bsz": "32", "num_updates": "45300", "lr": "4.77589e-05", "gnorm": "0.934", "train_wall": "140", "wall": "179081"}
2022-11-14 01:25:10 | INFO | train_inner | {"epoch": 28, "update": 27.751, "loss": "2.164", "nll_loss": "0.276", "ppl": "1.21", "wps": "3098.2", "ups": "0.71", "wpb": "4355.6", "bsz": "32", "num_updates": "45400", "lr": "4.77539e-05", "gnorm": "0.923", "train_wall": "140", "wall": "179222"}
2022-11-14 01:27:28 | INFO | train_inner | {"epoch": 28, "update": 27.812, "loss": "2.174", "nll_loss": "0.288", "ppl": "1.22", "wps": "3089.7", "ups": "0.72", "wpb": "4271.5", "bsz": "32", "num_updates": "45500", "lr": "4.77489e-05", "gnorm": "0.955", "train_wall": "138", "wall": "179360"}
2022-11-14 01:29:50 | INFO | train_inner | {"epoch": 28, "update": 27.873, "loss": "2.174", "nll_loss": "0.289", "ppl": "1.22", "wps": "3088.3", "ups": "0.71", "wpb": "4375.7", "bsz": "32", "num_updates": "45600", "lr": "4.77439e-05", "gnorm": "0.926", "train_wall": "141", "wall": "179502"}
2022-11-14 01:32:07 | INFO | train_inner | {"epoch": 28, "update": 27.934, "loss": "2.169", "nll_loss": "0.283", "ppl": "1.22", "wps": "3068.7", "ups": "0.73", "wpb": "4214.2", "bsz": "32", "num_updates": "45700", "lr": "4.77389e-05", "gnorm": "0.952", "train_wall": "137", "wall": "179639"}
2022-11-14 01:34:25 | INFO | train_inner | {"epoch": 28, "update": 27.995, "loss": "2.164", "nll_loss": "0.276", "ppl": "1.21", "wps": "3083.8", "ups": "0.72", "wpb": "4261.8", "bsz": "32", "num_updates": "45800", "lr": "4.77339e-05", "gnorm": "0.92", "train_wall": "137", "wall": "179777"}
2022-11-14 01:34:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-14 02:50:31 | INFO | valid | {"epoch": 28, "valid_loss": "2.619", "valid_nll_loss": "0.727", "valid_ppl": "1.66", "valid_bleu": "69.38", "valid_wps": "195.7", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "45808", "valid_best_bleu": "69.51"}
2022-11-14 02:50:31 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-14 02:50:55 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_last.pt (epoch 28 @ 45808 updates, score 69.38) (writing took 23.633804835844785 seconds)
2022-11-14 02:50:55 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-11-14 02:50:55 | INFO | train | {"epoch": 28, "train_loss": "2.166", "train_nll_loss": "0.279", "train_ppl": "1.21", "train_wps": "1030.9", "train_ups": "0.24", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "45808", "train_lr": "4.77335e-05", "train_gnorm": "0.922", "train_train_wall": "2291", "train_wall": "184367"}
2022-11-14 02:50:55 | INFO | fairseq.trainer | begin training epoch 29
2022-11-14 02:53:00 | INFO | train_inner | {"epoch": 29, "update": 28.056, "loss": "2.155", "nll_loss": "0.266", "ppl": "1.2", "wps": "90.5", "ups": "0.02", "wpb": "4269.4", "bsz": "31.7", "num_updates": "45900", "lr": "4.77289e-05", "gnorm": "0.89", "train_wall": "135", "wall": "184493"}
2022-11-14 02:55:21 | INFO | train_inner | {"epoch": 29, "update": 28.117, "loss": "2.161", "nll_loss": "0.274", "ppl": "1.21", "wps": "3127.1", "ups": "0.71", "wpb": "4401.7", "bsz": "32", "num_updates": "46000", "lr": "4.77239e-05", "gnorm": "0.875", "train_wall": "140", "wall": "184633"}
2022-11-14 02:57:41 | INFO | train_inner | {"epoch": 29, "update": 28.178, "loss": "2.165", "nll_loss": "0.278", "ppl": "1.21", "wps": "3115.4", "ups": "0.72", "wpb": "4353.4", "bsz": "32", "num_updates": "46100", "lr": "4.77189e-05", "gnorm": "0.914", "train_wall": "139", "wall": "184773"}
2022-11-14 03:00:00 | INFO | train_inner | {"epoch": 29, "update": 28.24, "loss": "2.153", "nll_loss": "0.265", "ppl": "1.2", "wps": "3085", "ups": "0.72", "wpb": "4291.6", "bsz": "32", "num_updates": "46200", "lr": "4.77139e-05", "gnorm": "0.88", "train_wall": "139", "wall": "184912"}
2022-11-14 03:02:21 | INFO | train_inner | {"epoch": 29, "update": 28.301, "loss": "2.161", "nll_loss": "0.274", "ppl": "1.21", "wps": "3087.8", "ups": "0.71", "wpb": "4360.3", "bsz": "32", "num_updates": "46300", "lr": "4.77089e-05", "gnorm": "0.9", "train_wall": "141", "wall": "185053"}
2022-11-14 03:04:42 | INFO | train_inner | {"epoch": 29, "update": 28.362, "loss": "2.154", "nll_loss": "0.266", "ppl": "1.2", "wps": "3089.7", "ups": "0.71", "wpb": "4338.4", "bsz": "32", "num_updates": "46400", "lr": "4.77039e-05", "gnorm": "0.886", "train_wall": "140", "wall": "185194"}
2022-11-14 03:07:02 | INFO | train_inner | {"epoch": 29, "update": 28.423, "loss": "2.156", "nll_loss": "0.268", "ppl": "1.2", "wps": "3090.2", "ups": "0.71", "wpb": "4343.3", "bsz": "32", "num_updates": "46500", "lr": "4.76988e-05", "gnorm": "0.898", "train_wall": "140", "wall": "185334"}
2022-11-14 03:09:23 | INFO | train_inner | {"epoch": 29, "update": 28.484, "loss": "2.16", "nll_loss": "0.273", "ppl": "1.21", "wps": "3093.1", "ups": "0.71", "wpb": "4350.3", "bsz": "32", "num_updates": "46600", "lr": "4.76938e-05", "gnorm": "0.909", "train_wall": "140", "wall": "185475"}
2022-11-14 03:11:42 | INFO | train_inner | {"epoch": 29, "update": 28.545, "loss": "2.153", "nll_loss": "0.265", "ppl": "1.2", "wps": "3073.2", "ups": "0.72", "wpb": "4293", "bsz": "32", "num_updates": "46700", "lr": "4.76888e-05", "gnorm": "0.908", "train_wall": "139", "wall": "185615"}
2022-11-14 03:14:03 | INFO | train_inner | {"epoch": 29, "update": 28.606, "loss": "2.158", "nll_loss": "0.271", "ppl": "1.21", "wps": "3090.5", "ups": "0.71", "wpb": "4350.8", "bsz": "32", "num_updates": "46800", "lr": "4.76838e-05", "gnorm": "0.929", "train_wall": "140", "wall": "185755"}
2022-11-14 03:16:24 | INFO | train_inner | {"epoch": 29, "update": 28.667, "loss": "2.177", "nll_loss": "0.292", "ppl": "1.22", "wps": "3090.4", "ups": "0.71", "wpb": "4353.5", "bsz": "32", "num_updates": "46900", "lr": "4.76788e-05", "gnorm": "0.945", "train_wall": "140", "wall": "185896"}
2022-11-14 03:18:45 | INFO | train_inner | {"epoch": 29, "update": 28.729, "loss": "2.163", "nll_loss": "0.276", "ppl": "1.21", "wps": "3080.6", "ups": "0.71", "wpb": "4333.9", "bsz": "32", "num_updates": "47000", "lr": "4.76738e-05", "gnorm": "0.916", "train_wall": "140", "wall": "186037"}
2022-11-14 03:21:06 | INFO | train_inner | {"epoch": 29, "update": 28.79, "loss": "2.158", "nll_loss": "0.27", "ppl": "1.21", "wps": "3083.1", "ups": "0.71", "wpb": "4363.8", "bsz": "32", "num_updates": "47100", "lr": "4.76688e-05", "gnorm": "0.909", "train_wall": "141", "wall": "186179"}
2022-11-14 03:23:28 | INFO | train_inner | {"epoch": 29, "update": 28.851, "loss": "2.16", "nll_loss": "0.272", "ppl": "1.21", "wps": "3036.6", "ups": "0.7", "wpb": "4316.4", "bsz": "32", "num_updates": "47200", "lr": "4.76638e-05", "gnorm": "0.921", "train_wall": "142", "wall": "186321"}
2022-11-14 03:25:50 | INFO | train_inner | {"epoch": 29, "update": 28.912, "loss": "2.159", "nll_loss": "0.272", "ppl": "1.21", "wps": "3094.1", "ups": "0.71", "wpb": "4383.4", "bsz": "32", "num_updates": "47300", "lr": "4.76588e-05", "gnorm": "0.909", "train_wall": "141", "wall": "186462"}
2022-11-14 03:28:10 | INFO | train_inner | {"epoch": 29, "update": 28.973, "loss": "2.16", "nll_loss": "0.272", "ppl": "1.21", "wps": "3077", "ups": "0.72", "wpb": "4290.9", "bsz": "32", "num_updates": "47400", "lr": "4.76538e-05", "gnorm": "0.907", "train_wall": "139", "wall": "186602"}
2022-11-14 03:29:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-14 04:38:29 | INFO | valid | {"epoch": 29, "valid_loss": "2.629", "valid_nll_loss": "0.744", "valid_ppl": "1.67", "valid_bleu": "69.87", "valid_wps": "214.4", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "47444", "valid_best_bleu": "69.87"}
2022-11-14 04:38:29 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-14 04:39:04 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_best.pt (epoch 29 @ 47444 updates, score 69.87) (writing took 35.27810726407915 seconds)
2022-11-14 04:39:04 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-11-14 04:39:04 | INFO | train | {"epoch": 29, "train_loss": "2.16", "train_nll_loss": "0.272", "train_ppl": "1.21", "train_wps": "1093", "train_ups": "0.25", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "47444", "train_lr": "4.76516e-05", "train_gnorm": "0.907", "train_train_wall": "2284", "train_wall": "190856"}
2022-11-14 04:39:04 | INFO | fairseq.trainer | begin training epoch 30
2022-11-14 04:40:22 | INFO | train_inner | {"epoch": 30, "update": 29.034, "loss": "2.168", "nll_loss": "0.283", "ppl": "1.22", "wps": "99.2", "ups": "0.02", "wpb": "4297.6", "bsz": "31.7", "num_updates": "47500", "lr": "4.76488e-05", "gnorm": "0.914", "train_wall": "137", "wall": "190934"}
2022-11-14 04:42:43 | INFO | train_inner | {"epoch": 30, "update": 29.095, "loss": "2.145", "nll_loss": "0.256", "ppl": "1.19", "wps": "3148.9", "ups": "0.71", "wpb": "4437.2", "bsz": "32", "num_updates": "47600", "lr": "4.76438e-05", "gnorm": "0.85", "train_wall": "140", "wall": "191075"}
2022-11-14 04:45:03 | INFO | train_inner | {"epoch": 30, "update": 29.156, "loss": "2.167", "nll_loss": "0.281", "ppl": "1.22", "wps": "3129.6", "ups": "0.71", "wpb": "4395.1", "bsz": "32", "num_updates": "47700", "lr": "4.76388e-05", "gnorm": "0.937", "train_wall": "140", "wall": "191215"}
2022-11-14 04:47:23 | INFO | train_inner | {"epoch": 30, "update": 29.218, "loss": "2.146", "nll_loss": "0.257", "ppl": "1.2", "wps": "3099.9", "ups": "0.71", "wpb": "4336.6", "bsz": "32", "num_updates": "47800", "lr": "4.76338e-05", "gnorm": "0.853", "train_wall": "139", "wall": "191355"}
2022-11-14 04:49:45 | INFO | train_inner | {"epoch": 30, "update": 29.279, "loss": "2.159", "nll_loss": "0.271", "ppl": "1.21", "wps": "3110.4", "ups": "0.71", "wpb": "4409.2", "bsz": "32", "num_updates": "47900", "lr": "4.76288e-05", "gnorm": "0.892", "train_wall": "141", "wall": "191497"}
2022-11-14 04:52:03 | INFO | train_inner | {"epoch": 30, "update": 29.34, "loss": "2.15", "nll_loss": "0.262", "ppl": "1.2", "wps": "3088.7", "ups": "0.72", "wpb": "4269.5", "bsz": "32", "num_updates": "48000", "lr": "4.76238e-05", "gnorm": "0.904", "train_wall": "138", "wall": "191635"}
2022-11-14 04:54:26 | INFO | train_inner | {"epoch": 30, "update": 29.401, "loss": "2.152", "nll_loss": "0.265", "ppl": "1.2", "wps": "3103.9", "ups": "0.7", "wpb": "4444.1", "bsz": "32", "num_updates": "48100", "lr": "4.76188e-05", "gnorm": "0.879", "train_wall": "143", "wall": "191778"}
2022-11-14 04:56:50 | INFO | train_inner | {"epoch": 30, "update": 29.462, "loss": "2.155", "nll_loss": "0.268", "ppl": "1.2", "wps": "3084.5", "ups": "0.69", "wpb": "4441.8", "bsz": "32", "num_updates": "48200", "lr": "4.76138e-05", "gnorm": "0.899", "train_wall": "143", "wall": "191922"}
2022-11-14 04:59:09 | INFO | train_inner | {"epoch": 30, "update": 29.523, "loss": "2.154", "nll_loss": "0.267", "ppl": "1.2", "wps": "3083.9", "ups": "0.72", "wpb": "4277.8", "bsz": "32", "num_updates": "48300", "lr": "4.76088e-05", "gnorm": "0.9", "train_wall": "138", "wall": "192061"}
2022-11-14 05:01:30 | INFO | train_inner | {"epoch": 30, "update": 29.584, "loss": "2.153", "nll_loss": "0.265", "ppl": "1.2", "wps": "3088.5", "ups": "0.71", "wpb": "4371.8", "bsz": "32", "num_updates": "48400", "lr": "4.76038e-05", "gnorm": "0.896", "train_wall": "141", "wall": "192203"}
2022-11-14 05:03:49 | INFO | train_inner | {"epoch": 30, "update": 29.645, "loss": "2.15", "nll_loss": "0.262", "ppl": "1.2", "wps": "3079.1", "ups": "0.72", "wpb": "4274.1", "bsz": "32", "num_updates": "48500", "lr": "4.75988e-05", "gnorm": "0.902", "train_wall": "138", "wall": "192341"}
2022-11-14 05:06:08 | INFO | train_inner | {"epoch": 30, "update": 29.707, "loss": "2.153", "nll_loss": "0.265", "ppl": "1.2", "wps": "3087.8", "ups": "0.72", "wpb": "4276.3", "bsz": "32", "num_updates": "48600", "lr": "4.75938e-05", "gnorm": "0.909", "train_wall": "138", "wall": "192480"}
2022-11-14 05:08:27 | INFO | train_inner | {"epoch": 30, "update": 29.768, "loss": "2.152", "nll_loss": "0.265", "ppl": "1.2", "wps": "3071.8", "ups": "0.72", "wpb": "4294.8", "bsz": "32", "num_updates": "48700", "lr": "4.75888e-05", "gnorm": "0.896", "train_wall": "139", "wall": "192620"}
2022-11-14 05:10:46 | INFO | train_inner | {"epoch": 30, "update": 29.829, "loss": "2.154", "nll_loss": "0.267", "ppl": "1.2", "wps": "3060.2", "ups": "0.72", "wpb": "4251.1", "bsz": "32", "num_updates": "48800", "lr": "4.75838e-05", "gnorm": "0.909", "train_wall": "138", "wall": "192759"}
2022-11-14 05:13:05 | INFO | train_inner | {"epoch": 30, "update": 29.89, "loss": "2.156", "nll_loss": "0.269", "ppl": "1.21", "wps": "3075.8", "ups": "0.72", "wpb": "4261.2", "bsz": "32", "num_updates": "48900", "lr": "4.75788e-05", "gnorm": "0.928", "train_wall": "138", "wall": "192897"}
2022-11-14 05:15:24 | INFO | train_inner | {"epoch": 30, "update": 29.951, "loss": "2.154", "nll_loss": "0.267", "ppl": "1.2", "wps": "3101.8", "ups": "0.72", "wpb": "4317.9", "bsz": "32", "num_updates": "49000", "lr": "4.75738e-05", "gnorm": "0.917", "train_wall": "139", "wall": "193036"}
2022-11-14 05:17:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-14 06:28:04 | INFO | valid | {"epoch": 30, "valid_loss": "2.632", "valid_nll_loss": "0.742", "valid_ppl": "1.67", "valid_bleu": "69.25", "valid_wps": "209.8", "valid_wpb": "544.9", "valid_bsz": "4", "valid_num_updates": "49080", "valid_best_bleu": "69.87"}
2022-11-14 06:28:04 | INFO | fairseq_cli.train | begin save checkpoint
2022-11-14 06:28:24 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/y_shi202/related-project/MODIT/models/WO-PLBART/medium.parent_code.child_full_code-large/checkpoint_last.pt (epoch 30 @ 49080 updates, score 69.25) (writing took 19.818032761104405 seconds)
2022-11-14 06:28:24 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-11-14 06:28:24 | INFO | train | {"epoch": 30, "train_loss": "2.154", "train_nll_loss": "0.267", "train_ppl": "1.2", "train_wps": "1081.2", "train_ups": "0.25", "train_wpb": "4335.3", "train_bsz": "32", "train_num_updates": "49080", "train_lr": "4.75698e-05", "train_gnorm": "0.898", "train_train_wall": "2281", "train_wall": "197416"}
2022-11-14 06:28:24 | INFO | fairseq_cli.train | done training in 197416.3 seconds
BLEU+case.mixed+numrefs.1+smooth.none+tok.none+version.1.5.1 = 71.2 87.2/76.5/67.6/60.0 (BP = 0.988 ratio = 0.988 hyp_len = 471198 ref_len = 477048)
BLEU: 71.22 ; Acc: 2.0
ngram match: 0.7122059604954443, weighted ngram match: 0.7162907078673602, syntax_match: 0.7969731941017523, dataflow_match: 0.7266756575989824
CodeBLEU score: 73.80
#############################################################################################
######## end ################
