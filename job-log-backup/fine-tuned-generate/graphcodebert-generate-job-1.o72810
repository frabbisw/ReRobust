######## start ##############
#############################################################################################
Experiment for graphcodebert-refactoring
=============================================================================================
on small dataset, before_refactoring, refactoring type is local_variable_renaming:
11/18/2022 13:31:06 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/local_variable_renaming/before_refactoring/small', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/before_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/before_refactoring/small/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/18/2022 13:31:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/18/2022 13:31:12 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin
11/18/2022 13:31:24 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/before_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/before_refactoring/small/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:22<02:36, 22.33s/it] 25%|██▌       | 2/8 [00:47<02:24, 24.15s/it] 38%|███▊      | 3/8 [01:10<01:58, 23.68s/it] 50%|█████     | 4/8 [01:34<01:35, 23.85s/it] 62%|██████▎   | 5/8 [02:00<01:13, 24.41s/it] 75%|███████▌  | 6/8 [02:24<00:48, 24.28s/it] 88%|████████▊ | 7/8 [02:46<00:23, 23.58s/it]100%|██████████| 8/8 [03:07<00:00, 22.59s/it]100%|██████████| 8/8 [03:07<00:00, 23.38s/it]
11/18/2022 13:34:32 - INFO - __main__ -     bleu-4 = 80.98 
11/18/2022 13:34:32 - INFO - __main__ -     xMatch = 13.9442 
11/18/2022 13:34:32 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 13.94 , BLEU: 80.98
CodeBLEU: 80.68
ngram_match_score: 80.68 , weighted_ngram_match_score: 82.35 , syntax_match_score: 82.68 , dataflow_match_score: 76.72
---------------------------------------------------------------------------------------------
on small dataset, after_refactoring, refactoring type is local_variable_renaming:
11/18/2022 13:34:35 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/local_variable_renaming/after_refactoring/small', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/after_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/after_refactoring/small/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/18/2022 13:34:35 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/18/2022 13:34:37 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin
11/18/2022 13:34:41 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/after_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/after_refactoring/small/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:22<02:38, 22.71s/it] 25%|██▌       | 2/8 [00:47<02:23, 23.88s/it] 38%|███▊      | 3/8 [01:10<01:57, 23.43s/it] 50%|█████     | 4/8 [01:34<01:34, 23.66s/it] 62%|██████▎   | 5/8 [01:59<01:12, 24.08s/it] 75%|███████▌  | 6/8 [02:23<00:48, 24.19s/it] 88%|████████▊ | 7/8 [02:45<00:23, 23.47s/it]100%|██████████| 8/8 [03:06<00:00, 22.58s/it]100%|██████████| 8/8 [03:06<00:00, 23.30s/it]
11/18/2022 13:37:50 - INFO - __main__ -     bleu-4 = 79.34 
11/18/2022 13:37:50 - INFO - __main__ -     xMatch = 11.9522 
11/18/2022 13:37:50 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 11.95 , BLEU: 79.34
CodeBLEU: 79.95
ngram_match_score: 79.95 , weighted_ngram_match_score: 82.46 , syntax_match_score: 82.8 , dataflow_match_score: 75.21
---------------------------------------------------------------------------------------------
on medium dataset, before_refactoring, refactoring type is local_variable_renaming:
11/18/2022 13:37:57 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/local_variable_renaming/before_refactoring/medium', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/before_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/before_refactoring/medium/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/18/2022 13:37:58 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/18/2022 13:38:00 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin
11/18/2022 13:38:09 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/before_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/before_refactoring/medium/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/35 [00:00<?, ?it/s]  3%|▎         | 1/35 [00:56<31:44, 56.02s/it]  6%|▌         | 2/35 [01:47<29:26, 53.54s/it]  9%|▊         | 3/35 [02:44<29:11, 54.74s/it] 11%|█▏        | 4/35 [03:42<28:57, 56.04s/it] 14%|█▍        | 5/35 [04:35<27:37, 55.25s/it] 17%|█▋        | 6/35 [05:28<26:17, 54.39s/it] 20%|██        | 7/35 [06:16<24:23, 52.27s/it] 23%|██▎       | 8/35 [07:08<23:33, 52.34s/it] 26%|██▌       | 9/35 [08:03<22:55, 52.89s/it] 29%|██▊       | 10/35 [09:02<22:50, 54.83s/it] 31%|███▏      | 11/35 [09:55<21:44, 54.35s/it] 34%|███▍      | 12/35 [10:50<20:56, 54.62s/it] 37%|███▋      | 13/35 [11:49<20:28, 55.84s/it] 40%|████      | 14/35 [12:44<19:29, 55.67s/it] 43%|████▎     | 15/35 [13:33<17:51, 53.55s/it] 46%|████▌     | 16/35 [14:32<17:27, 55.14s/it] 49%|████▊     | 17/35 [15:24<16:19, 54.41s/it] 51%|█████▏    | 18/35 [16:16<15:09, 53.52s/it] 54%|█████▍    | 19/35 [17:05<13:56, 52.30s/it] 57%|█████▋    | 20/35 [17:54<12:49, 51.29s/it] 60%|██████    | 21/35 [18:53<12:28, 53.43s/it] 63%|██████▎   | 22/35 [19:50<11:48, 54.48s/it] 66%|██████▌   | 23/35 [20:42<10:45, 53.81s/it] 69%|██████▊   | 24/35 [21:35<09:49, 53.55s/it] 71%|███████▏  | 25/35 [22:29<08:56, 53.66s/it] 74%|███████▍  | 26/35 [23:24<08:07, 54.16s/it] 77%|███████▋  | 27/35 [24:09<06:51, 51.38s/it] 80%|████████  | 28/35 [25:06<06:12, 53.23s/it] 83%|████████▎ | 29/35 [25:57<05:15, 52.52s/it] 86%|████████▌ | 30/35 [26:51<04:24, 52.84s/it] 89%|████████▊ | 31/35 [27:44<03:32, 53.03s/it] 91%|█████████▏| 32/35 [28:40<02:41, 53.84s/it] 94%|█████████▍| 33/35 [29:33<01:46, 53.48s/it] 97%|█████████▋| 34/35 [30:28<00:53, 53.91s/it]100%|██████████| 35/35 [30:45<00:00, 43.01s/it]100%|██████████| 35/35 [30:45<00:00, 52.74s/it]
11/18/2022 14:08:57 - INFO - __main__ -     bleu-4 = 89.66 
11/18/2022 14:08:57 - INFO - __main__ -     xMatch = 6.0055 
11/18/2022 14:08:57 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 6.01 , BLEU: 89.66
CodeBLEU: 86.28
ngram_match_score: 86.28 , weighted_ngram_match_score: 89.76 , syntax_match_score: 88.58 , dataflow_match_score: 77.12
---------------------------------------------------------------------------------------------
on medium dataset, after_refactoring, refactoring type is local_variable_renaming:
11/18/2022 14:09:04 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/local_variable_renaming/after_refactoring/medium', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/after_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/after_refactoring/medium/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/18/2022 14:09:05 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/18/2022 14:09:07 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin
11/18/2022 14:09:11 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/after_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/local_variable_renaming/after_refactoring/medium/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/35 [00:00<?, ?it/s]  3%|▎         | 1/35 [00:55<31:27, 55.52s/it]  6%|▌         | 2/35 [01:46<29:12, 53.12s/it]  9%|▊         | 3/35 [02:42<28:54, 54.21s/it] 11%|█▏        | 4/35 [03:38<28:26, 55.06s/it] 14%|█▍        | 5/35 [04:33<27:25, 54.85s/it] 17%|█▋        | 6/35 [05:25<26:06, 54.01s/it] 20%|██        | 7/35 [06:12<24:03, 51.56s/it] 23%|██▎       | 8/35 [07:03<23:13, 51.60s/it] 26%|██▌       | 9/35 [07:58<22:50, 52.70s/it] 29%|██▊       | 10/35 [08:57<22:40, 54.42s/it] 31%|███▏      | 11/35 [09:50<21:37, 54.05s/it] 34%|███▍      | 12/35 [10:45<20:46, 54.20s/it] 37%|███▋      | 13/35 [11:42<20:16, 55.28s/it] 40%|████      | 14/35 [12:38<19:21, 55.29s/it] 43%|████▎     | 15/35 [13:26<17:42, 53.12s/it] 46%|████▌     | 16/35 [14:24<17:17, 54.63s/it] 49%|████▊     | 17/35 [15:15<16:05, 53.64s/it] 51%|█████▏    | 18/35 [16:06<14:57, 52.77s/it] 54%|█████▍    | 19/35 [16:54<13:43, 51.47s/it] 57%|█████▋    | 20/35 [17:43<12:39, 50.64s/it] 60%|██████    | 21/35 [18:42<12:22, 53.02s/it] 63%|██████▎   | 22/35 [19:39<11:44, 54.20s/it] 66%|██████▌   | 23/35 [20:31<10:43, 53.63s/it] 69%|██████▊   | 24/35 [21:23<09:44, 53.17s/it] 71%|███████▏  | 25/35 [22:16<08:51, 53.19s/it] 74%|███████▍  | 26/35 [23:11<08:04, 53.80s/it] 77%|███████▋  | 27/35 [23:56<06:48, 51.09s/it] 80%|████████  | 28/35 [24:53<06:10, 52.88s/it] 83%|████████▎ | 29/35 [25:45<05:14, 52.41s/it] 86%|████████▌ | 30/35 [26:36<04:21, 52.22s/it] 89%|████████▊ | 31/35 [27:28<03:27, 51.98s/it] 91%|█████████▏| 32/35 [28:22<02:38, 52.77s/it] 94%|█████████▍| 33/35 [29:15<01:45, 52.65s/it] 97%|█████████▋| 34/35 [30:10<00:53, 53.28s/it]100%|██████████| 35/35 [30:27<00:00, 42.46s/it]100%|██████████| 35/35 [30:27<00:00, 52.21s/it]
11/18/2022 14:39:40 - INFO - __main__ -     bleu-4 = 89.65 
11/18/2022 14:39:40 - INFO - __main__ -     xMatch = 4.9136 
11/18/2022 14:39:40 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 4.91 , BLEU: 89.65
CodeBLEU: 86.28
ngram_match_score: 86.28 , weighted_ngram_match_score: 89.74 , syntax_match_score: 88.62 , dataflow_match_score: 77.12
---------------------------------------------------------------------------------------------
on small dataset, before_refactoring, refactoring type is method_renaming:
11/18/2022 14:39:48 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/method_renaming/before_refactoring/small', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/before_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/before_refactoring/small/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/18/2022 14:39:48 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/18/2022 14:39:51 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin
11/18/2022 14:39:54 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/before_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/before_refactoring/small/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/178 [00:00<?, ?it/s]  1%|          | 1/178 [00:22<1:04:58, 22.02s/it]  1%|          | 2/178 [00:45<1:07:50, 23.13s/it]  2%|▏         | 3/178 [01:13<1:13:17, 25.13s/it]  2%|▏         | 4/178 [01:38<1:13:00, 25.18s/it]  3%|▎         | 5/178 [02:02<1:10:53, 24.59s/it]  3%|▎         | 6/178 [02:21<1:05:40, 22.91s/it]  4%|▍         | 7/178 [02:49<1:10:06, 24.60s/it]  4%|▍         | 8/178 [03:12<1:08:09, 24.06s/it]  5%|▌         | 9/178 [03:37<1:08:33, 24.34s/it]  6%|▌         | 10/178 [03:57<1:04:30, 23.04s/it]  6%|▌         | 11/178 [04:21<1:04:26, 23.15s/it]  7%|▋         | 12/178 [04:43<1:03:20, 22.90s/it]  7%|▋         | 13/178 [05:07<1:03:27, 23.07s/it]  8%|▊         | 14/178 [05:31<1:03:59, 23.41s/it]  8%|▊         | 15/178 [05:57<1:05:51, 24.24s/it]  9%|▉         | 16/178 [06:19<1:03:42, 23.59s/it] 10%|▉         | 17/178 [06:45<1:05:01, 24.23s/it] 10%|█         | 18/178 [07:13<1:07:36, 25.35s/it] 11%|█         | 19/178 [07:33<1:03:21, 23.91s/it] 11%|█         | 20/178 [07:59<1:03:58, 24.30s/it] 12%|█▏        | 21/178 [08:18<59:43, 22.82s/it]   12%|█▏        | 22/178 [08:43<1:01:13, 23.55s/it] 13%|█▎        | 23/178 [09:06<1:00:32, 23.43s/it] 13%|█▎        | 24/178 [09:32<1:01:47, 24.08s/it] 14%|█▍        | 25/178 [09:59<1:03:36, 24.94s/it] 15%|█▍        | 26/178 [10:20<1:00:29, 23.88s/it] 15%|█▌        | 27/178 [10:42<58:12, 23.13s/it]   16%|█▌        | 28/178 [11:04<57:15, 22.90s/it] 16%|█▋        | 29/178 [11:32<1:00:37, 24.41s/it] 17%|█▋        | 30/178 [11:53<57:34, 23.34s/it]   17%|█▋        | 31/178 [12:17<57:59, 23.67s/it] 18%|█▊        | 32/178 [12:40<57:14, 23.52s/it] 19%|█▊        | 33/178 [13:01<54:40, 22.62s/it] 19%|█▉        | 34/178 [13:23<53:51, 22.44s/it] 20%|█▉        | 35/178 [13:46<53:53, 22.61s/it] 20%|██        | 36/178 [14:08<52:56, 22.37s/it] 21%|██        | 37/178 [14:30<52:34, 22.37s/it] 21%|██▏       | 38/178 [14:54<53:34, 22.96s/it] 22%|██▏       | 39/178 [15:19<54:29, 23.52s/it] 22%|██▏       | 40/178 [15:40<52:02, 22.63s/it] 23%|██▎       | 41/178 [16:03<52:05, 22.81s/it] 24%|██▎       | 42/178 [16:29<53:39, 23.67s/it] 24%|██▍       | 43/178 [16:53<53:31, 23.79s/it] 25%|██▍       | 44/178 [17:18<54:22, 24.35s/it] 25%|██▌       | 45/178 [17:47<56:33, 25.51s/it] 26%|██▌       | 46/178 [18:09<53:53, 24.49s/it] 26%|██▋       | 47/178 [18:34<54:07, 24.79s/it] 27%|██▋       | 48/178 [19:02<55:21, 25.55s/it] 28%|██▊       | 49/178 [19:22<51:48, 24.10s/it] 28%|██▊       | 50/178 [19:45<50:26, 23.64s/it] 29%|██▊       | 51/178 [20:08<49:50, 23.55s/it] 29%|██▉       | 52/178 [20:32<49:43, 23.68s/it] 30%|██▉       | 53/178 [20:54<47:52, 22.98s/it] 30%|███       | 54/178 [21:21<50:08, 24.26s/it] 31%|███       | 55/178 [21:42<47:34, 23.21s/it] 31%|███▏      | 56/178 [22:04<46:52, 23.05s/it] 32%|███▏      | 57/178 [22:30<48:01, 23.81s/it] 33%|███▎      | 58/178 [22:53<47:25, 23.71s/it] 33%|███▎      | 59/178 [23:22<50:02, 25.23s/it] 34%|███▎      | 60/178 [23:45<48:07, 24.47s/it] 34%|███▍      | 61/178 [24:05<45:11, 23.18s/it] 35%|███▍      | 62/178 [24:31<46:42, 24.16s/it] 35%|███▌      | 63/178 [24:55<46:03, 24.03s/it] 36%|███▌      | 64/178 [25:15<43:00, 22.63s/it] 37%|███▋      | 65/178 [25:38<43:17, 22.99s/it] 37%|███▋      | 66/178 [26:03<43:35, 23.35s/it] 38%|███▊      | 67/178 [26:32<46:29, 25.13s/it] 38%|███▊      | 68/178 [26:54<44:18, 24.17s/it] 39%|███▉      | 69/178 [27:10<39:26, 21.71s/it] 39%|███▉      | 70/178 [27:33<40:00, 22.23s/it] 40%|███▉      | 71/178 [27:55<39:37, 22.22s/it] 40%|████      | 72/178 [28:19<40:04, 22.69s/it] 41%|████      | 73/178 [28:39<38:18, 21.89s/it] 42%|████▏     | 74/178 [29:02<38:14, 22.06s/it] 42%|████▏     | 75/178 [29:24<38:02, 22.16s/it] 43%|████▎     | 76/178 [29:48<38:28, 22.63s/it] 43%|████▎     | 77/178 [30:11<38:36, 22.93s/it] 44%|████▍     | 78/178 [30:31<36:29, 21.89s/it] 44%|████▍     | 79/178 [30:56<37:42, 22.86s/it] 45%|████▍     | 80/178 [31:21<38:19, 23.47s/it] 46%|████▌     | 81/178 [31:48<39:52, 24.66s/it] 46%|████▌     | 82/178 [32:13<39:25, 24.64s/it] 47%|████▋     | 83/178 [32:36<38:28, 24.30s/it] 47%|████▋     | 84/178 [32:59<37:10, 23.73s/it] 48%|████▊     | 85/178 [33:21<36:15, 23.39s/it] 48%|████▊     | 86/178 [33:45<35:48, 23.36s/it] 49%|████▉     | 87/178 [34:10<36:09, 23.84s/it] 49%|████▉     | 88/178 [34:36<36:57, 24.64s/it] 50%|█████     | 89/178 [35:00<36:18, 24.48s/it] 51%|█████     | 90/178 [35:26<36:26, 24.85s/it] 51%|█████     | 91/178 [35:50<35:50, 24.72s/it] 52%|█████▏    | 92/178 [36:15<35:16, 24.61s/it] 52%|█████▏    | 93/178 [36:37<34:01, 24.01s/it] 53%|█████▎    | 94/178 [37:02<33:59, 24.28s/it] 53%|█████▎    | 95/178 [37:25<33:05, 23.92s/it] 54%|█████▍    | 96/178 [37:47<31:36, 23.13s/it] 54%|█████▍    | 97/178 [38:13<32:29, 24.07s/it] 55%|█████▌    | 98/178 [38:34<31:04, 23.30s/it] 56%|█████▌    | 99/178 [39:06<33:58, 25.81s/it] 56%|█████▌    | 100/178 [39:34<34:17, 26.37s/it] 57%|█████▋    | 101/178 [40:03<35:01, 27.29s/it] 57%|█████▋    | 102/178 [40:28<33:33, 26.49s/it] 58%|█████▊    | 103/178 [40:51<32:02, 25.63s/it] 58%|█████▊    | 104/178 [41:16<31:24, 25.47s/it] 59%|█████▉    | 105/178 [41:41<30:28, 25.05s/it] 60%|█████▉    | 106/178 [42:06<30:19, 25.27s/it] 60%|██████    | 107/178 [42:31<29:36, 25.03s/it] 61%|██████    | 108/178 [42:55<29:04, 24.92s/it] 61%|██████    | 109/178 [43:21<28:55, 25.15s/it] 62%|██████▏   | 110/178 [43:44<27:35, 24.35s/it] 62%|██████▏   | 111/178 [44:06<26:34, 23.80s/it] 63%|██████▎   | 112/178 [44:30<26:14, 23.85s/it] 63%|██████▎   | 113/178 [44:52<25:10, 23.24s/it] 64%|██████▍   | 114/178 [45:17<25:29, 23.89s/it] 65%|██████▍   | 115/178 [45:39<24:14, 23.09s/it] 65%|██████▌   | 116/178 [46:01<23:44, 22.98s/it] 66%|██████▌   | 117/178 [46:28<24:27, 24.06s/it] 66%|██████▋   | 118/178 [46:52<23:58, 23.97s/it] 67%|██████▋   | 119/178 [47:19<24:36, 25.03s/it] 67%|██████▋   | 120/178 [47:47<24:54, 25.76s/it] 68%|██████▊   | 121/178 [48:06<22:47, 23.99s/it] 69%|██████▊   | 122/178 [48:31<22:25, 24.02s/it] 69%|██████▉   | 123/178 [48:58<22:49, 24.90s/it] 70%|██████▉   | 124/178 [49:28<23:55, 26.59s/it] 70%|███████   | 125/178 [49:51<22:27, 25.42s/it] 71%|███████   | 126/178 [50:17<22:12, 25.62s/it] 71%|███████▏  | 127/178 [50:39<21:00, 24.72s/it] 72%|███████▏  | 128/178 [51:02<20:06, 24.13s/it] 72%|███████▏  | 129/178 [51:25<19:23, 23.74s/it] 73%|███████▎  | 130/178 [51:46<18:19, 22.92s/it] 74%|███████▎  | 131/178 [52:11<18:25, 23.52s/it] 74%|███████▍  | 132/178 [52:30<17:04, 22.27s/it] 75%|███████▍  | 133/178 [52:54<16:54, 22.55s/it] 75%|███████▌  | 134/178 [53:20<17:19, 23.63s/it] 76%|███████▌  | 135/178 [53:41<16:32, 23.08s/it] 76%|███████▋  | 136/178 [54:05<16:12, 23.16s/it] 77%|███████▋  | 137/178 [54:28<15:50, 23.18s/it] 78%|███████▊  | 138/178 [54:49<15:06, 22.66s/it] 78%|███████▊  | 139/178 [55:16<15:28, 23.80s/it] 79%|███████▊  | 140/178 [55:39<14:56, 23.59s/it] 79%|███████▉  | 141/178 [56:01<14:12, 23.04s/it] 80%|███████▉  | 142/178 [56:24<13:51, 23.09s/it] 80%|████████  | 143/178 [56:48<13:42, 23.51s/it] 81%|████████  | 144/178 [57:08<12:42, 22.42s/it] 81%|████████▏ | 145/178 [57:31<12:24, 22.56s/it] 82%|████████▏ | 146/178 [57:51<11:39, 21.85s/it] 83%|████████▎ | 147/178 [58:11<11:00, 21.30s/it] 83%|████████▎ | 148/178 [58:35<11:02, 22.07s/it] 84%|████████▎ | 149/178 [58:54<10:06, 20.93s/it] 84%|████████▍ | 150/178 [59:18<10:19, 22.12s/it] 85%|████████▍ | 151/178 [59:45<10:32, 23.44s/it] 85%|████████▌ | 152/178 [1:00:11<10:27, 24.12s/it] 86%|████████▌ | 153/178 [1:00:34<09:52, 23.72s/it] 87%|████████▋ | 154/178 [1:00:58<09:34, 23.95s/it] 87%|████████▋ | 155/178 [1:01:22<09:09, 23.88s/it] 88%|████████▊ | 156/178 [1:01:48<09:03, 24.71s/it] 88%|████████▊ | 157/178 [1:02:11<08:26, 24.14s/it] 89%|████████▉ | 158/178 [1:02:39<08:23, 25.19s/it] 89%|████████▉ | 159/178 [1:03:03<07:51, 24.82s/it] 90%|████████▉ | 160/178 [1:03:26<07:17, 24.29s/it] 90%|█████████ | 161/178 [1:03:51<06:59, 24.67s/it] 91%|█████████ | 162/178 [1:04:18<06:46, 25.40s/it] 92%|█████████▏| 163/178 [1:04:42<06:13, 24.89s/it] 92%|█████████▏| 164/178 [1:05:06<05:42, 24.49s/it] 93%|█████████▎| 165/178 [1:05:28<05:10, 23.87s/it] 93%|█████████▎| 166/178 [1:05:51<04:44, 23.68s/it] 94%|█████████▍| 167/178 [1:06:22<04:41, 25.64s/it] 94%|█████████▍| 168/178 [1:06:40<03:54, 23.45s/it] 95%|█████████▍| 169/178 [1:07:03<03:30, 23.38s/it] 96%|█████████▌| 170/178 [1:07:25<03:03, 22.92s/it] 96%|█████████▌| 171/178 [1:07:49<02:43, 23.35s/it] 97%|█████████▋| 172/178 [1:08:15<02:24, 24.13s/it] 97%|█████████▋| 173/178 [1:08:37<01:57, 23.51s/it] 98%|█████████▊| 174/178 [1:09:02<01:35, 23.90s/it] 98%|█████████▊| 175/178 [1:09:24<01:10, 23.41s/it] 99%|█████████▉| 176/178 [1:09:45<00:45, 22.63s/it] 99%|█████████▉| 177/178 [1:10:07<00:22, 22.51s/it]100%|██████████| 178/178 [1:10:16<00:00, 18.26s/it]100%|██████████| 178/178 [1:10:16<00:00, 23.69s/it]
11/18/2022 15:50:17 - INFO - __main__ -     bleu-4 = 79.48 
11/18/2022 15:50:17 - INFO - __main__ -     xMatch = 17.6771 
11/18/2022 15:50:17 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 17.68 , BLEU: 79.48
CodeBLEU: 79.62
ngram_match_score: 79.62 , weighted_ngram_match_score: 79.76 , syntax_match_score: 82.17 , dataflow_match_score: 77.09
---------------------------------------------------------------------------------------------
on small dataset, after_refactoring, refactoring type is method_renaming:
11/18/2022 15:50:31 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/method_renaming/after_refactoring/small', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/after_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/after_refactoring/small/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/18/2022 15:50:31 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/18/2022 15:50:34 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin
11/18/2022 15:50:37 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/after_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/after_refactoring/small/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/178 [00:00<?, ?it/s]  1%|          | 1/178 [00:22<1:05:12, 22.10s/it]  1%|          | 2/178 [00:46<1:09:18, 23.63s/it]  2%|▏         | 3/178 [01:14<1:14:27, 25.53s/it]  2%|▏         | 4/178 [01:39<1:13:20, 25.29s/it]  3%|▎         | 5/178 [02:02<1:10:59, 24.62s/it]  3%|▎         | 6/178 [02:23<1:06:11, 23.09s/it]  4%|▍         | 7/178 [02:50<1:10:09, 24.62s/it]  4%|▍         | 8/178 [03:13<1:08:06, 24.04s/it]  5%|▌         | 9/178 [03:38<1:08:47, 24.42s/it]  6%|▌         | 10/178 [03:59<1:04:45, 23.13s/it]  6%|▌         | 11/178 [04:22<1:04:09, 23.05s/it]  7%|▋         | 12/178 [04:43<1:02:48, 22.70s/it]  7%|▋         | 13/178 [05:06<1:02:30, 22.73s/it]  8%|▊         | 14/178 [05:30<1:03:20, 23.17s/it]  8%|▊         | 15/178 [05:56<1:05:15, 24.02s/it]  9%|▉         | 16/178 [06:18<1:02:45, 23.24s/it] 10%|▉         | 17/178 [06:44<1:04:34, 24.06s/it] 10%|█         | 18/178 [07:11<1:06:54, 25.09s/it] 11%|█         | 19/178 [07:32<1:02:42, 23.67s/it] 11%|█         | 20/178 [07:57<1:03:19, 24.05s/it] 12%|█▏        | 21/178 [08:17<59:52, 22.88s/it]   12%|█▏        | 22/178 [08:42<1:01:19, 23.58s/it] 13%|█▎        | 23/178 [09:06<1:00:58, 23.60s/it] 13%|█▎        | 24/178 [09:31<1:02:05, 24.19s/it] 14%|█▍        | 25/178 [09:58<1:04:03, 25.12s/it] 15%|█▍        | 26/178 [10:20<1:00:57, 24.06s/it] 15%|█▌        | 27/178 [10:42<58:37, 23.29s/it]   16%|█▌        | 28/178 [11:04<57:37, 23.05s/it] 16%|█▋        | 29/178 [11:32<1:00:51, 24.51s/it] 17%|█▋        | 30/178 [11:53<57:46, 23.42s/it]   17%|█▋        | 31/178 [12:17<57:52, 23.62s/it] 18%|█▊        | 32/178 [12:40<57:13, 23.52s/it] 19%|█▊        | 33/178 [13:01<54:45, 22.66s/it] 19%|█▉        | 34/178 [13:23<53:42, 22.38s/it] 20%|█▉        | 35/178 [13:45<53:22, 22.39s/it] 20%|██        | 36/178 [14:07<52:41, 22.26s/it] 21%|██        | 37/178 [14:29<52:27, 22.32s/it] 21%|██▏       | 38/178 [14:53<53:15, 22.82s/it] 22%|██▏       | 39/178 [15:18<53:59, 23.31s/it] 22%|██▏       | 40/178 [15:38<51:29, 22.39s/it] 23%|██▎       | 41/178 [16:02<51:54, 22.73s/it] 24%|██▎       | 42/178 [16:27<53:12, 23.48s/it] 24%|██▍       | 43/178 [16:51<53:26, 23.75s/it] 25%|██▍       | 44/178 [17:16<53:37, 24.01s/it] 25%|██▌       | 45/178 [17:44<55:40, 25.12s/it] 26%|██▌       | 46/178 [18:05<52:55, 24.05s/it] 26%|██▋       | 47/178 [18:30<53:14, 24.38s/it] 27%|██▋       | 48/178 [18:57<54:39, 25.23s/it] 28%|██▊       | 49/178 [19:18<51:11, 23.81s/it] 28%|██▊       | 50/178 [19:41<50:22, 23.61s/it] 29%|██▊       | 51/178 [20:04<49:40, 23.47s/it] 29%|██▉       | 52/178 [20:28<49:26, 23.55s/it] 30%|██▉       | 53/178 [20:50<47:51, 22.98s/it] 30%|███       | 54/178 [21:17<50:04, 24.23s/it] 31%|███       | 55/178 [21:39<48:12, 23.52s/it] 31%|███▏      | 56/178 [22:02<47:29, 23.35s/it] 32%|███▏      | 57/178 [22:28<48:39, 24.13s/it] 33%|███▎      | 58/178 [22:51<47:58, 23.99s/it] 33%|███▎      | 59/178 [23:20<50:20, 25.38s/it] 34%|███▎      | 60/178 [23:43<48:29, 24.65s/it] 34%|███▍      | 61/178 [24:03<45:40, 23.42s/it] 35%|███▍      | 62/178 [24:29<46:42, 24.16s/it] 35%|███▌      | 63/178 [24:53<46:07, 24.07s/it] 36%|███▌      | 64/178 [25:13<43:08, 22.71s/it] 37%|███▋      | 65/178 [25:36<43:04, 22.87s/it] 37%|███▋      | 66/178 [26:00<43:30, 23.31s/it] 38%|███▊      | 67/178 [26:29<46:11, 24.97s/it] 38%|███▊      | 68/178 [26:51<43:52, 23.94s/it] 39%|███▉      | 69/178 [27:07<39:16, 21.62s/it] 39%|███▉      | 70/178 [27:31<40:05, 22.27s/it] 40%|███▉      | 71/178 [27:53<39:41, 22.26s/it] 40%|████      | 72/178 [28:17<40:10, 22.74s/it] 41%|████      | 73/178 [28:36<38:16, 21.88s/it] 42%|████▏     | 74/178 [28:59<38:14, 22.06s/it] 42%|████▏     | 75/178 [29:20<37:27, 21.82s/it] 43%|████▎     | 76/178 [29:44<38:01, 22.37s/it] 43%|████▎     | 77/178 [30:07<37:58, 22.56s/it] 44%|████▍     | 78/178 [30:26<35:55, 21.55s/it] 44%|████▍     | 79/178 [30:51<37:28, 22.71s/it] 45%|████▍     | 80/178 [31:17<38:13, 23.41s/it] 46%|████▌     | 81/178 [31:44<39:53, 24.68s/it] 46%|████▌     | 82/178 [32:09<39:19, 24.57s/it] 47%|████▋     | 83/178 [32:31<38:03, 24.04s/it] 47%|████▋     | 84/178 [32:53<36:44, 23.45s/it] 48%|████▊     | 85/178 [33:16<35:58, 23.21s/it] 48%|████▊     | 86/178 [33:41<36:11, 23.60s/it] 49%|████▉     | 87/178 [34:06<36:25, 24.02s/it] 49%|████▉     | 88/178 [34:33<37:30, 25.01s/it] 50%|█████     | 89/178 [34:57<36:42, 24.75s/it] 51%|█████     | 90/178 [35:22<36:33, 24.93s/it] 51%|█████     | 91/178 [35:46<35:46, 24.67s/it] 52%|█████▏    | 92/178 [36:11<35:12, 24.57s/it] 52%|█████▏    | 93/178 [36:33<33:48, 23.86s/it] 53%|█████▎    | 94/178 [36:58<34:03, 24.32s/it] 53%|█████▎    | 95/178 [37:21<32:55, 23.81s/it] 54%|█████▍    | 96/178 [37:42<31:13, 22.85s/it] 54%|█████▍    | 97/178 [38:08<32:06, 23.78s/it] 55%|█████▌    | 98/178 [38:29<30:44, 23.06s/it] 56%|█████▌    | 99/178 [39:00<33:37, 25.54s/it] 56%|█████▌    | 100/178 [39:28<34:10, 26.28s/it] 57%|█████▋    | 101/178 [39:57<34:46, 27.10s/it] 57%|█████▋    | 102/178 [40:22<33:35, 26.51s/it] 58%|█████▊    | 103/178 [40:46<31:53, 25.52s/it] 58%|█████▊    | 104/178 [41:11<31:19, 25.40s/it] 59%|█████▉    | 105/178 [41:35<30:31, 25.08s/it] 60%|█████▉    | 106/178 [42:01<30:31, 25.44s/it] 60%|██████    | 107/178 [42:26<29:45, 25.15s/it] 61%|██████    | 108/178 [42:51<29:28, 25.26s/it] 61%|██████    | 109/178 [43:18<29:29, 25.64s/it] 62%|██████▏   | 110/178 [43:41<28:04, 24.77s/it] 62%|██████▏   | 111/178 [44:03<26:51, 24.05s/it] 63%|██████▎   | 112/178 [44:27<26:28, 24.07s/it] 63%|██████▎   | 113/178 [44:48<25:12, 23.27s/it] 64%|██████▍   | 114/178 [45:15<25:42, 24.10s/it] 65%|██████▍   | 115/178 [45:36<24:30, 23.35s/it] 65%|██████▌   | 116/178 [45:58<23:47, 23.02s/it] 66%|██████▌   | 117/178 [46:24<24:20, 23.95s/it] 66%|██████▋   | 118/178 [46:47<23:39, 23.65s/it] 67%|██████▋   | 119/178 [47:15<24:24, 24.83s/it] 67%|██████▋   | 120/178 [47:43<24:52, 25.74s/it] 68%|██████▊   | 121/178 [48:03<22:56, 24.15s/it] 69%|██████▊   | 122/178 [48:28<22:34, 24.18s/it] 69%|██████▉   | 123/178 [48:54<22:50, 24.91s/it] 70%|██████▉   | 124/178 [49:25<23:57, 26.62s/it] 70%|███████   | 125/178 [49:48<22:30, 25.48s/it] 71%|███████   | 126/178 [50:14<22:17, 25.72s/it] 71%|███████▏  | 127/178 [50:37<21:08, 24.88s/it] 72%|███████▏  | 128/178 [51:00<20:19, 24.39s/it] 72%|███████▏  | 129/178 [51:22<19:25, 23.79s/it] 73%|███████▎  | 130/178 [51:44<18:34, 23.22s/it] 74%|███████▎  | 131/178 [52:10<18:40, 23.84s/it] 74%|███████▍  | 132/178 [52:29<17:12, 22.46s/it] 75%|███████▍  | 133/178 [52:52<16:54, 22.55s/it] 75%|███████▌  | 134/178 [53:18<17:25, 23.77s/it] 76%|███████▌  | 135/178 [53:40<16:41, 23.29s/it] 76%|███████▋  | 136/178 [54:04<16:20, 23.34s/it] 77%|███████▋  | 137/178 [54:27<15:56, 23.34s/it] 78%|███████▊  | 138/178 [54:49<15:14, 22.87s/it] 78%|███████▊  | 139/178 [55:15<15:30, 23.85s/it] 79%|███████▊  | 140/178 [55:38<14:59, 23.68s/it] 79%|███████▉  | 141/178 [56:00<14:09, 22.96s/it] 80%|███████▉  | 142/178 [56:23<13:50, 23.07s/it] 80%|████████  | 143/178 [56:47<13:35, 23.29s/it] 81%|████████  | 144/178 [57:07<12:39, 22.34s/it] 81%|████████▏ | 145/178 [57:31<12:30, 22.74s/it] 82%|████████▏ | 146/178 [57:51<11:41, 21.92s/it] 83%|████████▎ | 147/178 [58:11<11:07, 21.55s/it] 83%|████████▎ | 148/178 [58:36<11:15, 22.52s/it] 84%|████████▎ | 149/178 [58:55<10:20, 21.41s/it] 84%|████████▍ | 150/178 [59:20<10:34, 22.64s/it] 85%|████████▍ | 151/178 [59:47<10:44, 23.87s/it] 85%|████████▌ | 152/178 [1:00:12<10:26, 24.10s/it] 86%|████████▌ | 153/178 [1:00:35<09:52, 23.71s/it] 87%|████████▋ | 154/178 [1:00:59<09:37, 24.07s/it] 87%|████████▋ | 155/178 [1:01:24<09:18, 24.28s/it] 88%|████████▊ | 156/178 [1:01:52<09:14, 25.19s/it] 88%|████████▊ | 157/178 [1:02:14<08:34, 24.49s/it] 89%|████████▉ | 158/178 [1:02:42<08:25, 25.27s/it] 89%|████████▉ | 159/178 [1:03:05<07:52, 24.87s/it] 90%|████████▉ | 160/178 [1:03:28<07:16, 24.28s/it] 90%|█████████ | 161/178 [1:03:54<06:57, 24.56s/it] 91%|█████████ | 162/178 [1:04:21<06:46, 25.40s/it] 92%|█████████▏| 163/178 [1:04:44<06:11, 24.74s/it] 92%|█████████▏| 164/178 [1:05:08<05:41, 24.37s/it] 93%|█████████▎| 165/178 [1:05:30<05:09, 23.80s/it] 93%|█████████▎| 166/178 [1:05:54<04:44, 23.75s/it] 94%|█████████▍| 167/178 [1:06:25<04:45, 25.96s/it] 94%|█████████▍| 168/178 [1:06:44<03:58, 23.87s/it] 95%|█████████▍| 169/178 [1:07:07<03:33, 23.68s/it] 96%|█████████▌| 170/178 [1:07:30<03:08, 23.50s/it] 96%|█████████▌| 171/178 [1:07:55<02:46, 23.81s/it] 97%|█████████▋| 172/178 [1:08:21<02:27, 24.58s/it] 97%|█████████▋| 173/178 [1:08:44<01:59, 23.94s/it] 98%|█████████▊| 174/178 [1:09:08<01:36, 24.15s/it] 98%|█████████▊| 175/178 [1:09:30<01:10, 23.57s/it] 99%|█████████▉| 176/178 [1:09:51<00:45, 22.74s/it] 99%|█████████▉| 177/178 [1:10:15<00:22, 22.99s/it]100%|██████████| 178/178 [1:10:23<00:00, 18.45s/it]100%|██████████| 178/178 [1:10:23<00:00, 23.73s/it]
11/18/2022 17:01:07 - INFO - __main__ -     bleu-4 = 79.03 
11/18/2022 17:01:07 - INFO - __main__ -     xMatch = 16.0909 
11/18/2022 17:01:07 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 16.09 , BLEU: 79.03
CodeBLEU: 79.29
ngram_match_score: 79.29 , weighted_ngram_match_score: 79.29 , syntax_match_score: 81.87 , dataflow_match_score: 76.96
---------------------------------------------------------------------------------------------
on medium dataset, before_refactoring, refactoring type is method_renaming:
11/18/2022 17:01:22 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/method_renaming/before_refactoring/medium', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/before_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/before_refactoring/medium/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/18/2022 17:01:22 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/18/2022 17:01:25 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin
11/18/2022 17:01:28 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/before_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/before_refactoring/medium/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/195 [00:00<?, ?it/s]  1%|          | 1/195 [00:58<3:07:40, 58.04s/it]  1%|          | 2/195 [01:55<3:05:45, 57.75s/it]  2%|▏         | 3/195 [02:56<3:09:20, 59.17s/it]  2%|▏         | 4/195 [04:00<3:14:27, 61.09s/it]  3%|▎         | 5/195 [05:07<3:20:01, 63.17s/it]  3%|▎         | 6/195 [06:03<3:11:19, 60.74s/it]  4%|▎         | 7/195 [07:06<3:13:16, 61.68s/it]  4%|▍         | 8/195 [08:04<3:08:23, 60.44s/it]  5%|▍         | 9/195 [09:07<3:09:56, 61.27s/it]  5%|▌         | 10/195 [10:12<3:12:32, 62.44s/it]  6%|▌         | 11/195 [11:11<3:07:55, 61.28s/it]  6%|▌         | 12/195 [12:14<3:08:11, 61.70s/it]  7%|▋         | 13/195 [13:18<3:09:17, 62.40s/it]  7%|▋         | 14/195 [14:19<3:06:59, 61.99s/it]  8%|▊         | 15/195 [15:29<3:13:27, 64.49s/it]  8%|▊         | 16/195 [16:24<3:04:14, 61.76s/it]  9%|▊         | 17/195 [17:21<2:58:31, 60.18s/it]  9%|▉         | 18/195 [18:24<3:00:26, 61.16s/it] 10%|▉         | 19/195 [19:27<3:00:37, 61.58s/it] 10%|█         | 20/195 [20:24<2:55:40, 60.23s/it] 11%|█         | 21/195 [21:25<2:55:00, 60.35s/it] 11%|█▏        | 22/195 [22:26<2:54:28, 60.51s/it] 12%|█▏        | 23/195 [23:24<2:51:29, 59.83s/it] 12%|█▏        | 24/195 [24:27<2:53:12, 60.77s/it] 13%|█▎        | 25/195 [25:30<2:54:10, 61.47s/it] 13%|█▎        | 26/195 [26:34<2:54:59, 62.13s/it] 14%|█▍        | 27/195 [27:34<2:52:32, 61.62s/it] 14%|█▍        | 28/195 [28:33<2:49:43, 60.98s/it] 15%|█▍        | 29/195 [29:27<2:42:41, 58.80s/it] 15%|█▌        | 30/195 [30:25<2:40:56, 58.53s/it] 16%|█▌        | 31/195 [31:24<2:40:08, 58.59s/it] 16%|█▋        | 32/195 [32:15<2:33:10, 56.39s/it] 17%|█▋        | 33/195 [33:14<2:34:12, 57.11s/it] 17%|█▋        | 34/195 [34:16<2:36:59, 58.51s/it] 18%|█▊        | 35/195 [35:13<2:35:11, 58.20s/it] 18%|█▊        | 36/195 [36:13<2:35:51, 58.81s/it] 19%|█▉        | 37/195 [37:09<2:32:19, 57.84s/it] 19%|█▉        | 38/195 [38:08<2:32:07, 58.14s/it] 20%|██        | 39/195 [39:02<2:28:23, 57.07s/it] 21%|██        | 40/195 [40:07<2:33:16, 59.33s/it] 21%|██        | 41/195 [41:06<2:32:26, 59.40s/it] 22%|██▏       | 42/195 [42:05<2:30:38, 59.08s/it] 22%|██▏       | 43/195 [43:04<2:29:32, 59.03s/it] 23%|██▎       | 44/195 [43:57<2:23:57, 57.20s/it] 23%|██▎       | 45/195 [44:53<2:22:33, 57.02s/it] 24%|██▎       | 46/195 [45:58<2:27:33, 59.42s/it] 24%|██▍       | 47/195 [46:54<2:23:39, 58.24s/it] 25%|██▍       | 48/195 [47:58<2:27:09, 60.06s/it] 25%|██▌       | 49/195 [48:58<2:26:18, 60.13s/it] 26%|██▌       | 50/195 [49:55<2:23:04, 59.21s/it] 26%|██▌       | 51/195 [51:04<2:28:42, 61.96s/it] 27%|██▋       | 52/195 [51:57<2:21:12, 59.25s/it] 27%|██▋       | 53/195 [52:54<2:18:43, 58.62s/it] 28%|██▊       | 54/195 [54:05<2:26:15, 62.24s/it] 28%|██▊       | 55/195 [55:02<2:22:05, 60.90s/it] 29%|██▊       | 56/195 [56:04<2:21:24, 61.04s/it] 29%|██▉       | 57/195 [57:05<2:20:40, 61.16s/it] 30%|██▉       | 58/195 [58:02<2:16:49, 59.92s/it] 30%|███       | 59/195 [59:12<2:22:21, 62.81s/it] 31%|███       | 60/195 [1:00:19<2:24:36, 64.27s/it] 31%|███▏      | 61/195 [1:01:14<2:16:49, 61.27s/it] 32%|███▏      | 62/195 [1:02:15<2:15:40, 61.21s/it] 32%|███▏      | 63/195 [1:03:17<2:15:23, 61.54s/it] 33%|███▎      | 64/195 [1:04:25<2:18:47, 63.57s/it] 33%|███▎      | 65/195 [1:05:13<2:07:11, 58.70s/it] 34%|███▍      | 66/195 [1:06:12<2:06:23, 58.78s/it] 34%|███▍      | 67/195 [1:07:12<2:06:37, 59.36s/it] 35%|███▍      | 68/195 [1:08:06<2:01:42, 57.50s/it] 35%|███▌      | 69/195 [1:09:04<2:01:35, 57.90s/it] 36%|███▌      | 70/195 [1:10:05<2:02:36, 58.85s/it] 36%|███▋      | 71/195 [1:11:07<2:03:00, 59.52s/it] 37%|███▋      | 72/195 [1:11:55<1:55:28, 56.33s/it] 37%|███▋      | 73/195 [1:13:01<2:00:11, 59.11s/it] 38%|███▊      | 74/195 [1:13:53<1:55:08, 57.09s/it] 38%|███▊      | 75/195 [1:14:53<1:55:34, 57.78s/it] 39%|███▉      | 76/195 [1:15:50<1:53:59, 57.48s/it] 39%|███▉      | 77/195 [1:16:47<1:52:56, 57.42s/it] 40%|████      | 78/195 [1:17:44<1:52:04, 57.48s/it] 41%|████      | 79/195 [1:18:43<1:52:00, 57.93s/it] 41%|████      | 80/195 [1:19:43<1:51:49, 58.34s/it] 42%|████▏     | 81/195 [1:20:41<1:50:47, 58.31s/it] 42%|████▏     | 82/195 [1:21:40<1:50:09, 58.49s/it] 43%|████▎     | 83/195 [1:22:36<1:47:40, 57.69s/it] 43%|████▎     | 84/195 [1:23:38<1:49:16, 59.07s/it] 44%|████▎     | 85/195 [1:24:43<1:51:24, 60.77s/it] 44%|████▍     | 86/195 [1:25:40<1:48:32, 59.75s/it] 45%|████▍     | 87/195 [1:26:40<1:47:31, 59.74s/it] 45%|████▌     | 88/195 [1:27:33<1:43:07, 57.83s/it] 46%|████▌     | 89/195 [1:28:41<1:47:31, 60.86s/it] 46%|████▌     | 90/195 [1:29:46<1:48:22, 61.93s/it] 47%|████▋     | 91/195 [1:30:48<1:47:29, 62.01s/it] 47%|████▋     | 92/195 [1:31:51<1:47:08, 62.41s/it] 48%|████▊     | 93/195 [1:32:49<1:43:51, 61.09s/it] 48%|████▊     | 94/195 [1:33:54<1:44:53, 62.31s/it] 49%|████▊     | 95/195 [1:34:54<1:42:32, 61.52s/it] 49%|████▉     | 96/195 [1:35:52<1:39:35, 60.36s/it] 50%|████▉     | 97/195 [1:36:47<1:36:10, 58.89s/it] 50%|█████     | 98/195 [1:37:51<1:37:49, 60.51s/it] 51%|█████     | 99/195 [1:38:51<1:36:11, 60.11s/it] 51%|█████▏    | 100/195 [1:39:51<1:35:25, 60.26s/it] 52%|█████▏    | 101/195 [1:40:45<1:31:25, 58.36s/it] 52%|█████▏    | 102/195 [1:41:41<1:29:08, 57.51s/it] 53%|█████▎    | 103/195 [1:42:37<1:27:27, 57.04s/it] 53%|█████▎    | 104/195 [1:43:35<1:27:12, 57.50s/it] 54%|█████▍    | 105/195 [1:44:37<1:28:25, 58.95s/it] 54%|█████▍    | 106/195 [1:45:34<1:26:10, 58.09s/it] 55%|█████▍    | 107/195 [1:46:34<1:26:07, 58.73s/it] 55%|█████▌    | 108/195 [1:47:34<1:25:49, 59.19s/it] 56%|█████▌    | 109/195 [1:48:34<1:25:02, 59.33s/it] 56%|█████▋    | 110/195 [1:49:36<1:25:15, 60.19s/it] 57%|█████▋    | 111/195 [1:50:35<1:23:50, 59.89s/it] 57%|█████▋    | 112/195 [1:51:36<1:23:06, 60.08s/it] 58%|█████▊    | 113/195 [1:52:40<1:23:46, 61.30s/it] 58%|█████▊    | 114/195 [1:53:42<1:23:08, 61.59s/it] 59%|█████▉    | 115/195 [1:54:44<1:22:10, 61.64s/it] 59%|█████▉    | 116/195 [1:55:45<1:20:59, 61.52s/it] 60%|██████    | 117/195 [1:56:47<1:20:09, 61.65s/it] 61%|██████    | 118/195 [1:57:48<1:18:42, 61.34s/it] 61%|██████    | 119/195 [1:58:50<1:17:57, 61.54s/it] 62%|██████▏   | 120/195 [1:59:55<1:18:22, 62.70s/it] 62%|██████▏   | 121/195 [2:00:48<1:13:43, 59.77s/it] 63%|██████▎   | 122/195 [2:01:50<1:13:26, 60.36s/it] 63%|██████▎   | 123/195 [2:02:49<1:12:03, 60.05s/it] 64%|██████▎   | 124/195 [2:03:46<1:09:52, 59.05s/it] 64%|██████▍   | 125/195 [2:04:48<1:09:52, 59.89s/it] 65%|██████▍   | 126/195 [2:05:40<1:06:23, 57.73s/it] 65%|██████▌   | 127/195 [2:06:41<1:06:32, 58.72s/it] 66%|██████▌   | 128/195 [2:07:39<1:05:17, 58.47s/it] 66%|██████▌   | 129/195 [2:08:36<1:03:49, 58.02s/it] 67%|██████▋   | 130/195 [2:09:34<1:02:56, 58.09s/it] 67%|██████▋   | 131/195 [2:10:33<1:02:09, 58.28s/it] 68%|██████▊   | 132/195 [2:11:30<1:00:44, 57.85s/it] 68%|██████▊   | 133/195 [2:12:30<1:00:33, 58.60s/it] 69%|██████▊   | 134/195 [2:13:39<1:02:30, 61.49s/it] 69%|██████▉   | 135/195 [2:14:30<58:27, 58.45s/it]   70%|██████▉   | 136/195 [2:15:26<56:41, 57.65s/it] 70%|███████   | 137/195 [2:16:37<59:39, 61.71s/it] 71%|███████   | 138/195 [2:17:34<57:25, 60.45s/it] 71%|███████▏  | 139/195 [2:18:29<54:45, 58.67s/it] 72%|███████▏  | 140/195 [2:19:32<54:57, 59.95s/it] 72%|███████▏  | 141/195 [2:20:34<54:32, 60.61s/it] 73%|███████▎  | 142/195 [2:21:30<52:11, 59.08s/it] 73%|███████▎  | 143/195 [2:22:33<52:28, 60.54s/it] 74%|███████▍  | 144/195 [2:23:33<51:09, 60.19s/it] 74%|███████▍  | 145/195 [2:24:31<49:39, 59.60s/it] 75%|███████▍  | 146/195 [2:25:34<49:35, 60.73s/it] 75%|███████▌  | 147/195 [2:26:40<49:48, 62.27s/it] 76%|███████▌  | 148/195 [2:27:39<47:54, 61.16s/it] 76%|███████▋  | 149/195 [2:28:42<47:26, 61.88s/it] 77%|███████▋  | 150/195 [2:29:34<44:01, 58.71s/it] 77%|███████▋  | 151/195 [2:30:31<42:40, 58.20s/it] 78%|███████▊  | 152/195 [2:31:27<41:15, 57.56s/it] 78%|███████▊  | 153/195 [2:32:31<41:35, 59.42s/it] 79%|███████▉  | 154/195 [2:33:31<40:46, 59.66s/it] 79%|███████▉  | 155/195 [2:34:34<40:27, 60.69s/it] 80%|████████  | 156/195 [2:35:33<39:14, 60.37s/it] 81%|████████  | 157/195 [2:36:32<37:51, 59.77s/it] 81%|████████  | 158/195 [2:37:28<36:15, 58.79s/it] 82%|████████▏ | 159/195 [2:38:29<35:40, 59.45s/it] 82%|████████▏ | 160/195 [2:39:25<34:03, 58.39s/it] 83%|████████▎ | 161/195 [2:40:25<33:18, 58.78s/it] 83%|████████▎ | 162/195 [2:41:23<32:15, 58.65s/it] 84%|████████▎ | 163/195 [2:42:33<33:07, 62.11s/it] 84%|████████▍ | 164/195 [2:43:31<31:24, 60.80s/it] 85%|████████▍ | 165/195 [2:44:29<29:59, 59.98s/it] 85%|████████▌ | 166/195 [2:45:37<30:06, 62.28s/it] 86%|████████▌ | 167/195 [2:46:38<28:52, 61.86s/it] 86%|████████▌ | 168/195 [2:47:33<26:54, 59.81s/it] 87%|████████▋ | 169/195 [2:48:26<25:02, 57.79s/it] 87%|████████▋ | 170/195 [2:49:28<24:40, 59.21s/it] 88%|████████▊ | 171/195 [2:50:32<24:11, 60.46s/it] 88%|████████▊ | 172/195 [2:51:37<23:40, 61.76s/it] 89%|████████▊ | 173/195 [2:52:30<21:45, 59.36s/it] 89%|████████▉ | 174/195 [2:53:24<20:11, 57.70s/it] 90%|████████▉ | 175/195 [2:54:24<19:27, 58.39s/it] 90%|█████████ | 176/195 [2:55:18<18:04, 57.07s/it] 91%|█████████ | 177/195 [2:56:24<17:53, 59.62s/it] 91%|█████████▏| 178/195 [2:57:21<16:42, 58.95s/it] 92%|█████████▏| 179/195 [2:58:24<16:03, 60.19s/it] 92%|█████████▏| 180/195 [2:59:26<15:09, 60.61s/it] 93%|█████████▎| 181/195 [3:00:27<14:09, 60.70s/it] 93%|█████████▎| 182/195 [3:01:29<13:14, 61.10s/it] 94%|█████████▍| 183/195 [3:02:29<12:08, 60.70s/it] 94%|█████████▍| 184/195 [3:03:31<11:12, 61.15s/it] 95%|█████████▍| 185/195 [3:04:36<10:23, 62.40s/it] 95%|█████████▌| 186/195 [3:05:37<09:18, 62.02s/it] 96%|█████████▌| 187/195 [3:06:43<08:26, 63.28s/it] 96%|█████████▋| 188/195 [3:07:37<07:03, 60.49s/it] 97%|█████████▋| 189/195 [3:08:37<06:00, 60.15s/it] 97%|█████████▋| 190/195 [3:09:33<04:55, 59.06s/it] 98%|█████████▊| 191/195 [3:10:34<03:58, 59.51s/it] 98%|█████████▊| 192/195 [3:11:35<03:00, 60.14s/it] 99%|█████████▉| 193/195 [3:12:42<02:04, 62.15s/it] 99%|█████████▉| 194/195 [3:13:38<01:00, 60.25s/it]100%|██████████| 195/195 [3:13:55<00:00, 47.24s/it]100%|██████████| 195/195 [3:13:55<00:00, 59.67s/it]
11/18/2022 20:15:38 - INFO - __main__ -     bleu-4 = 89.64 
11/18/2022 20:15:38 - INFO - __main__ -     xMatch = 6.7396 
11/18/2022 20:15:38 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 6.74 , BLEU: 89.64
CodeBLEU: 87.13
ngram_match_score: 87.13 , weighted_ngram_match_score: 89.68 , syntax_match_score: 89.12 , dataflow_match_score: 80.08
---------------------------------------------------------------------------------------------
on medium dataset, after_refactoring, refactoring type is method_renaming:
11/18/2022 20:16:08 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/method_renaming/after_refactoring/medium', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/after_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/after_refactoring/medium/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/18/2022 20:16:08 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/18/2022 20:16:11 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin
11/18/2022 20:16:14 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/after_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/method_renaming/after_refactoring/medium/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/195 [00:00<?, ?it/s]  1%|          | 1/195 [00:59<3:11:39, 59.28s/it]  1%|          | 2/195 [01:57<3:08:52, 58.72s/it]  2%|▏         | 3/195 [02:59<3:11:56, 59.98s/it]  2%|▏         | 4/195 [04:04<3:17:16, 61.97s/it]  3%|▎         | 5/195 [05:11<3:22:37, 63.98s/it]  3%|▎         | 6/195 [06:09<3:14:26, 61.73s/it]  4%|▎         | 7/195 [07:13<3:16:22, 62.67s/it]  4%|▍         | 8/195 [08:12<3:11:07, 61.33s/it]  5%|▍         | 9/195 [09:15<3:12:19, 62.04s/it]  5%|▌         | 10/195 [10:22<3:15:32, 63.42s/it]  6%|▌         | 11/195 [11:21<3:10:35, 62.15s/it]  6%|▌         | 12/195 [12:25<3:11:16, 62.71s/it]  7%|▋         | 13/195 [13:29<3:11:24, 63.10s/it]  7%|▋         | 14/195 [14:31<3:09:05, 62.68s/it]  8%|▊         | 15/195 [15:42<3:15:46, 65.26s/it]  8%|▊         | 16/195 [16:38<3:06:13, 62.42s/it]  9%|▊         | 17/195 [17:34<3:00:03, 60.69s/it]  9%|▉         | 18/195 [18:39<3:02:10, 61.75s/it] 10%|▉         | 19/195 [19:42<3:02:08, 62.09s/it] 10%|█         | 20/195 [20:39<2:56:58, 60.68s/it] 11%|█         | 21/195 [21:40<2:56:28, 60.85s/it] 11%|█▏        | 22/195 [22:42<2:55:59, 61.04s/it] 12%|█▏        | 23/195 [23:40<2:52:48, 60.28s/it] 12%|█▏        | 24/195 [24:44<2:54:56, 61.38s/it] 13%|█▎        | 25/195 [25:48<2:55:54, 62.08s/it] 13%|█▎        | 26/195 [26:53<2:57:28, 63.01s/it] 14%|█▍        | 27/195 [27:54<2:54:57, 62.49s/it] 14%|█▍        | 28/195 [28:55<2:52:15, 61.89s/it] 15%|█▍        | 29/195 [29:49<2:45:07, 59.68s/it] 15%|█▌        | 30/195 [30:48<2:43:42, 59.53s/it] 16%|█▌        | 31/195 [31:47<2:42:15, 59.37s/it] 16%|█▋        | 32/195 [32:40<2:35:27, 57.22s/it] 17%|█▋        | 33/195 [33:39<2:36:09, 57.84s/it] 17%|█▋        | 34/195 [34:41<2:38:51, 59.20s/it] 18%|█▊        | 35/195 [35:39<2:36:56, 58.85s/it] 18%|█▊        | 36/195 [36:40<2:37:09, 59.31s/it] 19%|█▉        | 37/195 [37:36<2:33:30, 58.29s/it] 19%|█▉        | 38/195 [38:35<2:33:16, 58.58s/it] 20%|██        | 39/195 [39:30<2:29:47, 57.61s/it] 21%|██        | 40/195 [40:35<2:34:36, 59.85s/it] 21%|██        | 41/195 [41:34<2:33:00, 59.61s/it] 22%|██▏       | 42/195 [42:34<2:31:39, 59.47s/it] 22%|██▏       | 43/195 [43:33<2:30:26, 59.39s/it] 23%|██▎       | 44/195 [44:27<2:25:22, 57.77s/it] 23%|██▎       | 45/195 [45:23<2:23:40, 57.47s/it] 24%|██▎       | 46/195 [46:28<2:27:55, 59.56s/it] 24%|██▍       | 47/195 [47:25<2:24:44, 58.68s/it] 25%|██▍       | 48/195 [48:29<2:28:20, 60.55s/it] 25%|██▌       | 49/195 [49:30<2:27:15, 60.52s/it] 26%|██▌       | 50/195 [50:27<2:24:05, 59.63s/it] 26%|██▌       | 51/195 [51:37<2:30:08, 62.56s/it] 27%|██▋       | 52/195 [52:30<2:22:43, 59.89s/it] 27%|██▋       | 53/195 [53:28<2:20:06, 59.20s/it] 28%|██▊       | 54/195 [54:40<2:27:51, 62.92s/it] 28%|██▊       | 55/195 [55:38<2:23:48, 61.63s/it] 29%|██▊       | 56/195 [56:40<2:22:50, 61.66s/it] 29%|██▉       | 57/195 [57:42<2:22:21, 61.89s/it] 30%|██▉       | 58/195 [58:40<2:18:25, 60.62s/it] 30%|███       | 59/195 [59:50<2:23:44, 63.42s/it] 31%|███       | 60/195 [1:00:59<2:26:11, 64.98s/it] 31%|███▏      | 61/195 [1:01:54<2:18:44, 62.12s/it] 32%|███▏      | 62/195 [1:02:56<2:17:33, 62.06s/it] 32%|███▏      | 63/195 [1:03:59<2:16:56, 62.25s/it] 33%|███▎      | 64/195 [1:05:07<2:20:03, 64.15s/it] 33%|███▎      | 65/195 [1:05:56<2:08:42, 59.40s/it] 34%|███▍      | 66/195 [1:06:55<2:07:36, 59.35s/it] 34%|███▍      | 67/195 [1:07:56<2:07:28, 59.75s/it] 35%|███▍      | 68/195 [1:08:49<2:02:41, 57.97s/it] 35%|███▌      | 69/195 [1:09:49<2:02:32, 58.35s/it] 36%|███▌      | 70/195 [1:10:50<2:03:36, 59.33s/it] 36%|███▋      | 71/195 [1:11:52<2:04:14, 60.12s/it] 37%|███▋      | 72/195 [1:12:43<1:57:23, 57.27s/it] 37%|███▋      | 73/195 [1:13:49<2:01:57, 59.98s/it] 38%|███▊      | 74/195 [1:14:43<1:56:57, 58.00s/it] 38%|███▊      | 75/195 [1:15:43<1:57:23, 58.70s/it] 39%|███▉      | 76/195 [1:16:40<1:55:31, 58.25s/it] 39%|███▉      | 77/195 [1:17:39<1:54:50, 58.39s/it] 40%|████      | 78/195 [1:18:37<1:53:39, 58.28s/it] 41%|████      | 79/195 [1:19:37<1:53:57, 58.94s/it] 41%|████      | 80/195 [1:20:38<1:53:45, 59.35s/it] 42%|████▏     | 81/195 [1:21:37<1:52:36, 59.26s/it] 42%|████▏     | 82/195 [1:22:36<1:51:36, 59.26s/it] 43%|████▎     | 83/195 [1:23:32<1:49:04, 58.43s/it] 43%|████▎     | 84/195 [1:24:36<1:50:42, 59.84s/it] 44%|████▎     | 85/195 [1:25:41<1:53:02, 61.66s/it] 44%|████▍     | 86/195 [1:26:40<1:50:11, 60.66s/it] 45%|████▍     | 87/195 [1:27:40<1:49:09, 60.64s/it] 45%|████▌     | 88/195 [1:28:36<1:45:30, 59.16s/it] 46%|████▌     | 89/195 [1:29:45<1:49:46, 62.14s/it] 46%|████▌     | 90/195 [1:30:51<1:50:46, 63.30s/it] 47%|████▋     | 91/195 [1:31:55<1:49:51, 63.38s/it] 47%|████▋     | 92/195 [1:33:00<1:49:33, 63.82s/it] 48%|████▊     | 93/195 [1:33:59<1:46:16, 62.51s/it] 48%|████▊     | 94/195 [1:35:05<1:47:03, 63.60s/it] 49%|████▊     | 95/195 [1:36:05<1:44:17, 62.57s/it] 49%|████▉     | 96/195 [1:37:04<1:41:13, 61.35s/it] 50%|████▉     | 97/195 [1:37:59<1:37:22, 59.62s/it] 50%|█████     | 98/195 [1:39:05<1:39:15, 61.40s/it] 51%|█████     | 99/195 [1:40:05<1:37:21, 60.85s/it] 51%|█████▏    | 100/195 [1:41:05<1:36:10, 60.75s/it] 52%|█████▏    | 101/195 [1:41:59<1:31:49, 58.62s/it] 52%|█████▏    | 102/195 [1:42:55<1:29:35, 57.80s/it] 53%|█████▎    | 103/195 [1:43:51<1:27:57, 57.37s/it] 53%|█████▎    | 104/195 [1:44:51<1:28:06, 58.09s/it] 54%|█████▍    | 105/195 [1:45:54<1:29:35, 59.73s/it] 54%|█████▍    | 106/195 [1:46:51<1:27:18, 58.86s/it] 55%|█████▍    | 107/195 [1:47:52<1:27:20, 59.55s/it] 55%|█████▌    | 108/195 [1:48:54<1:27:11, 60.13s/it] 56%|█████▌    | 109/195 [1:49:54<1:26:07, 60.09s/it] 56%|█████▋    | 110/195 [1:50:56<1:26:13, 60.87s/it] 57%|█████▋    | 111/195 [1:51:56<1:24:39, 60.46s/it] 57%|█████▋    | 112/195 [1:52:56<1:23:35, 60.43s/it] 58%|█████▊    | 113/195 [1:54:01<1:24:20, 61.72s/it] 58%|█████▊    | 114/195 [1:55:04<1:23:49, 62.09s/it] 59%|█████▉    | 115/195 [1:56:06<1:22:34, 61.93s/it] 59%|█████▉    | 116/195 [1:57:07<1:21:23, 61.81s/it] 60%|██████    | 117/195 [1:58:10<1:20:37, 62.02s/it] 61%|██████    | 118/195 [1:59:10<1:19:08, 61.66s/it] 61%|██████    | 119/195 [2:00:12<1:18:11, 61.73s/it] 62%|██████▏   | 120/195 [2:01:19<1:18:57, 63.17s/it] 62%|██████▏   | 121/195 [2:02:12<1:14:22, 60.31s/it] 63%|██████▎   | 122/195 [2:03:14<1:13:53, 60.73s/it] 63%|██████▎   | 123/195 [2:04:13<1:12:18, 60.26s/it] 64%|██████▎   | 124/195 [2:05:11<1:10:14, 59.36s/it] 64%|██████▍   | 125/195 [2:06:13<1:10:24, 60.35s/it] 65%|██████▍   | 126/195 [2:07:07<1:07:12, 58.44s/it] 65%|██████▌   | 127/195 [2:08:08<1:07:03, 59.17s/it] 66%|██████▌   | 128/195 [2:09:07<1:05:49, 58.95s/it] 66%|██████▌   | 129/195 [2:10:04<1:04:25, 58.56s/it] 67%|██████▋   | 130/195 [2:11:03<1:03:27, 58.58s/it] 67%|██████▋   | 131/195 [2:12:02<1:02:37, 58.72s/it] 68%|██████▊   | 132/195 [2:12:59<1:01:12, 58.30s/it] 68%|██████▊   | 133/195 [2:14:00<1:01:01, 59.05s/it] 69%|██████▊   | 134/195 [2:15:09<1:03:02, 62.00s/it] 69%|██████▉   | 135/195 [2:16:01<58:58, 58.98s/it]   70%|██████▉   | 136/195 [2:16:58<57:20, 58.31s/it] 70%|███████   | 137/195 [2:18:10<1:00:22, 62.45s/it] 71%|███████   | 138/195 [2:19:07<57:58, 61.03s/it]   71%|███████▏  | 139/195 [2:20:01<55:01, 58.96s/it] 72%|███████▏  | 140/195 [2:21:05<55:10, 60.20s/it] 72%|███████▏  | 141/195 [2:22:07<54:45, 60.84s/it] 73%|███████▎  | 142/195 [2:23:03<52:26, 59.36s/it] 73%|███████▎  | 143/195 [2:24:07<52:41, 60.80s/it] 74%|███████▍  | 144/195 [2:25:06<51:11, 60.22s/it] 74%|███████▍  | 145/195 [2:26:05<49:51, 59.83s/it] 75%|███████▍  | 146/195 [2:27:09<49:52, 61.07s/it] 75%|███████▌  | 147/195 [2:28:15<50:10, 62.71s/it] 76%|███████▌  | 148/195 [2:29:14<48:07, 61.43s/it] 76%|███████▋  | 149/195 [2:30:17<47:38, 62.13s/it] 77%|███████▋  | 150/195 [2:31:08<44:02, 58.71s/it] 77%|███████▋  | 151/195 [2:32:05<42:43, 58.27s/it] 78%|███████▊  | 152/195 [2:33:02<41:22, 57.74s/it] 78%|███████▊  | 153/195 [2:34:06<41:41, 59.56s/it] 79%|███████▉  | 154/195 [2:35:06<40:47, 59.68s/it] 79%|███████▉  | 155/195 [2:36:09<40:31, 60.79s/it] 80%|████████  | 156/195 [2:37:09<39:23, 60.60s/it] 81%|████████  | 157/195 [2:38:08<38:07, 60.19s/it] 81%|████████  | 158/195 [2:39:06<36:33, 59.27s/it] 82%|████████▏ | 159/195 [2:40:07<36:00, 60.00s/it] 82%|████████▏ | 160/195 [2:41:04<34:25, 59.01s/it] 83%|████████▎ | 161/195 [2:42:04<33:33, 59.22s/it] 83%|████████▎ | 162/195 [2:43:03<32:38, 59.35s/it] 84%|████████▎ | 163/195 [2:44:14<33:31, 62.87s/it] 84%|████████▍ | 164/195 [2:45:13<31:47, 61.52s/it] 85%|████████▍ | 165/195 [2:46:11<30:14, 60.47s/it] 85%|████████▌ | 166/195 [2:47:19<30:18, 62.70s/it] 86%|████████▌ | 167/195 [2:48:20<29:04, 62.32s/it] 86%|████████▌ | 168/195 [2:49:15<26:58, 59.94s/it] 87%|████████▋ | 169/195 [2:50:08<25:04, 57.87s/it] 87%|████████▋ | 170/195 [2:51:10<24:38, 59.14s/it] 88%|████████▊ | 171/195 [2:52:13<24:08, 60.37s/it] 88%|████████▊ | 172/195 [2:53:18<23:39, 61.70s/it] 89%|████████▊ | 173/195 [2:54:12<21:48, 59.48s/it] 89%|████████▉ | 174/195 [2:55:07<20:17, 57.98s/it] 90%|████████▉ | 175/195 [2:56:06<19:28, 58.44s/it] 90%|█████████ | 176/195 [2:57:00<18:06, 57.20s/it] 91%|█████████ | 177/195 [2:58:06<17:55, 59.73s/it] 91%|█████████▏| 178/195 [2:59:04<16:48, 59.33s/it] 92%|█████████▏| 179/195 [3:00:07<16:07, 60.45s/it] 92%|█████████▏| 180/195 [3:01:09<15:13, 60.89s/it] 93%|█████████▎| 181/195 [3:02:10<14:13, 60.96s/it] 93%|█████████▎| 182/195 [3:03:12<13:15, 61.16s/it] 94%|█████████▍| 183/195 [3:04:13<12:11, 60.94s/it] 94%|█████████▍| 184/195 [3:05:15<11:15, 61.42s/it] 95%|█████████▍| 185/195 [3:06:20<10:26, 62.61s/it] 95%|█████████▌| 186/195 [3:07:22<09:20, 62.29s/it] 96%|█████████▌| 187/195 [3:08:28<08:27, 63.45s/it] 96%|█████████▋| 188/195 [3:09:22<07:03, 60.54s/it] 97%|█████████▋| 189/195 [3:10:22<06:01, 60.33s/it] 97%|█████████▋| 190/195 [3:11:18<04:55, 59.15s/it] 98%|█████████▊| 191/195 [3:12:20<03:59, 59.86s/it] 98%|█████████▊| 192/195 [3:13:21<03:00, 60.33s/it] 99%|█████████▉| 193/195 [3:14:29<02:05, 62.53s/it] 99%|█████████▉| 194/195 [3:15:25<01:00, 60.57s/it]100%|██████████| 195/195 [3:15:41<00:00, 47.42s/it]100%|██████████| 195/195 [3:15:41<00:00, 60.22s/it]
11/18/2022 23:32:10 - INFO - __main__ -     bleu-4 = 89.67 
11/18/2022 23:32:10 - INFO - __main__ -     xMatch = 6.4983 
11/18/2022 23:32:10 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 6.5 , BLEU: 89.67
CodeBLEU: 87.2
ngram_match_score: 87.2 , weighted_ngram_match_score: 89.71 , syntax_match_score: 89.16 , dataflow_match_score: 80.26
---------------------------------------------------------------------------------------------
on small dataset, before_refactoring, refactoring type is parameter_renaming:
11/18/2022 23:32:40 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/parameter_renaming/before_refactoring/small', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/before_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/before_refactoring/small/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/18/2022 23:32:40 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/18/2022 23:32:43 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin
11/18/2022 23:32:46 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/before_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/before_refactoring/small/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/108 [00:00<?, ?it/s]  1%|          | 1/108 [00:24<43:32, 24.42s/it]  2%|▏         | 2/108 [00:53<47:30, 26.89s/it]  3%|▎         | 3/108 [01:18<45:38, 26.08s/it]  4%|▎         | 4/108 [01:44<45:37, 26.32s/it]  5%|▍         | 5/108 [02:09<43:58, 25.62s/it]  6%|▌         | 6/108 [02:31<41:40, 24.51s/it]  6%|▋         | 7/108 [02:55<41:10, 24.46s/it]  7%|▋         | 8/108 [03:18<39:48, 23.88s/it]  8%|▊         | 9/108 [03:42<39:11, 23.75s/it]  9%|▉         | 10/108 [04:05<38:50, 23.78s/it] 10%|█         | 11/108 [04:30<38:55, 24.07s/it] 11%|█         | 12/108 [04:53<37:51, 23.67s/it] 12%|█▏        | 13/108 [05:17<37:34, 23.73s/it] 13%|█▎        | 14/108 [05:40<37:04, 23.66s/it] 14%|█▍        | 15/108 [06:09<39:02, 25.19s/it] 15%|█▍        | 16/108 [06:32<37:49, 24.67s/it] 16%|█▌        | 17/108 [06:56<36:51, 24.30s/it] 17%|█▋        | 18/108 [07:21<36:37, 24.41s/it] 18%|█▊        | 19/108 [07:46<36:38, 24.70s/it] 19%|█▊        | 20/108 [08:07<34:44, 23.69s/it] 19%|█▉        | 21/108 [08:29<33:24, 23.04s/it] 20%|██        | 22/108 [08:54<33:47, 23.58s/it] 21%|██▏       | 23/108 [09:18<33:35, 23.71s/it] 22%|██▏       | 24/108 [09:43<33:54, 24.22s/it] 23%|██▎       | 25/108 [10:05<32:38, 23.60s/it] 24%|██▍       | 26/108 [10:31<33:02, 24.18s/it] 25%|██▌       | 27/108 [10:58<33:55, 25.13s/it] 26%|██▌       | 28/108 [11:23<33:25, 25.07s/it] 27%|██▋       | 29/108 [11:49<33:20, 25.32s/it] 28%|██▊       | 30/108 [12:12<32:07, 24.71s/it] 29%|██▊       | 31/108 [12:34<30:29, 23.76s/it] 30%|██▉       | 32/108 [12:58<30:08, 23.80s/it] 31%|███       | 33/108 [13:23<30:26, 24.35s/it] 31%|███▏      | 34/108 [13:44<28:46, 23.33s/it] 32%|███▏      | 35/108 [14:10<29:06, 23.92s/it] 33%|███▎      | 36/108 [14:37<30:05, 25.08s/it] 34%|███▍      | 37/108 [15:01<29:20, 24.80s/it] 35%|███▌      | 38/108 [15:28<29:28, 25.27s/it] 36%|███▌      | 39/108 [15:51<28:13, 24.54s/it] 37%|███▋      | 40/108 [16:14<27:28, 24.24s/it] 38%|███▊      | 41/108 [16:41<27:55, 25.01s/it] 39%|███▉      | 42/108 [17:04<26:44, 24.30s/it] 40%|███▉      | 43/108 [17:27<25:56, 23.94s/it] 41%|████      | 44/108 [17:49<24:53, 23.33s/it] 42%|████▏     | 45/108 [18:11<24:06, 22.96s/it] 43%|████▎     | 46/108 [18:36<24:20, 23.56s/it] 44%|████▎     | 47/108 [18:59<23:49, 23.44s/it] 44%|████▍     | 48/108 [19:22<23:13, 23.23s/it] 45%|████▌     | 49/108 [19:49<23:59, 24.40s/it] 46%|████▋     | 50/108 [20:13<23:34, 24.39s/it] 47%|████▋     | 51/108 [20:38<23:18, 24.53s/it] 48%|████▊     | 52/108 [21:02<22:37, 24.23s/it] 49%|████▉     | 53/108 [21:27<22:32, 24.59s/it] 50%|█████     | 54/108 [21:59<24:11, 26.87s/it] 51%|█████     | 55/108 [22:28<24:19, 27.53s/it] 52%|█████▏    | 56/108 [22:53<23:11, 26.75s/it] 53%|█████▎    | 57/108 [23:19<22:27, 26.42s/it] 54%|█████▎    | 58/108 [23:42<21:10, 25.41s/it] 55%|█████▍    | 59/108 [24:07<20:44, 25.40s/it] 56%|█████▌    | 60/108 [24:39<21:44, 27.19s/it] 56%|█████▋    | 61/108 [25:11<22:31, 28.75s/it] 57%|█████▋    | 62/108 [25:38<21:44, 28.37s/it] 58%|█████▊    | 63/108 [26:05<20:51, 27.81s/it] 59%|█████▉    | 64/108 [26:30<19:41, 26.85s/it] 60%|██████    | 65/108 [26:56<19:05, 26.64s/it] 61%|██████    | 66/108 [27:22<18:32, 26.49s/it] 62%|██████▏   | 67/108 [27:44<17:17, 25.30s/it] 63%|██████▎   | 68/108 [28:08<16:38, 24.95s/it] 64%|██████▍   | 69/108 [28:30<15:32, 23.90s/it] 65%|██████▍   | 70/108 [28:54<15:05, 23.84s/it] 66%|██████▌   | 71/108 [29:17<14:31, 23.56s/it] 67%|██████▋   | 72/108 [29:41<14:13, 23.72s/it] 68%|██████▊   | 73/108 [30:10<14:52, 25.50s/it] 69%|██████▊   | 74/108 [30:32<13:50, 24.42s/it] 69%|██████▉   | 75/108 [30:59<13:45, 25.00s/it] 70%|███████   | 76/108 [31:30<14:17, 26.80s/it] 71%|███████▏  | 77/108 [31:58<14:02, 27.19s/it] 72%|███████▏  | 78/108 [32:22<13:10, 26.35s/it] 73%|███████▎  | 79/108 [32:46<12:26, 25.76s/it] 74%|███████▍  | 80/108 [33:09<11:33, 24.77s/it] 75%|███████▌  | 81/108 [33:29<10:32, 23.41s/it] 76%|███████▌  | 82/108 [33:54<10:20, 23.85s/it] 77%|███████▋  | 83/108 [34:18<09:53, 23.76s/it] 78%|███████▊  | 84/108 [34:41<09:24, 23.53s/it] 79%|███████▊  | 85/108 [35:05<09:06, 23.74s/it] 80%|███████▉  | 86/108 [35:26<08:25, 22.96s/it] 81%|████████  | 87/108 [35:50<08:11, 23.41s/it] 81%|████████▏ | 88/108 [36:13<07:42, 23.13s/it] 82%|████████▏ | 89/108 [36:35<07:13, 22.80s/it] 83%|████████▎ | 90/108 [36:58<06:50, 22.83s/it] 84%|████████▍ | 91/108 [37:17<06:08, 21.69s/it] 85%|████████▌ | 92/108 [37:43<06:09, 23.06s/it] 86%|████████▌ | 93/108 [38:08<05:53, 23.58s/it] 87%|████████▋ | 94/108 [38:31<05:30, 23.59s/it] 88%|████████▊ | 95/108 [38:57<05:13, 24.13s/it] 89%|████████▉ | 96/108 [39:19<04:43, 23.63s/it] 90%|████████▉ | 97/108 [39:47<04:33, 24.86s/it] 91%|█████████ | 98/108 [40:13<04:12, 25.22s/it] 92%|█████████▏| 99/108 [40:40<03:51, 25.75s/it] 93%|█████████▎| 100/108 [41:08<03:30, 26.31s/it] 94%|█████████▎| 101/108 [41:36<03:08, 26.87s/it] 94%|█████████▍| 102/108 [42:05<02:44, 27.39s/it] 95%|█████████▌| 103/108 [42:29<02:12, 26.54s/it] 96%|█████████▋| 104/108 [42:59<01:50, 27.60s/it] 97%|█████████▋| 105/108 [43:28<01:24, 28.05s/it] 98%|█████████▊| 106/108 [43:52<00:53, 26.75s/it] 99%|█████████▉| 107/108 [44:14<00:25, 25.27s/it]100%|██████████| 108/108 [44:29<00:00, 22.28s/it]100%|██████████| 108/108 [44:29<00:00, 24.72s/it]
11/19/2022 00:17:20 - INFO - __main__ -     bleu-4 = 80.37 
11/19/2022 00:17:20 - INFO - __main__ -     xMatch = 18.6702 
11/19/2022 00:17:20 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 18.67 , BLEU: 80.37
CodeBLEU: 80.67
ngram_match_score: 80.67 , weighted_ngram_match_score: 80.6 , syntax_match_score: 83.16 , dataflow_match_score: 78.55
---------------------------------------------------------------------------------------------
on small dataset, after_refactoring, refactoring type is parameter_renaming:
11/19/2022 00:17:30 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/parameter_renaming/after_refactoring/small', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/after_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/after_refactoring/small/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/19/2022 00:17:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/19/2022 00:17:32 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin
11/19/2022 00:17:36 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/after_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/after_refactoring/small/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/108 [00:00<?, ?it/s]  1%|          | 1/108 [00:26<47:41, 26.74s/it]  2%|▏         | 2/108 [00:57<51:42, 29.27s/it]  3%|▎         | 3/108 [01:24<49:20, 28.19s/it]  4%|▎         | 4/108 [01:51<48:08, 27.77s/it]  5%|▍         | 5/108 [02:18<46:42, 27.21s/it]  6%|▌         | 6/108 [02:41<43:53, 25.81s/it]  6%|▋         | 7/108 [03:06<43:02, 25.57s/it]  7%|▋         | 8/108 [03:28<41:03, 24.64s/it]  8%|▊         | 9/108 [03:54<41:13, 24.98s/it]  9%|▉         | 10/108 [04:18<40:29, 24.79s/it] 10%|█         | 11/108 [04:44<40:33, 25.09s/it] 11%|█         | 12/108 [05:08<39:43, 24.82s/it] 12%|█▏        | 13/108 [05:33<39:11, 24.75s/it] 13%|█▎        | 14/108 [05:57<38:35, 24.64s/it] 14%|█▍        | 15/108 [06:29<41:19, 26.66s/it] 15%|█▍        | 16/108 [06:54<40:03, 26.12s/it] 16%|█▌        | 17/108 [07:17<38:32, 25.41s/it] 17%|█▋        | 18/108 [07:45<39:04, 26.05s/it] 18%|█▊        | 19/108 [08:14<40:13, 27.11s/it] 19%|█▊        | 20/108 [08:37<37:38, 25.66s/it] 19%|█▉        | 21/108 [08:59<35:41, 24.62s/it] 20%|██        | 22/108 [09:27<36:37, 25.56s/it] 21%|██▏       | 23/108 [09:53<36:27, 25.73s/it] 22%|██▏       | 24/108 [10:20<36:47, 26.28s/it] 23%|██▎       | 25/108 [10:45<35:51, 25.92s/it] 24%|██▍       | 26/108 [11:13<36:09, 26.45s/it] 25%|██▌       | 27/108 [11:42<36:33, 27.08s/it] 26%|██▌       | 28/108 [12:07<35:32, 26.66s/it] 27%|██▋       | 29/108 [12:35<35:28, 26.94s/it] 28%|██▊       | 30/108 [13:00<34:14, 26.34s/it] 29%|██▊       | 31/108 [13:22<32:06, 25.02s/it] 30%|██▉       | 32/108 [13:46<31:25, 24.81s/it] 31%|███       | 33/108 [14:14<32:13, 25.78s/it] 31%|███▏      | 34/108 [14:37<30:51, 25.02s/it] 32%|███▏      | 35/108 [15:04<30:56, 25.44s/it] 33%|███▎      | 36/108 [15:34<32:07, 26.78s/it] 34%|███▍      | 37/108 [15:58<30:55, 26.14s/it] 35%|███▌      | 38/108 [16:27<31:16, 26.81s/it] 36%|███▌      | 39/108 [16:52<30:15, 26.31s/it] 37%|███▋      | 40/108 [17:17<29:25, 25.97s/it] 38%|███▊      | 41/108 [17:45<29:39, 26.56s/it] 39%|███▉      | 42/108 [18:09<28:30, 25.92s/it] 40%|███▉      | 43/108 [18:36<28:11, 26.02s/it] 41%|████      | 44/108 [18:59<26:51, 25.18s/it] 42%|████▏     | 45/108 [19:21<25:28, 24.26s/it] 43%|████▎     | 46/108 [19:49<26:17, 25.44s/it] 44%|████▎     | 47/108 [20:14<25:45, 25.34s/it] 44%|████▍     | 48/108 [20:38<24:53, 24.89s/it] 45%|████▌     | 49/108 [21:07<25:39, 26.09s/it] 46%|████▋     | 50/108 [21:34<25:19, 26.19s/it] 47%|████▋     | 51/108 [21:59<24:38, 25.93s/it] 48%|████▊     | 52/108 [22:25<24:15, 25.99s/it] 49%|████▉     | 53/108 [22:52<24:08, 26.35s/it] 50%|█████     | 54/108 [23:22<24:39, 27.40s/it] 51%|█████     | 55/108 [23:49<24:03, 27.24s/it] 52%|█████▏    | 56/108 [24:15<23:21, 26.96s/it] 53%|█████▎    | 57/108 [24:42<22:46, 26.80s/it] 54%|█████▎    | 58/108 [25:05<21:22, 25.65s/it] 55%|█████▍    | 59/108 [25:31<21:11, 25.95s/it] 56%|█████▌    | 60/108 [26:04<22:17, 27.86s/it] 56%|█████▋    | 61/108 [26:37<23:09, 29.56s/it] 57%|█████▋    | 62/108 [27:06<22:34, 29.45s/it] 58%|█████▊    | 63/108 [27:36<22:02, 29.39s/it] 59%|█████▉    | 64/108 [28:04<21:17, 29.03s/it] 60%|██████    | 65/108 [28:35<21:16, 29.69s/it] 61%|██████    | 66/108 [29:03<20:27, 29.24s/it] 62%|██████▏   | 67/108 [29:28<19:01, 27.84s/it] 63%|██████▎   | 68/108 [29:53<18:05, 27.13s/it] 64%|██████▍   | 69/108 [30:16<16:42, 25.70s/it] 65%|██████▍   | 70/108 [30:40<16:05, 25.39s/it] 66%|██████▌   | 71/108 [31:04<15:26, 25.05s/it] 67%|██████▋   | 72/108 [31:30<15:10, 25.28s/it] 68%|██████▊   | 73/108 [32:04<16:09, 27.70s/it] 69%|██████▊   | 74/108 [32:29<15:15, 26.93s/it] 69%|██████▉   | 75/108 [32:57<14:57, 27.21s/it] 70%|███████   | 76/108 [33:23<14:24, 27.03s/it] 71%|███████▏  | 77/108 [33:52<14:18, 27.68s/it] 72%|███████▏  | 78/108 [34:16<13:12, 26.41s/it] 73%|███████▎  | 79/108 [34:41<12:31, 25.90s/it] 74%|███████▍  | 80/108 [35:04<11:45, 25.18s/it] 75%|███████▌  | 81/108 [35:30<11:24, 25.34s/it] 76%|███████▌  | 82/108 [35:57<11:10, 25.79s/it] 77%|███████▋  | 83/108 [36:22<10:44, 25.78s/it] 78%|███████▊  | 84/108 [36:47<10:10, 25.44s/it] 79%|███████▊  | 85/108 [37:15<10:05, 26.32s/it] 80%|███████▉  | 86/108 [37:40<09:30, 25.94s/it] 81%|████████  | 87/108 [38:09<09:20, 26.71s/it] 81%|████████▏ | 88/108 [38:33<08:35, 25.79s/it] 82%|████████▏ | 89/108 [38:56<07:55, 25.01s/it] 83%|████████▎ | 90/108 [39:21<07:30, 25.01s/it] 84%|████████▍ | 91/108 [39:41<06:41, 23.61s/it] 85%|████████▌ | 92/108 [40:10<06:41, 25.09s/it] 86%|████████▌ | 93/108 [40:35<06:17, 25.18s/it] 87%|████████▋ | 94/108 [41:01<05:53, 25.27s/it] 88%|████████▊ | 95/108 [41:27<05:34, 25.70s/it] 89%|████████▉ | 96/108 [41:51<05:01, 25.13s/it] 90%|████████▉ | 97/108 [42:18<04:41, 25.61s/it] 91%|█████████ | 98/108 [42:44<04:17, 25.79s/it] 92%|█████████▏| 99/108 [43:09<03:49, 25.49s/it] 93%|█████████▎| 100/108 [43:33<03:21, 25.25s/it] 94%|█████████▎| 101/108 [44:00<02:59, 25.67s/it] 94%|█████████▍| 102/108 [44:29<02:39, 26.59s/it] 95%|█████████▌| 103/108 [44:52<02:07, 25.58s/it] 96%|█████████▋| 104/108 [45:18<01:43, 25.76s/it] 97%|█████████▋| 105/108 [45:46<01:19, 26.44s/it] 98%|█████████▊| 106/108 [46:11<00:51, 25.84s/it] 99%|█████████▉| 107/108 [46:34<00:25, 25.08s/it]100%|██████████| 108/108 [46:50<00:00, 22.31s/it]100%|██████████| 108/108 [46:50<00:00, 26.02s/it]
11/19/2022 01:04:31 - INFO - __main__ -     bleu-4 = 78.9 
11/19/2022 01:04:31 - INFO - __main__ -     xMatch = 14.0534 
11/19/2022 01:04:31 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 14.05 , BLEU: 78.9
CodeBLEU: 79.51
ngram_match_score: 79.51 , weighted_ngram_match_score: 79.16 , syntax_match_score: 82.27 , dataflow_match_score: 77.7
---------------------------------------------------------------------------------------------
on medium dataset, before_refactoring, refactoring type is parameter_renaming:
11/19/2022 01:04:40 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/parameter_renaming/before_refactoring/medium', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/before_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/before_refactoring/medium/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/19/2022 01:04:41 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/19/2022 01:04:43 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin
11/19/2022 01:04:47 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/before_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/before_refactoring/medium/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/135 [00:00<?, ?it/s]  1%|          | 1/135 [01:01<2:18:04, 61.83s/it]  1%|▏         | 2/135 [02:04<2:18:06, 62.30s/it]  2%|▏         | 3/135 [03:12<2:22:28, 64.76s/it]  3%|▎         | 4/135 [04:09<2:14:43, 61.71s/it]  4%|▎         | 5/135 [05:16<2:18:25, 63.89s/it]  4%|▍         | 6/135 [06:18<2:15:20, 62.95s/it]  5%|▌         | 7/135 [07:23<2:16:07, 63.81s/it]  6%|▌         | 8/135 [08:30<2:17:10, 64.81s/it]  7%|▋         | 9/135 [09:37<2:17:12, 65.34s/it]  7%|▋         | 10/135 [10:45<2:18:00, 66.25s/it]  8%|▊         | 11/135 [11:48<2:15:06, 65.38s/it]  9%|▉         | 12/135 [12:45<2:08:31, 62.69s/it] 10%|▉         | 13/135 [13:50<2:09:17, 63.59s/it] 10%|█         | 14/135 [14:47<2:03:52, 61.43s/it] 11%|█         | 15/135 [15:50<2:03:37, 61.81s/it] 12%|█▏        | 16/135 [16:46<1:59:30, 60.26s/it] 13%|█▎        | 17/135 [17:58<2:05:12, 63.67s/it] 13%|█▎        | 18/135 [18:58<2:01:55, 62.53s/it] 14%|█▍        | 19/135 [20:00<2:00:43, 62.44s/it] 15%|█▍        | 20/135 [20:52<1:53:27, 59.19s/it] 16%|█▌        | 21/135 [21:47<1:50:26, 58.12s/it] 16%|█▋        | 22/135 [22:45<1:49:09, 57.96s/it] 17%|█▋        | 23/135 [23:43<1:48:18, 58.02s/it] 18%|█▊        | 24/135 [24:46<1:50:20, 59.64s/it] 19%|█▊        | 25/135 [25:46<1:49:23, 59.67s/it] 19%|█▉        | 26/135 [26:39<1:44:54, 57.74s/it] 20%|██        | 27/135 [27:36<1:43:28, 57.49s/it] 21%|██        | 28/135 [28:37<1:44:05, 58.37s/it] 21%|██▏       | 29/135 [29:36<1:43:25, 58.55s/it] 22%|██▏       | 30/135 [30:37<1:43:55, 59.38s/it] 23%|██▎       | 31/135 [31:36<1:42:45, 59.28s/it] 24%|██▎       | 32/135 [32:42<1:45:25, 61.41s/it] 24%|██▍       | 33/135 [33:49<1:47:03, 62.97s/it] 25%|██▌       | 34/135 [34:54<1:46:58, 63.55s/it] 26%|██▌       | 35/135 [35:56<1:45:11, 63.11s/it] 27%|██▋       | 36/135 [37:03<1:45:58, 64.23s/it] 27%|██▋       | 37/135 [38:04<1:43:32, 63.39s/it] 28%|██▊       | 38/135 [39:07<1:42:11, 63.21s/it] 29%|██▉       | 39/135 [40:08<1:40:09, 62.60s/it] 30%|██▉       | 40/135 [41:09<1:38:02, 61.92s/it] 30%|███       | 41/135 [42:17<1:40:09, 63.94s/it] 31%|███       | 42/135 [43:30<1:43:16, 66.63s/it] 32%|███▏      | 43/135 [44:23<1:35:50, 62.51s/it] 33%|███▎      | 44/135 [45:25<1:34:39, 62.41s/it] 33%|███▎      | 45/135 [46:34<1:36:41, 64.46s/it] 34%|███▍      | 46/135 [47:26<1:29:38, 60.44s/it] 35%|███▍      | 47/135 [48:28<1:29:20, 60.91s/it] 36%|███▌      | 48/135 [49:24<1:26:11, 59.44s/it] 36%|███▋      | 49/135 [50:22<1:24:33, 58.99s/it] 37%|███▋      | 50/135 [51:18<1:22:41, 58.38s/it] 38%|███▊      | 51/135 [52:18<1:22:12, 58.72s/it] 39%|███▊      | 52/135 [53:14<1:19:54, 57.77s/it] 39%|███▉      | 53/135 [54:15<1:20:28, 58.89s/it] 40%|████      | 54/135 [55:10<1:18:01, 57.80s/it] 41%|████      | 55/135 [56:13<1:19:00, 59.26s/it] 41%|████▏     | 56/135 [57:16<1:19:25, 60.32s/it] 42%|████▏     | 57/135 [58:17<1:18:49, 60.64s/it] 43%|████▎     | 58/135 [59:18<1:17:46, 60.60s/it] 44%|████▎     | 59/135 [1:00:20<1:17:16, 61.00s/it] 44%|████▍     | 60/135 [1:01:26<1:18:07, 62.50s/it] 45%|████▌     | 61/135 [1:02:25<1:15:46, 61.44s/it] 46%|████▌     | 62/135 [1:03:21<1:12:48, 59.84s/it] 47%|████▋     | 63/135 [1:04:28<1:14:25, 62.02s/it] 47%|████▋     | 64/135 [1:05:34<1:14:55, 63.31s/it] 48%|████▊     | 65/135 [1:06:40<1:14:37, 63.96s/it] 49%|████▉     | 66/135 [1:07:39<1:11:58, 62.58s/it] 50%|████▉     | 67/135 [1:08:49<1:13:33, 64.91s/it] 50%|█████     | 68/135 [1:09:53<1:11:57, 64.44s/it] 51%|█████     | 69/135 [1:10:58<1:11:04, 64.62s/it] 52%|█████▏    | 70/135 [1:11:52<1:06:31, 61.41s/it] 53%|█████▎    | 71/135 [1:12:52<1:05:06, 61.04s/it] 53%|█████▎    | 72/135 [1:13:49<1:02:55, 59.94s/it] 54%|█████▍    | 73/135 [1:14:50<1:02:14, 60.23s/it] 55%|█████▍    | 74/135 [1:15:55<1:02:32, 61.52s/it] 56%|█████▌    | 75/135 [1:16:54<1:00:52, 60.88s/it] 56%|█████▋    | 76/135 [1:17:56<1:00:19, 61.35s/it] 57%|█████▋    | 77/135 [1:18:57<59:12, 61.24s/it]   58%|█████▊    | 78/135 [1:19:54<56:49, 59.82s/it] 59%|█████▊    | 79/135 [1:20:58<57:03, 61.14s/it] 59%|█████▉    | 80/135 [1:21:59<55:57, 61.05s/it] 60%|██████    | 81/135 [1:23:00<54:51, 60.96s/it] 61%|██████    | 82/135 [1:24:05<54:56, 62.20s/it] 61%|██████▏   | 83/135 [1:25:07<53:54, 62.19s/it] 62%|██████▏   | 84/135 [1:26:11<53:26, 62.88s/it] 63%|██████▎   | 85/135 [1:27:14<52:21, 62.84s/it] 64%|██████▎   | 86/135 [1:28:15<50:50, 62.26s/it] 64%|██████▍   | 87/135 [1:29:11<48:20, 60.42s/it] 65%|██████▌   | 88/135 [1:30:07<46:17, 59.09s/it] 66%|██████▌   | 89/135 [1:31:06<45:14, 59.00s/it] 67%|██████▋   | 90/135 [1:32:01<43:25, 57.90s/it] 67%|██████▋   | 91/135 [1:33:04<43:31, 59.36s/it] 68%|██████▊   | 92/135 [1:34:03<42:28, 59.26s/it] 69%|██████▉   | 93/135 [1:35:04<41:47, 59.71s/it] 70%|██████▉   | 94/135 [1:36:01<40:17, 58.97s/it] 70%|███████   | 95/135 [1:37:08<40:51, 61.29s/it] 71%|███████   | 96/135 [1:38:05<39:02, 60.07s/it] 72%|███████▏  | 97/135 [1:39:05<38:03, 60.09s/it] 73%|███████▎  | 98/135 [1:40:08<37:30, 60.83s/it] 73%|███████▎  | 99/135 [1:41:07<36:17, 60.50s/it] 74%|███████▍  | 100/135 [1:42:04<34:35, 59.29s/it] 75%|███████▍  | 101/135 [1:43:06<34:04, 60.13s/it] 76%|███████▌  | 102/135 [1:44:09<33:35, 61.07s/it] 76%|███████▋  | 103/135 [1:45:16<33:27, 62.72s/it] 77%|███████▋  | 104/135 [1:46:16<32:03, 62.04s/it] 78%|███████▊  | 105/135 [1:47:16<30:36, 61.23s/it] 79%|███████▊  | 106/135 [1:48:14<29:11, 60.38s/it] 79%|███████▉  | 107/135 [1:49:15<28:16, 60.59s/it] 80%|████████  | 108/135 [1:50:19<27:46, 61.72s/it] 81%|████████  | 109/135 [1:51:18<26:22, 60.86s/it] 81%|████████▏ | 110/135 [1:52:21<25:33, 61.34s/it] 82%|████████▏ | 111/135 [1:53:22<24:34, 61.45s/it] 83%|████████▎ | 112/135 [1:54:25<23:39, 61.74s/it] 84%|████████▎ | 113/135 [1:55:35<23:34, 64.31s/it] 84%|████████▍ | 114/135 [1:56:36<22:06, 63.15s/it] 85%|████████▌ | 115/135 [1:57:42<21:20, 64.00s/it] 86%|████████▌ | 116/135 [1:58:38<19:34, 61.84s/it] 87%|████████▋ | 117/135 [1:59:33<17:53, 59.64s/it] 87%|████████▋ | 118/135 [2:00:35<17:08, 60.50s/it] 88%|████████▊ | 119/135 [2:01:43<16:44, 62.75s/it] 89%|████████▉ | 120/135 [2:02:41<15:16, 61.10s/it] 90%|████████▉ | 121/135 [2:03:34<13:41, 58.64s/it] 90%|█████████ | 122/135 [2:04:29<12:29, 57.69s/it] 91%|█████████ | 123/135 [2:05:33<11:54, 59.58s/it] 92%|█████████▏| 124/135 [2:06:37<11:08, 60.80s/it] 93%|█████████▎| 125/135 [2:07:38<10:09, 60.98s/it] 93%|█████████▎| 126/135 [2:08:39<09:08, 60.91s/it] 94%|█████████▍| 127/135 [2:09:40<08:07, 60.93s/it] 95%|█████████▍| 128/135 [2:10:47<07:19, 62.72s/it] 96%|█████████▌| 129/135 [2:11:49<06:15, 62.66s/it] 96%|█████████▋| 130/135 [2:12:51<05:12, 62.53s/it] 97%|█████████▋| 131/135 [2:13:46<04:01, 60.28s/it] 98%|█████████▊| 132/135 [2:14:40<02:54, 58.17s/it] 99%|█████████▊| 133/135 [2:15:40<01:57, 58.81s/it] 99%|█████████▉| 134/135 [2:16:44<01:00, 60.34s/it]100%|██████████| 135/135 [2:17:09<00:00, 49.73s/it]100%|██████████| 135/135 [2:17:09<00:00, 60.96s/it]
11/19/2022 03:22:06 - INFO - __main__ -     bleu-4 = 89.77 
11/19/2022 03:22:06 - INFO - __main__ -     xMatch = 6.2064 
11/19/2022 03:22:06 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 6.21 , BLEU: 89.77
CodeBLEU: 87.37
ngram_match_score: 87.37 , weighted_ngram_match_score: 89.8 , syntax_match_score: 89.35 , dataflow_match_score: 80.55
---------------------------------------------------------------------------------------------
on medium dataset, after_refactoring, refactoring type is parameter_renaming:
11/19/2022 03:22:27 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/parameter_renaming/after_refactoring/medium', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/after_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/after_refactoring/medium/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/19/2022 03:22:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/19/2022 03:22:30 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin
11/19/2022 03:22:33 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/after_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/parameter_renaming/after_refactoring/medium/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/135 [00:00<?, ?it/s]  1%|          | 1/135 [01:03<2:21:30, 63.36s/it]  1%|▏         | 2/135 [02:07<2:20:55, 63.58s/it]  2%|▏         | 3/135 [03:16<2:25:53, 66.31s/it]  3%|▎         | 4/135 [04:14<2:17:52, 63.15s/it]  4%|▎         | 5/135 [05:24<2:21:43, 65.41s/it]  4%|▍         | 6/135 [06:27<2:18:45, 64.54s/it]  5%|▌         | 7/135 [07:35<2:20:03, 65.65s/it]  6%|▌         | 8/135 [08:42<2:20:17, 66.28s/it]  7%|▋         | 9/135 [09:48<2:18:45, 66.08s/it]  7%|▋         | 10/135 [10:56<2:18:51, 66.65s/it]  8%|▊         | 11/135 [12:00<2:16:20, 65.97s/it]  9%|▉         | 12/135 [12:58<2:10:17, 63.56s/it] 10%|▉         | 13/135 [14:06<2:11:54, 64.87s/it] 10%|█         | 14/135 [15:04<2:06:16, 62.62s/it] 11%|█         | 15/135 [16:08<2:06:18, 63.16s/it] 12%|█▏        | 16/135 [17:10<2:04:30, 62.77s/it] 13%|█▎        | 17/135 [18:24<2:10:17, 66.25s/it] 13%|█▎        | 18/135 [19:27<2:07:25, 65.34s/it] 14%|█▍        | 19/135 [20:33<2:06:09, 65.26s/it] 15%|█▍        | 20/135 [21:26<1:58:25, 61.78s/it] 16%|█▌        | 21/135 [22:23<1:54:48, 60.42s/it] 16%|█▋        | 22/135 [23:22<1:52:51, 59.92s/it] 17%|█▋        | 23/135 [24:22<1:51:45, 59.87s/it] 18%|█▊        | 24/135 [25:29<1:54:47, 62.05s/it] 19%|█▊        | 25/135 [26:31<1:53:25, 61.87s/it] 19%|█▉        | 26/135 [27:24<1:48:03, 59.49s/it] 20%|██        | 27/135 [28:23<1:46:47, 59.33s/it] 21%|██        | 28/135 [29:26<1:47:47, 60.45s/it] 21%|██▏       | 29/135 [30:29<1:48:03, 61.16s/it] 22%|██▏       | 30/135 [31:32<1:47:48, 61.60s/it] 23%|██▎       | 31/135 [32:35<1:47:45, 62.17s/it] 24%|██▎       | 32/135 [33:41<1:48:33, 63.24s/it] 24%|██▍       | 33/135 [34:47<1:48:49, 64.02s/it] 25%|██▌       | 34/135 [35:54<1:49:01, 64.76s/it] 26%|██▌       | 35/135 [36:55<1:46:10, 63.71s/it] 27%|██▋       | 36/135 [38:00<1:46:04, 64.28s/it] 27%|██▋       | 37/135 [38:58<1:41:47, 62.33s/it] 28%|██▊       | 38/135 [40:00<1:40:44, 62.31s/it] 29%|██▉       | 39/135 [41:03<1:39:44, 62.33s/it] 30%|██▉       | 40/135 [42:06<1:39:02, 62.55s/it] 30%|███       | 41/135 [43:15<1:40:59, 64.47s/it] 31%|███       | 42/135 [44:30<1:44:47, 67.61s/it] 32%|███▏      | 43/135 [45:23<1:37:04, 63.31s/it] 33%|███▎      | 44/135 [46:25<1:35:29, 62.96s/it] 33%|███▎      | 45/135 [47:35<1:37:31, 65.01s/it] 34%|███▍      | 46/135 [48:28<1:30:59, 61.34s/it] 35%|███▍      | 47/135 [49:32<1:31:27, 62.36s/it] 36%|███▌      | 48/135 [50:32<1:29:19, 61.60s/it] 36%|███▋      | 49/135 [51:32<1:27:34, 61.10s/it] 37%|███▋      | 50/135 [52:31<1:25:41, 60.49s/it] 38%|███▊      | 51/135 [53:31<1:24:21, 60.26s/it] 39%|███▊      | 52/135 [54:26<1:21:16, 58.75s/it] 39%|███▉      | 53/135 [55:30<1:22:32, 60.39s/it] 40%|████      | 54/135 [56:31<1:21:23, 60.28s/it] 41%|████      | 55/135 [57:33<1:21:22, 61.03s/it] 41%|████▏     | 56/135 [58:38<1:21:51, 62.18s/it] 42%|████▏     | 57/135 [59:40<1:20:40, 62.05s/it] 43%|████▎     | 58/135 [1:00:41<1:19:18, 61.79s/it] 44%|████▎     | 59/135 [1:01:45<1:19:03, 62.41s/it] 44%|████▍     | 60/135 [1:02:52<1:19:48, 63.84s/it] 45%|████▌     | 61/135 [1:03:53<1:17:30, 62.85s/it] 46%|████▌     | 62/135 [1:04:52<1:15:08, 61.75s/it] 47%|████▋     | 63/135 [1:06:00<1:16:26, 63.70s/it] 47%|████▋     | 64/135 [1:07:09<1:17:09, 65.20s/it] 48%|████▊     | 65/135 [1:08:17<1:17:08, 66.12s/it] 49%|████▉     | 66/135 [1:09:17<1:13:51, 64.23s/it] 50%|████▉     | 67/135 [1:10:23<1:13:18, 64.68s/it] 50%|█████     | 68/135 [1:11:22<1:10:30, 63.14s/it] 51%|█████     | 69/135 [1:12:28<1:10:30, 64.10s/it] 52%|█████▏    | 70/135 [1:13:24<1:06:37, 61.50s/it] 53%|█████▎    | 71/135 [1:14:23<1:04:51, 60.80s/it] 53%|█████▎    | 72/135 [1:15:26<1:04:33, 61.48s/it] 54%|█████▍    | 73/135 [1:16:28<1:03:38, 61.59s/it] 55%|█████▍    | 74/135 [1:17:36<1:04:29, 63.43s/it] 56%|█████▌    | 75/135 [1:18:36<1:02:30, 62.50s/it] 56%|█████▋    | 76/135 [1:19:41<1:02:11, 63.24s/it] 57%|█████▋    | 77/135 [1:20:44<1:00:57, 63.06s/it] 58%|█████▊    | 78/135 [1:21:42<58:37, 61.72s/it]   59%|█████▊    | 79/135 [1:22:48<58:51, 63.07s/it] 59%|█████▉    | 80/135 [1:23:57<59:21, 64.76s/it] 60%|██████    | 81/135 [1:25:03<58:32, 65.04s/it] 61%|██████    | 82/135 [1:26:12<58:24, 66.13s/it] 61%|██████▏   | 83/135 [1:27:18<57:17, 66.10s/it] 62%|██████▏   | 84/135 [1:28:25<56:27, 66.41s/it] 63%|██████▎   | 85/135 [1:29:28<54:37, 65.56s/it] 64%|██████▎   | 86/135 [1:30:34<53:29, 65.50s/it] 64%|██████▍   | 87/135 [1:31:29<49:58, 62.47s/it] 65%|██████▌   | 88/135 [1:32:25<47:27, 60.59s/it] 66%|██████▌   | 89/135 [1:33:27<46:48, 61.06s/it] 67%|██████▋   | 90/135 [1:34:25<44:57, 59.94s/it] 67%|██████▋   | 91/135 [1:35:28<44:47, 61.09s/it] 68%|██████▊   | 92/135 [1:36:29<43:33, 60.77s/it] 69%|██████▉   | 93/135 [1:37:31<42:57, 61.37s/it] 70%|██████▉   | 94/135 [1:38:30<41:20, 60.50s/it] 70%|███████   | 95/135 [1:39:40<42:12, 63.32s/it] 71%|███████   | 96/135 [1:40:43<41:07, 63.28s/it] 72%|███████▏  | 97/135 [1:41:46<39:59, 63.15s/it] 73%|███████▎  | 98/135 [1:42:52<39:33, 64.16s/it] 73%|███████▎  | 99/135 [1:43:54<38:00, 63.33s/it] 74%|███████▍  | 100/135 [1:44:51<35:54, 61.55s/it] 75%|███████▍  | 101/135 [1:45:55<35:20, 62.37s/it] 76%|███████▌  | 102/135 [1:47:00<34:40, 63.05s/it] 76%|███████▋  | 103/135 [1:48:07<34:15, 64.25s/it] 77%|███████▋  | 104/135 [1:49:06<32:22, 62.65s/it] 78%|███████▊  | 105/135 [1:50:12<31:49, 63.65s/it] 79%|███████▊  | 106/135 [1:51:15<30:41, 63.48s/it] 79%|███████▉  | 107/135 [1:52:17<29:23, 62.97s/it] 80%|████████  | 108/135 [1:53:23<28:48, 64.03s/it] 81%|████████  | 109/135 [1:54:27<27:46, 64.08s/it] 81%|████████▏ | 110/135 [1:55:32<26:45, 64.21s/it] 82%|████████▏ | 111/135 [1:56:35<25:29, 63.72s/it] 83%|████████▎ | 112/135 [1:57:38<24:23, 63.64s/it] 84%|████████▎ | 113/135 [1:58:45<23:41, 64.63s/it] 84%|████████▍ | 114/135 [1:59:45<22:11, 63.39s/it] 85%|████████▌ | 115/135 [2:00:54<21:37, 64.85s/it] 86%|████████▌ | 116/135 [2:01:58<20:26, 64.56s/it] 87%|████████▋ | 117/135 [2:02:58<19:02, 63.46s/it] 87%|████████▋ | 118/135 [2:04:10<18:38, 65.82s/it] 88%|████████▊ | 119/135 [2:05:19<17:51, 67.00s/it] 89%|████████▉ | 120/135 [2:06:19<16:10, 64.70s/it] 90%|████████▉ | 121/135 [2:07:13<14:21, 61.55s/it] 90%|█████████ | 122/135 [2:08:12<13:09, 60.70s/it] 91%|█████████ | 123/135 [2:09:19<12:32, 62.69s/it] 92%|█████████▏| 124/135 [2:10:26<11:42, 63.85s/it] 93%|█████████▎| 125/135 [2:11:28<10:35, 63.55s/it] 93%|█████████▎| 126/135 [2:12:31<09:28, 63.21s/it] 94%|█████████▍| 127/135 [2:13:36<08:29, 63.75s/it] 95%|█████████▍| 128/135 [2:14:45<07:37, 65.32s/it] 96%|█████████▌| 129/135 [2:15:51<06:32, 65.50s/it] 96%|█████████▋| 130/135 [2:16:56<05:27, 65.47s/it] 97%|█████████▋| 131/135 [2:17:55<04:13, 63.35s/it] 98%|█████████▊| 132/135 [2:18:54<03:06, 62.07s/it] 99%|█████████▊| 133/135 [2:19:57<02:05, 62.53s/it] 99%|█████████▉| 134/135 [2:21:04<01:03, 63.87s/it]100%|██████████| 135/135 [2:21:30<00:00, 52.42s/it]100%|██████████| 135/135 [2:21:30<00:00, 62.89s/it]
11/19/2022 05:44:14 - INFO - __main__ -     bleu-4 = 89.32 
11/19/2022 05:44:14 - INFO - __main__ -     xMatch = 4.8117 
11/19/2022 05:44:14 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 4.81 , BLEU: 89.32
CodeBLEU: 86.95
ngram_match_score: 86.95 , weighted_ngram_match_score: 89.35 , syntax_match_score: 89.11 , dataflow_match_score: 80.02
---------------------------------------------------------------------------------------------
on small dataset, before_refactoring, refactoring type is boolean_exchange:
11/19/2022 05:44:36 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/boolean_exchange/before_refactoring/small', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/before_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/before_refactoring/small/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/19/2022 05:44:36 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/19/2022 05:44:38 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin
11/19/2022 05:44:42 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/before_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/before_refactoring/small/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:26<00:00, 26.41s/it]100%|██████████| 1/1 [00:26<00:00, 26.42s/it]
11/19/2022 05:45:08 - INFO - __main__ -     bleu-4 = 84.63 
11/19/2022 05:45:08 - INFO - __main__ -     xMatch = 12.5 
11/19/2022 05:45:08 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 12.5 , BLEU: 84.63
CodeBLEU: 84.45
ngram_match_score: 84.45 , weighted_ngram_match_score: 84.87 , syntax_match_score: 86.94 , dataflow_match_score: 81.36
---------------------------------------------------------------------------------------------
on small dataset, after_refactoring, refactoring type is boolean_exchange:
11/19/2022 05:45:10 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/boolean_exchange/after_refactoring/small', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/after_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/after_refactoring/small/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/19/2022 05:45:10 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/19/2022 05:45:13 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/small/pytorch_model.bin
11/19/2022 05:45:16 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/after_refactoring/small/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/after_refactoring/small/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:27<00:00, 27.91s/it]100%|██████████| 1/1 [00:27<00:00, 27.91s/it]
11/19/2022 05:45:44 - INFO - __main__ -     bleu-4 = 77.15 
11/19/2022 05:45:44 - INFO - __main__ -     xMatch = 0.0 
11/19/2022 05:45:44 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 0.0 , BLEU: 77.15
CodeBLEU: 77.71
ngram_match_score: 77.71 , weighted_ngram_match_score: 77.56 , syntax_match_score: 81.9 , dataflow_match_score: 74.24
---------------------------------------------------------------------------------------------
on medium dataset, before_refactoring, refactoring type is boolean_exchange:
11/19/2022 05:45:46 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/boolean_exchange/before_refactoring/medium', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/before_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/before_refactoring/medium/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/19/2022 05:45:47 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/19/2022 05:45:49 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin
11/19/2022 05:45:52 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/before_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/before_refactoring/medium/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [01:01<04:05, 61.40s/it] 40%|████      | 2/5 [01:59<02:59, 59.71s/it] 60%|██████    | 3/5 [02:57<01:57, 58.66s/it] 80%|████████  | 4/5 [03:56<00:59, 59.05s/it]100%|██████████| 5/5 [04:29<00:00, 49.50s/it]100%|██████████| 5/5 [04:29<00:00, 53.91s/it]
11/19/2022 05:50:22 - INFO - __main__ -     bleu-4 = 91.55 
11/19/2022 05:50:22 - INFO - __main__ -     xMatch = 6.1644 
11/19/2022 05:50:22 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 6.16 , BLEU: 91.55
CodeBLEU: 88.39
ngram_match_score: 88.39 , weighted_ngram_match_score: 91.64 , syntax_match_score: 89.16 , dataflow_match_score: 81.2
---------------------------------------------------------------------------------------------
on medium dataset, after_refactoring, refactoring type is boolean_exchange:
11/19/2022 05:50:25 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=32, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=256, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/y_shi202/thesis-project/APR-Models-Performance/result/refactoring/graphcodebert/boolean_exchange/after_refactoring/medium', seed=42, test_filename='/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/after_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/after_refactoring/medium/test.buggy-fixed.fixed', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
11/19/2022 05:50:25 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/19/2022 05:50:28 - INFO - __main__ -   reload model from /home/y_shi202/thesis-project/APR-Models-Performance/models/original/graphcodebert/medium/pytorch_model.bin
11/19/2022 05:50:31 - INFO - __main__ -   Test file: /home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/after_refactoring/medium/test.buggy-fixed.buggy,/home/y_shi202/thesis-project/APR-Models-Performance/data/refactoring/boolean_exchange/after_refactoring/medium/test.buggy-fixed.fixed
====================================================================================================
Total parameters : 172503552
====================================================================================================
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [01:02<04:09, 62.43s/it] 40%|████      | 2/5 [02:02<03:02, 60.83s/it] 60%|██████    | 3/5 [03:03<02:01, 60.93s/it] 80%|████████  | 4/5 [04:04<01:01, 61.02s/it]100%|██████████| 5/5 [04:37<00:00, 50.84s/it]100%|██████████| 5/5 [04:37<00:00, 55.43s/it]
11/19/2022 05:55:09 - INFO - __main__ -     bleu-4 = 84.81 
11/19/2022 05:55:09 - INFO - __main__ -     xMatch = 3.4247 
11/19/2022 05:55:09 - INFO - __main__ -     ********************
/home/y_shi202/thesis-project/APR-Models-Performance
Accuracy: 3.42 , BLEU: 84.81
CodeBLEU: 79.39
ngram_match_score: 79.39 , weighted_ngram_match_score: 85.62 , syntax_match_score: 83.88 , dataflow_match_score: 63.26
---------------------------------------------------------------------------------------------
######## end ################
